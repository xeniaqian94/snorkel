{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run 2: Extract Meaningful Span\n",
    "\n",
    "This notebook continues from Test Run 1, but defines *Span* more meaningfully. We want to achieve that, 1 *Sentence* = 1+ *Spans* = 1+ *Clauses*. After the default `Ngram()` class, we customize Matcher to exclude any span with comma.\n",
    "\n",
    "Note that in this test run, we will initiate `SnorkelSession()` without re-create `Document` or `Sentence`, which has been created in test run 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 1000\n",
      "Sentences: 4487\n",
      "The longest sentence has 101 tokens.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "session = SnorkelSession()\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())\n",
    "\n",
    "sents = session.query(Sentence).all()\n",
    "n_max_corpus=0\n",
    "for sent in sents:\n",
    "    n_max_corpus=max(n_max_corpus,len(sent.words))\n",
    "\n",
    "print(\"The longest sentence has \"+str(n_max_corpus)+\" tokens.\")\n",
    "\n",
    "from snorkel.models import Document\n",
    "from util import number_of_people\n",
    "\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents   = set()\n",
    "test_sents  = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if i % 10 == 8:\n",
    "            dev_sents.add(s)\n",
    "        elif i % 10 == 9:\n",
    "            test_sents.add(s)\n",
    "        else:\n",
    "            train_sents.add(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In test run 1, we have tried using **single** `DictionaryMatcher`. Now it's time to explore more, e.g. combining **multiple** `DictionaryMatchers`. \n",
    "\n",
    "Fortunately, we could combine **multiple** `DictionaryMatchers` into what-we-named-as **compound** `Matchers` through:\n",
    "1. `Union(Matcher)` (takes the union of candidate sets returned by child matcher), \n",
    "2. `Intersection(Matcher)`, or \n",
    "3. `Concat(Matcher)` (candidates which are the concatenation of adjacent matches from child matchers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import *\n",
    "\n",
    "Background = candidate_subclass('Background', ['background_cue'])\n",
    "ngrams = Ngrams(n_max=n_max_corpus) # we define the maximum n value as n_max_corpus\n",
    "\n",
    "# Compound Matcher Example 1 (Dict-based): \n",
    "non_comma_matcher=DictionaryMatch(d=[','],longest_match_only=True,reverse=True)  \n",
    "dict_background_matcher=DictionaryMatch(d=['previous','motivated','recent','widely'],longest_match_only=True) \n",
    "non_comma_dict_background_matcher=CandidateExtractor(Background, [ngrams], [Intersection(non_comma_matcher,dict_background_matcher)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 7.92 s, sys: 208 ms, total: 8.13 s\n",
      "Wall time: 8.02 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Split 0 - number of candidates extracted: 106**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 1.13 s, sys: 86.5 ms, total: 1.21 s\n",
      "Wall time: 1.17 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Split 1 - number of candidates extracted: 11**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 1.14 s, sys: 89.6 ms, total: 1.23 s\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Split 2 - number of candidates extracted: 9**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    %time non_comma_dict_background_matcher.apply(sents, split=i)\n",
    "    printmd(\"**Split \"+str(i)+\" - number of candidates extracted: \"+str(session.query(Background).filter(Background.split == i).count())+\"**\\n\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**0/106 Candidate/Span:**\t`Span(\"b'simple threshold-based methods remain the most widely deployed and most popular approach among practitioners.'\", sentence=2300, chars=[98,206], words=[14,30])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tDespite the proliferation of detection and containment techniques in the worm defense literature, simple threshold-based methods remain the most widely deployed and most popular approach among practitioners."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115abf4a8>, 'name': '5834868425ff05a97b00ce09', 'stable_id': '5834868425ff05a97b00ce09::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 269, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00ce09,0,b'Abstract:'), Sentence(Document 5834868425ff05a97b00ce09,1,b'Despite the proliferation of detection and containment techniques in the worm defense literature, simple threshold-based methods remain the most widely deployed and most popular approach among practitioners.'), Sentence(Document 5834868425ff05a97b00ce09,2,b'This popularity arises out of the simplistic appeal, ease of use, and independence from attack-specific properties such as scanning strategies and signatures.'), Sentence(Document 5834868425ff05a97b00ce09,3,b'However, such approaches have known limitations: they either fail to detect low-rate attacks or incur very high false positive rates.'), Sentence(Document 5834868425ff05a97b00ce09,4,b'We propose a multi-\\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1/106 Candidate/Span:**\t`Span(\"b'Abstract Despite the recent trend of increasingly large datasets for object detection'\", sentence=4830, chars=[0,84], words=[0,11])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tAbstract Despite the recent trend of increasingly large datasets for object detection, there still exist many classes with few training examples."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115acbe80>, 'name': '5834868425ff05a97b00d0e7', 'stable_id': '5834868425ff05a97b00d0e7::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 845, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00d0e7,0,b'Abstract Despite the recent trend of increasingly large datasets for object detection, there still exist many classes with few training examples.'), Sentence(Document 5834868425ff05a97b00d0e7,1,b'To overcome this lack of training data for certain classes, we propose a novel way of augmenting the training data for each class by borrowing and transforming examples from other classes.'), Sentence(Document 5834868425ff05a97b00d0e7,2,b'Our model learns which training instances from other classes to borrow and how to transform the borrowed examples so that they become more similar to instances from the target class.'), Sentence(Document 5834868425ff05a97b00d0e7,3,b'Our experimental results \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**2/106 Candidate/Span:**\t`Span(\"b'In previous work'\", sentence=5091, chars=[0,15], words=[0,2])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tIn previous work, we developed a reliable navigation technique that uses partially observable Markov models to represent metric, actuator and sensor uncertainties."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115aec2b0>, 'name': '5834868425ff05a97b00d663', 'stable_id': '5834868425ff05a97b00d663::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 908, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00d663,0,b'Abstract: Navigation methods for office delivery robots need to take various sources of uncertainty into account in order to get robust performance.'), Sentence(Document 5834868425ff05a97b00d663,1,b'In previous work, we developed a reliable navigation technique that uses partially observable Markov models to represent metric, actuator and sensor uncertainties.'), Sentence(Document 5834868425ff05a97b00d663,2,b\"This paper describes an algorithm that adjusts the probabilities of the initial Markov model by passively observing the robot's interactions with its environment.\"), Sentence(Document 5834868425ff05a97b00d663,3,b'The learned probabilities more accurately reflect the actual uncertainties \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**3/106 Candidate/Span:**\t`Span(\"b'The robot design extends upon previous prototypes of HeartLander'\", sentence=4718, chars=[0,63], words=[0,8])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tThe robot design extends upon previous prototypes of HeartLander, a miniature mobile robot that moves in an inchworm-like fashion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x1122240b8>, 'name': '5834868425ff05a97b00c8cf', 'stable_id': '5834868425ff05a97b00c8cf::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 820, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00c8cf,0,b'Abstract\\xe2\\x80\\x94'), Sentence(Document 5834868425ff05a97b00c8cf,1,b'This paper describes the development and construction of a mobile robot driven by miniature ultrasonic piezoelectric motors for minimally invasive cardiac therapy.'), Sentence(Document 5834868425ff05a97b00c8cf,2,b'The robot design extends upon previous prototypes of HeartLander, a miniature mobile robot that moves in an inchworm-like fashion.'), Sentence(Document 5834868425ff05a97b00c8cf,3,b'Construction of the system included motor selection, body design, and development of the control system.'), Sentence(Document 5834868425ff05a97b00c8cf,4,b'The robotic design was developed as a proof of concept to demonstrate mobility on the cardiac surface.'), Sentence(Document 5834868425ff05a97b00c8cf,5,b'This paper presents the \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**4/106 Candidate/Span:**\t`Span(\"b'has motivated recent efforts in improving the quality of Internet video.'\", sentence=5341, chars=[115,186], words=[19,30])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tAbstract The key role that video quality plays in impacting user engagement, and consequently providers' revenues, has motivated recent efforts in improving the quality of Internet video."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115ab5fd0>, 'name': '5834868425ff05a97b00cdf8', 'stable_id': '5834868425ff05a97b00cdf8::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 966, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00cdf8,0,b\"Abstract The key role that video quality plays in impacting user engagement, and consequently providers' revenues, has motivated recent efforts in improving the quality of Internet video.\"), Sentence(Document 5834868425ff05a97b00cdf8,1,b'This includes work on adaptive bitrate selection, multi-CDN optimization, and global control plane architectures.'), Sentence(Document 5834868425ff05a97b00cdf8,2,b'Before we embark on deploying these designs, we need to first understand the nature of video of quality problems to see if this complexity is necessary, and if simpler approaches can yield comparable benefits.'), Sentence(Document 5834868425ff05a97b00cdf8,3,b'To this end, this \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**5/106 Candidate/Span:**\t`Span(\"b'It is based on a recently discovered connection between homotopy the-ory and type theory.'\", sentence=4352, chars=[0,88], words=[0,16])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tIt is based on a recently discovered connection between homotopy the-ory and type theory."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115a9e400>, 'name': '5834868425ff05a97b00cbc8', 'stable_id': '5834868425ff05a97b00cbc8::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 733, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00cbc8,0,b'Homotopy type theory is a new branch of mathematics that combines aspects of several different fields in a surprising way.'), Sentence(Document 5834868425ff05a97b00cbc8,1,b'It is based on a recently discovered connection between homotopy the-ory and type theory.'), Sentence(Document 5834868425ff05a97b00cbc8,2,b'Homotopy theory is an outgrowth of algebraic topology and homological algebra, with relationships to higher category theory; while type theory is a branch of mathematical logic and theoretical computer science.'), Sentence(Document 5834868425ff05a97b00cbc8,3,b'Although the connections between the two are currently the focus of intense investigation, it is increasingly clear that \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**6/106 Candidate/Span:**\t`Span(\"b'Abstract: The recent proliferation of richly structured probabilistic models raises the question of how to automatically determine an appropriate model for a dataset.'\", sentence=2713, chars=[0,165], words=[0,24])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tAbstract: The recent proliferation of richly structured probabilistic models raises the question of how to automatically determine an appropriate model for a dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115acbd30>, 'name': '5834868425ff05a97b00d0d6', 'stable_id': '5834868425ff05a97b00d0d6::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 362, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00d0d6,0,b'Abstract: The recent proliferation of richly structured probabilistic models raises the question of how to automatically determine an appropriate model for a dataset.'), Sentence(Document 5834868425ff05a97b00d0d6,1,b'We investigate this question for a space of matrix decomposition models which can express a variety of widely used models from unsupervised learning.'), Sentence(Document 5834868425ff05a97b00d0d6,2,b'To enable model selection, we organize these models into a context-free grammar which generates a wide variety of structures through the compositional application of a few simple rules.'), Sentence(Document 5834868425ff05a97b00d0d6,3,b'We use our grammar to generically and \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cands = session.query(Background).filter(Background.split == 0).all()\n",
    "document_list=list()\n",
    "for i in range(7): # to print all cands, range(len(cands))\n",
    "    printmd(\"**\"+str(i)+\"/\"+str(len(cands))+\" Candidate/Span:**\\t`\"+str(cands[i].background_cue)+\"`\")\n",
    "    printmd(\"**Its parent Sentence's text:**\\t\"+str(cands[i].get_parent().text))\n",
    "    printmd(\"**Its parent Document's text:**\\t\"+str(cands[i].get_parent().get_parent().__dict__))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we move to `RegexMatch`, to extract *Spans* that starts with \"to\"/\"for\"/\"by\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 9.37 s, sys: 254 ms, total: 9.63 s\n",
      "Wall time: 9.5 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Split 0 - number of candidates extracted: 2042**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 1.36 s, sys: 153 ms, total: 1.52 s\n",
      "Wall time: 1.41 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Split 1 - number of candidates extracted: 239**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 1.4 s, sys: 150 ms, total: 1.55 s\n",
      "Wall time: 1.44 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Split 2 - number of candidates extracted: 236**\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compound Matcher Example 2 (Regex-based):\n",
    "# E.g. to match either begining To/By/For or middle to/by/or, \n",
    "# we could use \"(^(?:(To)|(By)|(For)) .*$)|(^.+ (?:(to)|(by)|(for)) .*$)\"\n",
    "\n",
    "non_comma_matcher=DictionaryMatch(d=[','],longest_match_only=True,reverse=True)  \n",
    "regex_background_matcher=RegexMatchSpan(rgx=\"(^(?:(To)|(By)|(For)) .*$)|(^.+ (?:(to)|(by)|(for)) .+$)\",longest_match_only=True)  \n",
    "non_comma_regex_background_matcher=CandidateExtractor(Background, [ngrams], [Intersection(non_comma_matcher,regex_background_matcher)])\n",
    "\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    %time non_comma_regex_background_matcher.apply(sents, split=i)\n",
    "    printmd(\"**Split \"+str(i)+\" - number of candidates extracted: \"+str(session.query(Background).filter(Background.split == i).count())+\"**\\n\\n\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**0/2042 Candidate/Span:**\t`Span(\"b'This is particularly challenging in time critical domains where goal rewards decrease over time and for tightly coupled coordination where multiple robots must work together on each goal.'\", sentence=2782, chars=[0,186], words=[0,28])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tThis is particularly challenging in time critical domains where goal rewards decrease over time and for tightly coupled coordination where multiple robots must work together on each goal."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115af76a0>, 'name': '5834868425ff05a97b00d8ca', 'stable_id': '5834868425ff05a97b00d8ca::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 374, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00d8ca,0,b'Abstract Enabling multiple robots to work together as a team is a difficult problem.'), Sentence(Document 5834868425ff05a97b00d8ca,1,b'Robots must decide amongst themselves who should work on which goals and at what time each goal should be achieved.'), Sentence(Document 5834868425ff05a97b00d8ca,2,b'Since the team is situated in some physical environment, the robots must consider travel time in these decisions.'), Sentence(Document 5834868425ff05a97b00d8ca,3,b'This is particularly challenging in time critical domains where goal rewards decrease over time and for tightly coupled coordination where multiple robots must work together on each goal.'), Sentence(Document 5834868425ff05a97b00d8ca,4,b'Further complications arise when \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**1/2042 Candidate/Span:**\t`Span(\"b'repeatable testbeds for mobile software and systems.'\", sentence=3740, chars=[146,197], words=[25,32])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tThis RFC argues that mobile network tracing provides both tools to improve our understanding of wireless channels, as well as to build realistic, repeatable testbeds for mobile software and systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115a7d400>, 'name': '5834868425ff05a97b00ca70', 'stable_id': '5834868425ff05a97b00ca70::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 588, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00ca70,0,b'Abstract Mobile networks are both poorly understood and difficult to experiment with.'), Sentence(Document 5834868425ff05a97b00ca70,1,b'This RFC argues that mobile network tracing provides both tools to improve our understanding of wireless channels, as well as to build realistic, repeatable testbeds for mobile software and systems.'), Sentence(Document 5834868425ff05a97b00ca70,2,b'The RFC is a status report on our work tracing mobile networks.'), Sentence(Document 5834868425ff05a97b00ca70,3,b'Our goal is to begin discussion on a standard format for mobile network tracing as well as a testbed for mobile systems research.'), Sentence(Document 5834868425ff05a97b00ca70,4,b'We present our format for collecting mobile network traces, and \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**2/2042 Candidate/Span:**\t`Span(\"b'This RFC argues that mobile network tracing provides both tools to improve our understanding of wireless channels'\", sentence=3740, chars=[0,112], words=[0,16])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tThis RFC argues that mobile network tracing provides both tools to improve our understanding of wireless channels, as well as to build realistic, repeatable testbeds for mobile software and systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115a7d400>, 'name': '5834868425ff05a97b00ca70', 'stable_id': '5834868425ff05a97b00ca70::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 588, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00ca70,0,b'Abstract Mobile networks are both poorly understood and difficult to experiment with.'), Sentence(Document 5834868425ff05a97b00ca70,1,b'This RFC argues that mobile network tracing provides both tools to improve our understanding of wireless channels, as well as to build realistic, repeatable testbeds for mobile software and systems.'), Sentence(Document 5834868425ff05a97b00ca70,2,b'The RFC is a status report on our work tracing mobile networks.'), Sentence(Document 5834868425ff05a97b00ca70,3,b'Our goal is to begin discussion on a standard format for mobile network tracing as well as a testbed for mobile systems research.'), Sentence(Document 5834868425ff05a97b00ca70,4,b'We present our format for collecting mobile network traces, and \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**3/2042 Candidate/Span:**\t`Span(\"b'as well as to build realistic'\", sentence=3740, chars=[115,143], words=[18,23])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tThis RFC argues that mobile network tracing provides both tools to improve our understanding of wireless channels, as well as to build realistic, repeatable testbeds for mobile software and systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115a7d400>, 'name': '5834868425ff05a97b00ca70', 'stable_id': '5834868425ff05a97b00ca70::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 588, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00ca70,0,b'Abstract Mobile networks are both poorly understood and difficult to experiment with.'), Sentence(Document 5834868425ff05a97b00ca70,1,b'This RFC argues that mobile network tracing provides both tools to improve our understanding of wireless channels, as well as to build realistic, repeatable testbeds for mobile software and systems.'), Sentence(Document 5834868425ff05a97b00ca70,2,b'The RFC is a status report on our work tracing mobile networks.'), Sentence(Document 5834868425ff05a97b00ca70,3,b'Our goal is to begin discussion on a standard format for mobile network tracing as well as a testbed for mobile systems research.'), Sentence(Document 5834868425ff05a97b00ca70,4,b'We present our format for collecting mobile network traces, and \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**4/2042 Candidate/Span:**\t`Span(\"b'Lecture 5 on Dynamical Systems & Dynamic Axioms investigated dynamic axioms for dynamical systems'\", sentence=3453, chars=[0,96], words=[0,13])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tLecture 5 on Dynamical Systems & Dynamic Axioms investigated dynamic axioms for dynamical systems, ie axioms in differential dynamic logic (dL) that characterize operators of the dynamical systems that dL describes by hybrid programs in terms of structurally simpler dL formulas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115a0da58>, 'name': '5834868425ff05a97b00c280', 'stable_id': '5834868425ff05a97b00c280::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 523, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00c280,0,b'Lecture 5 on Dynamical Systems & Dynamic Axioms investigated dynamic axioms for dynamical systems, ie axioms in differential dynamic logic (dL) that characterize operators of the dynamical systems that dL describes by hybrid programs in terms of structurally simpler dL formulas.'), Sentence(Document 5834868425ff05a97b00c280,1,b'All it takes to understand the bigger system, thus, is to apply the axiom and investigate the smaller remainders.'), Sentence(Document 5834868425ff05a97b00c280,2,b'That lecture did not quite show all important axioms yet, but it still revealed enough to prove a property of a bouncing ball.'), Sentence(Document 5834868425ff05a97b00c280,3,b\"Yet, there's more to \\n\")]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**5/2042 Candidate/Span:**\t`Span(\"b'ie axioms in differential dynamic logic (dL) that characterize operators of the dynamical systems that dL describes by hybrid programs in terms of structurally simpler dL formulas.'\", sentence=3453, chars=[99,278], words=[15,44])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tLecture 5 on Dynamical Systems & Dynamic Axioms investigated dynamic axioms for dynamical systems, ie axioms in differential dynamic logic (dL) that characterize operators of the dynamical systems that dL describes by hybrid programs in terms of structurally simpler dL formulas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115a0da58>, 'name': '5834868425ff05a97b00c280', 'stable_id': '5834868425ff05a97b00c280::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 523, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00c280,0,b'Lecture 5 on Dynamical Systems & Dynamic Axioms investigated dynamic axioms for dynamical systems, ie axioms in differential dynamic logic (dL) that characterize operators of the dynamical systems that dL describes by hybrid programs in terms of structurally simpler dL formulas.'), Sentence(Document 5834868425ff05a97b00c280,1,b'All it takes to understand the bigger system, thus, is to apply the axiom and investigate the smaller remainders.'), Sentence(Document 5834868425ff05a97b00c280,2,b'That lecture did not quite show all important axioms yet, but it still revealed enough to prove a property of a bouncing ball.'), Sentence(Document 5834868425ff05a97b00c280,3,b\"Yet, there's more to \\n\")]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**6/2042 Candidate/Span:**\t`Span(\"b\"The work presented here captures progress on an initial empirical evaluation of how well the current VANE system is able to reproduce a real autonomy system's perception performance.\"\", sentence=1494, chars=[0,181], words=[0,29])`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Sentence's text:**\tThe work presented here captures progress on an initial empirical evaluation of how well the current VANE system is able to reproduce a real autonomy system's perception performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Its parent Document's text:**\t{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x115a2a908>, 'name': '5834868425ff05a97b00c345', 'stable_id': '5834868425ff05a97b00c345::document:0:0', 'meta': {'file_name': '70kpaper_061418_cleaned.tsv'}, 'id': 100, 'type': 'document', 'sentences': [Sentence(Document 5834868425ff05a97b00c345,0,b\"Abstract: The US Army Corps of Engineers'(USACE)\"), Sentence(Document 5834868425ff05a97b00c345,1,b'Virtual Autonomous Navigation Environment (VANE) is a physics-based, multi-scale numerical testbed designed to quantitatively and accurately predict sensor and autonomous system performance in a simulation environment.'), Sentence(Document 5834868425ff05a97b00c345,2,b\"The work presented here captures progress on an initial empirical evaluation of how well the current VANE system is able to reproduce a real autonomy system's perception performance.\"), Sentence(Document 5834868425ff05a97b00c345,3,b'Findings will directly guide continuing development of \\n')]}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cands = session.query(Background).filter(Background.split == 0).all()\n",
    "document_list=list()\n",
    "for i in range(7): # to print all cands, range(len(cands))\n",
    "    printmd(\"**\"+str(i)+\"/\"+str(len(cands))+\" Candidate/Span:**\\t`\"+str(cands[i].background_cue)+\"`\")\n",
    "    printmd(\"**Its parent Sentence's text:**\\t\"+str(cands[i].get_parent().text))\n",
    "    printmd(\"**Its parent Document's text:**\\t\"+str(cands[i].get_parent().get_parent().__dict__))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### Stopped here as of Mon 06/25 1:36 am. More to come ... ###\n",
    "\n",
    "## TODO List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for reading! \n",
    "\n",
    "Some debugging note to memorize (could ignore). \n",
    "\n",
    "```\n",
    "python -m spacy download en\n",
    "```\n",
    "\n",
    "Current issue: parser does not parse *by periods*. Sentence count is significantly fewer than expected! \n",
    "Potential fix: https://github.com/explosion/spaCy/issues/93\n",
    "\n",
    "======= Some more debugging log here (not necessary, could skip reading) ======\n",
    "~~~~\n",
    "Xins-MacBook-Pro:~ xin$ source activate snorkel\n",
    "(snorkel) Xins-MacBook-Pro:~ xin$ python\n",
    "Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33) \n",
    "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> import spacey\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "ModuleNotFoundError: No module named 'spacey'\n",
    ">>> import spacy\n",
    ">>> spacy.load('en')\n",
    "<spacy.en.English object at 0x1080e1da0>\n",
    ">>> model=spacy.load('en')\n",
    ">>> docs=model.tokenizer('Hello, world. Here are two sentences.')\n",
    ">>> for sent in docs.sents:\n",
    "...     pritn(sent.text)\n",
    "... \n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"spacy/tokens/doc.pyx\", line 439, in __get__ (spacy/tokens/doc.cpp:9808)\n",
    "ValueError: Sentence boundary detection requires the dependency parse, which requires data to be installed. For more info, see the documentation: \n",
    "https://spacy.io/docs/usage\n",
    "\n",
    ">>> for sent in docs.sents:\n",
    "...     print(sent.text)\n",
    "... \n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \"spacy/tokens/doc.pyx\", line 439, in __get__ (spacy/tokens/doc.cpp:9808)\n",
    "ValueError: Sentence boundary detection requires the dependency parse, which requires data to be installed. For more info, see the documentation: \n",
    "https://spacy.io/docs/usage\n",
    "\n",
    ">>> from spacy.en import English\n",
    ">>> nlp = English()\n",
    ">>> doc = nlp(raw_text)\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "NameError: name 'raw_text' is not defined\n",
    ">>> raw_text='Hello, world. Here are two sentences.'\n",
    ">>> doc = nlp(raw_text)\n",
    ">>> sentences = [sent.string.strip() for sent in doc.sents]\n",
    ">>> sentences\n",
    "['Hello, world.', 'Here are two sentences.']\n",
    ">>> model(raw_text)\n",
    "Hello, world. Here are two sentences.\n",
    ">>> docs=model(raw_text)\n",
    ">>> docs.sents\n",
    "<generator object at 0x14ad31948>\n",
    ">>> docs=model(raw_text)\n",
    ">>> sentences = [sent.string.strip() for sent in docs.sents]\n",
    ">>> sentences\n",
    "['Hello, world.', 'Here are two sentences.']\n",
    ">>> \n",
    "~~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
