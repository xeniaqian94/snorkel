{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2050it [00:00, 19181.85it/s]\n",
      "461it [00:00, 4608.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "len(word_counter) 26211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:09, 41080.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "word_counter = Counter()\n",
    "with open(os.path.expanduser(\"~/Desktop/snorkel/abstractnet/testrun/data/annotations_label-level_all-to-date-2018-4-25-WithTitle_full_abstract_punc_concatenated.csv\")) as f:\n",
    "    for i, l in enumerate(tqdm(f)):\n",
    "        line=l.split(\"\\t\")\n",
    "        word_counter.update(line[1].lower().split())\n",
    "#     print(word_counter)\n",
    "\n",
    "print(\"the\" in word_counter)\n",
    "print(\"len(word_counter)\",len(word_counter))\n",
    "glove_words={}\n",
    "with open(r\"/Users/xinq/Downloads/glove/glove.6B.300d.txt\",\"rb\") as f:\n",
    "    for l in tqdm(f):\n",
    "        line=l.decode().split()\n",
    "        word=line[0].lower()\n",
    "        if word in word_counter:\n",
    "            glove_words[word]=np.array(line[1:]).astype(np.float)\n",
    "print(len(glove_words))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# model = FastText.load_fasttext_format(os.path.expanduser('~/Downloads/crawl-300d-2M-subword/crawl-300d-2M-subword.bin'))\n",
    "\n",
    "# print(datetime.datetime.now())\n",
    "# print(model.most_similar('teacher'))\n",
    "# # Output = [('headteacher', 0.8075869083404541), ('schoolteacher', 0.7955552339553833), ('teachers', 0.733420729637146), ('teaches', 0.6839243173599243), ('meacher', 0.6825737357139587), ('teach', 0.6285147070884705), ('taught', 0.6244685649871826), ('teaching', 0.6199781894683838), ('schoolmaster', 0.6037642955780029), ('lessons', 0.5812176465988159)]\n",
    "\n",
    "# print(model.similarity('teacher', 'teaches'))\n",
    "# Output = 0.683924396754\n",
    "\n",
    "\n",
    "# import datetime\n",
    "# from pyfasttext import FastText\n",
    "\n",
    "# print(datetime.datetime.now())\n",
    "# model = FastText()\n",
    "# model.load_model(os.path.expanduser('~/Downloads/crawl-300d-2M-subword/crawl-300d-2M-subword.bin'))\n",
    "\n",
    "# model.similarity('dog', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(glove_words[\"we\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('develops', 'developed') 0.49661092540331286\n",
      "('propose', 'studied') 0.05757609106478856\n",
      "('method', 'methods') 0.8125367771569797\n",
      "('rapid', 'fast') 0.5067919725048657\n",
      "('propose', 'proposed') 0.7014895383086073\n",
      "('propose', 'introduce') 0.5480073989454151\n",
      "('method', 'approach') 0.5083667577658175\n",
      "('model', 'approach') 0.374941019397907\n",
      "('algorithm', 'model') 0.24167632349440082\n",
      "('models', 'model') 0.8394742702249793\n",
      "('models', 'modeling') 0.5491412682429521\n",
      "('modeling', 'model') 0.5327991434922285\n",
      "('dataset', 'corpus') 0.06971408535509105\n",
      "('growth', 'development') 0.5540347710817433\n",
      "('emerging', 'arising') 0.25509423502619777\n",
      "('emerging', 'emerged') 0.5859760870866682\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# 1. we will examine the similarity between developed and develop\n",
    "\n",
    "# 7. algorithm and theory\n",
    "# 5. datasets and benchmark \n",
    "# 6. dataset and corpus\n",
    "# 7. explosive and emerging\n",
    "# 8. emerging and arising\n",
    "# 9. growth and development\n",
    "\n",
    "for pair in [(\"develops\",\"developed\"),(\"propose\",\"studied\"),(\"method\",\"methods\"),(\"rapid\",\"fast\"),(\"propose\",\"proposed\"),(\"propose\",\"introduce\"),(\"method\",\"approach\"),(\"model\",\"approach\"),(\"algorithm\",\"model\"),(\"models\",\"model\"),(\"models\",\"modeling\"),(\"modeling\",\"model\"),(\"dataset\",\"corpus\"),(\"growth\",\"development\"),(\"emerging\",\"arising\"),(\"emerging\",\"emerged\")]:\n",
    "    if pair[0] in glove_words and pair[1] in glove_words:\n",
    "        print(pair,1-cosine(glove_words[pair[0]],glove_words[pair[1]]))\n",
    "    else:\n",
    "        print(\"at lease one not in glove_words\",pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: b'\\xba\\x16O/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-01871d251858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/Downloads/crawl-300d-2M-subword/crawl-300d-2M-subword.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-01871d251858>\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: b'\\xba\\x16O/'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'rb')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "\n",
    "model=load_vectors(os.path.expanduser('~/Downloads/crawl-300d-2M-subword/crawl-300d-2M-subword.bin'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(os.path.expanduser('~/Downloads/GoogleNews-vectors-negative300.bin'), binary=True)\n",
    "model.most_similar('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2050it [00:00, 15590.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['online', 'communities', 'have', 'the', 'potential', 'to', 'be', 'supportive', ',', 'cruel', ',', 'or', 'anywhere', 'in', 'between', '.', 'the', 'development', 'of', 'positive', 'norms', 'for', 'interaction', 'can', 'help', 'users', 'build', 'bonds', ',', 'grow', ',', 'and', 'learn', '.', 'using', 'millions', 'of', 'messages', 'sent', 'in', 'twitch', 'chatrooms', ',', 'we', 'explore', 'the', 'effectiveness', 'of', 'methods', 'for', 'encouraging', 'and', 'discouraging', 'specific', 'behaviors', ',', 'including', 'taking', 'advantage', 'of', 'imitation', 'effects', 'through', 'setting', 'positive', 'examples', 'and', 'using', 'moderation', 'tools', 'to', 'discourage', 'antisocial', 'behaviors', '.', 'consistent', 'with', 'aspects', 'of', 'imitation', 'theory', 'and', 'deterrence', 'theory', ',', 'users', 'imitated', 'examples', 'of', 'behavior', 'that', 'they', 'saw', ',', 'and', 'more', 'so', 'for', 'behaviors', 'from', 'high', 'status', 'users', '.', 'proactive', 'moderation', 'tools', ',', 'such', 'as', 'chat', 'modes', 'which', 'restricted', 'the', 'ability', 'to', 'post', 'certain', 'content', ',', 'proved', 'effective', 'at', 'discouraging', 'spam', 'behaviors', ',', 'while', 'reactive', 'bans', 'were', 'able', 'to', 'discourage', 'a', 'wider', 'variety', 'of', 'behaviors', '.', 'this', 'work', 'considers', 'the', 'intersection', 'of', 'tools', ',', 'authority', ',', 'and', 'types', 'of', 'behaviors', ',', 'offering', 'a', 'new', 'frame', 'through', 'which', 'to', 'consider', 'the', 'development', 'of', 'moderation', 'strategies', '.'], ['recent', 'research', 'has', 'demonstrated', 'that', '(', 'a', ')', 'groups', 'can', 'be', 'characterized', 'by', 'a', 'collective', 'intelligence', '(', 'ci', ')', 'factor', 'that', 'measures', 'their', 'ability', 'to', 'perform', 'together', 'on', 'a', 'wide', 'range', 'of', 'different', 'tasks', ',', 'and', '(', 'b', ')', 'this', 'factor', 'can', 'predict', 'groups', \"'\", 'performance', 'on', 'other', 'tasks', 'in', 'the', 'future', '.', 'the', 'current', 'study', 'examines', 'whether', 'these', 'results', 'translate', 'into', 'the', 'world', 'of', 'teams', 'in', 'competitive', 'online', 'video', 'games', 'where', 'self-organized', ',', 'time-pressured', ',', 'and', 'intense', 'collaboration', 'occurs', 'purely', 'online', '.', 'in', 'this', 'study', 'of', 'teams', 'playing', 'the', 'online', 'game', 'league', 'of', 'legends', ',', 'we', 'find', 'that', 'ci', 'does', ',', 'indeed', ',', 'predict', 'the', 'competitive', 'performance', 'of', 'teams', 'controlling', 'for', 'the', 'amount', 'of', 'time', 'played', 'as', 'a', 'team', '.', 'we', 'also', 'find', 'that', 'ci', 'is', 'positively', 'correlated', 'with', 'the', 'presence', 'of', 'a', 'female', 'team', 'member', 'and', 'with', 'the', 'team', 'members', \"'\", 'average', 'social', 'perceptiveness', '.', 'finally', ',', 'unlike', 'in', 'prior', 'studies', ',', 'tacit', 'coordination', 'in', 'this', 'setting', 'plays', 'a', 'larger', 'role', 'than', 'verbal', 'communication', '.'], ['forming', 'work', 'teams', 'involves', 'matching', 'people', 'with', 'complementary', 'skills', 'and', 'personalities', ',', 'but', 'requires', 'obtaining', 'such', 'data', 'a', 'priori', '.', 'we', 'introduce', 'team', 'dating', ',', 'where', 'people', 'interact', 'on', 'brief', 'tasks', 'before', 'working', 'with', 'a', 'dedicated', 'partner', 'for', 'longer', ',', 'more', 'complex', 'tasks', '.', 'we', 'studied', 'team', 'dating', 'through', 'two', 'online', 'experiments', '.', 'in', 'experiment', '1', ',', 'workers', 'from', 'a', 'crowd', 'platform', 'independently', 'wrote', 'an', 'ad', 'slogan', ',', 'discussed', 'it', 'with', 'three', 'consecutive', 'people', 'and', 'evaluated', 'their', 'team', 'date', 'interactions', '.', 'they', 'then', 'selected', 'preferred', 'teammates', 'from', 'a', 'list', 'showing', 'average', 'ratings', 'for', 'people', 'they', 'had', 'dated', 'and', 'not', 'dated', '.', 'results', 'show', 'that', 'participants', 'evaluated', 'their', 'dates', 'based', 'on', 'evidence', 'beyond', 'externally', 'judged', 'slogan', 'quality', ',', 'and', 'relied', 'heavily', 'on', 'their', 'dyad-specific', 'judgments', 'in', 'selecting', 'teammates', '.', 'in', 'experiment', '2', ',', 'we', 'replicated', 'the', 'individual', 'and', 'team', 'dating', 'tasks', ',', 'and', 'formed', 'teams', ',', 'either', 'i', ')', 'by', 'honoring', 'pairwise', 'team', 'dating', 'preferences', ',', 'ii', ')', 'randomly', 'from', 'their', 'pool', 'of', 'dates', ',', 'or', 'iii', ')', 'randomly', 'from', 'those', 'not', 'dated', '.', 'results', 'show', 'that', 'teams', 'formed', 'from', 'preferred', 'dates', 'performed', 'better', 'on', 'a', 'final', 'creative', 'task', 'compared', 'to', 'random', 'dates', 'or', 'non-dates', '.', 'team', 'dating', 'provides', 'a', 'dynamic', 'technique', 'for', 'forming', 'ad', 'hoc', 'teams', 'accounting', 'for', 'interpersonal', 'dynamics', '.', 'the', 'initial', 'interactions', 'provided', 'information', 'that', 'helped', 'people', 'select', 'and', 'work', 'with', 'an', 'appropriate', 'teammate', '.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'total_examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0b418fa1522d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/deprecated/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss)\u001b[0m\n\u001b[1;32m    611\u001b[0m             self.train(\n\u001b[1;32m    612\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m                 \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m             )\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'total_examples'"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText\n",
    "\n",
    "from gensim.models.wrappers import FastText\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "texts=[]\n",
    "with open(os.path.expanduser(\"~/Desktop/snorkel/abstractnet/testrun/data/annotations_label-level_all-to-date-2018-4-25-WithTitle_full_abstract_punc_concatenated.csv\")) as f:\n",
    "    for i, l in enumerate(tqdm(f)):\n",
    "        line=l.split(\"\\t\")\n",
    "        texts+=[line[1].lower().replace(\",\",\" ,\").replace(\".\", \" .\").replace(\":\",\" :\").strip().split()]\n",
    "\n",
    "print(texts[:3])\n",
    "model = FastText(sentences=texts[:10], size=100, window=5, min_count=1, iter=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspired from https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb\n",
    "\n",
    "Data processing cmd \n",
    "`sed 's/[[:punct:]]*//g'  annotations_label-level_all-to-date-2018-4-25-WithTitle_full_abstract_punc_concatenated_for_fasttext.csv | sed -e 'y/ABCDEFGHIJKLMNOPQRSTUVWXYZ/abcdefghijklmnopqrstuvwxyz/' > annotations_label-level_all-to-date-2018-4-25-WithTitle_full_abstract_no_punc_all_lowercase.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "FastText(vocab=5943, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "\n",
    "# Set file names for train and test data\n",
    "data_dir = os.path.expanduser(\"~/Desktop/snorkel/abstractnet/testrun/data/annotations_label-level_all-to-date-2018-4-25-WithTitle_full_abstract_no_punc_all_lowercase.csv\")\n",
    "# data_dir = os.path.expanduser(\"~/Desktop/snorkel/abstractnet/testrun/data/slim-s2-corpus-00-no_punc_all_lowercase\")\n",
    "train_file = data_dir\n",
    "lee_data = LineSentence(train_file)\n",
    "model_gensim = FT_gensim(size=100)\n",
    "     \n",
    "# # build the vocabulary\n",
    "print(model_gensim.iter)\n",
    "model_gensim.build_vocab(lee_data)        \n",
    "model_gensim.train(lee_data, total_examples=model_gensim.corpus_count, epochs=10,sg=0)\n",
    "\n",
    "print(model_gensim)\n",
    "\n",
    "# # saving a model trained via Gensim's fastText implementation\n",
    "# model_gensim.save('saved_model_gensim')\n",
    "# loaded_model = FT_gensim.load('saved_model_gensim')\n",
    "# print(loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fasttext embedding\n",
      "('develops', 'developed') 0.92244047\n",
      "('propose', 'studied') 0.3148588\n",
      "('method', 'methods') 0.93224454\n",
      "('rapid', 'fast') 0.22997245\n",
      "('slow', 'fast') 0.35160828\n",
      "('processing', 'progress') 0.53527766\n",
      "('variance', 'progress') 0.42412412\n",
      "('is', 'progress') 0.26761043\n",
      "('processing', 'big') 0.4266252\n",
      "('processing', 'data') 0.09639058\n",
      "('propose', 'proposed') 0.84788966\n",
      "('propose', 'introduce') 0.8839904\n",
      "('method', 'approach') 0.955304\n",
      "('model', 'approach') 0.7533798\n",
      "('algorithm', 'model') 0.742679\n",
      "('models', 'model') 0.8832899\n",
      "('models', 'modeling') 0.734455\n",
      "('modeling', 'model') 0.73662484\n",
      "('dataset', 'corpus') 0.5104697\n",
      "('growth', 'development') 0.14482492\n",
      "('emerging', 'arising') 0.94459754\n",
      "('emerging', 'emerged') 0.55221665\n",
      "Words that are most similar to propose:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('develops', 0.988737940788269),\n",
       " ('envelope', 0.9361028671264648),\n",
       " ('present', 0.9157117605209351),\n",
       " ('describe', 0.9155176877975464),\n",
       " ('prescribe', 0.9084881544113159),\n",
       " ('developed', 0.9062520265579224),\n",
       " ('propose', 0.9010077714920044),\n",
       " ('proposal', 0.9000095725059509),\n",
       " ('development', 0.8932777643203735),\n",
       " ('desktop', 0.8921788334846497),\n",
       " ('descent', 0.8897629976272583),\n",
       " ('introduce', 0.8877784013748169),\n",
       " ('developmental', 0.8832550048828125),\n",
       " ('impose', 0.8828449845314026),\n",
       " ('prim', 0.8812589645385742),\n",
       " ('premise', 0.8750422596931458),\n",
       " ('preserve', 0.8738477230072021),\n",
       " ('proposing', 0.8711374998092651),\n",
       " ('decompose', 0.870032787322998),\n",
       " ('introduced', 0.8697421550750732),\n",
       " ('descriptive', 0.8577750325202942),\n",
       " ('developing', 0.8571362495422363),\n",
       " ('proposals', 0.8561248779296875),\n",
       " ('prefix', 0.8553857803344727),\n",
       " ('produce', 0.8551808595657349),\n",
       " ('proportional', 0.8512907028198242),\n",
       " ('purpose', 0.8492997884750366),\n",
       " ('described', 0.8481528162956238),\n",
       " ('prescribed', 0.8471862077713013),\n",
       " ('priori', 0.843252956867218)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"proposed\" in model_gensim.wv.vocab)\n",
    "# print(\"propose\" in model_gensim.wv.vocab)\n",
    "\n",
    "print(\"Testing fasttext embedding\")\n",
    "for pair in [(\"develops\",\"developed\"),(\"propose\",\"studied\"),(\"method\",\"methods\"),(\"rapid\",\"fast\"),(\"slow\",\"fast\"),(\"processing\",\"progress\"),(\"variance\",\"progress\"),(\"is\",\"progress\"),(\"processing\",\"big\"),(\"processing\",\"data\"),(\"propose\",\"proposed\"),(\"propose\",\"introduce\"),(\"method\",\"approach\"),(\"model\",\"approach\"),(\"algorithm\",\"model\"),(\"models\",\"model\"),(\"models\",\"modeling\"),(\"modeling\",\"model\"),(\"dataset\",\"corpus\"),(\"growth\",\"development\"),(\"emerging\",\"arising\"),(\"emerging\",\"emerged\")]:\n",
    "    if pair[0] in model_gensim.wv.vocab and pair[1] in model_gensim.wv.vocab:\n",
    "        print(pair,model_gensim.similarity(pair[0],pair[1]))\n",
    "    else:\n",
    "        print(\"at lease one not in fasttext embedding\",pair)\n",
    "\n",
    "print(\"Words that are most similar to propose:\" )\n",
    "model_gensim.most_similar(\"develop\",topn=30)\n",
    "# print(help(model_gensim.most_similar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
