Online communities have the potential to be supportive	background	2K_dev_0
cruel	background	2K_dev_0
or anywhere in between The development of positive norms for interaction can help users build bonds	background	2K_dev_0
grow	background	2K_dev_0
and learn	background	2K_dev_0
Consistent with aspects of imitation theory and deterrence theory	background	2K_dev_0
This work considers the intersection of tools	background	2K_dev_0
authority	background	2K_dev_0
and types of behaviors	background	2K_dev_0
offering a new frame through which to consider the development of moderation strategies	background	2K_dev_0
users imitated examples of behavior that they saw	finding	2K_dev_0
and more so for behaviors from high status users	finding	2K_dev_0
Proactive moderation tools	finding	2K_dev_0
such as chat modes which restricted the ability to post certain content	finding	2K_dev_0
proved effective at discouraging spam behaviors	finding	2K_dev_0
while reactive bans were able to discourage a wider variety of behaviors	finding	2K_dev_0
	finding	2K_dev_0
	mechanism	2K_dev_0
Using millions of messages sent in Twitch chatrooms	method	2K_dev_0
	method	2K_dev_0
we explore the effectiveness of methods for encouraging and discouraging specific behaviors	purpose	2K_dev_0
including taking advantage of imitation effects through setting positive examples and using moderation tools to discourage antisocial behaviors	purpose	2K_dev_0
Recent research has demonstrated that ( a ) groups can be characterized by a collective intelligence ( CI ) factor that measures their ability to perform together on a wide range of different tasks	background	2K_dev_1
and ( b ) this factor can predict groups ' performance on other tasks in the future	background	2K_dev_1
	background	2K_dev_1
we find that CI does	finding	2K_dev_1
indeed	finding	2K_dev_1
predict the competitive performance of teams controlling for the amount of time played as a team	finding	2K_dev_1
We also find that CI is positively correlated with the presence of a female team member and with the team members ' average social perceptiveness	finding	2K_dev_1
Finally	finding	2K_dev_1
unlike in prior studies	finding	2K_dev_1
tacit coordination in this setting plays a larger role than verbal communication	finding	2K_dev_1
	finding	2K_dev_1
	mechanism	2K_dev_1
In this study of teams playing the online game League of Legends	method	2K_dev_1
	method	2K_dev_1
The current study examines whether these results translate into the world of teams in competitive online video games where self-organized	purpose	2K_dev_1
time-pressured	purpose	2K_dev_1
and intense collaboration occurs purely online	purpose	2K_dev_1
	purpose	2K_dev_1
	background	2K_dev_2
Results show that participants evaluated their dates based on evidence beyond externally judged slogan quality	finding	2K_dev_2
and relied heavily on their dyad-specific judgments in selecting teammates Results show that teams formed from preferred dates performed better on a final creative task compared to random dates or non-dates	finding	2K_dev_2
We introduce team dating	mechanism	2K_dev_2
where people interact on brief tasks before working with a dedicated partner for longer	mechanism	2K_dev_2
more complex tasks Team dating provides a dynamic technique The initial interactions provided information that helped people select and work with an appropriate teammate	mechanism	2K_dev_2
	mechanism	2K_dev_2
We studied team dating through two online experiments In Experiment 1	method	2K_dev_2
workers from a crowd platform independently wrote an ad slogan	method	2K_dev_2
discussed it with three consecutive people and evaluated their team date interactions	method	2K_dev_2
They then selected preferred teammates from a list showing average ratings for people they had dated and not dated In Experiment 2	method	2K_dev_2
we replicated the individual and team dating tasks	method	2K_dev_2
and formed teams	method	2K_dev_2
either i ) by honoring pairwise team dating preferences	method	2K_dev_2
ii ) randomly from their pool of dates	method	2K_dev_2
or iii ) randomly from those not dated	method	2K_dev_2
Forming work teams involves matching people with complementary skills and personalities	purpose	2K_dev_2
but requires obtaining such data a priori	purpose	2K_dev_2
for forming ad hoc teams accounting for interpersonal dynamics	purpose	2K_dev_2
Collective intelligence ( CI )	background	2K_dev_3
a group 's capacity to perform a wide variety of tasks	background	2K_dev_3
is a key factor in successful collaboration	background	2K_dev_3
Our results have important implications for online collaborations and distributed teams	background	2K_dev_3
	background	2K_dev_3
We find that synchrony in facial expressions ( indicative of shared experience ) was associated with CI and synchrony in skin conductance ( indicative of shared arousal ) with group satisfaction	finding	2K_dev_3
Furthermore	finding	2K_dev_3
various forms of synchrony mediated the effect of member diversity and social perceptiveness on CI and group satisfaction	finding	2K_dev_3
	finding	2K_dev_3
	mechanism	2K_dev_3
We present results from a laboratory experiment where 60 dyads completed the Test of Collective Intelligence ( TCI ) together online and rated their group satisfaction	method	2K_dev_3
while wearing physiological sensors	method	2K_dev_3
	method	2K_dev_3
Group composition	purpose	2K_dev_3
particularly diversity and member social perceptiveness	purpose	2K_dev_3
are consistent predictors of CI	purpose	2K_dev_3
but we have limited knowledge about the mechanisms underlying their effects	purpose	2K_dev_3
To address this gap	purpose	2K_dev_3
we examine how physiological synchrony	purpose	2K_dev_3
as an indicator of coordination and rapport	purpose	2K_dev_3
relates to CI in computer-mediated teams	purpose	2K_dev_3
and if synchrony might serve as a mechanism explaining the effect of group composition on CI	purpose	2K_dev_3
	purpose	2K_dev_3
Feedback is information that can improve task performance	background	2K_dev_4
Online communities	background	2K_dev_4
educational forums	background	2K_dev_4
and crowd-based feedback platforms all support feedback exchange among a more diverse set of sources than ever before	background	2K_dev_4
with greater control over how to moderate this exchange Our findings provide design implications for platforms to support more fruitful feedback exchange	background	2K_dev_4
	background	2K_dev_4
We found that critiques with positive affec-tive language increased positive emotions and reduced participants ' annoyance and frustration	finding	2K_dev_4
which led to an increase in work quality	finding	2K_dev_4
compared to critiques without positive language	finding	2K_dev_4
Feedback without positive affective language led to more edits	finding	2K_dev_4
but not better work outcomes	finding	2K_dev_4
Participants reacted more positively to feedback from an anonymous source than from a peer or an authority	finding	2K_dev_4
	finding	2K_dev_4
	mechanism	2K_dev_4
We conducted an online experiment manipulating affective language and source of feedback on a writing task	method	2K_dev_4
	method	2K_dev_4
In this work	purpose	2K_dev_4
we study how the power relationship between the source and receiver and the tone of language influence the recep-tivity	purpose	2K_dev_4
effort	purpose	2K_dev_4
and work performance resulting from online feedback exchange	purpose	2K_dev_4
	purpose	2K_dev_4
How do individuals perceive algorithmic vs	background	2K_dev_5
group-made decisions ?	background	2K_dev_5
about one third of the participants perceived algorithmic decisions as less than fair ( 30 % for self	finding	2K_dev_5
36 % for group )	finding	2K_dev_5
often because algorithmic assumptions about users did not account for multiple concepts of fairness or social behaviors	finding	2K_dev_5
and the process of quantifying preferences through interfaces was prone to error	finding	2K_dev_5
algorithmic decisions were perceived to be less fair than discussion-based decisions	finding	2K_dev_5
dependent on participants ' interpersonal power and computer programming knowledge	finding	2K_dev_5
Our work suggests that for algorithmic mediation to be fair	finding	2K_dev_5
algorithms and their interfaces should account for social and altruistic behaviors that may be difficult to define in mathematical terms	finding	2K_dev_5
	finding	2K_dev_5
	mechanism	2K_dev_5
In our first qualitative study	method	2K_dev_5
In our second experiment	method	2K_dev_5
	method	2K_dev_5
We investigated people 's perceptions of mathematically-proven fair division algorithms making social division decisions	purpose	2K_dev_5
	purpose	2K_dev_5
Social identities carry widely agreed upon meanings	background	2K_dev_6
called stereotypes	background	2K_dev_6
that have important effects on social processes	background	2K_dev_6
	background	2K_dev_6
Our work provides unique insights into the stereotypes of these users	finding	2K_dev_6
as well as providing a way of quantifying stereotypes that blends existing sociological and psychological theory in a novel	finding	2K_dev_6
parsimonious way	finding	2K_dev_6
	finding	2K_dev_6
Our method is grounded in two distinct strands of theory	mechanism	2K_dev_6
one that represents stereotypes as identities ' affective meanings and the other that represents stereotypes as semantic relationships between identities	mechanism	2K_dev_6
	mechanism	2K_dev_6
After validating our approach via a prediction task	method	2K_dev_6
we apply the model to a dataset of 45 thousand Twitter users who actively tweeted about the Michael Brown and Eric Garner tragedies	method	2K_dev_6
	method	2K_dev_6
In the present work	purpose	2K_dev_6
we develop a method to extract the stereotypes of Twitter users	purpose	2K_dev_6
	purpose	2K_dev_6
A key issue	background	2K_dev_7
whenever people work together to solve a complex problem	background	2K_dev_7
is	background	2K_dev_7
The early results suggest that the method can	finding	2K_dev_7
indeed	finding	2K_dev_7
work at scale as intended	finding	2K_dev_7
	finding	2K_dev_7
with groups of contests called contest webs Based on the analogy of supply chains for physical products	mechanism	2K_dev_7
the method provides incentives for people to ( a ) reuse work done by themselves and others	mechanism	2K_dev_7
( b ) simultaneously explore multiple ways of combining interchangeable parts	mechanism	2K_dev_7
and ( c ) work on parts of the problem where they can contribute the most	mechanism	2K_dev_7
	mechanism	2K_dev_7
The paper also describes a field test of this method in an online community of over 50	method	2K_dev_7
000 people who are developing proposals for what to do about global climate change	method	2K_dev_7
how to divide the problem into parts done by different people and combine the parts into a solution for the whole problem	purpose	2K_dev_7
This paper presents a novel way of doing this	purpose	2K_dev_7
Crowd workers are distributed and decentralized	background	2K_dev_8
Crowd guilds produced reputation signals more strongly correlated with ground-truth worker quality than signals available on current crowd working platforms	finding	2K_dev_8
and more accurate than in the traditional model	finding	2K_dev_8
	finding	2K_dev_8
In this paper	mechanism	2K_dev_8
we draw inspiration from historical worker guilds ( e	mechanism	2K_dev_8
g	mechanism	2K_dev_8
	mechanism	2K_dev_8
in the silk trade ) to design and implement crowd guilds: centralized groups of crowd workers who collectively certify each other 's quality through double-blind peer assessment	mechanism	2K_dev_8
	method	2K_dev_8
A two-week field experiment compared crowd guilds to a traditional decentralized crowd work model	method	2K_dev_8
	method	2K_dev_8
While decentralization is designed to utilize independent judgment to promote high-quality results	purpose	2K_dev_8
it paradoxically undercuts behaviors and institutions that are critical to high-quality work Reputation is one central example: crowdsourcing systems depend on reputation scores from decentralized workers and requesters	purpose	2K_dev_8
but these scores are notoriously inflated and uninformative	purpose	2K_dev_8
	purpose	2K_dev_8
Social science researchers spend significant time annotating behavioral events in video data in order to quantitatively assess interactions [ 2 ]	background	2K_dev_9
These behavioral events may be instantaneous changes	background	2K_dev_9
continuous actions that span unbounded periods of time	background	2K_dev_9
or behaviors that would be best described by severity or other scalar ratings	background	2K_dev_9
	background	2K_dev_9
These new features allow analysts to acquire more specific information about events in video datasets	finding	2K_dev_9
	finding	2K_dev_9
Glance [ 4 ] introduced a means of leveraging human intelligence by recruiting crowds of paid online workers to accurately analyze hours of video data in a matter of minutes	mechanism	2K_dev_9
This approach has been shown to expedite work in human-centered fields	mechanism	2K_dev_9
as well as generate training data for automated recognition systems	mechanism	2K_dev_9
In this paper	mechanism	2K_dev_9
we describe an interactive demonstration of an improved	mechanism	2K_dev_9
more expressive version of Glance that expands the initial set of supported annotation formats ( e	mechanism	2K_dev_9
g	mechanism	2K_dev_9
time range	mechanism	2K_dev_9
classification	mechanism	2K_dev_9
etc	mechanism	2K_dev_9
) from one to nine	mechanism	2K_dev_9
Worker interfaces for each of these options are dynamically generated	mechanism	2K_dev_9
along with tutorials	mechanism	2K_dev_9
based on the analyst 's question	mechanism	2K_dev_9
	mechanism	2K_dev_9
	method	2K_dev_9
The complexity of these judgments	purpose	2K_dev_9
coupled with the time and effort required to meticulously assess video	purpose	2K_dev_9
results in a training and evaluation process that can take days or weeks	purpose	2K_dev_9
Computational analysis of video data is still limited due to the challenges introduced by objective interpretation and varied contexts	purpose	2K_dev_9
	purpose	2K_dev_9
How effective are call and SMS logs in modeling tie strength ? Frequency and duration of communication has long been cited as a major aspect of tie strength	background	2K_dev_10
Intuitively	background	2K_dev_10
this makes sense: people communicate with those that they feel close to	background	2K_dev_10
	background	2K_dev_10
Consistent with theory	finding	2K_dev_10
we found that frequent or long-duration communication likely indicates a strong tie	finding	2K_dev_10
However	finding	2K_dev_10
the use of call and SMS logs produced many errors in separating strong and weak ties	finding	2K_dev_10
suggesting this approach is incomplete	finding	2K_dev_10
Follow-up interviews indicate fundamental challenges for inferring tie strength from communication logs	finding	2K_dev_10
	finding	2K_dev_10
	mechanism	2K_dev_10
We collected call and SMS logs and ground truth relationship data from 36 participants	method	2K_dev_10
	method	2K_dev_10
Highly cited research papers have pushed this idea further	purpose	2K_dev_10
using communication as a direct proxy for tie strength	purpose	2K_dev_10
However	purpose	2K_dev_10
this operationalization has not been validated	purpose	2K_dev_10
Our work evaluates this assumption	purpose	2K_dev_10
	purpose	2K_dev_10
Social influence is key in technology adoption	background	2K_dev_11
	background	2K_dev_11
Our results suggest that social influence affects one 's likelihood to adopt a security feature	finding	2K_dev_11
but its effect varies based on the observability of the feature	finding	2K_dev_11
the current feature adoption rate among a potential adopter 's friends	finding	2K_dev_11
and the number of distinct social circles from which those feature-adopting friends originate Curiously	finding	2K_dev_11
there may be a threshold higher than which having more security feature adopting friends predicts for higher adoption likelihood	finding	2K_dev_11
but below which having more feature-adopting friends predicts for lower adoption likelihood	finding	2K_dev_11
Furthermore	finding	2K_dev_11
the magnitude of this threshold is modulated by the attributes of a feature-features that are more noticeable ( Login Approvals	finding	2K_dev_11
Trusted Contacts ) have lower thresholds	finding	2K_dev_11
	finding	2K_dev_11
	mechanism	2K_dev_11
Here	method	2K_dev_11
we analyzed how three Facebook security features ' Login Approvals	method	2K_dev_11
Login Notifications	method	2K_dev_11
and Trusted Contacts-diffused through the social networks of 1	method	2K_dev_11
5 million people	method	2K_dev_11
	method	2K_dev_11
but its role in security-feature adoption is unique and remains unclear	purpose	2K_dev_11
	purpose	2K_dev_11
Feedback is an important component of the design process	background	2K_dev_12
but We conclude with implications for the design of crowd feedback services	background	2K_dev_12
	background	2K_dev_12
In the first study	finding	2K_dev_12
we compared crowd and expert critiques and found evidence that aggregated crowd critique approaches expert critique In a second study	finding	2K_dev_12
we found that designers who got crowd feedback perceived that it improved their design process The third study showed that designers were enthusiastic about crowd critiques and used them to change their designs	finding	2K_dev_12
We present CrowdCrit	mechanism	2K_dev_12
a web-based system that allows designers to receive design critiques from non-expert crowd workers	mechanism	2K_dev_12
We evaluated CrowdCrit in three studies focusing on the designer 's experience and benefits of the critiques	method	2K_dev_12
	method	2K_dev_12
gaining access to high-quality critique outside a classroom or firm is challenging	purpose	2K_dev_12
	purpose	2K_dev_12
Massive Open Online Courses ( MOOCs ) enable everyone to receive high-quality education	background	2K_dev_13
	background	2K_dev_13
Our experiment show that ACD and PCD can detect usage of a cheat sheet with good accuracy and can reduce the overall human resources required to monitor MOOCs for cheating	finding	2K_dev_13
	finding	2K_dev_13
In this paper	mechanism	2K_dev_13
we propose a Massive Open Online Proctoring ( MOOP ) framework	mechanism	2K_dev_13
which combines both automatic and collaborative approaches to detect cheating behaviors in online tests The MOOP framework consists of three major components: Automatic Cheating Detector ( ACD )	mechanism	2K_dev_13
Peer Cheating Detector ( PCD )	mechanism	2K_dev_13
and Final Review Committee ( FRC )	mechanism	2K_dev_13
ACD uses webcam video or other sensors to monitor students and automatically flag suspected cheating behavior	mechanism	2K_dev_13
Ambiguous cases are then sent to the PCD	mechanism	2K_dev_13
where students peer-review flagged webcam video to confirm suspicious cheating behaviors	mechanism	2K_dev_13
Finally	mechanism	2K_dev_13
the list of suspicious cheating behaviors is sent to the FRC to make the final punishing decision	mechanism	2K_dev_13
	mechanism	2K_dev_13
	method	2K_dev_13
However	purpose	2K_dev_13
current MOOC creators can not provide an effective	purpose	2K_dev_13
economical	purpose	2K_dev_13
and scalable method to detect cheating on tests	purpose	2K_dev_13
which would be required for any certification	purpose	2K_dev_13
	purpose	2K_dev_13
Online communities	background	2K_dev_14
much like companies in the business world	background	2K_dev_14
often need to transfer best practices internally from one unit to another to improve their performance	background	2K_dev_14
The current research introduces a contingency perspective on practice transfer	finding	2K_dev_14
holding that the value of modifications depends on when they are introduced and who introduces them modifications are more helpful if they are introduced after the receiving project has had experience with the imported practice Furthermore	finding	2K_dev_14
modifications are more effective if they are introduced by members who have experience in a variety of other projects	finding	2K_dev_14
	finding	2K_dev_14
	mechanism	2K_dev_14
Empirical research on the transfer of a quality-improvement practice between projects within Wikipedia shows that	method	2K_dev_14
Organizational scholars disagree about how much a recipient unit should modify a best practice when incorporating it Some evidence indicates that modifying a practice that has been successful in one environment will introduce problems	purpose	2K_dev_14
undercut its effectiveness and harm the performance of the recipient unit Other evidence	purpose	2K_dev_14
though	purpose	2K_dev_14
suggests that recipients need to adapt the practice to fit their local environment	purpose	2K_dev_14
Online crowds are a promising source of new innovations	background	2K_dev_15
However	background	2K_dev_15
crowd innovation quality does not always match its quantity	background	2K_dev_15
	background	2K_dev_15
A series of controlled experiments show that experienced facilitators increased the quantity and creativity of workers ' ideas compared to unfacilitated workers	finding	2K_dev_15
while Novice facilitators reduced workers ' creativity	finding	2K_dev_15
Analyses of inspiration strategies suggest these opposing results stem from differential use of successful inspiration strategies ( e	finding	2K_dev_15
g	finding	2K_dev_15
	finding	2K_dev_15
provoking mental simulations )	finding	2K_dev_15
The results show that expert facilitation can significantly improve crowd innovation	finding	2K_dev_15
but inexperienced facilitators may need scaffolding to be successful	finding	2K_dev_15
	finding	2K_dev_15
One approach would for experts to provide personalized feed-back	mechanism	2K_dev_15
but this scales poorly	mechanism	2K_dev_15
and may lead to premature convergence during creative work	mechanism	2K_dev_15
Drawing on strategies for facilitating face-to-face brainstorms	mechanism	2K_dev_15
we introduce a crowd ideation system where experts monitor incoming ideas through a dashboard and offer high-level `` inspirations '' to guide ideation	mechanism	2K_dev_15
	mechanism	2K_dev_15
	method	2K_dev_15
In this paper	purpose	2K_dev_15
we explore how to improve crowd innovation with real-time expert guidance	purpose	2K_dev_15
	purpose	2K_dev_15
support a broad range of collaborative and cooperative tasks	background	2K_dev_16
discuss possible incentives and safeguards to context sharing from a user standpoint	background	2K_dev_16
	background	2K_dev_16
Through two prototypes	finding	2K_dev_16
we demonstrate how GCF can be used to We then show how our framework 's architecture allows devices to opportunistically detect and collaborate with one another	finding	2K_dev_16
even when running different applications Finally	finding	2K_dev_16
we present two real-world domains that show how GCF 's ability to form groups increases users ' access to relevant and timely information	finding	2K_dev_16
and	finding	2K_dev_16
In this paper	mechanism	2K_dev_16
we present the Group Context Framework ( GCF )	mechanism	2K_dev_16
a general-purpose toolkit that GCF provides a standardized way for developers to request contextual data for their applications The framework then intelligently groups with other devices to satisfy these requirements	mechanism	2K_dev_16
	method	2K_dev_16
allows mobile devices to opportunistically share contextual information	purpose	2K_dev_16
Telepresence means business people can make deals in other countries	background	2K_dev_17
doctors can give remote medical advice	background	2K_dev_17
and soldiers can rescue someone from thousands of miles away	background	2K_dev_17
When interaction is mediated	background	2K_dev_17
people are removed from and lack context about the person they are making decisions about We discuss implications of our results for theory and future research	background	2K_dev_17
	background	2K_dev_17
The results suggest that technological mediation influences decision making	finding	2K_dev_17
but its influence depends on an individual 's self-construal: participants who saw themselves as defined through their relationships ( interdependent self-construal ) recommended riskier and more painful treatments in video conferencing than when face-to-face	finding	2K_dev_17
	finding	2K_dev_17
	mechanism	2K_dev_17
We conducted a laboratory experiment involving medical treatment decisions	method	2K_dev_17
In this paper	purpose	2K_dev_17
we explore the impact of technological mediation on risk and dehumanization in decision-making	purpose	2K_dev_17
	purpose	2K_dev_17
Online question and answer ( Q & A ) sites	background	2K_dev_18
which are platforms for users to post and answer questions on a wide range of topics	background	2K_dev_18
are becoming large repositories of valuable knowledge and important to societies	background	2K_dev_18
In order to sustain success	background	2K_dev_18
Q & A sites face the challenges of ensuring content quality and encouraging user contributions	background	2K_dev_18
This work has implications for understanding and designing large-scale social computing systems	background	2K_dev_18
	background	2K_dev_18
we found that the benefits of collaborative editing outweigh its risks	finding	2K_dev_18
For example	finding	2K_dev_18
each substantive edit from other users can increase the number of positive votes by 181 % for the questions and 119 % for the answers	finding	2K_dev_18
On the other hand	finding	2K_dev_18
each edit only decreases askers and answerers ' subsequent contributions by no more than 5 %	finding	2K_dev_18
	finding	2K_dev_18
	mechanism	2K_dev_18
By examining five years ' archival data of Stack Overflow	method	2K_dev_18
	method	2K_dev_18
This paper examines a particular design decision in Q & A sites-allowing Wikipedia-like collaborative editing on questions and answers	purpose	2K_dev_18
and explores its beneficial effects on content quality and potential detrimental effects on users ' contributions	purpose	2K_dev_18
	purpose	2K_dev_18
The Internet has the potential to accelerate scientific problem solving by engaging a global pool of contributors	background	2K_dev_19
Existing approaches focus on broadcasting problems to many independent solvers	background	2K_dev_19
A better understanding of such collaborative strategies can inform the design of tools to support distributed collaboration on complex problems	background	2K_dev_19
	background	2K_dev_19
We contribute a simple taxonomy of collaborative acts derived from a Our results indicate a diversity of ways in which mathematicians are reaching a solution	finding	2K_dev_19
including by iteratively advancing a solution	finding	2K_dev_19
process-level examination of collaborations and a quantitative analysis relating collaborative acts to solution quality	mechanism	2K_dev_19
by examining a community for mathematical problem solving -- MathOverflow -- in which contributors communicate and collaborate to solve new mathematical 'micro-problems ' online	method	2K_dev_19
We investigate other approaches that may be advantageous	purpose	2K_dev_19
Crowdsourcing has become a popular and indispensable component of many problem-solving pipelines in the research literature	background	2K_dev_20
with crowd workers often treated as computational resources that can reliably solve problems that computers have trouble with	background	2K_dev_20
such as image labeling/classification	background	2K_dev_20
natural language processing	background	2K_dev_20
or document writing	background	2K_dev_20
Yet	background	2K_dev_20
obviously crowd workers are human	background	2K_dev_20
and long sequences of the same monotonous tasks might intuitively reduce the amount of good quality work done by the workers	background	2K_dev_20
	background	2K_dev_20
We find that micro-diversions can significantly improve worker retention rate while retaining the same work quality	finding	2K_dev_20
	finding	2K_dev_20
diversions containing small amounts of entertainment We call these small period of entertainment ``micro-diversions ''	mechanism	2K_dev_20
which we hypothesize	mechanism	2K_dev_20
We experimentally test micro-diversions on Amazon 's Mechanical Turk	method	2K_dev_20
a large paid-crowdsourcing platform	method	2K_dev_20
	method	2K_dev_20
Here we propose an investigation into how we can use to improve crowd workers ' experiences	purpose	2K_dev_20
to provide timely relief to workers during long sequences of micro-tasks	purpose	2K_dev_20
We hope to improve productivity by retaining workers to work on our tasks longer and to either improve or retain the quality of work	purpose	2K_dev_20
	purpose	2K_dev_20
When health services involve long-term treatment over months or years	background	2K_dev_21
providers have the ability	background	2K_dev_21
not present in acute emergency care	background	2K_dev_21
to collaboratively reflect on clients ' changing health data and adjust interventions Our fieldwork in this context complements and provides contrasts to previous CSCW studies performed in time-critical hospital settings Current literature shows a bias toward standardized records and routines in the implementation of health information technology	background	2K_dev_21
a policy that may not be appropriate for long-term health services We discuss how the design of information systems should vary based on temporal factors	background	2K_dev_21
	background	2K_dev_21
We define a temporal spectrum ranging from time-critical services that benefit from standardization to long-term services that require more flexibility	finding	2K_dev_21
	mechanism	2K_dev_21
We provide empirical evidence from fieldwork that we performed in organizations providing long-term behavioral and mental health services for children	method	2K_dev_21
In this paper	purpose	2K_dev_21
we discuss temporality as a factor in the design of health information technology	purpose	2K_dev_21
	purpose	2K_dev_21
inform a model of factors contributing to impression formation in this specific context	background	2K_dev_22
as well as experiments testing and providing design recommendations for improving members ' ability to interact and effectively learn about each other	background	2K_dev_22
	background	2K_dev_22
	finding	2K_dev_22
	mechanism	2K_dev_22
I have conducted interviews with professionals in different domains who post and share their work online	method	2K_dev_22
	method	2K_dev_22
My dissertation work focuses on understanding how and why professionals use activity traces generated by social work-sharing sites online to form impressions of fellow professionals ' expertise and inform personal interactions around work artifacts	purpose	2K_dev_22
These findings will then	purpose	2K_dev_22
Despite benefits and uses of social networking sites ( SNSs ) users are not always satisfied with their behaviors on the sites These desires for behavior change both provide insight into users ' perceptions of how SNSs impact their lives ( positively or negatively ) and can inform tools for helping users achieve desired behavior changes	background	2K_dev_23
Based on these results we provide insights both into how participants perceive different SNSs	background	2K_dev_23
as well as potential designs for behavior-change mechanisms to target SNS behaviors	background	2K_dev_23
	background	2K_dev_23
While some participants want to reduce site use	finding	2K_dev_23
others want to improve their use or increase a range of behaviors These desired changes differ by SNS	finding	2K_dev_23
and	finding	2K_dev_23
for Twitter	finding	2K_dev_23
by participants ' levels of site use	finding	2K_dev_23
Participants also expect a range of benefits from these goals	finding	2K_dev_23
including increased time	finding	2K_dev_23
contact with others	finding	2K_dev_23
intrinsic benefits	finding	2K_dev_23
better security/privacy	finding	2K_dev_23
and improved self presentation	finding	2K_dev_23
	mechanism	2K_dev_23
We use a 604-participant online survey	method	2K_dev_23
explore SNS users ' behavior-change goals for Facebook	purpose	2K_dev_23
Instagram	purpose	2K_dev_23
and Twitter	purpose	2K_dev_23
	purpose	2K_dev_23
Analysts synthesize complex	background	2K_dev_24
qualitative data to uncover themes and concepts	background	2K_dev_24
but the process is time-consuming	background	2K_dev_24
cognitively taxing	background	2K_dev_24
and automated techniques show mixed success Crowdsourcing could help this process through on-demand harnessing of flexible and powerful human cognition	background	2K_dev_24
but incurs other challenges including limited attention and expertise Further	background	2K_dev_24
text data can be complex	background	2K_dev_24
high-dimensional	background	2K_dev_24
and ill-structured	background	2K_dev_24
We demonstrate a classification-plus-context approach elicits the most accurate categories at the most useful level of abstraction	finding	2K_dev_24
To address these challenges we present an empirical study of a two-stage approach to A ) we draw on cognitive theory to assess how re-representing data can shorten and focus the data on salient dimensions ; and B ) introduce an iterative clustering approach that provides workers a global overview of data	mechanism	2K_dev_24
	mechanism	2K_dev_24
	method	2K_dev_24
We address two major challenges unsolved in prior crowd clustering work: scaffolding expertise for novice crowd workers	purpose	2K_dev_24
and creating consistent and accurate categories when each worker only sees a small portion of the data enable crowds to create an accurate and useful overview of a dataset:	purpose	2K_dev_24
Hackathons are events where people who are not normally collocated converge for a few days to write code together Hackathons	background	2K_dev_25
it seems	background	2K_dev_25
are everywhere	background	2K_dev_25
Our findings have implications for technology support that needs to be in place for hackathons and for understanding the role of brief interludes of collocation in loosely-coupled	background	2K_dev_25
geographically distributed work	background	2K_dev_25
suggest the way that hackathon-style collocation advances technical work varies across technical domain	finding	2K_dev_25
community structure	finding	2K_dev_25
and expertise of participants	finding	2K_dev_25
Building social ties	finding	2K_dev_25
in contrast	finding	2K_dev_25
seems relatively constant across hackathons Results from different hackathon team formation strategies suggest a tradeoff between advancing technical work and building social ties	finding	2K_dev_25
	mechanism	2K_dev_25
We present results from a multiple-case study that	method	2K_dev_25
We know that long- term collocation helps advance technical work and facilitate enduring interpersonal relationships	purpose	2K_dev_25
but can similar benefits come from brief	purpose	2K_dev_25
hackathon-style collocation ? How do participants spend their time preparing	purpose	2K_dev_25
working face-to- face	purpose	2K_dev_25
and following through these brief encounters ? Do the activities participants select suggest a tradeoff between the social and technical benefits of collocation ?	purpose	2K_dev_25
A growing number of large collaborative idea generation platforms promise that by generating ideas together	background	2K_dev_26
people can create better ideas than any would have alone	background	2K_dev_26
But how might these platforms best leverage the number and diversity of contributors to help each contributor generate even better ideas ? Prior research suggests that seeing particularly creative or diverse ideas from others can inspire you	background	2K_dev_26
We see this work as a step toward building more effective online systems for supporting large scale collective ideation	background	2K_dev_26
	background	2K_dev_26
Our validation study reveals that human raters agree with the estimates of dissimilarity derived from our idea map as much or more than they agree with each other	finding	2K_dev_26
People seeing the diverse sets of examples from our idea map generate more diverse ideas than those seeing randomly selected examples	finding	2K_dev_26
Our results also corroborate findings from prior research showing that people presented with creative examples generated more creative ideas than those who saw a set of random examples	finding	2K_dev_26
	finding	2K_dev_26
We contribute a new scalable crowd-powered method The method relies on similarity comparisons ( is idea A more similar to B or C ) generated by non-experts to create an abstract spatial idea map	mechanism	2K_dev_26
	mechanism	2K_dev_26
	method	2K_dev_26
but few scalable mechanisms exist to assess diversity	purpose	2K_dev_26
for evaluating the diversity of sets of ideas	purpose	2K_dev_26
	purpose	2K_dev_26
One main challenge in large creative online communities is helping their members find inspirational ideas from a large pool of ideas	background	2K_dev_27
A high-level approach to address this challenge is to create a synthesis of emerging solution space that can be used to provide participants with creative and diverse inspirational ideas of others	background	2K_dev_27
	background	2K_dev_27
This feedback in turn helps the community identify diverse inspirational ideas that can prompt community members to generate more high-quality and diverse ideas	finding	2K_dev_27
	finding	2K_dev_27
We built IDEAHOUND a collaborative idea generation system that demonstrates an alternative `` organic '' human computation approach	mechanism	2K_dev_27
where community members ( rather than external crowds ) contribute feedback about ideas as a byproduct of an activity that naturally integrates into the ideation process	mechanism	2K_dev_27
	mechanism	2K_dev_27
	method	2K_dev_27
Existing approaches to generate the synthesis of solution space either require community members to engage in tasks that detract from the main activity of generating ideas or depend on external crowd workers to help organize the ideas	purpose	2K_dev_27
	purpose	2K_dev_27
Previous work has shown the promise of crowdsourcing analogical idea generation	background	2K_dev_28
where distributing the stages of analogical processing across many people can reduce fixation	background	2K_dev_28
identify inspirations from more diverse domains	background	2K_dev_28
and lead to more creative ideas	background	2K_dev_28
Our results show that crowds find the most useful inspirations when the problem domain is represented abstractly and constraints are represented more concretely	finding	2K_dev_28
This paper contributes a systematic crowdsourcing approach	mechanism	2K_dev_28
	method	2K_dev_28
However	purpose	2K_dev_28
prior work has only considered problems with a single constraint	purpose	2K_dev_28
while many real-world problems involve multiple constraints for eliciting multiple constraints inherent in a problem and using those constraints to find inspirations useful in solving it To do so we identify methods to elicit useful constraints at different levels of abstraction	purpose	2K_dev_28
and empirical results that identify how the level of abstraction influences creative idea generation	purpose	2K_dev_28
	purpose	2K_dev_28
People are more creative at solving difficult design problems when they use relevant examples from outside of the problem 's domain as inspirations	background	2K_dev_29
We report an empirical study demonstrating how crowds can generate domains of expertise and that showing people an abstract representation rather than the original problem helps them identify more distant domains Crowd workers drawing inspirations from the distant domains produced more creative solutions to the original problem than did those who sought inspiration on their own	finding	2K_dev_29
or drew inspiration from domains closer to or not sharing structural correspondence with the original problem	finding	2K_dev_29
	finding	2K_dev_29
In this paper	mechanism	2K_dev_29
we demonstrate an approach in which non-experts identify domains that have the potential to yield useful and non-obvious inspirations for solutions	mechanism	2K_dev_29
	method	2K_dev_29
However	purpose	2K_dev_29
finding such `` outside-the-box '' inspirations is difficult	purpose	2K_dev_29
particularly in large idea repositories such as the web	purpose	2K_dev_29
because without guidance people select domains to search based on surface similarity to the problem 's domain	purpose	2K_dev_29
Eye tracking is a compelling tool for revealing people 's spatial-temporal distribution of visual attention Such an approach will allow designers to evaluate and refine their visual design without requiring the use of limited/expensive eye trackers	background	2K_dev_30
which demonstrated good accuracy when compared to a real eye tracker	finding	2K_dev_30
and showed that it accurately generated gaze heatmaps and trajectory maps	finding	2K_dev_30
	finding	2K_dev_30
we introduce a new approach that harnesses the crowd to understand allocation of visual attention In our approach	mechanism	2K_dev_30
crowdsourcing participants use mouse clicks to self-report the positions and trajectory for the following valuable eye tracking measures: first gaze	mechanism	2K_dev_30
last gaze and all gazes	mechanism	2K_dev_30
	mechanism	2K_dev_30
We validate our crowdsourcing approach with a user study	method	2K_dev_30
We then deployed our prototype	method	2K_dev_30
GazeCrowd	method	2K_dev_30
in a crowdsourcing setting	method	2K_dev_30
	method	2K_dev_30
But quality eye tracking hardware is expensive and can only be used with one person at a time	purpose	2K_dev_30
Further	purpose	2K_dev_30
webcam eye tracking systems have significant limitations on head movement and lighting conditions that result in significant data loss and inaccuracies	purpose	2K_dev_30
To address these drawbacks	purpose	2K_dev_30
	purpose	2K_dev_30
Researchers and theorists have proposed that feelings of attachment to subgroups within a larger online community or site can increase users ' loyalty to the site	background	2K_dev_31
They have identified two types of attachment	background	2K_dev_31
with distinct causes and consequences With bond-based attachment	background	2K_dev_31
people feel connections to other group members	background	2K_dev_31
while with identity-based attachment they feel connections to the group as a whole	background	2K_dev_31
	background	2K_dev_31
Communication with other people in a subgroup but not simple awareness of them increases attachment to the larger community	finding	2K_dev_31
the experiments show that bond- and identity-based attachment have different causes	finding	2K_dev_31
But the experiments show no evidence that bond and identity attachment have different consequences	finding	2K_dev_31
We consider both theoretical and methodological reasons why the consequences of bond-based and identity-based attachment are so similar	finding	2K_dev_31
	finding	2K_dev_31
By varying how the communication is structured	mechanism	2K_dev_31
between dyads or with all group members simultaneously	mechanism	2K_dev_31
	mechanism	2K_dev_31
In two experiments we show	method	2K_dev_31
that these feelings of attachment to subgroups increase loyalty to the larger community	purpose	2K_dev_31
	purpose	2K_dev_31
People spend an enormous amount of time searching for complex information online ; for example	background	2K_dev_32
consumers researching new purchases or patients learning about their conditions for others with similar interests	background	2K_dev_32
Through a controlled experiment we show that having access to others ' schemas while foraging for information helps new users to induce more useful	finding	2K_dev_32
prototypical	finding	2K_dev_32
and better-structured schemas than gathering information alone	finding	2K_dev_32
In this paper we introduce a novel approach for integrating the schemas individuals develop as they gather information online and surfacing them for others with similar interests	mechanism	2K_dev_32
	method	2K_dev_32
As they search	purpose	2K_dev_32
people build up rich mental schemas about their target domains ; which	purpose	2K_dev_32
if effectively shared	purpose	2K_dev_32
could accelerate learning	purpose	2K_dev_32
Online collaboration tools enable developers of interactive systems to quickly reach potential users for usability testing Online needfinding may help designers create products and services that can target a more diverse user population	background	2K_dev_33
	background	2K_dev_33
We found that video can sufficiently capture nuanced reactions to preliminary concept storyboards	finding	2K_dev_33
but that feedback providers need guidance and structure	finding	2K_dev_33
The case study demonstrates that combining online crowdsourcing with a video survey tool provides a simple and cost-efficient way to collect early-stage feedback	finding	2K_dev_33
	finding	2K_dev_33
	mechanism	2K_dev_33
To explore this	method	2K_dev_33
we conducted a feasibility study to compare face-to-face methods with online needfinding sessions conduct a case study with a professional design team	method	2K_dev_33
The team conducted needfinding activities with local participants	method	2K_dev_33
as well as a cost-equivalent number of online participants	method	2K_dev_33
Can these technologies serve designers who seek feedback on user needs during the earliest stages of design We then introduce a tool for collecting early-stage design feedback from online participants and	purpose	2K_dev_33
	background	2K_dev_34
Some significant differences were discovered between the two collections	finding	2K_dev_34
namely in the clients used to post them	finding	2K_dev_34
their conversational aspects	finding	2K_dev_34
the sentiment vocabulary present in them	finding	2K_dev_34
and the days of the week they were posted	finding	2K_dev_34
However	finding	2K_dev_34
in other dimensions for which analysis was possible	finding	2K_dev_34
no substantial differences were found	finding	2K_dev_34
Finally	finding	2K_dev_34
we discuss some ramifications of this work for understanding Twitter usage and management of one 's privacy	finding	2K_dev_34
	finding	2K_dev_34
	mechanism	2K_dev_34
This paper describes an empirical study of 1	method	2K_dev_34
6M deleted tweets collected over a continuous one-week period from a set of 292K Twitter users	method	2K_dev_34
	method	2K_dev_34
We examine several aggregate properties of deleted tweets	purpose	2K_dev_34
including their connections to other tweets ( e	purpose	2K_dev_34
g	purpose	2K_dev_34
	purpose	2K_dev_34
whether they are replies or retweets )	purpose	2K_dev_34
the clients used to produce them	purpose	2K_dev_34
temporal aspects of deletion	purpose	2K_dev_34
and the presence of geotagging information	purpose	2K_dev_34
	background	2K_dev_35
We show that we can use this to characterize distinct classes of articles	finding	2K_dev_35
We also find that social media reactions can help predict future visitation patterns early and accurately	finding	2K_dev_35
We show that it is possible to model accurately the overall traffic articles will ultimately receive by observing the first ten to twenty minutes of social media reactions	finding	2K_dev_35
Achieving the same prediction accuracy with visits alone would require to wait for three hours of data	finding	2K_dev_35
We also describe significant improvements on the accuracy of the early prediction of shelf-life for news stories	finding	2K_dev_35
We describe the interplay between website visitation patterns and social media reactions to news content hybrid observation method	mechanism	2K_dev_35
We validate our methods using qualitative analysis as well as quantitative analysis on data from a large international news network	method	2K_dev_35
for a set of articles generating more than 3	method	2K_dev_35
000	method	2K_dev_35
000 visits and 200	method	2K_dev_35
000 social media reactions	method	2K_dev_35
	method	2K_dev_35
This paper presents a study of the life cycle of news articles posted online	purpose	2K_dev_35
A challenge for many online production communities is to direct their members to accomplish tasks that are important to the group	background	2K_dev_36
even when these tasks may not match individual members ' interests	background	2K_dev_36
Finally	background	2K_dev_36
we discuss design and managerial implications based on our findings	background	2K_dev_36
	background	2K_dev_36
Results demonstrate that 1 ) publicizing important group goals via COTW can have a strong motivating influence on editors who have voluntarily identified themselves as group members compared to those who have not self-identified ; 2 ) the effects of goals spill over to non-goal related tasks ; and 3 ) editors exposed to group role models in COTW are more likely to perform similarly to the models on group-relevant citizenship behaviors	finding	2K_dev_36
	finding	2K_dev_36
	mechanism	2K_dev_36
We tested our hypotheses in the context of Wikipedia 's Collaborations of the Week ( COTW )	method	2K_dev_36
a group goal setting mechanism and a social event within Wikiprojects	method	2K_dev_36
	method	2K_dev_36
Here we investigate how combining group identification and direction setting can motivate volunteers in online communities to accomplish tasks important to the success of the group as a whole We hypothesize that group identity	purpose	2K_dev_36
the perception of belonging to a group	purpose	2K_dev_36
triggers in-group favoritism ; and direction setting ( including explicit direction from group goals and implicit direction from role models ) focuses people 's group-oriented motivation towards the group 's important tasks	purpose	2K_dev_36
	purpose	2K_dev_36
In crowd-collaborative innovation platforms	background	2K_dev_37
other contributors ' ideas can serve as sources of inspiration for creative ideas	background	2K_dev_37
We discuss implications for research and development of crowd-collaborative innovation platforms	background	2K_dev_37
Surprisingly	finding	2K_dev_37
we find that innovators who cite conceptually near sources of inspiration achieve a higher success rate than those who prefer far sources	finding	2K_dev_37
	mechanism	2K_dev_37
We predict the success rate of 2	method	2K_dev_37
344 ideas for 12 different design challenges in a collaborative Web-based innovation platform based on their cited sources ' conceptual distance from the target domain ( measured using probabilistic topic modeling of the ideas )	method	2K_dev_37
	method	2K_dev_37
but what patterns of interactions with others ' ideas are most helpful ? We investigate the hypothesis that building on inspiration sources that are conceptually far from one 's target domain are most helpful	purpose	2K_dev_37
a popular hypothesis with mixed empirical support	purpose	2K_dev_37
	purpose	2K_dev_37
thus improving their ability to facilitate one-time or spontaneous exchanges of information	background	2K_dev_38
	background	2K_dev_38
show how leveraging multiple contexts improves our ability to detect and form relevant groupings Through two prototypes	finding	2K_dev_38
we demonstrate how DIDJA enhances existing user experiences	finding	2K_dev_38
and show how developers can use our toolkit to easily facilitate frictionless collaborations between users and their environment We then perform an extended experiment and show how DIDJA is able to accurately form groups under realistic conditions	finding	2K_dev_38
	finding	2K_dev_38
In our approach	mechanism	2K_dev_38
devices share context with each other	mechanism	2K_dev_38
and form groups when these readings are found to be similar to one another Through a formative study	mechanism	2K_dev_38
We then present DIDJA	mechanism	2K_dev_38
a robust software toolkit that automatically collects and analyzes contextual information in order to find and form groups	mechanism	2K_dev_38
	method	2K_dev_38
We present a new technique that allows mobile devices to opportunistically group with one another	purpose	2K_dev_38
we examine the limitations of using a single type of context to form groups	purpose	2K_dev_38
and	purpose	2K_dev_38
A significant challenge for crowdsourcing has been increasing worker engagement and output quality The findings of this paper provide strategies for harnessing the crowd to perform complex tasks	background	2K_dev_39
as well as insight into crowd workers ' motivation	background	2K_dev_39
	background	2K_dev_39
we show that 1 ) using these strategies together increased workers ' engagement and the quality of their work ; 2 ) a social strategy was most effective for increasing engagement ; 3 ) a learning strategy was most effective in improving quality	finding	2K_dev_39
	mechanism	2K_dev_39
Through three experiments	method	2K_dev_39
	method	2K_dev_39
We explore the effects of social	purpose	2K_dev_39
learning	purpose	2K_dev_39
and financial strategies	purpose	2K_dev_39
and their combinations	purpose	2K_dev_39
on increasing worker retention across tasks and change in the quality of worker output	purpose	2K_dev_39
	background	2K_dev_40
We designed and implemented a prototype and our early experiences with it indicate the promise of offering quick video messaging at home and the challenges of a no-touch interface	finding	2K_dev_40
	finding	2K_dev_40
A physical artifact dedicated to remote family members makes it easier to chat with them over video	mechanism	2K_dev_40
HomeProxy combines a form factor designed for the home environment with a `` no-touch '' user experience and an interface that quickly transitions between recorded and live video communication	mechanism	2K_dev_40
	method	2K_dev_40
HomeProxy is a research prototype that uses a physical proxy to support video messaging at home among distributed family members	purpose	2K_dev_40
Sharing scientific data	background	2K_dev_41
software	background	2K_dev_41
and instruments is becoming increasingly common as science moves toward large-scale	background	2K_dev_41
distributed collaborations	background	2K_dev_41
Sharing these resources requires extra work to make them generally useful	background	2K_dev_41
Although we know much about the extra work associated with sharing data	background	2K_dev_41
Our results have important implications for future empirical studies as well as funding policy	background	2K_dev_41
Our findings indicate that they conduct a rich set of extra work around community management	finding	2K_dev_41
code maintenance	finding	2K_dev_41
education and training	finding	2K_dev_41
developer-user interaction	finding	2K_dev_41
and foreseeing user needs	finding	2K_dev_41
We identify several conditions under which they are likely to do this work	finding	2K_dev_41
as well as design principles that can facilitate it	finding	2K_dev_41
	finding	2K_dev_41
	mechanism	2K_dev_41
This paper presents a qualitative	method	2K_dev_41
interview-based study of the extra work that developers and end users of scientific software undertake	method	2K_dev_41
	method	2K_dev_41
we know little about the work associated with sharing contributions to software	purpose	2K_dev_41
even though software is of vital importance to nearly every scientific result	purpose	2K_dev_41
	purpose	2K_dev_41
Crowd feedback systems offer designers an emerging approach for improving their designs	background	2K_dev_42
	background	2K_dev_42
Results showed that the crowd feedback system prompted deep and cosmetic changes and led to improved designs	finding	2K_dev_42
the crowd recognized the design improvements	finding	2K_dev_42
and structured workflows generated more interpretative	finding	2K_dev_42
diverse and critical feedback than free-form prompts	finding	2K_dev_42
	mechanism	2K_dev_42
Users in an introductory visual design course created initial designs satisfying a design brief and received crowd feedback on the designs	method	2K_dev_42
Users revised the designs and the system was used to generate feedback again	method	2K_dev_42
This format enabled us to detect the changes between the initial and revised designs and how the feedback related to those changes	method	2K_dev_42
Further	method	2K_dev_42
we analyzed the value of crowd feedback by comparing it with expert evaluation and feedback generated via free-form prompts	method	2K_dev_42
but there is little empirical evidence of the benefit of these systems This paper reports the results of a study of using a crowd feedback system to iterate on visual designs	purpose	2K_dev_42
	purpose	2K_dev_42
In a variety of peer production settings	background	2K_dev_43
from Wikipedia to open source software development to crowdsourcing	background	2K_dev_43
individuals may encounter	background	2K_dev_43
edit	background	2K_dev_43
or review the work of unknown others	background	2K_dev_43
Typically this is done without much context to the person 's past behavior or performance	background	2K_dev_43
This work provides insight into the impact of activity history design factors on psychological and behavioral outcomes that can be of use in other related settings	background	2K_dev_43
	background	2K_dev_43
Surprisingly	finding	2K_dev_43
negative work history did not lead to negative outcomes	finding	2K_dev_43
but in contrast	finding	2K_dev_43
a positive work history led to positive initial impressions that persisted in the face of contrary information	finding	2K_dev_43
	finding	2K_dev_43
	mechanism	2K_dev_43
we conducted an online experiment on Mechanical Turk varying the content	method	2K_dev_43
quality	method	2K_dev_43
and presentation of information about another Turker 's work history	method	2K_dev_43
	method	2K_dev_43
To understand how exposure to an unknown individual 's activity history influences attitudes and behaviors	purpose	2K_dev_43
	purpose	2K_dev_43
When personalities clash	background	2K_dev_44
teams operate less effectively Personality differences affect face-to-face collaboration and may lower trust in virtual teams This work demonstrates a simple personality matching strategy for forming more effective teams in crowdsourcing contexts	background	2K_dev_44
	background	2K_dev_44
Results show that balancing for personality leads to significantly better performance on a collaborative task Balanced teams exhibited less conflict and their members reported higher levels of satisfaction and acceptance	finding	2K_dev_44
	mechanism	2K_dev_44
Using the DISC personality test	method	2K_dev_44
we composed 14 five-person teams ( N=70 ) with either a harmonious coverage of personalities ( balanced ) or a surplus of leader-type personalities ( imbalanced	method	2K_dev_44
For relatively short-lived assignments	purpose	2K_dev_44
like those of online crowdsourcing	purpose	2K_dev_44
personality matching could provide a simple	purpose	2K_dev_44
scalable strategy for effective team formation	purpose	2K_dev_44
However	purpose	2K_dev_44
it is not clear how ( or if ) personality differences affect teamwork in this novel context where the workforce is more transient and diverse This study examines how personality compatibility in crowd teams affects performance and individual perceptions	purpose	2K_dev_44
	purpose	2K_dev_44
We close by identifying several ways in which crowd labor platform operators and/or individual task requestors could improve the accessibility of this increasingly important form of employment	background	2K_dev_45
Our findings establish that people with a variety of disabilities currently participate in the crowd labor marketplace	finding	2K_dev_45
despite challenges such as crowdsourcing workflow designs that inadvertently prohibit participation by	finding	2K_dev_45
and may negatively affect the worker reputations of	finding	2K_dev_45
people with disabilities Despite such challenges	finding	2K_dev_45
we find that crowdwork potentially offers different opportunities for people with disabilities relative to the normative office environment	finding	2K_dev_45
such as job flexibility and lack of a need to rely on public transit	finding	2K_dev_45
	mechanism	2K_dev_45
via in-depth open-ended interviews of 17 people ( disabled crowdworkers and job coaches for people with disabilities ) and a survey of 631 adults with disabilities	method	2K_dev_45
	method	2K_dev_45
We present the first formal study of crowdworkers who have disabilities	purpose	2K_dev_45
Increasingly	background	2K_dev_46
the advice people receive on the Internet is socially transparent in the sense that it displays contextual information about the advice-givers or their actions CSCW research usually emphasizes how to increase information sharing ; this work suggests when shared information may be inappropriate We suggest ways to counter activity transparency 's potential downsides	background	2K_dev_46
	background	2K_dev_46
We found that the presence of a web history increased the likelihood of following a financial advisor 's advice and reduced participant earnings ( Exp	finding	2K_dev_46
1 )	finding	2K_dev_46
especially when the web history implied greater task focus ( Exp	finding	2K_dev_46
2	finding	2K_dev_46
3 )	finding	2K_dev_46
	finding	2K_dev_46
	mechanism	2K_dev_46
We report three experiments	method	2K_dev_46
We hypothesize that activity transparency -seeing an advice giver 's process while creating his or her recommendations - will increase advice taking	purpose	2K_dev_46
testing the effect of activity transparency on taking mediocre advice	purpose	2K_dev_46
	purpose	2K_dev_46
Social networking sites ( SNSs ) offer users a platform to build and maintain social connections	background	2K_dev_47
Understanding when people feel comfortable sharing information about themselves on SNSs is critical to a good user experience	background	2K_dev_47
because self-disclosure helps maintain friendships and increase relationship closeness	background	2K_dev_47
	background	2K_dev_47
Results show that women self-disclose more than men	finding	2K_dev_47
People with a stronger desire to manage impressions self-disclose less	finding	2K_dev_47
Network size is negatively associated with self-disclosure	finding	2K_dev_47
while tie strength and network density are positively associated	finding	2K_dev_47
	finding	2K_dev_47
Features include emotional valence	mechanism	2K_dev_47
social distance between the poster and people mentioned in the post	mechanism	2K_dev_47
the language similarity between the post and the community and post topic	mechanism	2K_dev_47
	mechanism	2K_dev_47
we applied it to de-identified	method	2K_dev_47
aggregated status updates from Facebook users	method	2K_dev_47
	method	2K_dev_47
This observational research develops a machine learning model to measure self-disclosure in SNSs and uses it to understand the contexts where it is higher or lower	purpose	2K_dev_47
To validate the model and advance our understanding about online self-disclosure	purpose	2K_dev_47
	purpose	2K_dev_47
Participatory sensing systems ( PSS ) require frequent injection of information that has a short shelf-life The use of crowds to gather information for PSS is therefore particularly challenging	background	2K_dev_48
Prior research has shown that request for help in crowdsourced system is an effective mechanism to increase contributions	background	2K_dev_48
Thus crowdsource system designers should consider imposing quid-pro-quo type policies for PSS that concentrate on fewer users	background	2K_dev_48
but makes them more productive	background	2K_dev_48
	background	2K_dev_48
Our results confirmed that quid-pro-quo led to more contribution	finding	2K_dev_48
but at a cost of faster departure from the study	finding	2K_dev_48
When a participant was simply requested to contribute	finding	2K_dev_48
but could still access community-generated data if they ignored a request	finding	2K_dev_48
was largely ineffective and was statistically similar to the control condition where no request for contribution occurred	finding	2K_dev_48
	finding	2K_dev_48
	mechanism	2K_dev_48
During a large-scale experimental study within a publicly deployed	method	2K_dev_48
crowdsourced	method	2K_dev_48
transit information system	method	2K_dev_48
we analyzed metrics associated with frequency of contribution and commitment to long-term use over a 10-month period	method	2K_dev_48
	method	2K_dev_48
In this study	purpose	2K_dev_48
we explore the impact of two policies on user contributions	purpose	2K_dev_48
A quid-pro-quo policy exchanges contributions from users for access to critical information in the system	purpose	2K_dev_48
A request policy simply reminds the user that information is needed to make the system function well	purpose	2K_dev_48
	purpose	2K_dev_48
Expert feedback is valuable but hard to obtain for many designers	background	2K_dev_49
We found that rubrics helped novice workers provide feedback that was rated nearly as valuable as expert feedback showed that student designers found feedback most helpful when it was emotionally positive and specific	finding	2K_dev_49
and that a rubric increased the occurrence of these characteristics in feedback The analysis also found that expertise correlated with longer critiques	finding	2K_dev_49
but not the other favorable characteristics	finding	2K_dev_49
indicates that experts may instead have produced value by providing clearer justifications	finding	2K_dev_49
	mechanism	2K_dev_49
To evaluate this	method	2K_dev_49
we conducted an experiment with a 2x2 factorial design	method	2K_dev_49
Student designers received feedback on a visual design from both experts and novices	method	2K_dev_49
who produced feedback using either an expert rubric or no rubric A follow-up analysis on writing style An informal evaluation	method	2K_dev_49
Online crowds can provide fast and affordable feedback	purpose	2K_dev_49
but workers may lack relevant domain knowledge and experience Can expert rubrics address this issue and help novices provide expert-level feedback ?	purpose	2K_dev_49
	background	2K_dev_50
	finding	2K_dev_50
A novel method of using task fingerprinting The technique focuses on the way workers work rather than the products they produce	mechanism	2K_dev_50
The technique captures behavioral traces from online crowd workers and uses them to build predictive models of task performance	mechanism	2K_dev_50
	mechanism	2K_dev_50
The effectiveness of the approach is evaluated across three contexts including classification	method	2K_dev_50
generation	method	2K_dev_50
and comprehension tasks	method	2K_dev_50
	method	2K_dev_50
to predict outcome measures such quality	purpose	2K_dev_50
errors	purpose	2K_dev_50
and the likelihood of cheating	purpose	2K_dev_50
particularly as applied to crowd sourced tasks	purpose	2K_dev_50
	purpose	2K_dev_50
	background	2K_dev_51
	finding	2K_dev_51
	mechanism	2K_dev_51
	method	2K_dev_51
	purpose	2K_dev_51
	background	2K_dev_52
	finding	2K_dev_52
	mechanism	2K_dev_52
	method	2K_dev_52
	purpose	2K_dev_52
Fast Fourier transform algorithms on large data sets achieve poor performance on various platforms because of the inefficient strided memory access patterns	background	2K_dev_53
	background	2K_dev_53
we demonstrate DRAM-optimized accelerator designs over a large tradeoff space given various problem ( single/double precision 1D	finding	2K_dev_53
2D and 3D FFTs ) and hardware platform ( off-chip DRAM	finding	2K_dev_53
3D-stacked DRAM	finding	2K_dev_53
ASIC	finding	2K_dev_53
FPGA	finding	2K_dev_53
etc	finding	2K_dev_53
) parameters	finding	2K_dev_53
We show that Spiral generated pareto optimal designs can achieve close to theoretical peak performance of the targeted platform offering 6x and 6	finding	2K_dev_53
5x system performance and power efficiency improvements respectively over conventional row-column FFT algorithms	finding	2K_dev_53
In this paper 1D	mechanism	2K_dev_53
2D and 3D FFTs targeting a generic machine model with a two-level memory hierarchy requiring block data transfers	mechanism	2K_dev_53
and derive using custom block data layouts These algorithms need to be carefully mapped to the targeted platform 's architecture	mechanism	2K_dev_53
particularly the memory subsystem	mechanism	2K_dev_53
to fully utilize performance and energy efficiency potentials Using the Kronecker product formalism	mechanism	2K_dev_53
we integrate our optimizations into Spiral framework	mechanism	2K_dev_53
and evaluate a family of DRAM-optimized FFT algorithms and their hardware implementation design space via automated techniques	method	2K_dev_53
In our evaluations	method	2K_dev_53
These inefficient access patterns need to be reshaped to achieve high performance implementations we formally restructure memory access pattern efficient algorithms	purpose	2K_dev_53
Languages for music audio processing typically offer a large assortment of unit generators There is great duplication among different language implementations	background	2K_dev_54
as each language must implement many of the same ( or nearly the same ) unit generators	background	2K_dev_54
We suggest that these techniques might eliminate most of the effort of building unit generator libraries and could help with the implementation of embedded audio systems where unit generators are needed but a full embedded Csound engine is not required	background	2K_dev_54
	finding	2K_dev_54
Using Aura as an example	mechanism	2K_dev_54
we modified Csound to allow efficient	mechanism	2K_dev_54
dynamic allocation of individual unit generators without using the Csound compiler or writing Csound instruments	mechanism	2K_dev_54
We then extended Aura using automatic code generation so that Csound unit generators can be accessed in the normal way from within Aura	mechanism	2K_dev_54
In this scheme	mechanism	2K_dev_54
Csound details are completely hidden from Aura users	mechanism	2K_dev_54
	mechanism	2K_dev_54
	method	2K_dev_54
Csound has a large library of unit generators and could be a useful source of reusable unit generators for other languages or for direct use in applications	purpose	2K_dev_54
In this study	purpose	2K_dev_54
we consider how Csound unit generators can be exposed to direct access by other audio processing languages	purpose	2K_dev_54
The results suggest that 1 ) the online disclosure of certain personal traits can influence the hiring decisions of U	background	2K_dev_55
S	background	2K_dev_55
firms and 2 ) the likelihood of hiring discrimination via online searches varies across employers	background	2K_dev_55
The findings also highlight the surprisingly lasting behavioral influence of traditional	background	2K_dev_55
offline networks in processes and scenarios where online interactions are becoming increasingly common	background	2K_dev_55
We find evidence of employers searching online for the candidates	finding	2K_dev_55
we find no difference in callback rates for the gay candidate compared to the straight candidate	finding	2K_dev_55
but a 13 % lower callback rate for the Muslim candidate compared to the Christian candidate	finding	2K_dev_55
While the difference is not significant at the national level	finding	2K_dev_55
it exhibits significant and robust heterogeneity in bias at the local level	finding	2K_dev_55
compatible with existing theories of discrimination	finding	2K_dev_55
In particular	finding	2K_dev_55
employers in Republican areas exhibit significant bias both against the Muslim candidate	finding	2K_dev_55
and in favor of the Christian candidate This bias is significantly larger than the bias in Democratic areas	finding	2K_dev_55
	finding	2K_dev_55
	mechanism	2K_dev_55
We create profiles for job candidates on popular social networks	method	2K_dev_55
manipulating information protected under U	method	2K_dev_55
S	method	2K_dev_55
laws	method	2K_dev_55
and submit job applications on their behalf to over 4	method	2K_dev_55
000 employers After comparing interview invitations for a Muslim versus a Christian candidate	method	2K_dev_55
and a gay versus a straight candidate	method	2K_dev_55
The results are robust to using state- and county-level data	method	2K_dev_55
to controlling for firm	method	2K_dev_55
job	method	2K_dev_55
and geographical characteristics	method	2K_dev_55
and to several model specifications	method	2K_dev_55
	method	2K_dev_55
We investigate whether personal information posted by job candidates on social media sites is sought and used by prospective employers	purpose	2K_dev_55
	purpose	2K_dev_55
Motivated by a radically new peer review system that the National Science Foundation recently experimented with	background	2K_dev_56
	background	2K_dev_56
	finding	2K_dev_56
An ( m ; k ) -selection mechanism asks each PI to review m proposals	mechanism	2K_dev_56
and uses these reviews to select ( at most ) k proposals	mechanism	2K_dev_56
We are interested in impartial mechanisms	mechanism	2K_dev_56
which guarantee that the ratings given by a PI to others ' proposals do not affect the likelihood of the PI 's own proposal being selected We design an impartial mechanism that selects a k-subset of proposals that is nearly as highly rated as the one selected by the non-impartial ( abstract version of ) the NSF pilot mechanism	mechanism	2K_dev_56
even when the latter mechanism has the `` unfair '' advantage of eliciting honest reviews	mechanism	2K_dev_56
	mechanism	2K_dev_56
	method	2K_dev_56
we study peer review systems in which proposals are reviewed by PIs who have submitted proposals themselves	purpose	2K_dev_56
The fairness notion of maximin share ( MMS ) guarantee underlies a deployed algorithm for allocating indivisible goods under additive valuations	background	2K_dev_57
Previous work has shown that such an MMS allocation may not exist	background	2K_dev_57
but the counterexample requires a number of goods that is exponential in the number of players ;	background	2K_dev_57
	finding	2K_dev_57
we give a new construction that uses only a linear number of goods	mechanism	2K_dev_57
On the positive side	mechanism	2K_dev_57
we formalize the intuition that these counterexamples are very delicate by designing an algorithm when valuations are drawn at random	mechanism	2K_dev_57
	mechanism	2K_dev_57
	method	2K_dev_57
Our goal is to understand when we can expect to be able to give each player his MMS guarantee	purpose	2K_dev_57
that provably finds an MMS allocation with high probability	purpose	2K_dev_57
A paradigmatic problem in social choice theory deals with the aggregation of subjective preferences of individuals represented as rankings of alternatives into a social ranking	background	2K_dev_58
We show that ignoring uncertainty altogether can lead to suboptimal outcomes	finding	2K_dev_58
Under the classic objective of minimizing the ( expected ) sum of Kendall tau distances between the input rankings and the output ranking	mechanism	2K_dev_58
we establish that preference elicitation is surprisingly straightforward and near-optimal solutions can be obtained in polynomial time	mechanism	2K_dev_58
both in theory and using real data	method	2K_dev_58
	method	2K_dev_58
We are interested in settings where individuals are uncertain about their own preferences	purpose	2K_dev_58
and represent their uncertainty as distributions over rankings	purpose	2K_dev_58
	purpose	2K_dev_58
	background	2K_dev_59
	finding	2K_dev_59
	mechanism	2K_dev_59
	method	2K_dev_59
	purpose	2K_dev_59
Simultaneously reverse engineering a collection of condition-specific gene networks from gene expression microarray data to uncover dynamic mechanisms is a key challenge in systems biology	background	2K_dev_60
We show the quantitative advantages of our approach reveals interesting results	finding	2K_dev_60
some of which are confirmed by previously validated results	finding	2K_dev_60
	finding	2K_dev_60
In this work	mechanism	2K_dev_60
we develop a more robust framework Just like microarray measurements across conditions must undergo proper normalization on their magnitudes before entering subsequent analysis	mechanism	2K_dev_60
we argue that networks across conditions also need to be normalized on their density when they are constructed	mechanism	2K_dev_60
and we provide an algorithm that allows such normalization to be facilitated while estimating the networks	mechanism	2K_dev_60
	mechanism	2K_dev_60
on synthetic and real data Our analysis of a hematopoietic stem cell dataset	method	2K_dev_60
However	purpose	2K_dev_60
existing methods for this task are very sensitive to variations in the size of the microarray samples across different biological conditions ( which we term sample size heterogeneity in network reconstruction )	purpose	2K_dev_60
and can potentially produce misleading results that can lead to incorrect biological interpretation that addresses this novel problem	purpose	2K_dev_60
	purpose	2K_dev_60
	background	2K_dev_61
We show that envy-free allocations of sellable goods are significantly more efficient than their unsellable counterparts	finding	2K_dev_61
	finding	2K_dev_61
Our novel setting includes an option to sell each good for a fraction of the minimum value any player has for the good	mechanism	2K_dev_61
	mechanism	2K_dev_61
we reason about the price of envy-freeness of allocations of sellable goods -- the ratio between the maximum social welfare and the social welfare of the best envy-free allocation	mechanism	2K_dev_61
	method	2K_dev_61
We study the envy-free allocation of indivisible goods between two players To rigorously quantify the efficiency gain from selling	purpose	2K_dev_61
Some crowdsourcing platforms ask workers to express their opinions by approving a set of k good alternatives	background	2K_dev_62
	background	2K_dev_62
results call attention to situations where approval voting is suboptimal	finding	2K_dev_62
	finding	2K_dev_62
by proposing a probabilistic framework of noisy voting	mechanism	2K_dev_62
and asking whether approval voting yields an alternative that is most likely to be the best alternative	mechanism	2K_dev_62
given k-approval votes	mechanism	2K_dev_62
While the answer is generally positive	method	2K_dev_62
our theoretical and empirical	method	2K_dev_62
It seems that the only reasonable way to aggregate these k-approval votes is the approval voting rule	purpose	2K_dev_62
which simply counts the number of times each alternative was approved	purpose	2K_dev_62
We challenge this assertion	purpose	2K_dev_62
Personal photos are enjoying explosive growth with the popularity of photo-taking devices and social media	background	2K_dev_63
The vast amount of online photos largely exhibit users ' interests	background	2K_dev_63
emotion and opinions	background	2K_dev_63
demonstrate the effectiveness of our model	finding	2K_dev_63
	finding	2K_dev_63
We propose a User Image Latent Space Model User interests are modeled as latent factors and each user is assumed to have a distribution over them	mechanism	2K_dev_63
By inferring the latent factors and users ' distributions	mechanism	2K_dev_63
we can discover what the users are interested in We model image contents with a four-level hierarchical structure where the layers correspond to themes	mechanism	2K_dev_63
semantic regions	mechanism	2K_dev_63
visual words and pixels respectively	mechanism	2K_dev_63
Users ' latent interests are embedded in the theme layer	mechanism	2K_dev_63
Given image contents	mechanism	2K_dev_63
users ' interests can be discovered by doing posterior inference	mechanism	2K_dev_63
We use variational inference to approximate the posteriors of latent variables and learn model parameters	mechanism	2K_dev_63
	mechanism	2K_dev_63
Experiments on 180K Flickr photos	method	2K_dev_63
Mining user interests from personal photos can boost a number of utilities	purpose	2K_dev_63
such as advertising	purpose	2K_dev_63
interest based community detection and photo recommendation	purpose	2K_dev_63
In this paper	purpose	2K_dev_63
we study the problem of user interests mining from personal photos	purpose	2K_dev_63
to jointly model user interests and image contents	purpose	2K_dev_63
	purpose	2K_dev_63
	background	2K_dev_64
	finding	2K_dev_64
We introduce the simultaneous model We show that this model enables the computation of divisions that satisfy proportionality -- a popular fairness notion -- using a protocol that circumvents a standard lower bound via parallel information elicitation	mechanism	2K_dev_64
Cake divisions satisfying another prominent fairness notion	mechanism	2K_dev_64
envy-freeness	mechanism	2K_dev_64
are impossible to compute in the simultaneous model	mechanism	2K_dev_64
but admit arbitrarily good approximations	mechanism	2K_dev_64
	method	2K_dev_64
for cake cutting ( the fair allocation of a divisible good )	purpose	2K_dev_64
in which agents simultaneously send messages containing a sketch of their preferences over the cake	purpose	2K_dev_64
Motivated by applications to crowdsourcing	background	2K_dev_65
	background	2K_dev_65
	finding	2K_dev_65
We show that there is such a voting rule	mechanism	2K_dev_65
which we call the modal ranking rule	mechanism	2K_dev_65
Moreover	mechanism	2K_dev_65
we establish that the modal ranking rule is the unique rule with the preceding robustness property within a large family of voting rules	mechanism	2K_dev_65
which includes a slew of well-studied rules	mechanism	2K_dev_65
	mechanism	2K_dev_65
	method	2K_dev_65
we study voting rules that output a correct ranking of alternatives by quality from a large collection of noisy input rankings We seek voting rules that are supremely robust to noise	purpose	2K_dev_65
in the sense of being correct in the face of any `` reasonable '' type of noise	purpose	2K_dev_65
	purpose	2K_dev_65
Classic social choice theory assumes that votes are independent ( but possibly conditioned on an underlying objective ground truth )	background	2K_dev_66
	background	2K_dev_66
	finding	2K_dev_66
We establish a general framework -- based on random utility theory -- on a social network with arbitrarily many alternatives ( in contrast to previous work	mechanism	2K_dev_66
which is restricted to two alternatives )	mechanism	2K_dev_66
We identify a family of voting rules which	mechanism	2K_dev_66
without knowledge of the social network structure	mechanism	2K_dev_66
are guaranteed with high probability in large networks	mechanism	2K_dev_66
with respect to a wide range of models of correlation among input votes	mechanism	2K_dev_66
	mechanism	2K_dev_66
	method	2K_dev_66
This assumption is unrealistic in settings where the voters are connected via an underlying social network structure	purpose	2K_dev_66
as social interactions lead to correlated votes	purpose	2K_dev_66
for ranked voting to recover the ground truth	purpose	2K_dev_66
Limited lookahead has been studied for decades in perfect-information games	background	2K_dev_67
	background	2K_dev_67
The limited-lookahead player often obtains the value of the game if she knows the expected values of nodes in the game tree for some equilibrium	finding	2K_dev_67
but we prove this is not sufficient in general	finding	2K_dev_67
This uncovers a lookahead pathology	finding	2K_dev_67
We characterize the hardness of finding a Nash equilibrium or an optimal commitment strategy for either player	mechanism	2K_dev_67
showing that in some of these variations the problem can be solved in polynomial time while in others it is PPAD-hard or NP-hard	mechanism	2K_dev_67
We proceed to design algorithms for when the opponent breaks ties 1 ) favorably	mechanism	2K_dev_67
2 ) according to a fixed rule	mechanism	2K_dev_67
or 3 ) adversarially	mechanism	2K_dev_67
	mechanism	2K_dev_67
The impact of limited lookahead is then investigated experimentally Finally	method	2K_dev_67
we study the impact of noise in those estimates and different lookahead depths	method	2K_dev_67
This paper initiates a new direction via two simultaneous deviation points : generalization to imperfect-information games and a game-theoretic approach The question of how one should act when facing an opponent whose lookahead is limited is studied along multiple axes : lookahead depth	purpose	2K_dev_67
whether the opponent ( s )	purpose	2K_dev_67
too	purpose	2K_dev_67
have imperfect information	purpose	2K_dev_67
and how they break ties for computing optimal commitment strategies	purpose	2K_dev_67
	background	2K_dev_68
	finding	2K_dev_68
We present an efficient algorithm When combined with a result of Chillingworth	mechanism	2K_dev_68
our algorithm is applicable to convex simplicial complexes embedded in R3 The running time of our algorithm is nearly-linear in the size of the complex and is logarithmic on its numerical properties	mechanism	2K_dev_68
Our algorithm is based on projection operators and combinatorial steps for transferring between them The former relies on decomposing flows into circulations and potential flows using fast solvers for graph Laplacians	mechanism	2K_dev_68
and the latter relates Gaussian elimination to topological properties of simplicial complexes	mechanism	2K_dev_68
	mechanism	2K_dev_68
	method	2K_dev_68
for solving a linear system arising from the 1-Laplacian corresponding to a collapsible simplicial complex with a known collapsing sequence	purpose	2K_dev_68
	purpose	2K_dev_68
	background	2K_dev_69
Specifically	finding	2K_dev_69
we show that each protocol in the class of generalized cut and choose ( GCC ) protocols which includes the most important discrete cake cutting protocols is guaranteed to have approximate subgame perfect Nash equilibria	finding	2K_dev_69
or even exact equilibria if the protocol 's tie-breaking rule is flexible	finding	2K_dev_69
We further observe that the ( approximate ) equilibria of proportional protocols which guarantee each of the n agents a 1/n-fraction of the cake must be ( approximately ) proportional	finding	2K_dev_69
thereby answering the above question in the positive ( at least for one common notion of fairness )	finding	2K_dev_69
	finding	2K_dev_69
we adopt a novel algorithmic approach	mechanism	2K_dev_69
proposing a concrete computational model and reasoning about the game-theoretic properties of algorithms that operate in this model	mechanism	2K_dev_69
We study the paradigmatic fair division problem of fairly allocating a divisible good among agents with heterogeneous preferences	method	2K_dev_69
commonly known as cake cutting	method	2K_dev_69
	method	2K_dev_69
Classic cake cutting protocols are susceptible to manipulation	purpose	2K_dev_69
Do their strategic outcomes still guarantee fairness ? To address this question	purpose	2K_dev_69
	background	2K_dev_70
	finding	2K_dev_70
This disclosure relates to a three-dimensional ( 3D ) integrated circuit ( 3DIC ) memory chip including computational logic-in-memory ( LiM ) Related memory systems and methods are also disclosed In one embodiment	mechanism	2K_dev_70
the 3DIC memory chip includes at least one memory layer that provides a primary memory configured to store data	mechanism	2K_dev_70
The 3DIC memory chip also includes a computational LiM layer	mechanism	2K_dev_70
The computational LiM layer is a type of memory layer having application-specific computational logic integrated into local memory while externally appearing as regular memory The computational LiM layer and the primary memory are interconnected through through-silica vias ( TSVs )	mechanism	2K_dev_70
In this manner	mechanism	2K_dev_70
the computational LiM layer may load data from the primary memory with the 3DIC memory chip without having to access an external bus coupling the 3DIC memory chip to a central processing unit ( CPU ) or other processors to computationally process the data and generate a computational result	mechanism	2K_dev_70
	mechanism	2K_dev_70
	method	2K_dev_70
for performing accelerated data processing	purpose	2K_dev_70
An adversary who has obtained the cryptographic hash of a user 's password can mount an offline attack to crack the password by comparing this hash value with the cryptographic hashes of likely password guesses	background	2K_dev_71
This offline attacker is limited only by the resources he is willing to invest to crack the password	background	2K_dev_71
Key-stretching techniques like hash iteration and memory hard functions have been proposed to mitigate the threat of offline attacks by making each password guess more expensive for the adversary to verify	background	2K_dev_71
	background	2K_dev_71
Our analysis shows that CASH can significantly reduce ( up to 50 % ) the fraction of password cracked by a rational offline adversary	finding	2K_dev_71
We introduce a novel Stackelberg game model In the game the defender first commits to a key-stretching mechanism	mechanism	2K_dev_71
and the offline attacker responds in a manner that optimizes his utility ( expected reward minus expected guessing costs )	mechanism	2K_dev_71
We then introduce Cost Asymmetric Secure Hash ( CASH )	mechanism	2K_dev_71
a randomized key-stretching mechanism without increasing amortized authentication costs for the legitimate authentication server CASH is motivated by the observation that the legitimate authentication server will typically run the authentication procedure to verify a correct password	mechanism	2K_dev_71
while an offline adversary will typically use incorrect password guesses	mechanism	2K_dev_71
By using randomization we can ensure that the amortized cost of running CASH to verify a correct password guess is significantly smaller than the cost of rejecting an incorrect password Using our Stackelberg game framework we can quantify the quality of the underlying CASH running time distribution in terms of the fraction of passwords that a rational offline adversary would crack	mechanism	2K_dev_71
We provide an efficient algorithm to compute high quality CASH distributions for the defender	mechanism	2K_dev_71
Finally	method	2K_dev_71
we analyze CASH using empirical data from two large scale password frequency datasets	method	2K_dev_71
	method	2K_dev_71
However	purpose	2K_dev_71
these techniques also increase costs for a legitimate authentication server	purpose	2K_dev_71
which captures the essential elements of this interaction between a defender and an offline attacker that minimizes the fraction of passwords that would be cracked by a rational offline attacker	purpose	2K_dev_71
	background	2K_dev_72
	finding	2K_dev_72
	mechanism	2K_dev_72
	method	2K_dev_72
	purpose	2K_dev_72
	background	2K_dev_73
Com2 spots intuitive patterns	finding	2K_dev_73
that is	finding	2K_dev_73
temporal communities ( comet communities )	finding	2K_dev_73
We report our findings	finding	2K_dev_73
which include large star-like patterns	finding	2K_dev_73
near-bipartite-cores	finding	2K_dev_73
as well as tiny groups ( 5 users )	finding	2K_dev_73
calling each other hundreds of times within a few days	finding	2K_dev_73
We propose Com2	mechanism	2K_dev_73
a novel and fast	mechanism	2K_dev_73
incremental tensor analysis approach	mechanism	2K_dev_73
The method is ( a ) scalable	mechanism	2K_dev_73
being linear on the input size ( b ) general	mechanism	2K_dev_73
( c ) needs no user-defined parameters and ( d ) effective	mechanism	2K_dev_73
returning results that agree with intuition	mechanism	2K_dev_73
	mechanism	2K_dev_73
We apply our method on real datasets	method	2K_dev_73
including a phone-call network and a computer-traffic network The phone call network consists of 4 million mobile users	method	2K_dev_73
with 51 million edges ( phonecalls )	method	2K_dev_73
over 14 days	method	2K_dev_73
	method	2K_dev_73
Abstract : Given a large network	purpose	2K_dev_73
changing over time	purpose	2K_dev_73
how can we find patterns and anomalies ? which can discover both transient and periodic/ repeating communities	purpose	2K_dev_73
	purpose	2K_dev_73
	background	2K_dev_74
	finding	2K_dev_74
	mechanism	2K_dev_74
	method	2K_dev_74
	purpose	2K_dev_74
Many graph mining and analysis services have been deployed on the cloud	background	2K_dev_75
which can alleviate users from the burden of implementing and maintaining graph algorithms	background	2K_dev_75
	background	2K_dev_75
we show how to apply our methods to perform analytics on encrypted graphs	finding	2K_dev_75
demonstrate the correctness and feasibility of our methods	finding	2K_dev_75
	finding	2K_dev_75
we propose CryptGraph	mechanism	2K_dev_75
which runs graph analytics on encrypted graph In CryptGraph	mechanism	2K_dev_75
users encrypt their graphs before uploading them to the cloud	mechanism	2K_dev_75
The cloud runs graph analysis on the encrypted graphs and obtains results which are also in encrypted form that the cloud can not decipher	mechanism	2K_dev_75
During the process of computing	mechanism	2K_dev_75
the encrypted graphs are never decrypted on the cloud side	mechanism	2K_dev_75
The encrypted results are sent back to users and users perform the decryption to obtain the plaintext results	mechanism	2K_dev_75
In this process	mechanism	2K_dev_75
users ' graphs and the analytics results are both encrypted and the cloud knows neither of them Thereby	mechanism	2K_dev_75
users ' privacy can be strongly protected	mechanism	2K_dev_75
Meanwhile	mechanism	2K_dev_75
with the help of homomorphic encryption	mechanism	2K_dev_75
the results analyzed from the encrypted graphs are guaranteed to be correct	mechanism	2K_dev_75
we propose hard computation outsourcing	mechanism	2K_dev_75
Using two graph algorithms as examples	method	2K_dev_75
Experiments on two datasets	method	2K_dev_75
However	purpose	2K_dev_75
putting graph analytics on the cloud can invade users ' privacy	purpose	2K_dev_75
To solve this problem	purpose	2K_dev_75
to preserve the privacy of both users ' graph data and the analytic results	purpose	2K_dev_75
In this paper	purpose	2K_dev_75
we present how to encrypt a graph using homomorphic encryption and how to query the structure of an encrypted graph by computing polynomials To solve the problem that certain operations are not executable on encrypted graphs	purpose	2K_dev_75
to seek help from users	purpose	2K_dev_75
	background	2K_dev_76
	finding	2K_dev_76
	mechanism	2K_dev_76
	method	2K_dev_76
	purpose	2K_dev_76
A key challenge in solving extensive-form games is dealing with large	background	2K_dev_77
or even infinite	background	2K_dev_77
action spaces	background	2K_dev_77
In games of imperfect information	background	2K_dev_77
the leading approach is to find a Nash equilibrium in a smaller abstract version of the game that includes only a few actions at each decision point	background	2K_dev_77
and then map the solution back to the original game	background	2K_dev_77
	background	2K_dev_77
show it can outperform fixed abstractions at every stage of the run : early on it improves as quickly as equilibrium finding in coarse abstractions	finding	2K_dev_77
and later it converges to a better solution than does equilibrium finding in fine-grained abstractions	finding	2K_dev_77
We introduce a method that combines abstraction with equilibrium finding by enabling actions to be added to the abstraction at run time	mechanism	2K_dev_77
This allows an agent to begin learning with a coarse abstraction	mechanism	2K_dev_77
and then to strategically insert actions at points that the strategy computed in the current abstraction deems important The algorithm can quickly add actions to the abstraction while provably not having to restart the equilibrium finding	mechanism	2K_dev_77
It enables anytime convergence to a Nash equilibrium of the full game even in infinite games	mechanism	2K_dev_77
Experiments	method	2K_dev_77
However	purpose	2K_dev_77
it is difficult to know which actions should be included in the abstraction without first solving the game	purpose	2K_dev_77
and it is infeasible to solve the game without first abstracting it	purpose	2K_dev_77
The success of Amazon Mechanical Turk ( MTurk ) as an online research platform has come at a price : MTurk exhibits slowing rates of population replenishment	background	2K_dev_78
and growing participants non-naivety	background	2K_dev_78
	background	2K_dev_78
We found that both platforms participants were more naive and less dishonest compared to MTurk	finding	2K_dev_78
CF showed the best response rate	finding	2K_dev_78
but CF participants failed more attention-check questions and did not reproduce known effects replicated on ProA and MTurk Moreover	finding	2K_dev_78
ProA participants produced data quality that was higher than CFs and comparable to MTurks	finding	2K_dev_78
	mechanism	2K_dev_78
We examined two such platforms	method	2K_dev_78
CrowdFlower ( CF ) and Prolific Academic ( ProA )	method	2K_dev_78
	method	2K_dev_78
Recently	purpose	2K_dev_78
a number of alternative platforms have emerged	purpose	2K_dev_78
offering capabilities similar to MTurk while providing access to new and more naive populations	purpose	2K_dev_78
Anecdotal evidence and scholarly research have shown that a significant portion of Internet users experience regrets over their online disclosures We discuss limitations of the current nudge designs and future directions for improvement	background	2K_dev_79
	background	2K_dev_79
Our system logs	finding	2K_dev_79
results from exit surveys	finding	2K_dev_79
and interviews suggest that privacy nudges could be a promising way to prevent unintended disclosure	finding	2K_dev_79
	finding	2K_dev_79
we employed lessons from behavioral decision research and research on soft paternalism We developed three such privacy nudges on Facebook	mechanism	2K_dev_79
The first nudge provides visual cues about the audience for a post	mechanism	2K_dev_79
The second nudge introduces time delays before a post is published	mechanism	2K_dev_79
The third nudge gives users feedback about their posts	mechanism	2K_dev_79
	mechanism	2K_dev_79
We tested the nudges in a three-week exploratory field trial with 21 Facebook users	method	2K_dev_79
and conducted 13 follow-up interviews	method	2K_dev_79
	method	2K_dev_79
To help individuals avoid regrettable online disclosures to design mechanisms that `` nudge '' users to consider the content and context of their online disclosures before posting them	purpose	2K_dev_79
	purpose	2K_dev_79
	background	2K_dev_80
	finding	2K_dev_80
	mechanism	2K_dev_80
	method	2K_dev_80
	purpose	2K_dev_80
	background	2K_dev_81
Finally	finding	2K_dev_81
we illustrate our results	finding	2K_dev_81
First	mechanism	2K_dev_81
we find necessary and sufficient conditions for an attacker to create a dynamically undetectable sensor attack and relate these conditions to properties of the system dynamics eigenvectors	mechanism	2K_dev_81
Next	mechanism	2K_dev_81
we provide an index that gives the minimum number of sensors that must be attacked in order for an attack to be undetectable	mechanism	2K_dev_81
with a numerical example on the Quadruple Tank Process	method	2K_dev_81
We study cyber-physical systems subject to dynamic sensor attacks	purpose	2K_dev_81
relating them to the system 's strong observability	purpose	2K_dev_81
	purpose	2K_dev_81
Tree structured graphical models are powerful at expressing long range or hierarchical dependency among many variables	background	2K_dev_82
and have been widely applied in different areas of computer science and statistics	background	2K_dev_82
The usefulness of the proposed methods are illustrated	finding	2K_dev_82
In this paper	mechanism	2K_dev_82
we propose new nonparametric methods based on reproducing kernel Hilbert space embeddings of distributions	mechanism	2K_dev_82
by thorough numerical results	method	2K_dev_82
	method	2K_dev_82
However	purpose	2K_dev_82
existing methods for parameter estimation	purpose	2K_dev_82
inference	purpose	2K_dev_82
and structure learning mainly rely on the Gaussian or discrete assumptions	purpose	2K_dev_82
which are restrictive under many applications	purpose	2K_dev_82
that can recover the latent tree structures	purpose	2K_dev_82
estimate the parameters	purpose	2K_dev_82
and perform inference for high dimensional continuous and non-Gaussian variables	purpose	2K_dev_82
	purpose	2K_dev_82
	background	2K_dev_83
	finding	2K_dev_83
In this paper we present HiveMind	mechanism	2K_dev_83
a system of methods simply by adjusting the value of one variable	mechanism	2K_dev_83
	method	2K_dev_83
One common problem plaguing crowdsourcing tasks is tuning the set of worker responses : Depending on task requirements	purpose	2K_dev_83
requesters may want a large set of rich and varied worker responses ( typically in subjective evaluation tasks ) or a more convergent response-set ( typically for more objective tasks such as fact-checking )	purpose	2K_dev_83
This problem is especially salient in tasks that combine workers responses to present a single output : Divergence in these settings could either add richness and complexity to the unified answer	purpose	2K_dev_83
or noise	purpose	2K_dev_83
that allow requesters to tune different levels of convergence in worker participation for different tasks	purpose	2K_dev_83
Active learning has shown to reduce the number of exper- iments needed to obtain high-confidence drug-target predictions	background	2K_dev_84
How- ever	background	2K_dev_84
in order to actually save experiments using active learning	background	2K_dev_84
it is crucial to have a method to evaluate the quality of the current pre- diction and decide when to stop the experimentation process	background	2K_dev_84
	background	2K_dev_84
that applying the stopping criteria can result in upto 40 % savings of the total experiments for highly accurate predictions	finding	2K_dev_84
We compute active learning traces on simulated drug-target matrices in order to learn regression model By analyzing the perfor- mance of the regression model on simulated data	mechanism	2K_dev_84
we design stopping criteria for previously unseen experimental matrices	mechanism	2K_dev_84
	mechanism	2K_dev_84
We demonstrate on four previously characterized drug effect data sets	method	2K_dev_84
Only by applying reliable stoping criteria to active learning	purpose	2K_dev_84
time and costs in the experimental process can be actually saved a for the accuracy of the active learner	purpose	2K_dev_84
These results show that this system could be a valuable addition to vehicle anomaly detection and safety systems	background	2K_dev_85
	background	2K_dev_85
The experiment shows that the system is capable of predicting the vehicle speed and gear position with near-perfect accuracy over 99 %	finding	2K_dev_85
	finding	2K_dev_85
This paper presents a machine learning system from the sound it makes Therefore	mechanism	2K_dev_85
we investigate predicting the state of a vehicle using audio features in a classification task We improve the classification results using correlation matrices	mechanism	2K_dev_85
calculated from signals correlating with the audio	mechanism	2K_dev_85
	mechanism	2K_dev_85
In an experiment	method	2K_dev_85
the sound of a moving vehicle is classified into discretized speed intervals and gear positions	method	2K_dev_85
	method	2K_dev_85
that is capable of predicting the speed and gear position of a moving vehicle While audio classification is widely used in other research areas such as music information retrieval and bioacoustics	purpose	2K_dev_85
its application to vehicle sounds is rare	purpose	2K_dev_85
	purpose	2K_dev_85
Training large machine learning ( ML ) models with many variables or parameters can take a long time if one employs sequential procedures even with stochastic updates	background	2K_dev_86
	background	2K_dev_86
We provide theoretical guarantees for our scheduler	finding	2K_dev_86
and demonstrate its efficacy versus static block structures	finding	2K_dev_86
We propose and showcase a general-purpose scheduler	mechanism	2K_dev_86
STRADS	mechanism	2K_dev_86
	mechanism	2K_dev_86
which harnesses the aforementioned opportunities in a systematic way	mechanism	2K_dev_86
	mechanism	2K_dev_86
by exploring the dynamic block structures and workloads therein present during ML program execution	method	2K_dev_86
which offers new opportunities for improving convergence	method	2K_dev_86
correctness	method	2K_dev_86
and load balancing in distributed ML	method	2K_dev_86
on Lasso and Matrix Factorization	method	2K_dev_86
	method	2K_dev_86
A natural solution is to turn to distributed computing on a cluster ; however	purpose	2K_dev_86
naive	purpose	2K_dev_86
unstructured parallelization of ML algorithms does not usually lead to a proportional speedup and can even result in divergence	purpose	2K_dev_86
because dependencies between model elements can attenuate the computational gains from parallelization and compromise correctness of inference Recent efforts toward this issue have benefited from exploiting the static	purpose	2K_dev_86
a priori block structures residing in ML algorithms	purpose	2K_dev_86
In this paper	purpose	2K_dev_86
we take this path further for coordinating distributed updates in ML algorithms	purpose	2K_dev_86
Interface-confinement is a common mechanism that secures untrusted code by executing it inside a sandbox	background	2K_dev_87
The sandbox limits ( confines ) the code 's interaction with key system resources to a restricted set of interfaces This practice is seen in web browsers	background	2K_dev_87
hypervisors	background	2K_dev_87
and other security-critical systems	background	2K_dev_87
and prove the soundness of System M relative to the model	finding	2K_dev_87
Motivated by these systems	mechanism	2K_dev_87
we present a program logic	mechanism	2K_dev_87
called System M In addition to using computation types to specify effects of computations	mechanism	2K_dev_87
System M includes a novel invariant type The interpretation of invariant type includes terms whose effects satisfy an invariant We construct a step-indexed model built over traces System M is the first program logic that allows proofs of safety for programs that execute adversary-supplied code without forcing the adversarial code to be available for deep static analysis System M can be used to model and verify protocols as well as system designs	mechanism	2K_dev_87
	mechanism	2K_dev_87
We demonstrate the reasoning principles of System M by verifying the state integrity property of the design of Memoir	method	2K_dev_87
a previously proposed trusted computing system	method	2K_dev_87
	method	2K_dev_87
for modeling and proving safety properties of systems that execute adversary-supplied code via interface-confinement	purpose	2K_dev_87
to specify the properties of interface-confined code	purpose	2K_dev_87
	purpose	2K_dev_87
	background	2K_dev_88
Combined	finding	2K_dev_88
our results confer strong correctness guarantees for communicating systems	finding	2K_dev_88
	finding	2K_dev_88
To this end	mechanism	2K_dev_88
we develop a logically motivated theory of parametric polymorphism	mechanism	2K_dev_88
reminiscent of the Girard-Reynolds polymorphic -calculus	mechanism	2K_dev_88
but casted in the setting of concurrent processes	mechanism	2K_dev_88
In our theory	mechanism	2K_dev_88
polymorphism accounts for the exchange of abstract communication protocols and dynamic instantiation of heterogeneous interfaces	mechanism	2K_dev_88
as opposed to the exchange of data types and dynamic instantiation of individual message types	mechanism	2K_dev_88
Our polymorphic session-typed process language satisfies strong forms of type preservation and global progress	mechanism	2K_dev_88
is strongly normalizing	mechanism	2K_dev_88
and enjoys a relational parametricity principle In particular	mechanism	2K_dev_88
parametricity is key to derive non-trivial results about internal protocol independence	mechanism	2K_dev_88
a concurrent analogous of representation independence	mechanism	2K_dev_88
and non-interference properties of modular	mechanism	2K_dev_88
distributed systems	mechanism	2K_dev_88
	mechanism	2K_dev_88
	method	2K_dev_88
We investigate a notion of behavioral genericity in the context of session type disciplines	purpose	2K_dev_88
A dataset has been classified by some unknown classifier into two types of points	background	2K_dev_89
What were the most important factors in determining the classification outcome ?	background	2K_dev_89
	finding	2K_dev_89
In this work	mechanism	2K_dev_89
we employ an axiomatic approach We show that our influence measure takes on an intuitive form when the unknown classifier is linear	mechanism	2K_dev_89
	mechanism	2K_dev_89
Finally	method	2K_dev_89
we employ our influence measure in order to analyze the effects of user profiling on Google 's online display advertising	method	2K_dev_89
	method	2K_dev_89
in order to uniquely characterize an influence measure : a function that	purpose	2K_dev_89
given a set of classified points	purpose	2K_dev_89
outputs a value for each feature corresponding to its influence in determining the classification outcome	purpose	2K_dev_89
	background	2K_dev_90
Namely	finding	2K_dev_90
if the sample size is above the threshold	finding	2K_dev_90
then $ l_1/l_2 $ -regularized Lasso correctly recovers the support union ; and if the sample size is below the threshold	finding	2K_dev_90
$ l_1/l_2 $ -regularized Lasso fails to recover the support union	finding	2K_dev_90
In particular	finding	2K_dev_90
the threshold precisely captures the impact of the sparsity of regression vectors and the statistical properties of the design matrices on sample complexity Therefore	finding	2K_dev_90
the threshold function also captures the advantages of joint support union recovery using multi-task Lasso over individual support recovery using single-task Lasso	finding	2K_dev_90
We characterize sufficient and necessary conditions on sample complexity \emph { as a sharp threshold } to guarantee successful recovery of the support union	mechanism	2K_dev_90
	mechanism	2K_dev_90
In this paper	method	2K_dev_90
we investigate a multivariate multi-response ( MVMR ) linear regression problem	method	2K_dev_90
which contains multiple linear regression models with differently distributed design matrices	method	2K_dev_90
and different regression and output vectors	method	2K_dev_90
The goal is to recover the support union of all regression vectors using $ l_1/l_2 $ -regularized Lasso	purpose	2K_dev_90
	purpose	2K_dev_90
Upsampling of a multi-dimensional data-set is an operation with wide application in image processing and quantum mechanical calculations using density functional theory	background	2K_dev_91
For small up sampling factors as seen in the quantum chemistry code ONETEP	background	2K_dev_91
a time-shift based implementation that shifts samples by a fraction of the original grid spacing to fill in the intermediate values using a frequency domain Fourier property can be a good choice Readily available highly optimized multidimensional FFT implementations are leveraged at the expense of extra passes through the entire working set	background	2K_dev_91
We demonstrate speed-ups in isolation averaging 3x and within ONETEP of up to 15 %	finding	2K_dev_91
In this paper we present Since ONETEP handles threading	mechanism	2K_dev_91
we address the memory hierarchy and SIMD vectorization	mechanism	2K_dev_91
and focus on problem dimensions relevant for ONETEP	mechanism	2K_dev_91
We present a formalization of this operation within the SPIRAL framework and demonstrate auto-generated and auto-tuned interpolation libraries	mechanism	2K_dev_91
	mechanism	2K_dev_91
We compare the performance of our generated code against the previous best implementations using highly optimized FFT libraries ( FFTW and MKL	method	2K_dev_91
an optimized variant of the time-shift based up sampling	purpose	2K_dev_91
When asked to mentally simulate coin tosses	background	2K_dev_92
people generate sequences that differ systematically from those generated by fair coins	background	2K_dev_92
It has been rarely noted that this divergence is apparent already in the very 1st mental toss This bias has far-reaching implications extending well beyond the context of randomness cognition ; in particular	background	2K_dev_92
to binary surveys ( e	background	2K_dev_92
g	background	2K_dev_92
	background	2K_dev_92
accept vs	background	2K_dev_92
reject ) and tests ( e	background	2K_dev_92
g	background	2K_dev_92
	background	2K_dev_92
TrueFalse )	background	2K_dev_92
In binary choice	background	2K_dev_92
there is an advantage to what presents first	background	2K_dev_92
	background	2K_dev_92
reveals that about 80 % of respondents start their sequence with Heads	finding	2K_dev_92
We attributed this to the linguistic convention describing coin toss outcomes as Heads or Tails	finding	2K_dev_92
not vice versa	finding	2K_dev_92
found the first-toss bias reversible	finding	2K_dev_92
in terms of a novel response bias	mechanism	2K_dev_92
which we call reachability	mechanism	2K_dev_92
It is more general than the 1st-toss bias	mechanism	2K_dev_92
and it reflects the relative ease of reaching 1 option compared to its alternative in any binary choice context	mechanism	2K_dev_92
When faced with a choice between 2 options ( e	mechanism	2K_dev_92
g	mechanism	2K_dev_92
	mechanism	2K_dev_92
Heads and Tails	mechanism	2K_dev_92
when tossing mental coins )	mechanism	2K_dev_92
whichever of the 2 is presented first by the choice architecture ( hence	mechanism	2K_dev_92
is more reachable ) will be favored	mechanism	2K_dev_92
	mechanism	2K_dev_92
Analysis of several existing data sets However	method	2K_dev_92
our subsequent experiments under minor changes in the experimental setup	method	2K_dev_92
such as mentioning Tails before Heads in the instructions	method	2K_dev_92
	method	2K_dev_92
We offer a comprehensive account	purpose	2K_dev_92
	background	2K_dev_93
This result shows that our distributed Kalman filter can track with bounded MSE any arbitrary linear dynamics	finding	2K_dev_93
	finding	2K_dev_93
of a distributed Kalman filter that we have previously proposed	mechanism	2K_dev_93
	mechanism	2K_dev_93
	method	2K_dev_93
This paper proves the asymptotic convergence of the meansquared error ( MSE )	purpose	2K_dev_93
Given information about medical drugs and their properties	background	2K_dev_94
how can we automatically discover that Aspirin has blood-thinning properties	background	2K_dev_94
and thus prevents Expressed in more general terms	background	2K_dev_94
if we have a large in- formation network that integrates data from heterogeneous data sources	background	2K_dev_94
how can we extract semantic information that provides a better understanding of the in- tegrated data and also helps us to identify missing links ?	background	2K_dev_94
We demonstrate the effectiveness and scalability of the proposed method	finding	2K_dev_94
The discovered concepts provide semantic information as well as an abstract view on the integrated data and thus improve the understanding of complex systems	mechanism	2K_dev_94
Our proposed method has the following desirable properties : ( a ) it is parameter-free and therefore requires no user-defined parameters ( b ) it is fault-tolerant	mechanism	2K_dev_94
allowing for the detection of missing links and ( c ) it is scalable	mechanism	2K_dev_94
being linear on the input size	mechanism	2K_dev_94
on real	method	2K_dev_94
publicly available graphs	method	2K_dev_94
	method	2K_dev_94
We propose to extract concepts that describe groups of objects and their common properties from the integrated data	purpose	2K_dev_94
Multilinear analysis is pervasive in a wide variety of fields	background	2K_dev_95
ranging from Signal Processing to Chemometrics	background	2K_dev_95
and from Machine Vision to Data Mining	background	2K_dev_95
Determining the quality of a given tensor decomposition is a task of utmost importance that spans all fields of application of tensors	background	2K_dev_95
This task by itself is hard in its nature	background	2K_dev_95
since even determining the rank of a tensor is an NP-hard problem	background	2K_dev_95
Fortunately	background	2K_dev_95
there exist heuristics in the literature that can be effectively used for this task ; one of these heuristics is the so-called Core Consistency Diagnostic ( CORCONDIA ) which is very intuitive and simple	background	2K_dev_95
However simple	background	2K_dev_95
computation of this diagnostic proves to be a very daunting task even for data of medium scale	background	2K_dev_95
let alone big tensor data	background	2K_dev_95
	background	2K_dev_95
	finding	2K_dev_95
In this work we derive a fast and exact algorithm for CORCONDIA which exploits data sparsity and scales very well as the tensor size increases	mechanism	2K_dev_95
	method	2K_dev_95
With the increase of the size of the tensor data that need to be analyzed there grows the need for efficient and scalable algorithms to compute diagnostics such as CORCONDIA	purpose	2K_dev_95
in order to assess the modelling quality	purpose	2K_dev_95
	purpose	2K_dev_95
As Machine Learning ( ML ) applications embrace greater data size and model complexity	background	2K_dev_96
practitioners turn to distributed clusters to satisfy the increased computational and memory demands Effective use of clusters for ML programs requires considerable expertise in writing distributed code	background	2K_dev_96
but existing highly-abstracted frameworks like Hadoop that pose low barriers to distributed-programming have not	background	2K_dev_96
in practice	background	2K_dev_96
matched the performance seen in highly specialized and advanced ML implementations	background	2K_dev_96
The recent Parameter Server ( PS ) paradigm is a middle ground between these extremes	background	2K_dev_96
allowing easy conversion of single-machine parallel ML programs into distributed ones	background	2K_dev_96
while maintaining high throughput through relaxed `` consistency models '' that allow asynchronous ( and	background	2K_dev_96
hence	background	2K_dev_96
inconsistent ) parameter reads	background	2K_dev_96
	background	2K_dev_96
	finding	2K_dev_96
We then use the gleaned insights to improve a consistency model using an `` eager '' PS communication mechanism	mechanism	2K_dev_96
and implement it as a new PS system	mechanism	2K_dev_96
Inspired by this challenge	method	2K_dev_96
we study both the theoretical guarantees and empirical behavior of iterative-convergent ML algorithms in existing PS consistency models	method	2K_dev_96
	method	2K_dev_96
However	purpose	2K_dev_96
due to insufficient theoretical study	purpose	2K_dev_96
it is not clear which of these consistency models can really ensure correct ML algorithm output ; at the same time	purpose	2K_dev_96
there remain many theoretically-motivated but undiscovered opportunities to maximize computational throughput that enables ML programs to reach their solution more quickly	purpose	2K_dev_96
	purpose	2K_dev_96
Principal Component Analysis ( PCA ) has wide applications in machine learning	background	2K_dev_97
text mining and computer vision	background	2K_dev_97
Classical PCA based on a Gaussian noise model is fragile to noise of large magnitude	background	2K_dev_97
	background	2K_dev_97
Experimental results demonstrate the robustness of Cauchy PCA to various noise patterns	finding	2K_dev_97
	finding	2K_dev_97
In this paper	mechanism	2K_dev_97
we propose Cauchy Principal Component Analysis ( Cauchy PCA )	mechanism	2K_dev_97
a very simple yet effective PCA method which is robust to various types of noise	mechanism	2K_dev_97
We utilize Cauchy distribution to model noise and derive Cauchy PCA under the maximum likelihood estimation ( MLE ) framework with low rank constraint	mechanism	2K_dev_97
Our method can robustly estimate the low rank matrix regardless of whether noise is large or small	mechanism	2K_dev_97
dense or sparse	mechanism	2K_dev_97
We analyze the robustness of Cauchy PCA from a robust statistics view and present an efficient singular value projection optimization method	mechanism	2K_dev_97
on both simulated data and real applications	method	2K_dev_97
Laplace noise assumption based PCA methods can not deal with dense noise effectively	purpose	2K_dev_97
People with disabilities can be reluctant to friendsource help from their own friends for fear of appearing dependent or annoying	background	2K_dev_98
	finding	2K_dev_98
Our social microvolunteering approach has volunteers post friendsourcing tasks on behalf of people with disabilities	mechanism	2K_dev_98
	mechanism	2K_dev_98
We demonstrate this approach via a Facebook application that answers visual questions on behalf of blind users	method	2K_dev_98
	method	2K_dev_98
	purpose	2K_dev_98
In prior research we have developed a Curry-Howard interpretation of linear sequent calculus as session-typed processes	background	2K_dev_99
	finding	2K_dev_99
via a linear contextual monad that isolates session-based concurrency	mechanism	2K_dev_99
Monadic values are open process expressions and are first class objects in the language	mechanism	2K_dev_99
thus providing a logical foundation for higher-order session typed processes We illustrate how the combined use of the monad and recursive types allows us to cleanly write a rich variety of concurrent programs	mechanism	2K_dev_99
including higher-order programs that communicate processes We show the standard metatheoretic result of type preservation	mechanism	2K_dev_99
as well as a global progress theorem	mechanism	2K_dev_99
which to the best of our knowledge	mechanism	2K_dev_99
is new in the higher-order session typed setting	mechanism	2K_dev_99
	method	2K_dev_99
In this paper we uniformly integrate this computational interpretation in a functional language	purpose	2K_dev_99
Multi-modal data is dramatically increasing with the fast growth of social media Learning a good distance measure for data with multiple modalities is of vital importance for many applications	background	2K_dev_100
including retrieval	background	2K_dev_100
clustering	background	2K_dev_100
classification and recommendation	background	2K_dev_100
and present empirical results on retrieval and classification to demonstrate the effectiveness and scalability	finding	2K_dev_100
	finding	2K_dev_100
In this paper	mechanism	2K_dev_100
we propose Based on the multi-wing harmonium model	mechanism	2K_dev_100
our method provides a principled way to embed data of arbitrary modalities into a single latent space	mechanism	2K_dev_100
of which an optimal distance metric can be learned under proper supervision	mechanism	2K_dev_100
i	mechanism	2K_dev_100
e	mechanism	2K_dev_100
	mechanism	2K_dev_100
by minimizing the distance between similar pairs whereas maximizing the distance between dissimilar pairs	mechanism	2K_dev_100
The parameters are learned by jointly optimizing the data likelihood under the latent space model and the loss induced by distance supervision	mechanism	2K_dev_100
thereby our method seeks a balance between explaining the data and providing an effective distance metric	mechanism	2K_dev_100
which naturally avoids overfitting	mechanism	2K_dev_100
	mechanism	2K_dev_100
We apply our general framework to text/image data	method	2K_dev_100
an effective and scalable multi-modal distance metric learning framework	purpose	2K_dev_100
	purpose	2K_dev_100
	background	2K_dev_101
shows DOT2DOT correctly groups nodes for which good connection paths can be constructed	finding	2K_dev_101
while separating distant nodes	finding	2K_dev_101
in terms of the Minimum Description Length principle : a set of paths is simple when we need few bits to describe each path from one node to another	mechanism	2K_dev_101
For example	mechanism	2K_dev_101
we want to avoid high-degree nodes	mechanism	2K_dev_101
unless we need to visit many of its spokes	mechanism	2K_dev_101
As such	mechanism	2K_dev_101
the best partitioning requires the least number of bits to describe the paths that visit all marked nodes	mechanism	2K_dev_101
We show that our formulation for finding simple paths between groups of nodes has connections to well-known other problems in graph theory	mechanism	2K_dev_101
and is NP-hard	mechanism	2K_dev_101
We propose fast effective solutions	mechanism	2K_dev_101
and introduce DOT2DOT	mechanism	2K_dev_101
an efficient algorithm	mechanism	2K_dev_101
Experimentation	method	2K_dev_101
Abstract : Suppose we are given a large graph in which	purpose	2K_dev_101
by some external process	purpose	2K_dev_101
a handful of nodes are marked	purpose	2K_dev_101
What can we say about these marked nodes ? Are they all close-by in the graph	purpose	2K_dev_101
or are they segregated into multiple groups ? How can we automatically determine how many	purpose	2K_dev_101
if any groups they form as well as find simple paths that connect the nodes in each group ? We formalize the problem for partitioning marked nodes as well as finding simple paths between nodes within parts	purpose	2K_dev_101
	purpose	2K_dev_101
	background	2K_dev_102
We validate the proposed methods	finding	2K_dev_102
Graphs model data with complex structure as signals on a graph	mechanism	2K_dev_102
Graph signal recovery recovers one or multiple smooth graph signals from noisy	mechanism	2K_dev_102
corrupted	mechanism	2K_dev_102
or incomplete measurements We formulate as an optimization problem	mechanism	2K_dev_102
for which we provide a general solution through the alternating direction methods of multipliers We show how signal inpainting	mechanism	2K_dev_102
matrix completion	mechanism	2K_dev_102
robust principal component analysis	mechanism	2K_dev_102
and anomaly detection all relate to graph signal recovery and provide corresponding specific solutions and theoretical analysis	mechanism	2K_dev_102
on real-world recovery problems	method	2K_dev_102
including online blog classification	method	2K_dev_102
bridge condition identification	method	2K_dev_102
temperature estimation	method	2K_dev_102
recommender system for jokes	method	2K_dev_102
and expert opinion combination of online blog classification	method	2K_dev_102
We consider the problem of signal recovery on graphs graph signal recovery	purpose	2K_dev_102
	background	2K_dev_103
and the performance of the new method The adjacency matrices estimated using the new method are shown to be close to the true graph in the simulated data and consistent with prior physical knowledge in the real dataset	finding	2K_dev_103
	finding	2K_dev_103
This paper presents a computationally tractable algorithm is presented	mechanism	2K_dev_103
The algorithm is demonstrated on simulated and real network time series datasets is compared to that of related methods for estimating graph structure	method	2K_dev_103
	method	2K_dev_103
for estimating the graph structure of graph signals	purpose	2K_dev_103
	background	2K_dev_104
and solidly outperformed the state-of-the-art algorithms under four evaluation protocols with a high accuracy of 89	finding	2K_dev_104
69 %	finding	2K_dev_104
a top score among image-restricted and unsupervised protocols	finding	2K_dev_104
The advancement of Spartans is also proven In addition	finding	2K_dev_104
our learning method based on advanced correlation filters is much more effective	finding	2K_dev_104
in both linear and non-linear cases	finding	2K_dev_104
	finding	2K_dev_104
In this paper	mechanism	2K_dev_104
we investigate a single-sample periocular-based alignment-robust face recognition technique Our Spartans framework starts by utilizing one single sample per subject class	mechanism	2K_dev_104
and generate new face images under a wide range of 3D rotations using the 3D generic elastic model which is both accurate and computationally economic	mechanism	2K_dev_104
Then	mechanism	2K_dev_104
we focus on the periocular region where the most stable and discriminant features on human faces are retained	mechanism	2K_dev_104
and marginalize out the regions beyond the periocular region since they are more susceptible to expression variations and occlusions A novel facial descriptor	mechanism	2K_dev_104
high-dimensional Walsh local binary patterns	mechanism	2K_dev_104
is uniformly sampled on facial images with robustness toward alignment	mechanism	2K_dev_104
During the learning stage	mechanism	2K_dev_104
subject-dependent advanced correlation filters are learned for pose-tolerant non-linear subspace modeling in kernel feature space followed by a coupled max-pooling mechanism which further improve the performance Given any unconstrained unseen face image	mechanism	2K_dev_104
the Spartans can produce a highly discriminative matching score	mechanism	2K_dev_104
thus achieving high verification rate	mechanism	2K_dev_104
We have evaluated our method on the challenging Labeled Faces in the Wild database in the Face Recognition Grand Challenge and Multi-PIE databases in terms of learning subject-dependent pose-tolerant subspaces	method	2K_dev_104
compared with many well-established subspace methods	method	2K_dev_104
that is pose-tolerant under unconstrained face matching scenarios	purpose	2K_dev_104
Summary form only given	background	2K_dev_105
	background	2K_dev_105
We show that fractals and self-similarity can explain several of the observed patterns	finding	2K_dev_105
and we conclude and a surprising result on virus propagation and immunization	finding	2K_dev_105
We present a long list of static and temporal laws	mechanism	2K_dev_105
and	mechanism	2K_dev_105
some recent observations on real graphs	method	2K_dev_105
with cascade analysis	method	2K_dev_105
What do graphs look like ? How do they evolve over time ? How does influence/news/viruses propagate	purpose	2K_dev_105
over time ?	purpose	2K_dev_105
Facial hair detection and segmentation play an important role in forensic facial analysis	background	2K_dev_106
	background	2K_dev_106
results have demonstrated the robustness and effectiveness of our proposed system in detecting and segmenting facial hair	finding	2K_dev_106
In this paper	mechanism	2K_dev_106
we propose a fast	mechanism	2K_dev_106
robust	mechanism	2K_dev_106
fully automatic and self-training system In order to overcome the limitations of illumination	mechanism	2K_dev_106
facial hair color and near-clear shaving	mechanism	2K_dev_106
our facial hair detection self-learns a transformation vector to separate a hair class and a non-hair class from the testing image itself A feature vector	mechanism	2K_dev_106
consisting of Histogram of Gabor ( HoG ) and Histogram of Oriented Gradient of Gabor ( HOGG ) at different directions and frequencies	mechanism	2K_dev_106
is proposed for both beard/moustache detection and segmentation in this paper	mechanism	2K_dev_106
A feature-based segmentation is then proposed to segment the beard/moustache from a region on the face that is discovered to contain facial hair	mechanism	2K_dev_106
Experimental in images drawn from three entire databases i	method	2K_dev_106
e	method	2K_dev_106
the Multiple Biometric Grand Challenge ( MBGC ) still face database	method	2K_dev_106
the NIST color Facial Recognition Technology FERET database and a large subset from Pinellas County database	method	2K_dev_106
for beard/moustache detection and segmentation in challenging facial images	purpose	2K_dev_106
	background	2K_dev_107
we demonstrate the appeal of this approach on synthetic examples and real power networks significantly larger than those previously considered in the literature	finding	2K_dev_107
Our focus is on an improved algorithm with convergence times that are several orders of magnitude faster than existing algorithms	mechanism	2K_dev_107
In particular	mechanism	2K_dev_107
we develop an efficient proximal Newton method which minimizes per-iteration cost with a coordinate descent active set approach and fast numerical solutions to the Lyapunov equations	mechanism	2K_dev_107
	mechanism	2K_dev_107
Experimentally	method	2K_dev_107
We consider the task of designing sparse control laws for large-scale systems by directly minimizing an infinite horizon quadratic cost with an $ \ell_1 $ penalty on the feedback controller gains that allows us to scale to large systems ( i	purpose	2K_dev_107
e	purpose	2K_dev_107
those where sparsity is most useful )	purpose	2K_dev_107
	background	2K_dev_108
Our result is promising : we found an average of 38	finding	2K_dev_108
6 % more bugs than three previous fuzzers over 8 applications using the same amount of fuzzing time	finding	2K_dev_108
	finding	2K_dev_108
We present the design of an algorithm given a program and a seed input The major intuition is to leverage white-box symbolic analysis on an execution trace for a given program-seed pair to detect dependencies among the bit positions of an input	mechanism	2K_dev_108
and then use this dependency relation to compute a probabilistically optimal mutation ratio for this program-seed pair	mechanism	2K_dev_108
	method	2K_dev_108
to maximize the number of bugs found for black-box mutational fuzzing	purpose	2K_dev_108
Crowdsourcing can solve problems beyond the reach of state-of-the-art fully automated systems	background	2K_dev_109
A common pattern found in many such systems is for the workers to discover	background	2K_dev_109
in parallel	background	2K_dev_109
a number of candidate solutions and then vote on the best one to pass forward	background	2K_dev_109
often within a fixed amount of time	background	2K_dev_109
	background	2K_dev_109
	finding	2K_dev_109
We present the propose-vote-abstain mechanism Each crowd worker is given a choice among proposing an answer	mechanism	2K_dev_109
voting among the answers proposed so far	mechanism	2K_dev_109
or abstaining	mechanism	2K_dev_109
i	mechanism	2K_dev_109
e	mechanism	2K_dev_109
	mechanism	2K_dev_109
doing nothing	mechanism	2K_dev_109
When a stopping condition is reached	mechanism	2K_dev_109
the mechanism returns the answer with the most votes	mechanism	2K_dev_109
Workers are paid a base amount	mechanism	2K_dev_109
with bonuses if they propose or vote for the winning answer	mechanism	2K_dev_109
	mechanism	2K_dev_109
	method	2K_dev_109
for eliciting from crowd workers the proper balance between solution discovery and selection	purpose	2K_dev_109
Crowdsourcing systems leverage short bursts of focused attention from many contributors to achieve a goal	background	2K_dev_110
	background	2K_dev_110
	finding	2K_dev_110
We discuss the design space for low-effort crowdsourcing	mechanism	2K_dev_110
and through a series of prototypes	mechanism	2K_dev_110
demonstrate interaction techniques	mechanism	2K_dev_110
mechanisms	mechanism	2K_dev_110
and emerging principles	mechanism	2K_dev_110
In this paper	method	2K_dev_110
we study opportunities for low-effort crowdsourcing that enable people to contribute to problem solving in such settings	method	2K_dev_110
	method	2K_dev_110
By requiring peoples full attention	purpose	2K_dev_110
existing crowdsourcing systems fail to leverage peoples cognitive surplus in the many settings for which they may be distracted	purpose	2K_dev_110
performing or waiting to perform another task	purpose	2K_dev_110
or barely paying attention for enabling low-effort crowdsourcing	purpose	2K_dev_110
	purpose	2K_dev_110
In large scale machine learning and data mining problems with high feature dimensionality	background	2K_dev_111
the Euclidean distance between data points can be uninformative	background	2K_dev_111
and Distance Metric Learning ( DML ) is often desired to learn a proper similarity measure ( using side information such as example data pairs being similar or dissimilar )	background	2K_dev_111
and we show that	finding	2K_dev_111
our program is able to complete a DML task	finding	2K_dev_111
22-thousand features	finding	2K_dev_111
and 200 million labeled data pairs	finding	2K_dev_111
in 15 hours ; and the learned metric shows great effectiveness in properly measuring distances	finding	2K_dev_111
	finding	2K_dev_111
In this paper	mechanism	2K_dev_111
we present a distributed algorithm for DML	mechanism	2K_dev_111
and a large-scale implementation on a parameter server architecture	mechanism	2K_dev_111
Our approach builds on a parallelizable reformulation of Xing et al	mechanism	2K_dev_111
( 2002 )	mechanism	2K_dev_111
and an asynchronous stochastic gradient descent optimization procedure	mechanism	2K_dev_111
To our knowledge	mechanism	2K_dev_111
this is the first distributed solution to DML	mechanism	2K_dev_111
	mechanism	2K_dev_111
	method	2K_dev_111
on a system with 256 CPU cores on a dataset with 1 million data points	method	2K_dev_111
However	purpose	2K_dev_111
high dimensionality and large volume of pairwise constraints in modern big data can lead to prohibitive computational cost for both the original DML formulation in Xing et al	purpose	2K_dev_111
( 2002 ) and later extensions	purpose	2K_dev_111
	background	2K_dev_112
	finding	2K_dev_112
We discuss an initial outline for Chorus : Mnemonic	mechanism	2K_dev_112
a system that augments the crowd 's collective memory of a conversation by automatically recovering past knowledge based on topic	mechanism	2K_dev_112
allowing the system to support consistent multi-session interactions We present the design of the system itself	mechanism	2K_dev_112
	mechanism	2K_dev_112
and discuss methods for testing its effectiveness	method	2K_dev_112
	method	2K_dev_112
Maintaining consistency is a difficult challenge in crowd-powered systems in which constituent crowd workers may change over time	purpose	2K_dev_112
Our goal is to provide consistency between long interactions with crowd-powered conversational assistants by using AI to augment crowd workers	purpose	2K_dev_112
	purpose	2K_dev_112
Examples include adaptive front lighting in vehicles	background	2K_dev_113
dynamic stage performance lighting	background	2K_dev_113
adaptive dynamic range imaging and volumetric displays	background	2K_dev_113
and demonstrate dis-illumination of falling snow-like particles and photography of fast moving scenes	finding	2K_dev_113
	finding	2K_dev_113
A simulator is developed Simulations are conducted to characterize system performance by analyzing the effects of end-to-end latency	mechanism	2K_dev_113
jitter	mechanism	2K_dev_113
and prediction algorithm complexity	mechanism	2K_dev_113
Key operating points are identified where systems with simple prediction algorithms can outperform systems with more complex prediction algorithms Based on the lessons learned from simulations	mechanism	2K_dev_113
a low latency and low jitter	mechanism	2K_dev_113
tight closed-loop reactive visual system is built	mechanism	2K_dev_113
	mechanism	2K_dev_113
For the first time	method	2K_dev_113
we measure end-to-end latency	method	2K_dev_113
perform jitter analysis	method	2K_dev_113
investigate various prediction algorithms and their effect on system performance	method	2K_dev_113
compare our system 's performance to previous work	method	2K_dev_113
	method	2K_dev_113
We consider the class of projector-camera systems that adaptively image and illuminate a dynamic environment	purpose	2K_dev_113
to explore the design space of such Reactive Visual Systems	purpose	2K_dev_113
Thousands of web APIs expose data and services that would be useful to access with natural dialog	background	2K_dev_114
from weather and sports to Twitter and movies	background	2K_dev_114
	background	2K_dev_114
and present results for each stage	finding	2K_dev_114
	finding	2K_dev_114
We present a crowd-powered system able to generate a natural languageinterface for arbitrary web APIs from scratch without domain-dependent training data or knowledge	mechanism	2K_dev_114
Our approach combines two types of crowd workers : non-expert Mechanical Turk workers interpret the functions of the API and elicit information from the user	mechanism	2K_dev_114
and expert oDesk workers provide a minimal sufficient scaffolding around the API to allow us to make general queries	mechanism	2K_dev_114
We describe our multi-stage process	mechanism	2K_dev_114
	method	2K_dev_114
The process of adapting each API to a robust dialog system is difficult and time-consuming	purpose	2K_dev_114
as it requires not only programming but also anticipating what is mostly likely to be asked and how it is likely to be asked	purpose	2K_dev_114
	purpose	2K_dev_114
	background	2K_dev_115
	finding	2K_dev_115
and suggest required modifications	mechanism	2K_dev_115
In this work	method	2K_dev_115
we study the effects of position inaccuracy of commonly-used GPS devices on some of our V2V intersection protocols	method	2K_dev_115
We have been investigating vehicle-to-vehicle ( V2V ) communications as a part of co-operative driving in the context of autonomous driving	purpose	2K_dev_115
to guarantee their safety and efficiency despite these impairments	purpose	2K_dev_115
	purpose	2K_dev_115
Many big data applications collect a large number of time series	background	2K_dev_116
for example	background	2K_dev_116
the financial data of companies quoted in a stock exchange	background	2K_dev_116
the health care data of all patients that visit the emergency room of a hospital	background	2K_dev_116
or the temperature sequences continuously measured by weather stations across the US	background	2K_dev_116
A first task in the analytics of these data is to derive a low dimensional representation	background	2K_dev_116
a graph or discrete manifold	background	2K_dev_116
that describes well the interrelations among the time series and their intrarelations across time	background	2K_dev_116
	background	2K_dev_116
The adjacency matrices estimated with the new method are close to the true graph in the simulated data and consistent with prior physical knowledge in the real dataset tested	finding	2K_dev_116
This paper presents a computationally tractable algorithm This graph is directed and weighted	mechanism	2K_dev_116
possibly representing causation relations	mechanism	2K_dev_116
not just correlations as in most existing approaches in the literature	mechanism	2K_dev_116
	mechanism	2K_dev_116
The algorithm is demonstrated on random graph and real network time series datasets	method	2K_dev_116
and its performance is compared to that of related methods	method	2K_dev_116
	method	2K_dev_116
for estimating this graph structure from the available data	purpose	2K_dev_116
	purpose	2K_dev_116
How can we correlate neural activity in the human brain as it responds to words	background	2K_dev_117
with behavioral data expressed as answers to questions about these same words ?	background	2K_dev_117
We show that this is an instance of the Coupled Matrix-Tensor Factorization ( CMTF ) problem	finding	2K_dev_117
we find that Scoup-SMT is 50-100 times faster than a state-of-the-art algorithm for CMTF	finding	2K_dev_117
along with a 5 fold increase in sparsity Scoup-SMT is able to find meaningful latent variables	finding	2K_dev_117
as well as to predict brain activity with competitive accuracy Finally	finding	2K_dev_117
we demonstrate the generality of Scoup-SMT there	finding	2K_dev_117
Scoup-SMT spots spammer-like anomalies	finding	2K_dev_117
	finding	2K_dev_117
We propose Scoup-SMT	mechanism	2K_dev_117
a novel	mechanism	2K_dev_117
fast	mechanism	2K_dev_117
and parallel algorithm and produces a sparse latent low-rank subspace of the data Moreover	mechanism	2K_dev_117
we extend Scoup-SMT to handle missing data without degradation of performance	mechanism	2K_dev_117
In our experiments We apply Scoup-SMT to BrainQ	method	2K_dev_117
a dataset consisting of a ( nouns	method	2K_dev_117
brain voxels	method	2K_dev_117
human subjects ) tensor and a ( nouns	method	2K_dev_117
properties ) matrix	method	2K_dev_117
with coupling along the nouns dimension by applying it on a Facebook dataset ( users	method	2K_dev_117
friends	method	2K_dev_117
wall-postings ) ;	method	2K_dev_117
In short	purpose	2K_dev_117
we want to find latent variables	purpose	2K_dev_117
that explain both the brain activity	purpose	2K_dev_117
as well as the behavioral responses	purpose	2K_dev_117
that solves the CMTF problem	purpose	2K_dev_117
	background	2K_dev_118
results show that	finding	2K_dev_118
albeit simple	finding	2K_dev_118
our model achieves state-of-the-arts results	finding	2K_dev_118
We propose a method We improve upon local descriptor based methods that have been among the most popular and successful models for representing videos	mechanism	2K_dev_118
The desired local descriptors need to satisfy two requirements : 1 ) to be representative	mechanism	2K_dev_118
2 ) to be discriminative	mechanism	2K_dev_118
Therefore	mechanism	2K_dev_118
they need to occur frequently enough in the videos and to be be able to tell the difference among different types of motions	mechanism	2K_dev_118
In this paper	mechanism	2K_dev_118
we introduce a long-short term motion feature that generates descriptors from video blocks with multiple lengths	mechanism	2K_dev_118
	mechanism	2K_dev_118
Experimental on several benchmark datasets	method	2K_dev_118
	method	2K_dev_118
for representing motion information for video classification and retrieval To generate such local descriptors	purpose	2K_dev_118
the video blocks they are based on must contain just the right amount of motion information	purpose	2K_dev_118
However	purpose	2K_dev_118
current state-of-the-art local descriptor methods use video blocks with a single fixed size	purpose	2K_dev_118
which is insufficient for covering actions with varying speeds	purpose	2K_dev_118
thus covering motions with large speed variance	purpose	2K_dev_118
	purpose	2K_dev_118
How can we find useful patterns and anomalies in large scale real-world data with multiple attributes ? For example	background	2K_dev_119
network intrusion logs	background	2K_dev_119
with ( source-ip	background	2K_dev_119
target-ip	background	2K_dev_119
port-number	background	2K_dev_119
timestamp ) ? Tensors are suitable for modeling these multi-dimensional data	background	2K_dev_119
and widely used for the analysis of social networks	background	2K_dev_119
web data	background	2K_dev_119
network traffic	background	2K_dev_119
and in many other settings	background	2K_dev_119
	background	2K_dev_119
and discover hidden concepts	finding	2K_dev_119
In this paper	mechanism	2K_dev_119
we propose HaTen2	mechanism	2K_dev_119
a scalable distributed suite of tensor decomposition algorithms running on the MapReduce platform By carefully reordering the operations	mechanism	2K_dev_119
and exploiting the sparsity of real world tensors	mechanism	2K_dev_119
HaTen2 dramatically reduces the intermediate data	mechanism	2K_dev_119
and the number of jobs	mechanism	2K_dev_119
As a result	mechanism	2K_dev_119
using HaTen2	mechanism	2K_dev_119
we analyze big real-world tensors that can not be handled by the current state of the art	method	2K_dev_119
However	purpose	2K_dev_119
current tensor decomposition methods do not scale for tensors with millions and billions of rows	purpose	2K_dev_119
columns and fibers	purpose	2K_dev_119
that often appear in real datasets	purpose	2K_dev_119
	purpose	2K_dev_119
	background	2K_dev_120
	finding	2K_dev_120
	mechanism	2K_dev_120
	method	2K_dev_120
	purpose	2K_dev_120
Building information models ( BIMs ) provide opportunities to serve as an information repository to store and deliver as-built information	background	2K_dev_121
Since a building is not always constructed exactly as the design information specifies	background	2K_dev_121
there will be discrepancies between a BIM created in the design phase ( called as-designed BIM ) and the as-built conditions	background	2K_dev_121
Point clouds captured by laser scans can be used as a reference to update an as-designed BIM into an as-built BIM ( i	background	2K_dev_121
e	background	2K_dev_121
	background	2K_dev_121
the BIM that captures the as-built information )	background	2K_dev_121
Occlusions and construction progress prevent a laser scan performed at a single point in time to capture a complete view of building components	background	2K_dev_121
Progressively scanning a building during the construction phase and combining the progressively captured point cloud data together can provide the geometric information missing in the point cloud data captured previously	background	2K_dev_121
	background	2K_dev_121
	finding	2K_dev_121
This paper provides the details of an approach developed	mechanism	2K_dev_121
	method	2K_dev_121
However	purpose	2K_dev_121
combining all point cloud data will result in large file sizes and might not always guarantee additional building component information	purpose	2K_dev_121
to help engineers decide on which progressively captured point cloud data to combine in order to get more geometric information and eliminate large file sizes due to redundant point clouds	purpose	2K_dev_121
	purpose	2K_dev_121
Both SAT and # SAT can represent difficult problems in seemingly dissimilar areas such as planning	background	2K_dev_122
verification	background	2K_dev_122
and probabilistic inference	background	2K_dev_122
# SAT problems require counting the number of satisfiable formulas in a concisely-describable set of existentially-quantified	background	2K_dev_122
propositional formulas	background	2K_dev_122
	background	2K_dev_122
Our experiments show that	finding	2K_dev_122
despite the formidable worst-case complexity of # PNP [ 1 ]	finding	2K_dev_122
many of the instances can be solved efficiently by noticing and exploiting a particular type of frequent structure	finding	2K_dev_122
We characterize the expressiveness and worst-case difficulty of # SAT by proving it is complete for the complexity class # PNP [ 1 ]	mechanism	2K_dev_122
and relating this class to more familiar complexity classes	mechanism	2K_dev_122
	mechanism	2K_dev_122
We also experiment with three new general-purpose # SAT solvers on a battery of problem distributions including a simple logistics domain	method	2K_dev_122
Here	purpose	2K_dev_122
we examine an expressive new language	purpose	2K_dev_122
# SAT	purpose	2K_dev_122
that generalizes both of these languages	purpose	2K_dev_122
Classic cake cutting protocols -- which fairly allocate a divisible good among agents with heterogeneous preferences -- are susceptible to manipulation	background	2K_dev_123
GCC protocols are guaranteed to have exact subgame perfect Nash equilibria	finding	2K_dev_123
we adopt a novel algorithmic approach	mechanism	2K_dev_123
proposing a concrete computational model and reasoning about the game-theoretic properties of algorithms that operate in this model Specifically	mechanism	2K_dev_123
we show that each protocol in the class of generalized cut and choose ( GCC ) protocols -- which includes the most important discrete cake cutting protocols -- is guaranteed to have approximate subgame perfect Nash equilibria Moreover	mechanism	2K_dev_123
we observe that the ( approximate ) equilibria of proportional protocols -- which guarantee each of the n agents a 1/n-fraction of the cake -- must be ( approximately ) proportional	mechanism	2K_dev_123
and design a GCC protocol where all Nash equilibrium outcomes satisfy the stronger fairness notion of envy-freeness	mechanism	2K_dev_123
Finally	method	2K_dev_123
we show that under an obliviousness restriction	method	2K_dev_123
which still allows the computation of approximately envy-free allocations	method	2K_dev_123
	method	2K_dev_123
Do their strategic outcomes still guarantee fairness ? To answer this question	purpose	2K_dev_123
	background	2K_dev_124
	finding	2K_dev_124
The paper introduces a method by which In the scenario considered	mechanism	2K_dev_124
sensor nodes communicate with each other within a graph structure to update their data according to linear dynamics using neighbor node data A subset of sensors can also report their state to a central location One physical interpretation of this situation would be a set of spatially distributed wireless sensors which can communicate with other sensors within range to update data and can possibly connect to a network backbone	mechanism	2K_dev_124
The costs would then be related to transmission energy	mechanism	2K_dev_124
The objective is to recover the vector of initial sensor measurements from the backbone outputs over time	mechanism	2K_dev_124
which requires that the dynamics of the overall networked system be observable	mechanism	2K_dev_124
The topology of the network is then determined by the nonzero elements of the optimal observable dynamics The following text contributes an efficient algorithm for designing the optimal observable dynamics and the network topology for a given set of sensors and cost function	mechanism	2K_dev_124
	mechanism	2K_dev_124
providing proof of correctness and example implementation	method	2K_dev_124
	method	2K_dev_124
to design the topology of a distributed sensor network that is minimal with respect to a communication cost function	purpose	2K_dev_124
The Bayesian paradigm has provided a useful conceptual theory for understanding perceptual computation in the brain	background	2K_dev_125
While the detailed neural mechanisms of Bayesian inference are not fully understood	background	2K_dev_125
recent computational and neurophysiological works have illuminated the underlying computational principles and representational architecture	background	2K_dev_125
The fundamental insights are that the visual system is organized as a modular hierarchy to encode an internal model of the world	background	2K_dev_125
and that perception is realized by statistical inference based on such internal model	background	2K_dev_125
	background	2K_dev_125
	finding	2K_dev_125
We will argue for a unified theoretical framework	mechanism	2K_dev_125
	method	2K_dev_125
In this paper	purpose	2K_dev_125
we will discuss and analyze the varieties of representational schemes of these internal models and how they might be used to perform learning and inference for relating the internal models to the observed neural phenomena and mechanisms in the visual cortex	purpose	2K_dev_125
	background	2K_dev_126
that this approach outperforms the Network Time Protocol ( NTP ) on smartphones by an order of magnitude	finding	2K_dev_126
providing an average 720s synchronization accuracy with clock drift rates as low as 2ppm	finding	2K_dev_126
In this paper	mechanism	2K_dev_126
we present the design and evaluation of a platform The platform uses the Time-Difference-Of-Arrival ( TDOA ) of multiple ultrasonic chirps broadcast from a network of beacons placed throughout the environment to find an initial location as well as synchronize a receivers clock with the infrastructure	mechanism	2K_dev_126
These chirps encode identification data and ranging information that can be used to compute the receivers location Once the clocks have been synchronized	mechanism	2K_dev_126
the system can continue performing localization directly using Time-of-Flight ( TOF ) ranging as opposed to TDOA	mechanism	2K_dev_126
This provides similar position accuracy with fewer beacons ( for tens of minutes ) until the mobile device clock drifts enough that a TDOA signal is once again required	mechanism	2K_dev_126
Our hardware platform uses RF-based time synchronization to distribute clock synchronization from a subset of infrastructure beacons connected to a GPS source	mechanism	2K_dev_126
Mobile devices use a novel time synchronization technique leverages the continuously free-running audio sampling subsystem of a smartphone to synchronize with global time Once synchronized	mechanism	2K_dev_126
each device can determine an accurate proximity from as little as one beacon using TOF measurements	mechanism	2K_dev_126
This significantly decreases the number of beacons required to cover an indoor space and improves performance in the face of obstructions	mechanism	2K_dev_126
	mechanism	2K_dev_126
We show through experiments	method	2K_dev_126
that can be used for time synchronization and indoor positioning of mobile devices	purpose	2K_dev_126
	purpose	2K_dev_126
Document clustering and topic modeling are two closely related tasks which can mutually benefit each other	background	2K_dev_127
Topic modeling can project documents into a topic space which facilitates effective document clustering	background	2K_dev_127
Cluster labels discovered by document clustering can be incorporated into topic models to extract local topics specific to each cluster and global topics shared by all clusters	background	2K_dev_127
	background	2K_dev_127
demonstrate the effectiveness of our model	finding	2K_dev_127
In this paper	mechanism	2K_dev_127
we propose a multi-grain clustering topic model ( MGCTM ) which integrates document clustering and topic modeling Our model tightly couples two components : a mixture component used for discovering latent groups in document collection and a topic model component used for mining multi-grain topics including local topics specific to each cluster and global topics shared across clusters We employ variational inference to approximate the posterior of hidden variables and learn model parameters	mechanism	2K_dev_127
Experiments on two datasets	method	2K_dev_127
into a unified framework and jointly performs the two tasks to achieve the overall best performance	purpose	2K_dev_127
	purpose	2K_dev_127
In the United States	background	2K_dev_128
over three billion dollars are spent due to office equipment being left on when not in use during the weekend and at night	background	2K_dev_128
	finding	2K_dev_128
by applying persuasive technologies We then proceeded to develop `` dashboard-controllers '' with expert feedback to save energy	mechanism	2K_dev_128
To this end	method	2K_dev_128
we conducted a literature review to investigate the persuasive methods appropriate to the field of building controls	method	2K_dev_128
	method	2K_dev_128
There is very little incentive for office workers to save energy because utility bills are not directly their responsibility	purpose	2K_dev_128
Our goal is to find ways to reduce the negative impact of this pervasive phenomenon to create awareness and encourage office workers towards more environmentally sustainable behavior	purpose	2K_dev_128
that enable office workers to control energy-using components	purpose	2K_dev_128
	background	2K_dev_129
	finding	2K_dev_129
	mechanism	2K_dev_129
	method	2K_dev_129
	purpose	2K_dev_129
Differential game logic ( dG L ) is a logic for specifying and verifying properties of hybrid games	background	2K_dev_130
i	background	2K_dev_130
e	background	2K_dev_130
	background	2K_dev_130
games that combine discrete	background	2K_dev_130
continuous	background	2K_dev_130
and adversarial dynamics	background	2K_dev_130
Unlike hybrid systems	background	2K_dev_130
hybrid games allow choices in the system dynamics to be resolved adversarially by different players with different objectives	background	2K_dev_130
	background	2K_dev_130
Finally	finding	2K_dev_130
dG L is proved to be strictly more expressive than the corresponding logic of hybrid systems	finding	2K_dev_130
The logic dG L can be used i	mechanism	2K_dev_130
e	mechanism	2K_dev_130
	mechanism	2K_dev_130
ways of resolving the players choices in some way so that he wins by achieving his objective for all choices of the opponent	mechanism	2K_dev_130
Hybrid games are determined	mechanism	2K_dev_130
i	mechanism	2K_dev_130
e	mechanism	2K_dev_130
	mechanism	2K_dev_130
from each state	mechanism	2K_dev_130
one player has a winning strategy	mechanism	2K_dev_130
yet computing their winning regions may take transfinitely many steps	mechanism	2K_dev_130
The logic dG L	mechanism	2K_dev_130
nevertheless	mechanism	2K_dev_130
has a sound and complete axiomatization relative to any expressive logic	mechanism	2K_dev_130
Separating axioms are identified that distinguish hybrid games from hybrid systems	mechanism	2K_dev_130
	mechanism	2K_dev_130
by characterizing the expressiveness of both	method	2K_dev_130
	method	2K_dev_130
to study the existence of winning strategies for such hybrid games	purpose	2K_dev_130
	purpose	2K_dev_130
	background	2K_dev_131
we detect two types of copycats ( deceptive and non-deceptive ) Our results indicate significant heterogeneity in the interactions between copycats and original apps over time : ( 1 ) Non-deceptive copycats are reluctant to enter the market when the original app is popular and free	finding	2K_dev_131
However	finding	2K_dev_131
this negative effect does not hold in other cases ; ( 2 ) Copycats can be either friends or foes of the original apps High quality copycats always have a negative effect on the original app downloads	finding	2K_dev_131
Interestingly	finding	2K_dev_131
low quality deceptive copycats have a positive effect on the original app downloads	finding	2K_dev_131
suggesting a potential positive spillover effect	finding	2K_dev_131
Using machine learning techniques on large-scale unstructured data	mechanism	2K_dev_131
Based on our detected copycats	mechanism	2K_dev_131
we model the key drivers of mobile app copycats as well as their major impacts	mechanism	2K_dev_131
from 10	method	2K_dev_131
100 action game apps from iOS App Store over five years	method	2K_dev_131
	method	2K_dev_131
In this paper	purpose	2K_dev_131
we examine the emerging copycat issue in the mobile apps market	purpose	2K_dev_131
	purpose	2K_dev_131
Protocols for tasks such as authentication	background	2K_dev_132
electronic voting	background	2K_dev_132
and secure multiparty computation ensure desirable security properties if agents follow their prescribed programs Thus	background	2K_dev_132
our definition applies to relevant security properties	background	2K_dev_132
	background	2K_dev_132
First	finding	2K_dev_132
we prove that violations of a specific class of safety properties always have an actual cause	finding	2K_dev_132
Specifically	mechanism	2K_dev_132
we define in an interacting program model what it means for a set of program actions to be an actual cause of a violation We present a sound technique We demonstrate the value of this formalism in two ways	mechanism	2K_dev_132
	mechanism	2K_dev_132
Second	method	2K_dev_132
we provide a cause analysis of a representative protocol designed to address weaknesses in the current public key certification infrastructure	method	2K_dev_132
	method	2K_dev_132
However	purpose	2K_dev_132
if some agents deviate from their prescribed programs and a security property is violated	purpose	2K_dev_132
it is important to hold agents accountable by determining which deviations actually caused the violation	purpose	2K_dev_132
Motivated by these applications	purpose	2K_dev_132
we initiate a formal study of program actions as actual causes	purpose	2K_dev_132
for establishing program actions as actual causes	purpose	2K_dev_132
Privacy has become a significant concern in modern society as personal information about individuals is increasingly collected	background	2K_dev_133
used	background	2K_dev_133
and shared	background	2K_dev_133
often using digital technologies	background	2K_dev_133
by a wide range of organizations To mitigate privacy concerns	background	2K_dev_133
organizations are required to respect privacy laws in regulated sectors e	background	2K_dev_133
g	background	2K_dev_133
	background	2K_dev_133
HIPAA in healthcare	background	2K_dev_133
GLBA in financial sector and to adhere to self-declared privacy policies in self-regulated sectors e	background	2K_dev_133
g	background	2K_dev_133
	background	2K_dev_133
privacy policies of companies such as Google and Facebook in Web services	background	2K_dev_133
	background	2K_dev_133
producing the first complete logical specification and audit of all disclosure-related clauses of the HIPAA Privacy Rule	finding	2K_dev_133
We formalize privacy policies that prescribe and proscribe flows of personal information as well as those that place restrictions on the purposes for which a governed entity may use personal information Recognizing that traditional preventive access control and information flow control mechanisms are inadequate for enforcing such privacy policies	mechanism	2K_dev_133
we develop principled accountability mechanisms that seek to encourage policy-compliant behavior by detecting policy violations	mechanism	2K_dev_133
assigning blame	mechanism	2K_dev_133
and punishing violators	mechanism	2K_dev_133
We apply these techniques to several U	method	2K_dev_133
S	method	2K_dev_133
privacy laws and organizational privacy policies	method	2K_dev_133
in particular	method	2K_dev_133
This article provides an overview of a body of work on formalizing and enforcing privacy policies	purpose	2K_dev_133
	purpose	2K_dev_133
	background	2K_dev_134
with 1 million topics and a 1-million-word vocabulary ( for a total of 1 trillion parameters )	finding	2K_dev_134
on a document collection with 200 billion tokens -- - a scale not yet reported even with thousands of machines	finding	2K_dev_134
evidence showing how this development puts massive data and models within reach on a small cluster	finding	2K_dev_134
while still enjoying proportional time cost reductions with increasing cluster size	finding	2K_dev_134
and show that with a modest cluster of as few as 8 machines	mechanism	2K_dev_134
we can train a topic model Our major contributions include : 1 ) a new	mechanism	2K_dev_134
highly-efficient O ( 1 ) Metropolis-Hastings sampling algorithm	mechanism	2K_dev_134
whose running cost is ( surprisingly ) agnostic of model size	mechanism	2K_dev_134
and empirically converges nearly an order of magnitude more quickly than current state-of-the-art Gibbs samplers ; 2 ) a model-scheduling scheme to handle the big model challenge	mechanism	2K_dev_134
where each worker machine schedules the fetch/use of sub-models as needed	mechanism	2K_dev_134
resulting in a frugal use of limited memory capacity and network bandwidth ; 3 ) a differential data-structure for model storage	mechanism	2K_dev_134
which uses separate data structures for high- and low-frequency words to allow extremely large models to fit in memory	mechanism	2K_dev_134
while maintaining high inference speed	mechanism	2K_dev_134
These contributions are built on top of the Petuum open-source distributed ML framework	mechanism	2K_dev_134
	mechanism	2K_dev_134
and we provide experimental	method	2K_dev_134
When building large-scale machine learning ( ML ) programs	purpose	2K_dev_134
such as massive topic models or deep neural networks with up to trillions of parameters and training examples	purpose	2K_dev_134
one usually assumes that such massive tasks can only be attempted with industrial-sized clusters with thousands of nodes	purpose	2K_dev_134
which are out of reach for most practitioners and academic researchers	purpose	2K_dev_134
We consider this challenge in the context of topic modeling on web-scale corpora	purpose	2K_dev_134
	purpose	2K_dev_134
	background	2K_dev_135
	finding	2K_dev_135
	mechanism	2K_dev_135
	method	2K_dev_135
	purpose	2K_dev_135
In distributed ML applications	background	2K_dev_136
shared parameters are usually replicated among computing nodes to minimize network overhead	background	2K_dev_136
Therefore	background	2K_dev_136
proper consistency model must be carefully chosen to ensure algorithm 's correctness and provide high throughput	background	2K_dev_136
Existing consistency models used in general-purpose databases and modern distributed ML systems are either too loose to guarantee correctness of the ML algorithms or too strict and thus fail to fully exploit the computing power of the underlying distributed system	background	2K_dev_136
Many ML algorithms fall into the category of \emph { iterative convergent algorithms } which start from a randomly chosen initial point and converge to optima by repeating iteratively a set of procedures	background	2K_dev_136
	background	2K_dev_136
	finding	2K_dev_136
In this paper	mechanism	2K_dev_136
we present several relaxed consistency models The proposed consistency models are implemented in a distributed parameter server	mechanism	2K_dev_136
theoretically prove their algorithmic correctness and evaluated in the context of a popular ML application : topic modeling	method	2K_dev_136
	method	2K_dev_136
We 've found that many such algorithms are to a bounded amount of inconsistency and still converge correctly This property allows distributed ML to relax strict consistency models to improve system performance while theoretically guarantees algorithmic correctness	purpose	2K_dev_136
for asynchronous parallel computation and	purpose	2K_dev_136
Modern organizations ( e	background	2K_dev_137
g	background	2K_dev_137
	background	2K_dev_137
hospitals	background	2K_dev_137
social networks	background	2K_dev_137
government agencies ) rely heavily on audit to detect and punish insiders who inappropriately access and disclose confidential information	background	2K_dev_137
that this transformation significantly speeds up computation of solutions for a class of audit games and security games	finding	2K_dev_137
	finding	2K_dev_137
We significantly generalize this audit game model where each resource is restricted to audit a subset of all potential violations	mechanism	2K_dev_137
thus We provide an FPTAS that computes an approximately optimal solution to the resulting non-convex optimization problem The main technical novelty is in the design and correctness proof of an optimization transformation that enables the construction of this FPTAS	mechanism	2K_dev_137
	mechanism	2K_dev_137
In addition	method	2K_dev_137
we experimentally demonstrate	method	2K_dev_137
Recent work on audit games models the strategic interaction between an auditor with a single audit resource and auditees as a Stackelberg game	purpose	2K_dev_137
augmenting associated well-studied security games with a configurable punishment parameter	purpose	2K_dev_137
to account for multiple audit resources enabling application to practical auditing scenarios	purpose	2K_dev_137
	purpose	2K_dev_137
To partly address people 's concerns over web tracking	background	2K_dev_138
Google has created the Ad Settings webpage to provide information about and some choice over the profiles Google creates on users Nevertheless	background	2K_dev_138
these results can form the starting point for deeper investigations by either the companies themselves or by regulatory bodies	background	2K_dev_138
In particular	finding	2K_dev_138
we found that visiting webpages associated with substance abuse changed the ads shown but not the settings page	finding	2K_dev_138
We also found that setting the gender to female resulted in getting fewer instances of an ad related to high paying jobs than setting it to male We can not determine who caused these findings due to our limited visibility into the ad ecosystem	finding	2K_dev_138
which includes Google	finding	2K_dev_138
advertisers	finding	2K_dev_138
websites	finding	2K_dev_138
and users	finding	2K_dev_138
	finding	2K_dev_138
We present AdFisher	mechanism	2K_dev_138
an automated tool AdFisher can run browser-based experiments and analyze data using machine learning and significance tests	mechanism	2K_dev_138
Our tool uses a rigorous experimental design and statistical analysis to ensure the statistical soundness of our results	mechanism	2K_dev_138
We use AdFisher to find that the Ad Settings was opaque about some features of a user 's profile	mechanism	2K_dev_138
that it does provide some choice on ads	mechanism	2K_dev_138
and that these choices can lead to seemingly discriminatory ads	mechanism	2K_dev_138
	mechanism	2K_dev_138
	method	2K_dev_138
that explores how user behaviors	purpose	2K_dev_138
Google 's ads	purpose	2K_dev_138
and Ad Settings interact	purpose	2K_dev_138
	background	2K_dev_139
password reuse benefits users not only by reducing the number of passwords that the user has to memorize	finding	2K_dev_139
but more importantly by in- creasing the natural rehearsal rate for each password	finding	2K_dev_139
We introduce quantitative usability and security models In the same way that security proofs in cryptography are based on complexity- theoretic assumptions ( e	mechanism	2K_dev_139
g	mechanism	2K_dev_139
	mechanism	2K_dev_139
hardness of factoring and discrete loga- rithm )	mechanism	2K_dev_139
we quantify usability by introducing usability assumptions	mechanism	2K_dev_139
I n particular	mechanism	2K_dev_139
password management relies on assumptions about human memory	mechanism	2K_dev_139
e	mechanism	2K_dev_139
g	mechanism	2K_dev_139
	mechanism	2K_dev_139
that a user who follows a particular rehearsal schedule will successfully maintain the corresponding memory These assumptions are informed by research in cognitive science and can be tested empirically Given rehearsal requirements and a user 's visitation schedule for each account	mechanism	2K_dev_139
we use the total number of extra rehearsals that the user would have to do to remember all of his passwords as a measure of the usability of the password scheme Our usability model leads us to a key observa- tion : We also present a security model which accounts with multiple accounts and associated threats	mechanism	2K_dev_139
including online	mechanism	2K_dev_139
offline	mechanism	2K_dev_139
and plaintext password leak attacks	mechanism	2K_dev_139
	mechanism	2K_dev_139
we present Shared Cues a new scheme in which the underlying secret is strategi- cally shared across accounts to ensure that most rehearsal requirements are satisfied naturally while simultaneously providing strong security The construction uses the Chinese Remainder Theorem to achieve these competing goals	mechanism	2K_dev_139
	mechanism	2K_dev_139
	method	2K_dev_139
to guide the design of password management schemes systematic strate- gies to help users create and remember multiple passwords	purpose	2K_dev_139
for the complexity of password man- agement Observing that current pass- word management schemes are either insecure or unusable	purpose	2K_dev_139
Many important applications fall into the broad class of iterative convergent algorithms	background	2K_dev_140
Parallel implementations of these algorithms are naturally expressed using the Bulk Synchronous Parallel ( BSP ) model of computation	background	2K_dev_140
	background	2K_dev_140
	finding	2K_dev_140
This paper presents the Stale Synchronous Parallel ( SSP ) model as a generalization of BSP Algorithms using SSP can execute efficiently	mechanism	2K_dev_140
even with significant delays in some threads	mechanism	2K_dev_140
addressing the oft-faced straggler problem	mechanism	2K_dev_140
	mechanism	2K_dev_140
	method	2K_dev_140
However	purpose	2K_dev_140
implementations using BSP are plagued by the straggler problem	purpose	2K_dev_140
where every transient slowdown of any given thread can delay all other threads	purpose	2K_dev_140
that preserves many of its advantages	purpose	2K_dev_140
while avoiding the straggler problem	purpose	2K_dev_140
	purpose	2K_dev_140
Ductal Carcinoma In Situ ( DCIS ) is a precursor lesion of Invasive Ductal Carcinoma ( IDC ) of the breast Investigating its temporal progression could provide fundamental new insights for the development of better diagnostic tools to predict which cases of DCIS will progress to IDC	background	2K_dev_141
The approach provides new insights into mechanisms of clonal progression in breast cancers and helps illustrate the power of the ILP approach for similar problems in reconstructing tumor evolution scenarios under complex sets of constraints	background	2K_dev_141
show that the corresponding predicted progression models are classifiable into categories having specific evolutionary characteristics	finding	2K_dev_141
Specifically	mechanism	2K_dev_141
by using a number of assumptions derived from the observation of cellular atypia occurring in IDC	mechanism	2K_dev_141
we design a possible predictive model using integer linear programming ( ILP )	mechanism	2K_dev_141
Computational experiments carried out on a preexisting data set of 13 patients with simultaneous DCIS and IDC	method	2K_dev_141
We investigate the problem of reconstructing a plausible progression from single-cell sampled data of an individual with synchronous DCIS and IDC	purpose	2K_dev_141
	purpose	2K_dev_141
A variety of problems in computing	background	2K_dev_142
service	background	2K_dev_142
and manufacturing systems can be modeled via infinite repeating Markov chains with an infinite number of levels and a finite number of phases	background	2K_dev_142
	background	2K_dev_142
	finding	2K_dev_142
We present a procedure	mechanism	2K_dev_142
which we call Clearing Analysis on Phases ( CAP ) The CAP method yields the limiting probability of each state in the repeating portion of the chain as a linear combination of scalar bases raised to a power corresponding to the level of the state	mechanism	2K_dev_142
The weights in these linear combinations can be determined by solving a finite system of linear equations	mechanism	2K_dev_142
	mechanism	2K_dev_142
	method	2K_dev_142
Many such chains are quasi-birth-death processes with transitions that are skip-free in level	purpose	2K_dev_142
in that one can only transition between consecutive levels	purpose	2K_dev_142
and unidirectional in phase	purpose	2K_dev_142
in that one can only transition from lower-numbered phases to higher-numbered phases for determining the limiting probabilities of such Markov chains exactly	purpose	2K_dev_142
	purpose	2K_dev_142
Any strong Nash equilibrium outcome is Pareto efficient for each coalition	background	2K_dev_143
Our main result	finding	2K_dev_143
in its simplest form	finding	2K_dev_143
states that if a game has a strong Nash equilibrium with full support ( that is	finding	2K_dev_143
both players randomize among all pure strategies )	finding	2K_dev_143
then the game is strictly competitive	finding	2K_dev_143
we use the indifference principle fulfilled by any Nash equilibrium	mechanism	2K_dev_143
and the classical KKT conditions ( in the vector setting )	mechanism	2K_dev_143
that are necessary conditions for Pareto efficiency	mechanism	2K_dev_143
Our characterization enables us to design a strong-Nash-equilibrium-finding algorithm with complexity in Smoothed- $ \mathcal { P } $	mechanism	2K_dev_143
So	mechanism	2K_dev_143
this problem -- -that Conitzer and Sandholm [ Conitzer	mechanism	2K_dev_143
V	mechanism	2K_dev_143
	mechanism	2K_dev_143
Sandholm	mechanism	2K_dev_143
T	mechanism	2K_dev_143
	mechanism	2K_dev_143
2008	mechanism	2K_dev_143
New complexity results about Nash equilibria	mechanism	2K_dev_143
Games Econ	mechanism	2K_dev_143
Behav	mechanism	2K_dev_143
63	mechanism	2K_dev_143
621 -- 641 ] proved to be computationally hard in the worst case -- -is generically easy	mechanism	2K_dev_143
Hence	mechanism	2K_dev_143
although the worst case complexity of finding a strong Nash equilibrium is harder than that of finding a Nash equilibrium	mechanism	2K_dev_143
once small perturbations are applied	mechanism	2K_dev_143
finding a strong Nash is easier than finding a Nash equilibrium Next we switch to the setting with more than two players	mechanism	2K_dev_143
We demonstrate that a strong Nash equilibrium can exist in which an outcome that is strictly Pareto dominated by a Nash equilibrium occurs with positive probability Finally	mechanism	2K_dev_143
we prove that games that have a strong Nash equilibrium where at least one player puts positive probability on at least two pure strategies are extremely rare : they are of zero measure	mechanism	2K_dev_143
	mechanism	2K_dev_143
First	method	2K_dev_143
we analyze the two -- player setting	method	2K_dev_143
In this paper we consider strong Nash equilibria	purpose	2K_dev_143
in mixed strategies	purpose	2K_dev_143
for finite games	purpose	2K_dev_143
In order to get our result	purpose	2K_dev_143
Many real world network problems often concern multivariate nodal attributes such as image	background	2K_dev_144
textual	background	2K_dev_144
and multi-view feature vectors on nodes	background	2K_dev_144
rather than simple univariate nodal attributes	background	2K_dev_144
	background	2K_dev_144
demonstrate performance of our method under various conditions	finding	2K_dev_144
	finding	2K_dev_144
In this paper	mechanism	2K_dev_144
we propose a new principled framework Instead of estimating the partial correlation as in current literature	mechanism	2K_dev_144
our method estimates the partial canonical correlations that naturally accommodate complex nodal features Computationally	mechanism	2K_dev_144
we provide an efficient algorithm which utilizes the multi-attribute structure	mechanism	2K_dev_144
Theoretically	mechanism	2K_dev_144
we provide sufficient conditions which guarantee consistent graph recovery	mechanism	2K_dev_144
Extensive simulation studies	method	2K_dev_144
The existing graph estimation methods built on Gaussian graphical models and covariance selection algorithms can not handle such data	purpose	2K_dev_144
neither can the theories developed around such methods be directly applied	purpose	2K_dev_144
for estimating multi-attribute graphs	purpose	2K_dev_144
	purpose	2K_dev_144
Proceedings : AACR 106th Annual Meeting 2015 ; April 18-22	background	2K_dev_145
2015 ; Philadelphia	background	2K_dev_145
PA Intratumor heterogeneity has long been a confounding factor in interpreting cancer genomic data	background	2K_dev_145
but has also been useful in reconstructing progression processes based on variation between clonal populations in single tumors We previously developed a strategy of applying computational deconvolution algorithms to gene expression or DNA copy number data to reconstruct models of progression of cell populations from bulk tumor samples	background	2K_dev_145
Citation Format : Theodore Roman	background	2K_dev_145
Russell Schwartz	background	2K_dev_145
All methods perform comparably on unstructured data but the new method substantially outperforms the others on data consistent with simple scenarios for tumor progression along multiple discrete subtypes	finding	2K_dev_145
The novel method	finding	2K_dev_145
however	finding	2K_dev_145
shows lower tolerance for noisy data than a Gaussian mixture model	finding	2K_dev_145
showed our method could partition tumors into discrete subcategories associated with HER2+	finding	2K_dev_145
ER/PR+	finding	2K_dev_145
and triple-negative status and could exploit the resulting substructure of the data to deconvolve tumor data and infer progression models reflecting partial sharing of progression states between subtypes	finding	2K_dev_145
showed association of deconvolved cell populations with a variety of gene functional categories suggestive of distinct progression mechanisms of the subtypes	finding	2K_dev_145
	finding	2K_dev_145
We present a novel approach designed to leverage the fact that tumors that partition into subtypes with similar evolutionary trajectories would be expected to lead to a mathematical substructure in the genomic data	mechanism	2K_dev_145
known as a simplicial complex	mechanism	2K_dev_145
which can be modeled computationally We have developed a computational pipeline while taking into consideration this kind of mathematical structure The pipeline clusters tumors to identify genetically distinct subgroups	mechanism	2K_dev_145
fits mixture models to these subgroups	mechanism	2K_dev_145
and uses overlap between them to infer a refined deconvolution of major cellular populations and possible pathways of progression between them	mechanism	2K_dev_145
	mechanism	2K_dev_145
We apply our methods to a set of RNASeq data from the TCGA breast cancer data set and to synthetic data modeling distinct scenarios of tumor progression	method	2K_dev_145
We first compare our methods on the synthetic data to our earlier work and to a comparative Gaussian mixture model	method	2K_dev_145
Application to the TCGA RNASeq data Gene enrichment analysis	method	2K_dev_145
Many tools have since been proposed for similar deconvolution analysis	purpose	2K_dev_145
but all are limited by the computational difficulty of unambiguously distinguishing small cell populations and variants from noise in genomic assays to infer tumor progression pathways from deconvolved genomic data to better deconvolve cell populations across tumor types	purpose	2K_dev_145
to perform tumor deconvolution Improved deconvolution of heterogeneous tumor data to reconstruct clonal evolution from bulk genomic samples	purpose	2K_dev_145
Signals and datasets that arise in physical and engineering applications	background	2K_dev_146
as well as social	background	2K_dev_146
genetics	background	2K_dev_146
biomolecular	background	2K_dev_146
and many other domains	background	2K_dev_146
are becoming increasingly larger and more complex	background	2K_dev_146
In contrast to traditional time and image signals	background	2K_dev_146
data in these domains are supported by arbitrary graphs	background	2K_dev_146
Signal processing on graphs extends concepts and techniques from traditional signal processing to data indexed by generic graphs	background	2K_dev_146
In traditional signal processing	background	2K_dev_146
these concepts are easily defined because of a natural frequency ordering that has a physical interpretation	background	2K_dev_146
For signals residing on graphs	background	2K_dev_146
in general	background	2K_dev_146
there is no obvious frequency ordering	background	2K_dev_146
	background	2K_dev_146
	finding	2K_dev_146
We propose a definition of total variation that naturally leads to a frequency ordering on graphs and defines low-	mechanism	2K_dev_146
high-	mechanism	2K_dev_146
and band-pass graph signals and filters	mechanism	2K_dev_146
	mechanism	2K_dev_146
We study the design of graph filters with specified frequency response	method	2K_dev_146
and illustrate our approach with applications to sensor malfunction detection and data classification	method	2K_dev_146
	method	2K_dev_146
This paper studies the concepts of low and high frequencies on graphs	purpose	2K_dev_146
and low-	purpose	2K_dev_146
high- and band-pass graph signals and graph filters	purpose	2K_dev_146
for graph signals	purpose	2K_dev_146
Block tridiagonal matrices arise in applied mathematics	background	2K_dev_147
physics	background	2K_dev_147
and signal processing	background	2K_dev_147
Many applications require knowledge of eigenvalues and eigenvectors of block tridiagonal matrices	background	2K_dev_147
which can be prohibitively expensive for large matrix sizes	background	2K_dev_147
that our work can lead to fast algorithms for the eigenvector expansion for block tridiagonal matrices	finding	2K_dev_147
by studying a connection between their eigenvalues and zeros of appropriate matrix polynomials We use this connection with matrix polynomials to derive a closed-form expression for the eigenvectors of block tridiagonal matrices	mechanism	2K_dev_147
which eliminates the need for their direct calculation and can lead to a faster calculation of eigenvalues	mechanism	2K_dev_147
We also demonstrate with an example	method	2K_dev_147
In this paper	purpose	2K_dev_147
we address the problem of the eigendecomposition of block tridiagonal matrices	purpose	2K_dev_147
	background	2K_dev_148
and confirm the effectiveness of the proposed approach	finding	2K_dev_148
	finding	2K_dev_148
Instead of indifferently pooling the shots	mechanism	2K_dev_148
we first define a novel notion of semantic saliency that assesses the relevance of each shot with the event of interest We then prioritize the shots according to their saliency scores since shots that are semantically more salient are expected to contribute more to the final event detector	mechanism	2K_dev_148
Next	mechanism	2K_dev_148
we propose a new isotonic regularizer that is able to exploit the semantic ordering information The resulting nearly-isotonic SVM classifier exhibits higher discriminative power Computationally	mechanism	2K_dev_148
we develop an efficient implementation using the proximal gradient algorithm	mechanism	2K_dev_148
and we prove new	mechanism	2K_dev_148
closed-form proximal steps	mechanism	2K_dev_148
	mechanism	2K_dev_148
We conduct extensive experiments on three real-world video datasets	method	2K_dev_148
We aim to detect complex events in long Internet videos that may last for hours A major challenge in this setting is that only a few shots in a long video are relevant to the event of interest while others are irrelevant or even misleading	purpose	2K_dev_148
which may be of independent interest	background	2K_dev_149
	finding	2K_dev_149
We present faster algorithms such as bounded genus	mechanism	2K_dev_149
minor free	mechanism	2K_dev_149
and geometric graphs Given such a graph with n vertices	mechanism	2K_dev_149
m edges along with a recursive n-vertex separator structure	mechanism	2K_dev_149
our algorithm finds an 1 -- e approximate maximum flow in time O ( m6/5poly ( e -- 1 ) )	mechanism	2K_dev_149
ignoring poly-logarithmic terms Similar speedups are also achieved for separable graphs with larger size separators albeit with larger run times These bounds also apply to image problems in two and three dimensions	mechanism	2K_dev_149
Key to our algorithm is an intermediate problem that we term grouped L2 flow	mechanism	2K_dev_149
which exists between maximum flows and electrical flows	mechanism	2K_dev_149
Our algorithm also makes use of spectral vertex sparsifiers in order to remove vertices while preserving the energy dissipation of electrical flows We also give faster spectral vertex sparsification algorithms on well separated graphs	mechanism	2K_dev_149
	mechanism	2K_dev_149
	method	2K_dev_149
for approximate maximum flow in undirected graphs with good separator structures	purpose	2K_dev_149
	purpose	2K_dev_149
The cake cutting problem models the fair division of a heterogeneous good between multiple agents	background	2K_dev_150
Previous work assumes that each agent derives value only from its own piece	background	2K_dev_150
	background	2K_dev_150
	finding	2K_dev_150
We extend the classical model Our technical results characterize the relationship between these generalized properties	mechanism	2K_dev_150
establish the existence or nonexistence of fair allocations	mechanism	2K_dev_150
and explore the computational feasibility of fairness in the face of externalities	mechanism	2K_dev_150
	mechanism	2K_dev_150
	method	2K_dev_150
However	purpose	2K_dev_150
agents may also care about the pieces assigned to other agents ; such externalities naturally arise in fair division settings	purpose	2K_dev_150
to capture externalities	purpose	2K_dev_150
and generalize the classical fairness notions of proportionality and envyfreeness	purpose	2K_dev_150
	purpose	2K_dev_150
	background	2K_dev_151
Our first contribution is the discovery that the relative frequencies obey a power-law ( sub-linear	finding	2K_dev_151
or super-linear )	finding	2K_dev_151
for a wide variety of diverse settings : tasks in a phone- call network	finding	2K_dev_151
like count of friends	finding	2K_dev_151
count of phone-calls	finding	2K_dev_151
total count of minutes ; tasks in a twitter-like network	finding	2K_dev_151
like count of tweets	finding	2K_dev_151
count of followees etc	finding	2K_dev_151
We show how to use our observations to spot clusters and outliers	finding	2K_dev_151
like	finding	2K_dev_151
e	finding	2K_dev_151
g	finding	2K_dev_151
	finding	2K_dev_151
telemarketers in our phone-call network	finding	2K_dev_151
	finding	2K_dev_151
The second contribution is that we further provide a full	mechanism	2K_dev_151
digitized 2-d distribution	mechanism	2K_dev_151
which we call the Almond-DG model	mechanism	2K_dev_151
thanks to the shape of its iso-surfaces	mechanism	2K_dev_151
The Almond-DG model matches all our empirical observations : super-linear relationships among variables	mechanism	2K_dev_151
and ( provably ) log-logistic marginals	mechanism	2K_dev_151
	mechanism	2K_dev_151
We illustrate our observations on two large	method	2K_dev_151
real network datasets	method	2K_dev_151
spanning 2	method	2K_dev_151
2M and 3	method	2K_dev_151
1M individu- als with 5 features each	method	2K_dev_151
If Alice has double the friends of Bob	purpose	2K_dev_151
will she also have dou- ble the phone-calls ( or wall-postings	purpose	2K_dev_151
or tweets ) ?	purpose	2K_dev_151
	background	2K_dev_152
	finding	2K_dev_152
	mechanism	2K_dev_152
	method	2K_dev_152
	purpose	2K_dev_152
Kidney exchange provides a life-saving alternative to long waiting lists for patients in need of a new kidney	background	2K_dev_153
Fielded exchanges typically match under utilitarian or near-utilitarian rules ; this approach marginalizes certain classes of patients	background	2K_dev_153
	background	2K_dev_153
	finding	2K_dev_153
we formally adapt a recently introduced measure of the tradeoff between fairness and efficiency -- -the price of fairness -- -to the standard kidney exchange model	mechanism	2K_dev_153
We show that the price of fairness in the standard theoretical model is small	mechanism	2K_dev_153
We then introduce two natural definitions of fairness	mechanism	2K_dev_153
and empirically explore the tradeoff between matching more hard-to-match patients and the overall utility of a utilitarian matching	method	2K_dev_153
on real data from the UNOS nationwide kidney exchange and simulated data from each of the standard kidney exchange distributions	method	2K_dev_153
In this paper	purpose	2K_dev_153
we focus on improving access to kidneys for highly-sensitized	purpose	2K_dev_153
or hard-to-match	purpose	2K_dev_153
patients Toward this end	purpose	2K_dev_153
	purpose	2K_dev_153
	background	2K_dev_154
	finding	2K_dev_154
	mechanism	2K_dev_154
	method	2K_dev_154
	purpose	2K_dev_154
Abstract : Privacy policies in sectors as diverse as Web services	background	2K_dev_155
finance and healthcare often place restrictions on the purposes for which a governed entity may use personal information	background	2K_dev_155
	background	2K_dev_155
	finding	2K_dev_155
using a formalism based on planning	mechanism	2K_dev_155
We model planning using Partially Observable Markov Decision Processes ( POMDPs )	mechanism	2K_dev_155
which supports an explicit model of information We argue that information use is for a purpose if and only if the information is used while planning to optimize the satisfaction of that purpose under the POMDP model We determine information use by simulating ignorance of the information prohibited by the purpose restriction	mechanism	2K_dev_155
which we relate to noninterference	mechanism	2K_dev_155
We use this semantics to develop a sound audit algorithm	mechanism	2K_dev_155
	method	2K_dev_155
Thus	purpose	2K_dev_155
automated methods for enforcing privacy policies require a semantics of purpose restrictions to determine whether a governed agent used information for a purpose	purpose	2K_dev_155
We provide such a semantics to automate the enforcement of purpose restrictions	purpose	2K_dev_155
	background	2K_dev_156
PLRE training is efficient and our approach outperforms stateof-the-art modified Kneser Ney baselines in terms of perplexity on large corpora as well as on BLEU score in a downstream machine translation task	finding	2K_dev_156
	finding	2K_dev_156
We present power low rank ensembles ( PLRE )	mechanism	2K_dev_156
a flexible framework where ensembles of low rank matrices and tensors are used to obtain smoothed probability estimates of words in context	mechanism	2K_dev_156
Our method can be understood as a generalization of ngram modeling to non-integer n	mechanism	2K_dev_156
and includes standard techniques such as absolute discounting and Kneser-Ney smoothing as special cases	mechanism	2K_dev_156
	method	2K_dev_156
for n-gram language modeling	purpose	2K_dev_156
contributing to the general theory of large deviations	background	2K_dev_157
When the topology is deterministic	finding	2K_dev_157
we establish the large deviations principle and find exactly the corresponding rate function	finding	2K_dev_157
equal at all nodes	finding	2K_dev_157
We show that the dependence of the rate function on the stochastic weight matrix associated with the network is fully captured by its left eigenvector corresponding to the unit eigenvalue	finding	2K_dev_157
Further	finding	2K_dev_157
when the sensors observations are Gaussian	finding	2K_dev_157
the rate function admits a closed-form expression	finding	2K_dev_157
we show that the network design problem can be formulated as a semidefinite ( convex ) program	finding	2K_dev_157
and hence can be solved efficiently the system exhibits an interesting property : the graph of the rate function always lies between the graphs of the rate function of an isolated node and the rate function of a fusion center that has access to all observations We prove that this fundamental property holds even when the topology and the associated system matrices change randomly over time	finding	2K_dev_157
with arbitrary distribution	finding	2K_dev_157
	finding	2K_dev_157
Motivated by these observations	mechanism	2K_dev_157
we formulate the optimal network design problem of	mechanism	2K_dev_157
for a given target accuracy	mechanism	2K_dev_157
This eigenvector therefore minimizes the time that the inference algorithm needs to reach the desired accuracy	mechanism	2K_dev_157
Due to the generality of its assumptions	mechanism	2K_dev_157
the latter result requires more subtle techniques than the standard large deviations tools	mechanism	2K_dev_157
	mechanism	2K_dev_157
For Gaussian observations When observations are identically distributed across agents	method	2K_dev_157
	method	2K_dev_157
We find large deviations rates for consensus-based distributed inference for directed networks finding the left eigenvector that achieves the highest value of the rate function	purpose	2K_dev_157
Our study has the potential to help advertisers design keyword portfolios	background	2K_dev_158
and help search engines improve the quality of sponsored ads	background	2K_dev_158
We find that consumer click behaviors vary significantly across keywords	finding	2K_dev_158
and keyword category and contextual ambiguity significantly affect such variation	finding	2K_dev_158
Specifically	finding	2K_dev_158
higher contextual ambiguity can lead to higher click-through rate ( CTR ) on top-positioned ads	finding	2K_dev_158
but the CTR tends to decay faster with position	finding	2K_dev_158
We propose based on topic models from machine learning and computational linguistics We quantify the effect of contextual ambiguity on keyword click-through performance using a hierarchical Bayesian model	mechanism	2K_dev_158
	mechanism	2K_dev_158
and validate our study using a novel dataset from a major search engine containing information on click activities for 12	method	2K_dev_158
790 keywords across multiple categories from over 4	method	2K_dev_158
6 million impressions	method	2K_dev_158
In this paper	purpose	2K_dev_158
we explore how the contextual ambiguity of a search can affect a keyword 's performance	purpose	2K_dev_158
an automatic way of categorizing keywords and examining keyword contextual ambiguity	purpose	2K_dev_158
Function to function regression ( FFR ) covers a large range of interesting applications including timeseries prediction problems	background	2K_dev_159
and also more general tasks like studying a mapping between two separate types of distributions	background	2K_dev_159
	background	2K_dev_159
Furthermore	finding	2K_dev_159
we show an improvement of several orders of magnitude in terms of prediction speed and a reduction in error over previous estimators	finding	2K_dev_159
we develop a novel scalable nonparametric estimator	mechanism	2K_dev_159
the Triple-Basis Estimator ( 3BE )	mechanism	2K_dev_159
which is capable of operating over data-sets with many instances	mechanism	2K_dev_159
To the best of our knowledge	mechanism	2K_dev_159
the 3BE is the first nonparametric FFR estimator that can scale to massive data-sets	mechanism	2K_dev_159
We analyze the 3BEs risk and derive an upperbound rate	method	2K_dev_159
in various real-world datasets	method	2K_dev_159
	method	2K_dev_159
We analyze the problem of regression when both input covariates and output responses are functions from a nonparametric function class	purpose	2K_dev_159
However	purpose	2K_dev_159
previous nonparametric estimators for FFR type problems scale badly computationally with the number of input/output pairs in a data-set Given the complexity of a mapping between general functions it may be necessary to consider large datasets in order to achieve a low estimation risk	purpose	2K_dev_159
To address this issue	purpose	2K_dev_159
	purpose	2K_dev_159
An interesting challenge for the cryptography community is to design authentication protocols that are so simple that a human can execute them without relying on a fully trusted computer	background	2K_dev_160
	background	2K_dev_160
For these schemes	finding	2K_dev_160
we prove that forging passwords is equivalent to recovering the secret mapping Thus	finding	2K_dev_160
our human computable password schemes can maintain strong security guarantees even after an adversary has observed the user login to many different accounts	finding	2K_dev_160
	finding	2K_dev_160
We propose several candidate authentication protocols -- - a computer that stores information and performs computations correctly but does not provide confidentiality	mechanism	2K_dev_160
Our schemes use a semi-trusted computer to store and display public challenges $ C_i\in [ n ] ^k $	mechanism	2K_dev_160
The human user memorizes a random secret mapping $ \sigma : [ n ] \rightarrow\mathbb { Z } _d $ and authenticates by computing responses $ f ( \sigma ( C_i ) ) $ to a sequence of public challenges where $ f : \mathbb { Z } _d^k\rightarrow\mathbb { Z } _d $ is a function that is easy for the human to evaluate	mechanism	2K_dev_160
We prove that any statistical adversary needs to sample $ m=\tilde { \Omega } ( n^ { s ( f ) } ) $ challenge-response pairs to recover $ \sigma $	mechanism	2K_dev_160
for a security parameter $ s ( f ) $ that depends on two key properties To obtain our results	mechanism	2K_dev_160
we apply the general hypercontractivity theorem to lower bound the statistical dimension of the distribution over challenge-response pairs induced by $ f $ and $ \sigma $	mechanism	2K_dev_160
Our lower bounds apply to arbitrary functions $ f $ ( not just to functions that are easy for a human to evaluate )	mechanism	2K_dev_160
and generalize recent results of Feldman et al	mechanism	2K_dev_160
	mechanism	2K_dev_160
As an application	method	2K_dev_160
we propose a family of human computable password functions $ f_ { k_1	method	2K_dev_160
k_2 } $ in which the user needs to perform $ 2k_1+2k_2+1 $ primitive operations ( e	method	2K_dev_160
g	method	2K_dev_160
	method	2K_dev_160
adding two digits or remembering $ \sigma ( i ) $ )	method	2K_dev_160
and we show that $ s ( f ) 0 \min\ { k_1+1	method	2K_dev_160
( k_2+1 ) /2\ } $	method	2K_dev_160
	method	2K_dev_160
for a setting in which the human user can only receive assistance from a semi-trusted computer	purpose	2K_dev_160
To achieve maximum security	background	2K_dev_161
defenders must perfectly synchronize their randomized allocations of resources	background	2K_dev_161
	background	2K_dev_161
indicate that the loss may be extremely high in the worst case	finding	2K_dev_161
establish a smaller yet significant loss in practice	finding	2K_dev_161
We introduce two notions under different assumptions : the price of miscoordination	mechanism	2K_dev_161
and the price of sequential commitment	mechanism	2K_dev_161
Generally speaking	method	2K_dev_161
our theoretical bounds while our simulations	method	2K_dev_161
We study security games with multiple defenders However	purpose	2K_dev_161
in real-life scenarios ( such as protection of the port of Boston ) this is not the case	purpose	2K_dev_161
Our goal is to quantify the loss incurred by miscoordination between defenders	purpose	2K_dev_161
both theoretically and empirically	purpose	2K_dev_161
that capture this loss	purpose	2K_dev_161
In real world industrial applications of topic modeling	background	2K_dev_162
the ability to capture gigantic conceptual space by learning an ultra-high dimensional topical representation	background	2K_dev_162
i	background	2K_dev_162
e	background	2K_dev_162
	background	2K_dev_162
the so-called `` big model ''	background	2K_dev_162
is becoming the next desideratum after enthusiasms on `` big data ''	background	2K_dev_162
especially for fine-grained downstream tasks such as online advertising	background	2K_dev_162
where good performances are usually achieved by regression-based predictors built on millions if not billions of input features	background	2K_dev_162
	background	2K_dev_162
demonstrate the ability of this system to handle topic modeling with unprecedented amount of 200 billion model variables only on a low-end cluster with very limited computational resources and bandwidth	finding	2K_dev_162
we explore another type of parallelism	mechanism	2K_dev_162
namely model-parallelism	mechanism	2K_dev_162
By integrating data-parallelism with model-parallelism	mechanism	2K_dev_162
we show that dependencies between distributed elements can be handled seamlessly	mechanism	2K_dev_162
achieving not only faster convergence but also an ability to tackle significantly bigger model size We describe an architecture for model-parallel inference of LDA	mechanism	2K_dev_162
and present a variant of collapsed Gibbs sampling algorithm tailored for it	mechanism	2K_dev_162
Experimental results	method	2K_dev_162
The conventional data-parallel approach for training gigantic topic models turns out to be rather inefficient in utilizing the power of parallelism	purpose	2K_dev_162
due to the heavy dependency on a centralized image of `` model ''	purpose	2K_dev_162
Big model size also poses another challenge on the storage	purpose	2K_dev_162
where available model size is bounded by the smallest RAM of nodes	purpose	2K_dev_162
To address these issues	purpose	2K_dev_162
which enables training of disjoint blocks of a big topic model in parallel	purpose	2K_dev_162
	purpose	2K_dev_162
The proliferation of mobile devices that are capable of estimating their position	background	2K_dev_163
has lead to the emergence of a new class of social networks	background	2K_dev_163
namely location-based social networks ( LBSNs for short )	background	2K_dev_163
The main interaction between users in an LBSN is location sharing	background	2K_dev_163
To the best of our knowledge	background	2K_dev_163
this is the first attempt to model this problem using tensor analysis	background	2K_dev_163
	background	2K_dev_163
	finding	2K_dev_163
In this work	mechanism	2K_dev_163
we propose the use of tensor decomposition	mechanism	2K_dev_163
	method	2K_dev_163
While the latter can be realized through continuous tracking of a user 's whereabouts from the service provider	purpose	2K_dev_163
the majority of LBSNs allow users to voluntarily share their location	purpose	2K_dev_163
through check-ins	purpose	2K_dev_163
LBSNs provide incentives to users to perform check-ins	purpose	2K_dev_163
However	purpose	2K_dev_163
these incentives can also lead to people faking their location	purpose	2K_dev_163
thus	purpose	2K_dev_163
generating false information	purpose	2K_dev_163
for spotting anomalies in the check-in behavior of users	purpose	2K_dev_163
	purpose	2K_dev_163
The computational characterization of game-theoretic solution concepts is a central topic in artificial intelligence	background	2K_dev_164
with the aim of developing computationally efficient tools for finding optimal ways to behave in strategic interactions	background	2K_dev_164
The central solution concept in game theory is Nash equilibrium ( NE )	background	2K_dev_164
However	background	2K_dev_164
it fails to capture the possibility that agents can form coalitions ( even in the 2-agent case )	background	2K_dev_164
Strong Nash equilibrium ( SNE ) refines NE to this setting	background	2K_dev_164
It is known that finding an SNE is NP-complete when the number of agents is constant	background	2K_dev_164
This hardness is solely due to the existence of mixed-strategy SNEs	background	2K_dev_164
given that the problem of enumerating all pure-strategy SNEs is trivially in P	background	2K_dev_164
	background	2K_dev_164
	finding	2K_dev_164
First	mechanism	2K_dev_164
we develop worst-case instances for support-enumeration algorithms	mechanism	2K_dev_164
These instances have only one SNE and the support size can be chosen to be of any size-in particular	mechanism	2K_dev_164
arbitrarily large	mechanism	2K_dev_164
Second	mechanism	2K_dev_164
we prove that	mechanism	2K_dev_164
unlike NE	mechanism	2K_dev_164
finding an SNE is in smoothed polynomial time : generic game instances ( i	mechanism	2K_dev_164
e	mechanism	2K_dev_164
	mechanism	2K_dev_164
all instances except knife-edge cases ) have only pure-strategy SNEs	mechanism	2K_dev_164
	method	2K_dev_164
Our central result is that	purpose	2K_dev_164
in order for a game to have at least one non-pure-strategy SNE	purpose	2K_dev_164
the agents ' payoffs restricted to the agents ' supports must	purpose	2K_dev_164
in the case of 2 agents	purpose	2K_dev_164
lie on the same line	purpose	2K_dev_164
and	purpose	2K_dev_164
in the case of n agents	purpose	2K_dev_164
lie on an ( n - 1 ) -dimensional hyperplane	purpose	2K_dev_164
Leveraging this result	purpose	2K_dev_164
we provide two contributions	purpose	2K_dev_164
If we know most of Smith 's friends are from Boston	background	2K_dev_165
what can we say about the rest of Smith 's friends ? which is one of the most important topics in AI and Web communities	background	2K_dev_165
	background	2K_dev_165
We also prove the theoretical connections of our algorithm to the semi-supervised learning ( SSL ) algorithms and to random-walks demonstrate the benefits of the proposed algorithm	finding	2K_dev_165
where OMNI-Prop outperforms the top competitors	finding	2K_dev_165
	finding	2K_dev_165
Our proposed algorithm which is referred to as OMNI-Prop has the following properties : ( a ) seamless and accurate ; it works well on any label correlations ( i	mechanism	2K_dev_165
e	mechanism	2K_dev_165
	mechanism	2K_dev_165
homophily	mechanism	2K_dev_165
het-erophily	mechanism	2K_dev_165
and mixture of them ) ( b ) fast ; it is efficient and guaranteed to converge on arbitrary graphs ( c ) quasi-parameter free ; it has just one well-interpretable parameter with heuristic default value of 1	mechanism	2K_dev_165
	mechanism	2K_dev_165
Experiments on four real	method	2K_dev_165
different network datasets	method	2K_dev_165
In this paper	purpose	2K_dev_165
we focus on the node classification problem on networks	purpose	2K_dev_165
	purpose	2K_dev_165
Single virus epidemics over complete networks are widely explored in the literature as the fraction of infected nodes is	background	2K_dev_166
under appropriate microscopic modeling of the virus infection	background	2K_dev_166
a Markov process	background	2K_dev_166
With non-complete networks	background	2K_dev_166
this macroscopic variable is no longer Markov	background	2K_dev_166
we show that the peer-to-peer local random rules of virus infection lead	finding	2K_dev_166
in the limit of large multipartite networks	finding	2K_dev_166
to the emergence of structured dynamics at the macroscale The exact fluid limit evolution of the fraction of nodes infected by each virus strain across islands obeys a set of nonlinear coupled differential equations	finding	2K_dev_166
see this http URL	finding	2K_dev_166
In this paper	mechanism	2K_dev_166
we develop methods	mechanism	2K_dev_166
In companying work this http URL	method	2K_dev_166
In this paper	purpose	2K_dev_166
we study virus diffusion	purpose	2K_dev_166
in particular	purpose	2K_dev_166
multi-virus epidemics	purpose	2K_dev_166
over non-complete stochastic networks	purpose	2K_dev_166
We focus on multipartite networks to analyze the qualitative behavior of these limiting dynamics	purpose	2K_dev_166
establishing conditions on the virus micro characteristics and network structure under which a virus persists or a natural selection phenomenon is observed	purpose	2K_dev_166
	purpose	2K_dev_166
Many modern machine learning ( ML ) algorithms are iterative	background	2K_dev_167
converging on a final solution via many iterations over the input data	background	2K_dev_167
	background	2K_dev_167
show that both approaches significantly increase convergence speeds	finding	2K_dev_167
behaving similarly when there are no stragglers	finding	2K_dev_167
but SSP outperforms BSP in the presence of stragglers	finding	2K_dev_167
	finding	2K_dev_167
Specifically	mechanism	2K_dev_167
we focus on bounded staleness	mechanism	2K_dev_167
in which each thread can see a view of the current intermediate solution that may be a limited number of iterations out-of-date	mechanism	2K_dev_167
Allowing staleness reduces communication costs ( batched updates and cached reads ) and synchronization ( less waiting for locks or straggling threads ) One approach is to increase the number of iterations between barriers in the oft-used Bulk Synchronous Parallel ( BSP ) model of parallelizing	mechanism	2K_dev_167
which mitigates these costs when all threads proceed at the same speed	mechanism	2K_dev_167
A more flexible approach	mechanism	2K_dev_167
called Stale Synchronous Parallel ( SSP )	mechanism	2K_dev_167
avoids barriers and allows threads to be a bounded number of iterations ahead of the current slowest thread	mechanism	2K_dev_167
Extensive experiments with ML algorithms for topic modeling	method	2K_dev_167
collaborative filtering	method	2K_dev_167
and PageRank	method	2K_dev_167
This paper explores approaches to exploiting these algorithms ' convergent nature to improve performance	purpose	2K_dev_167
by allowing parallel and distributed threads to use loose consistency models for shared algorithm state	purpose	2K_dev_167
	background	2K_dev_168
	finding	2K_dev_168
as a function of decimal-number representations of regions of the first and second images	mechanism	2K_dev_168
The decimal-number representations are generated by performing discrete transforms on the regions so as to obtain discrete-transform coefficients	mechanism	2K_dev_168
performing local-bit-pattern encoding of the coefficients to create data streams	mechanism	2K_dev_168
and converting the data streams to decimal numbers In one embodiment	mechanism	2K_dev_168
the first and second images depict periocular facial regions	mechanism	2K_dev_168
and the disclosed techniques Subspace modeling may be used to improve accuracy	mechanism	2K_dev_168
	mechanism	2K_dev_168
	method	2K_dev_168
Determining a match between the subjects of first and second images can be used for face recognition	purpose	2K_dev_168
even where a small portion of a person 's face is captured in an image	purpose	2K_dev_168
	purpose	2K_dev_168
Practical applications of Bayesian nonparametric ( BNP ) models have been limited	background	2K_dev_169
due to their high computational complexity and poor scaling on large data	background	2K_dev_169
and the near-linear scalability indicates great potential for even bigger problem sizes	background	2K_dev_169
	background	2K_dev_169
our system learns a 10K-node DNT topic model on 8M documents that captures both high-frequency and longtail topics	finding	2K_dev_169
Our data and model scales are orders-of-magnitude larger than recent results on the hierarchical Dirichlet process	finding	2K_dev_169
	finding	2K_dev_169
and develop a large-scale distributed training system Our major contributions include : ( 1 ) an effective memoized variational inference for DNTs	mechanism	2K_dev_169
with a novel birth-merge strategy for exploring the unbounded tree space ; ( 2 ) a model-parallel scheme for concurrent tree growing/pruning and efficient model alignment	mechanism	2K_dev_169
through conflict-free model partitioning and lightweight synchronization ; ( 3 ) a data-parallel scheme for variational parameter updates that allows distributed processing of massive data	mechanism	2K_dev_169
	mechanism	2K_dev_169
Using 64 cores in 36 hours	method	2K_dev_169
	method	2K_dev_169
In this paper	purpose	2K_dev_169
we consider dependent nonparametric trees ( DNTs )	purpose	2K_dev_169
a powerful infinite model that captures time-evolving hierarchies	purpose	2K_dev_169
	purpose	2K_dev_169
It is unsolved even for two bidders and two items for sale	background	2K_dev_170
	background	2K_dev_170
show that our algorithms create mechanisms that yield significantly higher revenue than the VCG and scale dramatically better than prior automated mechanism design algorithms The algorithms yielded deterministic mechanisms with the highest known revenues for the settings tested	finding	2K_dev_170
including the canonical setting with two bidders	finding	2K_dev_170
two items	finding	2K_dev_170
and uniform additive valuations	finding	2K_dev_170
	finding	2K_dev_170
Rather than pursuing the manual approach of attempting to characterize the optimal CA	mechanism	2K_dev_170
we introduce a family of CAs and then seek a high-revenue auction within that family	mechanism	2K_dev_170
The family is based on bidder weighting and allocation boosting ; we coin such CAs virtual valuations combinatorial auctions ( VVCAs ) VVCAs are the Vickrey-Clarke-Groves ( VCG ) mechanism executed on virtual valuations that are affine transformations of the bidders valuations	mechanism	2K_dev_170
The auction family is parameterized by the coefficients in the transformations The problem of designing a CA is thereby reduced to search in the parameter space of VVCAor the more general space of affine maximizer auctions	mechanism	2K_dev_170
We first construct VVCAs with logarithmic approximation guarantees in canonical special settings : ( 1 ) limited supply with additive valuations and ( 2 ) unlimited supply	mechanism	2K_dev_170
In the main part of the paper	mechanism	2K_dev_170
we develop algorithms that design high-revenue CAs for general valuations using samples from the prior distribution over bidders valuations	mechanism	2K_dev_170
( Priors turn out to be necessary for achieving high revenue	mechanism	2K_dev_170
) We prove properties of the problem that guide our design of algorithms	mechanism	2K_dev_170
We then introduce a series of algorithms that use economic insights to guide the search and thus reduce the computational complexity	mechanism	2K_dev_170
Experiments	method	2K_dev_170
Designing optimalthat is	purpose	2K_dev_170
revenue-maximizingcombinatorial auctions ( CAs ) is an important elusive problem	purpose	2K_dev_170
	purpose	2K_dev_170
	background	2K_dev_171
	finding	2K_dev_171
	mechanism	2K_dev_171
	method	2K_dev_171
	purpose	2K_dev_171
How many listens will an artist receive on a online radio ? How about plays on a YouTube video ? How many of these visits are new or returning users ? Modeling and mining popularity dynamics of social activity has important implications for researchers	background	2K_dev_172
content creators and providers	background	2K_dev_172
	background	2K_dev_172
we show the effect of revisits in the popularity evolution of such objects	finding	2K_dev_172
	finding	2K_dev_172
Secondly	mechanism	2K_dev_172
we propose the Phoenix-R model Phoenix-R has the desired properties of being : ( 1 ) parsimonious	mechanism	2K_dev_172
being based on the minimum description length principle	mechanism	2K_dev_172
and achieving lower root mean squared error than state-of-the-art baselines ; ( 2 ) applicable	mechanism	2K_dev_172
the model is effective for predicting future popularity values of objects	mechanism	2K_dev_172
	mechanism	2K_dev_172
Using four datasets of social activity	method	2K_dev_172
with up to tens of millions media objects ( e	method	2K_dev_172
g	method	2K_dev_172
	method	2K_dev_172
YouTube videos	method	2K_dev_172
Twitter hashtags or LastFM artists )	method	2K_dev_172
We here investigate the effect of revisits ( successive visits from a single user ) on content popularity which captures the popularity dynamics of individual objects	purpose	2K_dev_172
	purpose	2K_dev_172
Social microvolunteering lets people volunteer despite temporal	background	2K_dev_173
financial	background	2K_dev_173
or physical limitations	background	2K_dev_173
	finding	2K_dev_173
We propose social microvolunteering	mechanism	2K_dev_173
in which people can do charitable microwork themselves for free	mechanism	2K_dev_173
but also grant access to their Facebook friends as additional volunteers	mechanism	2K_dev_173
	method	2K_dev_173
to magnify their effort	purpose	2K_dev_173
	purpose	2K_dev_173
	background	2K_dev_174
For the year of 2013	finding	2K_dev_174
we show a reduction of up to 24	finding	2K_dev_174
8 % in the monthly bill is possible we show that EV aggregations decrease their contribution to the system peak load by approximately 37 % ( median ) when charging is controlled within arrival and departure times	finding	2K_dev_174
Our results also show that it could be expected to shift approximately 0	finding	2K_dev_174
25kWh ( 2	finding	2K_dev_174
8 % ) of energy per non-residential EV charging session from peak periods ( 12PM6PM ) to off-peak periods ( after 6PM ) in Northern California for the year of 2013	finding	2K_dev_174
We develop a smart charging framework by relaxing the assumptions made in these studies regarding : ( i ) driving patterns	mechanism	2K_dev_174
driver behavior and driver types ; ( ii ) the scalability of a limited number of simulated vehicles to represent different load aggregation points in the power system with different customer characteristics ; and ( iii ) the charging profile of EVs	mechanism	2K_dev_174
Then	mechanism	2K_dev_174
following a similar aggregation strategy	mechanism	2K_dev_174
	mechanism	2K_dev_174
In this paper	method	2K_dev_174
we use data collected from over 2000 non-residential electric vehicle supply equipments ( EVSEs ) located in Northern California for the year of 2013 First	method	2K_dev_174
we study the benefits of EV aggregations behind-the-meter	method	2K_dev_174
where a time-of-use pricing schema is used to understand the benefits to the owner when EV aggregations shift load from high cost periods to lower cost periods	method	2K_dev_174
	method	2K_dev_174
to estimate the potential benefits of smart electric vehicle ( EV ) charging	purpose	2K_dev_174
to identify the benefits of non-residential EV charging to the load aggregators and the distribution grid Using this extensive dataset	purpose	2K_dev_174
we aim to improve upon past studies focusing on the benefits of smart EV charging	purpose	2K_dev_174
Given the pace of discovery in medicine	background	2K_dev_175
accessing the literature to make informed decisions at the point of care has become increasingly difficult Advances in social computation and human computer interactions offer a potential solution to this problem	background	2K_dev_175
Journal of Hospital Medicine 2014 ; 9:451456	background	2K_dev_175
2014 Society of Hospital Medicine	background	2K_dev_175
85 registered users logged 1544 page views and sent 45 consult questions	finding	2K_dev_175
The median initial first response from the crowd occurred within 19 minutes Review of the transcripts revealed several dominant themes	finding	2K_dev_175
including complex medical decision making and inquiries related to prescription medication use	finding	2K_dev_175
Feedback from the post-trial survey identified potential hurdles related to medical crowdsourcing	finding	2K_dev_175
including a reluctance to expose personal knowledge gaps and the potential risk for distracted doctoring	finding	2K_dev_175
Users also suggested program modifications that could support future adoption	finding	2K_dev_175
including changes to the mobile interface and mechanisms that could expand the crowd of participating healthcare providers	finding	2K_dev_175
We developed and piloted the mobile application DocCHIRP	mechanism	2K_dev_175
which uses a system of point-to-multipoint push notifications designed	mechanism	2K_dev_175
Over the 244-day pilot period	method	2K_dev_175
	method	2K_dev_175
Although the Internet creates unprecedented access to information	purpose	2K_dev_175
gaps in the medical literature and inefficient searches often leave healthcare providers ' questions unanswered to help providers problem solve by crowdsourcing from their peers	purpose	2K_dev_175
	purpose	2K_dev_175
We conclude with a discussion of ways the modeling approach might be applied	background	2K_dev_176
along with caveats from limitations	background	2K_dev_176
and directions for future work	background	2K_dev_176
In each of three MOOCs we find evidence that participation in two to four subcommunities out of the twenty is associated with significantly higher or lower dropout rates than average	finding	2K_dev_176
illustrates how the learned models can be used as a lens for understanding the values and focus of discussions within the subcommunities	finding	2K_dev_176
and in the illustrative example to think about the association between those and detected higher or lower dropout rates than average in the three courses	finding	2K_dev_176
demonstrates that the patterns that emerge make sense : It associates evidence of stronger expressed motivation to actively participate in the course as well as evidence of stronger cognitive engagement with the material in subcommunities associated with lower attrition	finding	2K_dev_176
and the opposite in subcommunities associated with higher attrition	finding	2K_dev_176
	finding	2K_dev_176
In this paper	mechanism	2K_dev_176
we describe a novel methodology	mechanism	2K_dev_176
grounded in techniques from the field of machine learning	mechanism	2K_dev_176
	mechanism	2K_dev_176
with an eye towards application in the threaded discussions of massive open online courses ( MOOCs )	mechanism	2K_dev_176
This modeling approach integrates two simpler	mechanism	2K_dev_176
well established prior techniques	mechanism	2K_dev_176
namely one related to social network structure and another related to thematic structure of text	mechanism	2K_dev_176
As an illustrative application of the integrated techniques use and utility	mechanism	2K_dev_176
We then use a survival model to measure the impact of participation in identified subcommunities on attrition along the way for students who have participated in the course discussion forums of the three courses	mechanism	2K_dev_176
we use it as a lens for exploring student dropout behavior in three different MOOCs	method	2K_dev_176
In particular	method	2K_dev_176
we use the model to identify twenty emerging subcommunities within the threaded discussions of each of the three MOOCs A qualitative post-hoc analysis Our qualitative analysis	method	2K_dev_176
for modeling emerging social structure as it develops in threaded discussion forums	purpose	2K_dev_176
Given a large number of taxi trajectories	background	2K_dev_177
we would like to find interesting and unexpected patterns from the data	background	2K_dev_177
How can we summarize the major trends	background	2K_dev_177
and how can we spot anomalies ? The anal- ysis of trajectories has been an issue of considerable interest with many applications such as tracking trails of migrating animals and predicting the path of hurricanes	background	2K_dev_177
In fact	finding	2K_dev_177
F-Trail does produce concise	finding	2K_dev_177
informative and interesting patterns	finding	2K_dev_177
we develop a novel method	mechanism	2K_dev_177
called F-Trail	mechanism	2K_dev_177
w hich al- lows us Our approach has the following advantages : ( a ) it is fast	mechanism	2K_dev_177
and scales linearly on the input size	mechanism	2K_dev_177
( b ) it is effective	mechanism	2K_dev_177
leading to novel discoveries	mechanism	2K_dev_177
and surprising outliers	mechanism	2K_dev_177
We demonstrate the effectiveness of our approach	method	2K_dev_177
by performing exper- iments on real taxi trajectories	method	2K_dev_177
	method	2K_dev_177
Several recent works propose methods on clus- tering and indexing trajectories data	purpose	2K_dev_177
However	purpose	2K_dev_177
these approaches are not especially well suited to pattern discovery with respect to the dynamics of social and economic behavior To further analyze a huge collection of taxi trajectories	purpose	2K_dev_177
to find meaningful patterns and anomalies	purpose	2K_dev_177
	purpose	2K_dev_177
	background	2K_dev_178
	finding	2K_dev_178
The present invention discloses CrowdScape	mechanism	2K_dev_178
a system that through interactive visualization and mixed initiative machine learning	mechanism	2K_dev_178
The system combines information about worker behavior with worker outputs and aggregate worker behavioral traces to allow the isolation of target worker clusters This approach allows users to develop and test their mental models of tasks and worker behaviors	mechanism	2K_dev_178
and then ground those models in worker outputs and majority or gold standard verifications	mechanism	2K_dev_178
	mechanism	2K_dev_178
	method	2K_dev_178
supports the human evaluation of complex crowd work	purpose	2K_dev_178
	background	2K_dev_179
	finding	2K_dev_179
	mechanism	2K_dev_179
	method	2K_dev_179
	purpose	2K_dev_179
	background	2K_dev_180
	finding	2K_dev_180
	mechanism	2K_dev_180
	method	2K_dev_180
	purpose	2K_dev_180
The increasing performance of modern processors makes virtualization a viable solution for consolidating real-time systems into a single hardware platform	background	2K_dev_181
Our experimental results indicate that vINT achieves timely interrupt handling while providing as good task schedulability as when it is not used	finding	2K_dev_181
shows that vINT yields significant benefits in reducing interrupt handling time and in protecting real-time tasks against interrupt storms permeating into the virtual machine	finding	2K_dev_181
In this paper	mechanism	2K_dev_181
we propose vINT	mechanism	2K_dev_181
an interrupt handling scheme vINT provides a pseudo-VCPU abstraction dedicated for interrupt handling	mechanism	2K_dev_181
which overcomes the limits imposed by the timing parameters of virtual CPUs in an analyzable way vINT also accounts for and enforces interrupt handling and resulting execution flows within a guest virtual machine vINT does not require any change to the guest OS code	mechanism	2K_dev_181
so it can be used for virtualizing proprietary	mechanism	2K_dev_181
closed-source OSs	mechanism	2K_dev_181
We analyze interrupt handling time as well as VCPU and task schedulability	method	2K_dev_181
with and without vINT	method	2K_dev_181
Our case study based on a prototype implementation on the KVM hyper visor	method	2K_dev_181
Although real-time task scheduling in a virtual machine can benefit from hierarchical scheduling	purpose	2K_dev_181
unbounded interrupt handling time and vulnerability to interrupt storms make practitioners hesitant to virtualize interrupt-driven real-time applications	purpose	2K_dev_181
designed for real-time system virtualization	purpose	2K_dev_181
Imperfect-recall abstraction has emerged as the leading paradigm for practical large-scale equilibrium computation in incomplete-information games	background	2K_dev_182
	background	2K_dev_182
	finding	2K_dev_182
In this paper	mechanism	2K_dev_182
we show the first general	mechanism	2K_dev_182
algorithm-agnostic	mechanism	2K_dev_182
solution quality guarantees and approximate self-trembling equilibria computed in imperfect-recall abstractions	mechanism	2K_dev_182
when implemented in the original ( perfect-recall ) game	mechanism	2K_dev_182
Our results are for a class of games that generalizes the only previously known class of imperfect-recall abstractions where any results had been obtained	mechanism	2K_dev_182
Further	mechanism	2K_dev_182
our analysis is tighter in two ways	mechanism	2K_dev_182
each of which can lead to an exponential reduction in the solution quality error bound We then show that for extensive-form games that satisfy certain properties	mechanism	2K_dev_182
the problem of computing a bound-minimizing abstraction for a single level of the game reduces to a clustering problem	mechanism	2K_dev_182
where the increase in our bound is the distance function This reduction leads to the first imperfect-recall abstraction algorithm with solution quality bounds We proceed to show a divide in the class of abstraction problems If payoffs are at the same scale at all information sets considered for abstraction	mechanism	2K_dev_182
the input forms a metric space	mechanism	2K_dev_182
Conversely	mechanism	2K_dev_182
if this condition is not satisfied	mechanism	2K_dev_182
we show that the input does not form a metric space	mechanism	2K_dev_182
Finally	method	2K_dev_182
we use these results to experimentally investigate the quality of our bound for single-level abstraction	method	2K_dev_182
	method	2K_dev_182
However	purpose	2K_dev_182
imperfect-recall abstractions are poorly understood	purpose	2K_dev_182
and only weak algorithm-specific guarantees on solution quality are known for Nash equilibria	purpose	2K_dev_182
	background	2K_dev_183
demonstrate the promising performance of our method	finding	2K_dev_183
both for event detection and evidence recounting	finding	2K_dev_183
	finding	2K_dev_183
In this work	mechanism	2K_dev_183
we propose a flexible deep CNN infrastructure	mechanism	2K_dev_183
namely Deep Event Network ( DevNet )	mechanism	2K_dev_183
that simultaneously detects pre-defined events and provides key spatial-temporal evidences Taking key frames of videos as input	mechanism	2K_dev_183
we first detect the event of interest at the video level by aggregating the CNN features of the key frames	mechanism	2K_dev_183
The pieces of evidences which recount the detection results	mechanism	2K_dev_183
are also automatically localized	mechanism	2K_dev_183
both temporally and spatially	mechanism	2K_dev_183
The challenge is that we only have video level labels	mechanism	2K_dev_183
while the key evidences usually take place at the frame levels	mechanism	2K_dev_183
Based on the intrinsic property of CNNs	mechanism	2K_dev_183
we first generate a spatial-temporal saliency map by back passing through DevNet	mechanism	2K_dev_183
which then can be used to find the key frames which are most indicative to the event	mechanism	2K_dev_183
as well as to localize the specific spatial position	mechanism	2K_dev_183
usually an object	mechanism	2K_dev_183
in the frame of the highly indicative area	mechanism	2K_dev_183
	mechanism	2K_dev_183
Experiments on the large scale TRECVID 2014 MEDTest dataset	method	2K_dev_183
In this paper	purpose	2K_dev_183
we focus on complex event detection in internet videos while also providing the key evidences of the detection results	purpose	2K_dev_183
Convolutional Neural Networks ( CNNs ) have achieved promising performance in image classification and action recognition tasks	purpose	2K_dev_183
However	purpose	2K_dev_183
it remains an open problem how to use CNNs for video event detection and recounting	purpose	2K_dev_183
mainly due to the complexity and diversity of video events	purpose	2K_dev_183
	purpose	2K_dev_183
Formal verification of industrial systems is very challenging	background	2K_dev_184
due to reasons ranging from scalability issues to communication difficulties with engineering-focused teams	background	2K_dev_184
More importantly	background	2K_dev_184
industrial systems are rarely designed for verification	background	2K_dev_184
but rather for operational needs The effort presented in this paper is an integral part of the ACAS X development and was performed in tight collaboration with the ACAS X development team	background	2K_dev_184
	background	2K_dev_184
	finding	2K_dev_184
In this paper we present an overview of our experience using hybrid systems theorem proving an airborne collision avoidance system for airliners scheduled to be operational around 2020 The methods and proof techniques presented here are an overview of the work already presented in [ 8 ]	mechanism	2K_dev_184
while the evaluation of ACAS X has been significantly expanded and updated to the most recent version of the system	mechanism	2K_dev_184
run 13	mechanism	2K_dev_184
	method	2K_dev_184
to formally verify ACAS X	purpose	2K_dev_184
Modern day law enforcement banks heavily on the use of commercial off-the-shelf ( COTS ) face recognition systems ( FRS ) as a tool for biometric evaluation and identification	background	2K_dev_185
However	background	2K_dev_185
in many real-world scenarios	background	2K_dev_185
when the face of an individual is occluded or degraded in some way	background	2K_dev_185
commercial recognition systems fail to accept the face for evaluation or simply return unusable matched faces	background	2K_dev_185
In these kinds of cases	background	2K_dev_185
forensic experts rely on image processing techniques and tools	background	2K_dev_185
to make the face fit to be processed by the commercial recognition systems ( e	background	2K_dev_185
g	background	2K_dev_185
use partial face images from another subject to fill in the occluded parts of the face of interest	background	2K_dev_185
or have a tight crop around the face )	background	2K_dev_185
Our results indicate that COTS FRS can be sensitive to the subjectivity in facial part swapping and cropping	finding	2K_dev_185
resulting in inconsistencies in the identification rankings and similarity scores	finding	2K_dev_185
	mechanism	2K_dev_185
More specifically	method	2K_dev_185
we study the change in the rank-1 identification result that is caused by forensic processing of faces-of-interest that are unusable by the commercial recognition systems Further	method	2K_dev_185
forensic processing of such faces is more of an art and it is extremely difficult to process faces consistently such that there is a predictable effect on the rank-n identification result	method	2K_dev_185
In this study	purpose	2K_dev_185
we evaluate the sensitivity of commercial recognition systems to such forensic techniques	purpose	2K_dev_185
This study is meant to serve as an evaluation of the effect of a few forensic techniques intended to allow commercial recognition systems to process and match face images that were otherwise unusable	purpose	2K_dev_185
Third parties play a prominent role in network-based explanations for successful knowledge transfer Third parties can be either shared or unshared Shared third parties signal insider status and have a predictable positive effect on knowledge transfer Unshared third parties	background	2K_dev_186
however	background	2K_dev_186
signal outsider status and are believed to undermine knowledge transfer Surprisingly	background	2K_dev_186
unshared third parties have been ignored in empirical analysis	background	2K_dev_186
and so we do not know if or how much unshared third parties contribute to the process	background	2K_dev_186
Our results provide a more complete view of how third parties contribute to knowledge sharing	background	2K_dev_186
The results also advance our understanding of network-based dynamics defined more broadly	background	2K_dev_186
	background	2K_dev_186
results indicate that unshared third parties undermine knowledge sharing	finding	2K_dev_186
and they also indicate that the magnitude of the negative unshared-third-party effect declines the more unshared third parties overlap in what they know By documenting how knowledge overlap among unshared third parties moderates their negative influence	finding	2K_dev_186
our results show when the benefits provided by third parties and by bridges i	finding	2K_dev_186
e	finding	2K_dev_186
	finding	2K_dev_186
relationships with outsiders will be opposed versus when both can be enjoyed	finding	2K_dev_186
	finding	2K_dev_186
	mechanism	2K_dev_186
Using knowledge transfer data from an online technical forum Empirical	method	2K_dev_186
we illustrate how unshared third parties affect the rate at which individuals initiate and sustain knowledge transfer relationships	purpose	2K_dev_186
How much did a network change since yesterday ? How different is the wiring between Bob 's brain ( a left-handed male ) and Alice 's brain ( a right-handed female ) ? Graph similarity with known node correspondence	background	2K_dev_187
i	background	2K_dev_187
e	background	2K_dev_187
the detection of changes in the connectivity of graphs	background	2K_dev_187
arises in numerous settings	background	2K_dev_187
	background	2K_dev_187
showcase the advantages of our method over existing similarity measures	finding	2K_dev_187
We propose DeltaCon	mechanism	2K_dev_187
a principled	mechanism	2K_dev_187
intuitive	mechanism	2K_dev_187
and scalable algorithm ( e	mechanism	2K_dev_187
g employees of a company	mechanism	2K_dev_187
customers of a mobile carrier )	mechanism	2K_dev_187
	mechanism	2K_dev_187
Experiments on various synthetic and real graphs Finally	method	2K_dev_187
we employ DeltaCon to real applications : ( a ) we classify people to groups of high and low creativity based on their brain connectivity graphs	method	2K_dev_187
and ( b ) do temporal anomaly detection in the who-emails-whom Enron graph	method	2K_dev_187
In this work	purpose	2K_dev_187
we formally state the axioms and desired properties of the graph similarity functions	purpose	2K_dev_187
and evaluate when state-of-the-art methods fail to detect crucial connectivity changes in graphs	purpose	2K_dev_187
that assesses the similarity between two graphs on the same nodes	purpose	2K_dev_187
Why does Smith follow Johnson on Twitter ?	background	2K_dev_188
	background	2K_dev_188
results show that TagF uncovers different	finding	2K_dev_188
but explainable reasons why users follow other users	finding	2K_dev_188
by proposing TagF	mechanism	2K_dev_188
which analyzes the who-follows-whom network ( matrix ) and the who-tags-whom network ( tensor ) simultaneously Concretely	mechanism	2K_dev_188
our method decomposes a coupled tensor constructed from these matrix and tensor	mechanism	2K_dev_188
	mechanism	2K_dev_188
The experimental on million-scale Twitter networks	method	2K_dev_188
In most cases	purpose	2K_dev_188
the reason why users follow other users is unavailable In this work	purpose	2K_dev_188
we answer this question	purpose	2K_dev_188
A lot of real-world data is spread across multiple domains	background	2K_dev_189
Handling such data has been a challenging task	background	2K_dev_189
Heterogeneous face biometrics has begun to receive attention in recent years	background	2K_dev_189
In real-world scenarios	background	2K_dev_189
many surveillance cameras capture data in the NIR ( near infrared ) spectrum	background	2K_dev_189
results report state-of-the-art results	finding	2K_dev_189
by developing a method to reconstruct VIS images in the NIR domain and vice-versa This approach is more applicable to real-world scenarios since it does not involve having to project millions of VIS database images into learned common subspace for subsequent matching We present a cross-spectral joint l 0 minimization based dictionary learning approach to learn a mapping function between the two domains	mechanism	2K_dev_189
One can then use the function to reconstruct facial images between the domains	mechanism	2K_dev_189
Our method is open set and can reconstruct any face not present in the training data	mechanism	2K_dev_189
We present on the CASIA NIR-VIS v2	method	2K_dev_189
0 database and	method	2K_dev_189
However	purpose	2K_dev_189
most datasets accessible to law enforcement have been collected in the VIS ( visible light ) domain	purpose	2K_dev_189
Thus	purpose	2K_dev_189
there exists a need to match NIR to VIS face images In this paper	purpose	2K_dev_189
we approach the problem	purpose	2K_dev_189
How often do individuals perform a given communication activity in the Web	background	2K_dev_190
such as posting comments on blogs or news ? Could we have a generative model to create communication events with realistic inter-event time distributions ( IEDs ) ? Which properties should we strive to match ?	background	2K_dev_190
reveal that the SFP mimics their properties very well	finding	2K_dev_190
being corner cases of the proposed Self-Feeding Process ( SFP )	mechanism	2K_dev_190
We show that the SFP ( a ) exhibits a unifying power	mechanism	2K_dev_190
which generates power law tails ( including the so-called `` top-concavity '' that real data exhibits )	mechanism	2K_dev_190
as well as short-term Poisson behavior ; ( b ) avoids the `` i	mechanism	2K_dev_190
i	mechanism	2K_dev_190
d fallacy ''	mechanism	2K_dev_190
which none of the prevailing models have studied before ; and ( c ) is extremely parsimonious	mechanism	2K_dev_190
requiring usually only one	mechanism	2K_dev_190
and in general	mechanism	2K_dev_190
at most two parameters	mechanism	2K_dev_190
	mechanism	2K_dev_190
Experiments conducted on eight large	method	2K_dev_190
diverse real datasets ( e	method	2K_dev_190
g	method	2K_dev_190
	method	2K_dev_190
Youtube and blog comments	method	2K_dev_190
e-mails	method	2K_dev_190
SMSs	method	2K_dev_190
etc )	method	2K_dev_190
Current literature has seemingly contradictory results for IED : some studies claim good fits with power laws ; others with non-homogeneous Poisson processes	purpose	2K_dev_190
Given these two approaches	purpose	2K_dev_190
we ask : which is the correct one ? Can we reconcile them all ? We show here that	purpose	2K_dev_190
surprisingly	purpose	2K_dev_190
both approaches are correct	purpose	2K_dev_190
	purpose	2K_dev_190
Gaussian processes ( GPs ) are a flexible class of methods with state of the art performance on spatial statistics applications	background	2K_dev_191
However	background	2K_dev_191
GPs require O ( n3 ) computations and O ( n2 ) storage	background	2K_dev_191
and popular GP kernels are typically limited to smoothing and interpolation	background	2K_dev_191
Using our model	finding	2K_dev_191
we discover spatially varying multiscale seasonal trends and produce highly accurate long-range local area forecasts	finding	2K_dev_191
We propose new scalable Kronecker methods using a Laplace approximation which involves linear conjugate gradients for inference	mechanism	2K_dev_191
and a lower bound on the GP marginal likelihood for kernel learning	mechanism	2K_dev_191
Our approach has near linear scaling	mechanism	2K_dev_191
requiring O ( DnD+1/D ) operations and O ( Dn2/D ) storage	mechanism	2K_dev_191
for n training data-points on a dense D > 1 dimensional grid	mechanism	2K_dev_191
Moreover	mechanism	2K_dev_191
we introduce a log Gaussian Cox process	mechanism	2K_dev_191
with highly expressive kernels	mechanism	2K_dev_191
for modelling spatiotemporal count processes	mechanism	2K_dev_191
	mechanism	2K_dev_191
and apply it to a point pattern ( n 0 233	method	2K_dev_191
088 ) of a decade of crime events in Chicago	method	2K_dev_191
To address these difficulties	purpose	2K_dev_191
Kronecker methods have been used to exploit structure in the GP covariance matrix for scalability	purpose	2K_dev_191
while allowing for expressive kernel learning ( Wilson et al	purpose	2K_dev_191
	purpose	2K_dev_191
2014 However	purpose	2K_dev_191
fast Kronecker methods have been confined to Gaussian likelihoods for Gaussian processes with non-Gaussian likelihoods	purpose	2K_dev_191
	purpose	2K_dev_191
The difference is that hybrid games also provide all the features of hybrid systems and discrete games	background	2K_dev_192
but only deterministic differential equations	background	2K_dev_192
Differential games	background	2K_dev_192
instead	background	2K_dev_192
provide differential equations with continuous-time game input by both players	background	2K_dev_192
but not the luxury of hybrid games	background	2K_dev_192
such as mode switches and discrete-time or alternating adversarial interaction	background	2K_dev_192
	finding	2K_dev_192
This article introduces differential hybrid games	mechanism	2K_dev_192
which combine differential games with hybrid games	mechanism	2K_dev_192
In both kinds of games	mechanism	2K_dev_192
two players interact with continuous dynamics This article augments differential game logic with modalities and introduces differential game invariants and differential game variants	mechanism	2K_dev_192
	method	2K_dev_192
for the combined dynamics of differential hybrid games It shows how hybrid games subsume differential games for proving properties of differential games inductively	purpose	2K_dev_192
	purpose	2K_dev_192
Most state-of-the-art action feature extractors involve differential operators	background	2K_dev_193
which act as highpass filters and tend to attenuate low frequency action information	background	2K_dev_193
This attenuation introduces bias to the resulting features and generates ill-conditioned feature matrices	background	2K_dev_193
	background	2K_dev_193
performance on challenging action recognition and event detection tasks Specifically	finding	2K_dev_193
our method exceeds and is comparable to MIFS can also be used as a speedup strategy for feature extraction with minimal or no accuracy cost	finding	2K_dev_193
	finding	2K_dev_193
we propose a novel feature enhancing technique called Multi-skIp Feature Stacking ( MIFS )	mechanism	2K_dev_193
which stacks features extracted using a family of differential filters parameterized with multiple time skips and encodes shift-invariance into the frequency space	mechanism	2K_dev_193
MIFS compensates for information lost from using differential operators by recapturing information at coarse scales	mechanism	2K_dev_193
This recaptured information allows us to match actions at different speeds and ranges of motion	mechanism	2K_dev_193
We prove that MIFS enhances the learnability of differential-based features exponentially	mechanism	2K_dev_193
The resulting feature matrices from MIFS have much smaller conditional numbers and variances than those from conventional methods	mechanism	2K_dev_193
results show significantly improved	mechanism	2K_dev_193
Experimental the state-of-the-arts on Hollywood2	method	2K_dev_193
UCF101 and UCF50 datasets state-of-the-arts on HMDB51 and Olympics Sports datasets	method	2K_dev_193
The Gaussian Pyramid has been used as a feature enhancing technique that encodes scale-invariant characteristics into the feature space in an attempt to deal with this attenuation	purpose	2K_dev_193
However	purpose	2K_dev_193
at the core of the Gaussian Pyramid is a convolutional smoothing operation	purpose	2K_dev_193
which makes it incapable of generating new features at coarse scales	purpose	2K_dev_193
In order to address this problem	purpose	2K_dev_193
Biometrics has come a long way over the past decade in terms of technologies and devices that are used to verify user identities	background	2K_dev_194
Three of the more well studied modalities in this field are the face	background	2K_dev_194
iris and fingerprint	background	2K_dev_194
with the latter two reporting very high user identification/verification rates	background	2K_dev_194
	background	2K_dev_194
Our approach yields high values of verification rates	finding	2K_dev_194
which shows the promise of using these modalities as user specific biometric signatures	finding	2K_dev_194
In this paper	mechanism	2K_dev_194
we propose using electromyograph ( EMG ) signals as a person 's biometric signature	mechanism	2K_dev_194
The EMG records the motor unit action potentials ( MUAP ) during any physical motion	mechanism	2K_dev_194
Keypress timings alone if used as a biometric	mechanism	2K_dev_194
are very easy to spoof and hence we fuse this modality with EMG signals	mechanism	2K_dev_194
In order to classify these features	mechanism	2K_dev_194
we use subspace modeling as well as Bayesian classifiers	mechanism	2K_dev_194
Our study is done within the context of a person using a keyboard to type a password or any other fixed phrase	method	2K_dev_194
Along with EMG signals	method	2K_dev_194
we log key press times for the user and study the feasibility of using this data too as a biometric feature	method	2K_dev_194
The experiments have been performed within the context of a user typing a fixed pass phrase at a workstation	method	2K_dev_194
The idea is to monitor both biometric modalities when this action is performed and study user verification across data capture sessions and within capture sessions	method	2K_dev_194
In the biometric community there has been little work in studying biomedical signals for user recognition purposes	purpose	2K_dev_194
	purpose	2K_dev_194
Generative score spaces provide a principled method to exploit generative information	background	2K_dev_195
e	background	2K_dev_195
g	background	2K_dev_195
	background	2K_dev_195
data distribution and hidden variables	background	2K_dev_195
in discriminative classifiers	background	2K_dev_195
The underlying methodology is to derive measures or score functions from generative models	background	2K_dev_195
The derived score functions	background	2K_dev_195
spanning the so-called score space	background	2K_dev_195
provide features of a fixed dimension for discriminative classification	background	2K_dev_195
shows that performance of the score space approach coupled with the proposed discriminative learning method is competitive with state-of-the-art classification methods	finding	2K_dev_195
	finding	2K_dev_195
In this paper	mechanism	2K_dev_195
we propose a simple yet effective score space We further propose a discriminative learning method by constraining the classification margin over the score space	mechanism	2K_dev_195
The form of score function allows the formulation of simple learning rules	mechanism	2K_dev_195
which are essentially the same learning rules for a generative model with an extra posterior imposed over its hidden variables	mechanism	2K_dev_195
Experimental evaluation of this approach over two generative models	method	2K_dev_195
which is essentially the sufficient statistics of the adopted generative models and does not involve the parameters of generative models	purpose	2K_dev_195
for the score space that seeks to utilize label information	purpose	2K_dev_195
A group 's collective action is an outcome of the group 's decision-making process	background	2K_dev_196
which may be reached by either averaging of the individual preferences or following the choices of certain members in the group	background	2K_dev_196
	background	2K_dev_196
Results of those comparisons	finding	2K_dev_196
We propose a generic statistical framework from the spatio-temporal data of group trajectories	mechanism	2K_dev_196
where each `` trajectory '' is a sequence of group actions	mechanism	2K_dev_196
This is achieved by systematically comparing each agent type 's influence on the group actions based on an array of spatio-temporal criteria	method	2K_dev_196
are then aggregated into a score	method	2K_dev_196
Our problem here is to decide which decision process the group has adopted given the data of the collective actions	purpose	2K_dev_196
to infer the group 's decision process to make inference about the group 's decision process	purpose	2K_dev_196
	purpose	2K_dev_196
	background	2K_dev_197
	finding	2K_dev_197
	mechanism	2K_dev_197
	method	2K_dev_197
	purpose	2K_dev_197
	background	2K_dev_198
	finding	2K_dev_198
	mechanism	2K_dev_198
	method	2K_dev_198
	purpose	2K_dev_198
Bayesian nonparametric models	background	2K_dev_199
such as Gaussian processes	background	2K_dev_199
provide a compelling framework for automatic statistical modelling : these models have a high degree of flexibility	background	2K_dev_199
and automatically calibrated complexity	background	2K_dev_199
	background	2K_dev_199
	finding	2K_dev_199
In this paper	mechanism	2K_dev_199
we create function extrapolation problems and acquire human responses	mechanism	2K_dev_199
and then design a kernel learning framework We use the learned kernels to gain psychological insights and to extrapolate in humanlike ways that go beyond traditional stationary and polynomial kernels	mechanism	2K_dev_199
	mechanism	2K_dev_199
Finally	method	2K_dev_199
we investigate Occam 's razor in human and Gaussian process based function learning	method	2K_dev_199
	method	2K_dev_199
However	purpose	2K_dev_199
automating human expertise remains elusive ; for example	purpose	2K_dev_199
Gaussian processes with standard kernels struggle on function extrapolation problems that are trivial for human learners to reverse engineer the inductive biases of human learners across a set of behavioral experiments	purpose	2K_dev_199
	purpose	2K_dev_199
	background	2K_dev_200
	finding	2K_dev_200
This paper introduces a new proof calculus that is entirely based on uniform substitution	mechanism	2K_dev_200
a proof rule that substitutes a formula for a predicate symbol everywhere	mechanism	2K_dev_200
Uniform substitutions make it possible to rely on axioms rather than axiom schemata	mechanism	2K_dev_200
substantially simplifying implementations	mechanism	2K_dev_200
Instead of nontrivial schema variables and soundness-critical side conditions on the occurrence patterns of variables	mechanism	2K_dev_200
the resulting calculus adopts only a finite number of ordinary dL formulas as axioms	mechanism	2K_dev_200
The static semantics of differential dynamic logic is captured exclusively in uniform substitutions and bound variable renamings as opposed to being spread in delicate ways across the prover implementation In addition to sound uniform substitutions	mechanism	2K_dev_200
this paper introduces differential forms that make it possible	mechanism	2K_dev_200
	method	2K_dev_200
for differential dynamic logic ( dL ) for differential dynamic logic to internalize differential invariants	purpose	2K_dev_200
differential substitutions	purpose	2K_dev_200
and derivations as first-class axioms in dL	purpose	2K_dev_200
	purpose	2K_dev_200
While the growth of the mobile apps market has created significant market opportunities and economic incentives for mobile app developers to innovate	background	2K_dev_201
it has also inevitably invited other developers to create rip-offs	background	2K_dev_201
Practitioners and developers of original apps claim that copycats steal the original apps idea and demand and have called for app platforms to take action against such copycats	background	2K_dev_201
Our study contributes to the growing literature on mobile app consumption by presenting a method to identify copycats and providing evidence of the impact of copycats on an original apps demand	background	2K_dev_201
Based on the detection results Our final results indicate that the effect of copycats on an original apps demand is determined by the quality and level of imitation of the copycat	finding	2K_dev_201
High-quality	finding	2K_dev_201
non-deceptive copycats negatively affect demand for the originals	finding	2K_dev_201
In contrast	finding	2K_dev_201
low-quality	finding	2K_dev_201
deceptive copycats positively affect demand for the originals	finding	2K_dev_201
Using a combination of machine learning techniques such as natural language processing	mechanism	2K_dev_201
latent semantic analysis	mechanism	2K_dev_201
network-based clustering and image analysis	mechanism	2K_dev_201
we propose a method	mechanism	2K_dev_201
	method	2K_dev_201
we conduct an econometric analysis to determine the impact of copycat apps on the demand for the original apps on a sample of 10	method	2K_dev_201
100 action game apps by 5	method	2K_dev_201
141 developers that were released in the iOS App Store over five years	method	2K_dev_201
	method	2K_dev_201
Surprisingly	purpose	2K_dev_201
however	purpose	2K_dev_201
there has been little rigorous research analyzing whether and how copycats affect an original apps demand The primary deterrent to such research is the lack of an objective way to identify similarities between different apps to compare apps and detect two types of copycats : deceptive and non-deceptive	purpose	2K_dev_201
	purpose	2K_dev_201
Hidden information derived from probabilistic generative models of data distributions can be used to construct features for discriminative classifiers	background	2K_dev_202
This observation has motivated the development of approaches that attempt to couple generative and discriminative models together for classification	background	2K_dev_202
	background	2K_dev_202
	finding	2K_dev_202
this new framework produces a general classification tool with state-of-the-art performance	finding	2K_dev_202
	finding	2K_dev_202
In this paper	mechanism	2K_dev_202
we propose a coupling mechanism developed under the PAC-Bayes framework that can fine-tune the generative models and the feature mapping functions iteratively In our approach	mechanism	2K_dev_202
a stochastic feature mapping	mechanism	2K_dev_202
which is a function over the random variables of a generative model	mechanism	2K_dev_202
is derived to generate feature vectors for a stochastic classifier	mechanism	2K_dev_202
We construct a stochastic classifier over the feature mapping and derive the PAC-Bayes generalization bound for the classifier	mechanism	2K_dev_202
for both supervised and semi-supervised learning This allows us to jointly learn the feature mapping and the classifier by minimizing the bound with an EM-like iterative algorithm using labeled and unlabeled data	mechanism	2K_dev_202
The resulting framework integrates the learning of the discriminative classifier and the generative model and allows iterative fine-tuning of the generative models	mechanism	2K_dev_202
and the feedforward feature mappings based on task performance feedback	mechanism	2K_dev_202
Our experiments show	method	2K_dev_202
in three distinct applications	method	2K_dev_202
However	purpose	2K_dev_202
existing approaches typically feed features derived from generative models to discriminative classifiers	purpose	2K_dev_202
and do not refine the generative models or the feature mapping functions based on classification results	purpose	2K_dev_202
to improve the classifier 's performance	purpose	2K_dev_202
	purpose	2K_dev_202
Community detection plays a key role in understanding the structure of real-life graphs with impact on recommendation systems	background	2K_dev_203
load balancing and routing	background	2K_dev_203
Previous community detection methods look for uniform blocks in adjacency matrices	background	2K_dev_203
	background	2K_dev_203
	finding	2K_dev_203
we provide empirical evidence that communities are best represented as having an hyperbolic structure	finding	2K_dev_203
We show that our method is effective in finding communities with a similar structure to self-declared ones	finding	2K_dev_203
We report findings	finding	2K_dev_203
We detail HyCoM - the Hyperbolic Community Model - and show improvements in compression compared to standard methods We also introduce HyCoM-FIT	mechanism	2K_dev_203
a fast	mechanism	2K_dev_203
parameter free algorithm	mechanism	2K_dev_203
However	method	2K_dev_203
after studying four real networks with ground-truth communities in real social networks	method	2K_dev_203
including a community in a blogging platform with over 34 million edges in which more than 1000 users established over 300 000 relations	method	2K_dev_203
What do real communities in social networks look like ? as a better representation of communities and the relationships between their members	purpose	2K_dev_203
to detect communities with hyperbolic structure	purpose	2K_dev_203
	purpose	2K_dev_203
	background	2K_dev_204
our new representation improves the Mean Average Precision ( mAP ) from 27	finding	2K_dev_204
6 % to 36	finding	2K_dev_204
8 % for the TRECVID MEDTest 14 dataset and from 34	finding	2K_dev_204
0 % to 44	finding	2K_dev_204
6 % for the TRECVID MEDTest 13 dataset	finding	2K_dev_204
	finding	2K_dev_204
In this paper	mechanism	2K_dev_204
we propose a discriminative video representation for event detection over a large scale video dataset when only limited hardware resources are available	mechanism	2K_dev_204
This paper makes two contributions to the inference of CNN video representation	mechanism	2K_dev_204
First	mechanism	2K_dev_204
while average pooling and max pooling have long been the standard approaches to aggregating frame level static features	mechanism	2K_dev_204
we show that performance can be significantly improved by taking advantage of an appropriate encoding method	mechanism	2K_dev_204
Second	mechanism	2K_dev_204
we propose using a set of latent concept descriptors as the frame descriptor	mechanism	2K_dev_204
which enriches visual information while keeping it computationally affordable	mechanism	2K_dev_204
The integration of the two contributions results in a new state-of-the-art performance in event detection over the largest video datasets	mechanism	2K_dev_204
Compared to improved Dense Trajectories	method	2K_dev_204
which has been recognized as the best video representation for event detection	method	2K_dev_204
	method	2K_dev_204
The focus of this paper is to effectively leverage deep Convolutional Neural Networks ( CNNs ) to advance event detection	purpose	2K_dev_204
where only frame level static descriptors can be extracted by the existing CNN toolkits	purpose	2K_dev_204
	purpose	2K_dev_204
	background	2K_dev_205
We show that our model can outperform state-of-art performances of gated Boltzmann machines ( GBM ) Our model can also interpolate missing events or predict future events in image sequences while simultaneously estimating contextual information We show it achieves state-of-art performances and possesses the ability to interpolate missing frames	finding	2K_dev_205
a function that is lacking in GBM	finding	2K_dev_205
	finding	2K_dev_205
We propose a new neurally-inspired model that can learn and by synthesis process in a predictive coding framework	mechanism	2K_dev_205
The model learns latent contextual representations by maximizing the predictability of visual events based on local and global contextual information through both top-down and bottom-up processes	mechanism	2K_dev_205
In contrast to standard predictive coding models	mechanism	2K_dev_205
the prediction error in this model is used to update the contextual representation but does not alter the feedforward input for the next layer	mechanism	2K_dev_205
and is thus more consistent with neurophysiological observations	mechanism	2K_dev_205
	mechanism	2K_dev_205
We establish the computational feasibility of this model by demonstrating its ability in several aspects	method	2K_dev_205
in estimation of contextual information	method	2K_dev_205
in terms of prediction accuracy in a variety of tasks	method	2K_dev_205
to encode the global relationship context of visual events across time and space to use the contextual information to modulate the analysis	purpose	2K_dev_205
	background	2K_dev_206
	finding	2K_dev_206
We propose the use of contracts concisely capturing the conditions for a safe operation in the context of a traffic network This reduces the analysis of flows in the full traffic network to simple arithmetic checks of the local compatibility of the traffic component contracts	mechanism	2K_dev_206
while retaining higher-fidelity correctness guarantees of the global hybrid systems models that inherits from correct contracts of the hybrid system components	mechanism	2K_dev_206
	mechanism	2K_dev_206
We evaluate our approach in a case study of a modular traffic network and a prototypical implementation in a model-based analysis and design tool for traffic flow networks	method	2K_dev_206
	method	2K_dev_206
We address the problem how high-fidelity verification results about the hybrid systems dynamics of cyber-physical flow systems can be provided at the scale of large ( traffic ) networks without prohibitive analytic cost	purpose	2K_dev_206
for traffic flow components	purpose	2K_dev_206
Background Computer-assisted diagnosis of dermoscopic images of skin lesions has the potential to improve melanoma early detection	background	2K_dev_207
Conclusions Our classifier may aid clinicians in deciding if a skin lesion should be biopsied and can easily be incorporated into a portable tool ( that uses no proprietary equipment ) that could aid clinicians in noninvasively evaluating cutaneous lesions	background	2K_dev_207
	background	2K_dev_207
Results The classifier sensitivity for melanoma was 97	finding	2K_dev_207
4 % ; specificity was 44	finding	2K_dev_207
2 % in a test set of images	finding	2K_dev_207
In the reader study	finding	2K_dev_207
the classifier 's sensitivity to melanoma was higher ( P P Limitations This is a retrospective study using existing images primarily chosen for biopsy by a dermatologist	finding	2K_dev_207
The size of the test set is small	finding	2K_dev_207
	finding	2K_dev_207
We sought to evaluate the performance of a novel classifier that uses decision forest classification of dermoscopic images	mechanism	2K_dev_207
Methods Severity scores were calculated for 173 dermoscopic images of skin lesions with known histologic diagnosis ( 39 melanomas	method	2K_dev_207
14 nonmelanoma skin cancers	method	2K_dev_207
and 120 benign lesions )	method	2K_dev_207
A threshold score was used to measure classifier sensitivity and specificity A reader study was conducted to compare the sensitivity and specificity of the classifier with those of 30 dermatology clinicians	method	2K_dev_207
Objective to generate a lesion severity score	purpose	2K_dev_207
	purpose	2K_dev_207
Most Lamb wave localization techniques require that we know the waves velocity characteristics ; yet	background	2K_dev_208
in many practical scenarios	background	2K_dev_208
velocity estimates can be challenging to acquire	background	2K_dev_208
are unavailable	background	2K_dev_208
or are unreliable because of the complexity of Lamb waves	background	2K_dev_208
We show that both methods can achieve less than 1 cm localization error and have less systematic error than traditional time-of-arrival localization methods	finding	2K_dev_208
through two novel source localization methods designed for sparse sensor arrays in isotropic media Both methods exploit the fundamental sparse structure of a Lamb wave 's frequencywavenumber representation The first method uses sparse recovery techniques to extract velocities from calibration data	mechanism	2K_dev_208
The second method uses kurtosis and the support earth movers distance to measure the sparseness of a Lamb waves approximate frequency-wavenumber representation These measures are then used to locate acoustic sources with no prior calibration data	mechanism	2K_dev_208
	mechanism	2K_dev_208
We experimentally study each method with a collection of acoustic emission data measured from a 1	method	2K_dev_208
22 m by 1	method	2K_dev_208
22 m isotropic aluminum plate	method	2K_dev_208
As a result	purpose	2K_dev_208
there is a significant need for new methods that can reduce a systems reliance on a priori velocity information This paper addresses this challenge	purpose	2K_dev_208
	background	2K_dev_209
	finding	2K_dev_209
and found it was effective at producing reasonable drafts	finding	2K_dev_209
However	finding	2K_dev_209
the workers often needed more structure and the authors more context	finding	2K_dev_209
	finding	2K_dev_209
In this paper we introduce a paradigm for completing complex tasks from wearable devices by leveraging crowdsourcing	mechanism	2K_dev_209
and demonstrate its validity for academic writing We explore this paradigm using a collaborative authoring system	mechanism	2K_dev_209
called WearWrite	mechanism	2K_dev_209
which is designed using an Android smartwatch and Google Docs to produce academic papers	mechanism	2K_dev_209
including this one	mechanism	2K_dev_209
WearWrite allows expert authors who do not have access to large devices to contribute bits of expertise and big picture direction from their watch	mechanism	2K_dev_209
while freeing them of the obligation of integrating their contributions into the overall document	mechanism	2K_dev_209
Crowd workers on desktop computers actually write the document WearWrite addresses these issues by focusing workers on specific tasks and providing select context to authors on the watch	mechanism	2K_dev_209
	mechanism	2K_dev_209
We used this approach to write several simple papers We demonstrate the system 's feasibility by writing this paper using it	method	2K_dev_209
to enable authors and crowd workers to work together	purpose	2K_dev_209
Road intersections are considered to be serious bottlenecks in urban transportation	background	2K_dev_210
More than 44 % of all reported crashes in U	background	2K_dev_210
S Occur within intersection areas	background	2K_dev_210
which in turn lead to 8	background	2K_dev_210
500 fatalities and approximately 1 million injuries every year Furthermore	background	2K_dev_210
because traffic traveling in one direction is generally stopped at busy intersections to allow traffic to flow in another direction	background	2K_dev_210
an intersection creates traffic congestion and frustration	background	2K_dev_210
The impact of road intersections on traffic delays leads to enormous waste of human and natural resources	background	2K_dev_210
According to the 2011 Urban Mobility Report	background	2K_dev_210
the delay endured by the average commuter was 34 hours	background	2K_dev_210
which costs in aggregate more than $ 100 billion each year in the U	background	2K_dev_210
S	background	2K_dev_210
With the advances in Cyber-Physical Systems ( CPS )	background	2K_dev_210
autonomous driving as a part of Intelligent Transportation Systems ( ITS ) is likely to be at the heart of urban transportation in the future	background	2K_dev_210
Autonomous vehicles have been demonstrated successfully at the DARPA Urban Challenge	background	2K_dev_210
General Motors ' Electrical-Networked Vehicle	background	2K_dev_210
CMU 's autonomous vehicle and Google 's car are just a few other recently unveiled examples	background	2K_dev_210
	background	2K_dev_210
results show that we are able to avoid collisions and increase the throughput of the intersections by up to 96	finding	2K_dev_210
24 % compared to common signalized intersections	finding	2K_dev_210
Under BRIP	finding	2K_dev_210
the optimal intersection capacity utilization of 100 % is achievable in certain cases	finding	2K_dev_210
In this paper	mechanism	2K_dev_210
we propose a spatio-temporal technique called the Ballroom Intersection Protocol ( BRIP ) BRIP aims to maximize the utilization of the capacity of the intersection area by increasing parallelism	mechanism	2K_dev_210
By enforcing a synchronized arrival of autonomous vehicles at intersections	mechanism	2K_dev_210
BRIP allows vehicles approaching from all directions to simultaneously and continuously cross without stopping behind or inside the intersection area	mechanism	2K_dev_210
Our simulation	method	2K_dev_210
Therefore	purpose	2K_dev_210
it is critical to address safety and throughput concerns as one of the main challenges for autonomous driving through intersections to manage the safe and efficient passage of autonomous vehicles through intersections To achieve high throughput at intersections	purpose	2K_dev_210
The harmful effects of cell phone usage on driver behavior have been well investigated and the growing problem has motivated several several research efforts aimed at developing automated cell phone usage detection systems	background	2K_dev_211
Computer vision based approaches for dealing with this problem have only emerged in recent years	background	2K_dev_211
demonstrate the method 's efficacy	finding	2K_dev_211
In this paper	mechanism	2K_dev_211
we present a vision based method To the best of our knowledge	mechanism	2K_dev_211
this is the first such evaluation carried out using this relatively new data	mechanism	2K_dev_211
Our approach utilizes the Supervised Descent Method ( SDM ) based facial landmark tracking algorithm to track the locations of facial landmarks in order to extract a crop of the region of interest	mechanism	2K_dev_211
Following this	mechanism	2K_dev_211
features are extracted from the crop and are classified using previously trained classifiers in order to determine if a driver is holding a cell phone	mechanism	2K_dev_211
	mechanism	2K_dev_211
and quantitatively on challenging Strategic Highway Research Program ( SHRP2 ) face view videos from the head pose validation data that was acquired to monitor driver head pose variation under naturalistic driving conditions	method	2K_dev_211
We adopt a through approach and benchmark the performance obtained using raw pixels and Histogram of Oriented Gradients ( HOG ) features in combination with various classifiers	method	2K_dev_211
to automatically determine if a driver is holding a cell phone close to one of his/her ears ( thus keeping only one hand on the steering wheel )	purpose	2K_dev_211
The use of deductive techniques	background	2K_dev_212
such as theorem provers	background	2K_dev_212
has several advantages in safety verification of hybrid systems ; however	background	2K_dev_212
state-of-the-art theorem provers require manual intervention to handle complex systems	background	2K_dev_212
	background	2K_dev_212
	finding	2K_dev_212
This paper presents an extension to KeYmaera	mechanism	2K_dev_212
a deductive verification tool ; the new technique using system designer intuition about performance within particular modes as part of a proof task	mechanism	2K_dev_212
Our approach allows the theorem prover to leverage forward invariants	mechanism	2K_dev_212
discovered using numerical techniques	mechanism	2K_dev_212
as part of a proof of safety	mechanism	2K_dev_212
We introduce a new inference rule into the proof calculus of KeYmaera	mechanism	2K_dev_212
the forward invariant cut rule	mechanism	2K_dev_212
and we present a methodology	mechanism	2K_dev_212
which are then used with the new cut rule	mechanism	2K_dev_212
We demonstrate how our new approach can be used to complete verification tasks that lie out of the reach of existing automatic verification approaches using several examples	method	2K_dev_212
including one involving an automotive powertrain control system	method	2K_dev_212
	method	2K_dev_212
Furthermore	purpose	2K_dev_212
there is often a gap between the type of assistance that a theorem prover requires to make progress on a proof task and the assistance that a system designer is able to provide directly for differential dynamic logic allows local reasoning to discover useful forward invariants to complete verification tasks	purpose	2K_dev_212
In recent years	background	2K_dev_213
many lawsuits have been filed by individuals seeking legal redress for harms caused by the loss or theft of their personal information	background	2K_dev_213
By providing the first comprehensive empirical analysis of data breach litigation	background	2K_dev_213
our findings offer insight into the debate over privacy litigation versus privacy regulation	background	2K_dev_213
Our results suggest that the odds of a firm being sued are 3	finding	2K_dev_213
5 times greater when individuals suffer financial harm	finding	2K_dev_213
but 6 times lower when the firm provides free credit monitoring Moreover	finding	2K_dev_213
defendants settle 30 percent more often when plaintiffs allege financial loss	finding	2K_dev_213
or when faced with a certified class action suit	finding	2K_dev_213
	finding	2K_dev_213
	mechanism	2K_dev_213
Using a unique and manually collected database	method	2K_dev_213
we analyze court dockets for more than 230 federal data breach lawsuits from 2000 to 2010	method	2K_dev_213
However	purpose	2K_dev_213
very little is known about the drivers	purpose	2K_dev_213
mechanics	purpose	2K_dev_213
and outcomes of those lawsuits	purpose	2K_dev_213
making it difficult to assess the effectiveness of litigation at balancing organizations ' usage of personal data with individual privacy rights	purpose	2K_dev_213
We investigate two questions : Which data breaches are being litigated ? and Which data breach lawsuits are settling ?	purpose	2K_dev_213
Epidemics in large complete networks is well established	background	2K_dev_214
	background	2K_dev_214
Namely	finding	2K_dev_214
we prove that	finding	2K_dev_214
as the multipartite network grows large	finding	2K_dev_214
the normalized Markov jump vector process $ \left ( \bar { \mathbf { Y } } ^\mathbf { N } ( t ) \right ) 0 \left ( \bar { Y } _1^\mathbf { N } ( t )	finding	2K_dev_214
\ldots	finding	2K_dev_214
\bar { Y } _M^\mathbf { N } ( t ) \right ) $ collecting the fraction of infected nodes at each island $ i=1	finding	2K_dev_214
\ldots	finding	2K_dev_214
M $	finding	2K_dev_214
converges weakly ( with respect to the Skorokhod topology on the space of \emph { c\` { a } dl\` { a } g } sample paths ) to the solution of an $ M $ -dimensional vector nonlinear coupled ordinary differential equation	finding	2K_dev_214
In the case of multi-virus diffusion with $ K\in\mathbb { N } $ distinct strains of virus	finding	2K_dev_214
the Markov jurmp matrix process $ \left ( \bar { \mathbf { Y } } ^\mathbf { N } ( t ) \right ) $	finding	2K_dev_214
stacking the fraction of nodes infected with virus type $ j $	finding	2K_dev_214
$ j=1	finding	2K_dev_214
\ldots	finding	2K_dev_214
K $	finding	2K_dev_214
at each island $ i=1	finding	2K_dev_214
\ldots	finding	2K_dev_214
M $	finding	2K_dev_214
converges weakly as well to the solution of a $ \left ( K\times M\right ) $ -dimensional vector differential equation that is also characterized	finding	2K_dev_214
	finding	2K_dev_214
We establish the fluid limit macroscopic dynamics of a multi-virus spread over a multipartite network as the number of nodes at each partite or island grows large	mechanism	2K_dev_214
The virus spread follows a peer-to-peer random rule of infection in line with the Harris contact process The model conforms to an SIS ( susceptible-infected-susceptible ) type	mechanism	2K_dev_214
where a node is either infected or it is healthy and prone to be infected The local ( at node level ) random infection model induces the emergence of structured dynamics at the macroscale	mechanism	2K_dev_214
	mechanism	2K_dev_214
	method	2K_dev_214
In contrast	purpose	2K_dev_214
we consider epidemics in non-complete networks	purpose	2K_dev_214
	purpose	2K_dev_214
	background	2K_dev_215
	finding	2K_dev_215
We apply a novel semantic scan statistic approach Our semantic scan approach successfully addresses this problem	mechanism	2K_dev_215
eliminates the need for classifying cases into pre-defined syndromes and identifies emerging clusters that public health officials could not have predicted in advance	mechanism	2K_dev_215
	mechanism	2K_dev_215
	method	2K_dev_215
to solve a problem posed by the NC DETECT team	purpose	2K_dev_215
North Carolina Division of Public Health ( NC DPH ) and UNC Department of Emergency Medicine Carolina Center for Health Informatics	purpose	2K_dev_215
and facilitated by the ISDS Technical Conventions Committee This use case identifies a need for methodology that detects emerging	purpose	2K_dev_215
potentially novel outbreaks in free-text emergency department ( ED ) chief complaint data	purpose	2K_dev_215
	purpose	2K_dev_215
	background	2K_dev_216
we discovered that duplicate points create subtle issues	finding	2K_dev_216
that the literature has ignored : if d max is the multiplicity of the most over-plotted point	finding	2K_dev_216
typical algorithms are quadratic on d max	finding	2K_dev_216
we report wall-clock times and our time savings ; and we show that our methods give either exact results	finding	2K_dev_216
or highly accurate approximate ones	finding	2K_dev_216
We propose several ways ;	mechanism	2K_dev_216
After careful analysis	method	2K_dev_216
	method	2K_dev_216
Given a large cloud of multi-dimensional points	purpose	2K_dev_216
and an off-the shelf outlier detection method	purpose	2K_dev_216
why does it take a week to finish ? to eliminate the problem	purpose	2K_dev_216
Instant access to computing	background	2K_dev_217
when and where we need it	background	2K_dev_217
has long been one of the aims of research areas such as ubiquitous computing	background	2K_dev_217
	background	2K_dev_217
	finding	2K_dev_217
In this paper	mechanism	2K_dev_217
we describe the WorldKit system	mechanism	2K_dev_217
which makes use of a paired depth camera and projector Using this system	mechanism	2K_dev_217
touch-based interactivity can	mechanism	2K_dev_217
without prior calibration	mechanism	2K_dev_217
be placed on nearly any unmodified surface literally with a wave of the hand	mechanism	2K_dev_217
as can other new forms of sensed interaction From a user perspective	mechanism	2K_dev_217
such interfaces are easy enough to instantiate that they could	mechanism	2K_dev_217
if desired	mechanism	2K_dev_217
be recreated or modified `` each time we sat down '' by `` painting '' them next to us From the programmer 's perspective	mechanism	2K_dev_217
our system encapsulates these capabilities in a simple set of abstractions that make the creation of interfaces quick and easy	mechanism	2K_dev_217
Further	mechanism	2K_dev_217
it is extensible to new	mechanism	2K_dev_217
custom interactors in a way that closely mimics conventional 2D graphical user interfaces	mechanism	2K_dev_217
hiding much of the complexity of working in this new domain	mechanism	2K_dev_217
	mechanism	2K_dev_217
We detail the hardware and software implementation of our system	method	2K_dev_217
and several example applications built using the library	method	2K_dev_217
to make ordinary surfaces instantly interactive	purpose	2K_dev_217
	purpose	2K_dev_217
	background	2K_dev_218
	finding	2K_dev_218
We propose using the statistical measurement of the sample skewness of the distribution of mean firing rates of a tuning curve For some features	mechanism	2K_dev_218
like binocular disparity	mechanism	2K_dev_218
tuning curves are best described by relatively complex and sometimes diverse functions	mechanism	2K_dev_218
making it difficult to quantify sharpness with a single function and parameter	mechanism	2K_dev_218
Skewness provides a robust nonparametric measure of tuning curve sharpness that is invariant with respect to the mean and variance of the tuning curve and is straightforward to apply to a wide range of tuning	mechanism	2K_dev_218
including simple orientation tuning curves and complex object tuning curves that often can not even be described parametrically	mechanism	2K_dev_218
Because skewness does not depend on a specific model or function of tuning	mechanism	2K_dev_218
it is especially appealing to cases of sharpening where recurrent interactions among neurons produce sharper tuning curves that deviate in a complex manner from the feedforward function of tuning	mechanism	2K_dev_218
Since tuning curves for all neurons are not typically well described by a single parametric function	mechanism	2K_dev_218
this model independence additionally allows skewness to be applied to all recorded neurons	mechanism	2K_dev_218
maximizing the statistical power of a set of data We also compare skewness with other nonparametric measures of tuning curve sharpness and selectivity Compared to these other nonparametric measures tested	mechanism	2K_dev_218
skewness is best used for capturing the sharpness of multimodal tuning curves defined by narrow peaks maximum and broad valleys minima Finally	mechanism	2K_dev_218
we provide a more formal definition of sharpness using a shape-based information gain measure and derive and show that skewness is correlated with this definition	mechanism	2K_dev_218
	method	2K_dev_218
to quantify sharpness of tuning	purpose	2K_dev_218
How can we describe a large	background	2K_dev_219
dynamic graph over time ? Is it random ? If not	background	2K_dev_219
what are the most apparent deviations from randomness -- a dense block of actors that persists over time	background	2K_dev_219
or perhaps a star with many satellite nodes that appears with some fixed periodicity ? In practice	background	2K_dev_219
these deviations indicate patterns -- for example	background	2K_dev_219
botnet attackers forming a bipartite core with their victims over the duration of an attack	background	2K_dev_219
family members bonding in a clique-like fashion over a difficult period of time	background	2K_dev_219
or research collaborations forming and fading away over the years	background	2K_dev_219
	background	2K_dev_219
We show that TIMECRUNCH is able to compress these graphs	finding	2K_dev_219
( a ) formulation : we show how to formalize this problem as minimizing the encoding cost in a data compression paradigm	mechanism	2K_dev_219
( b ) algorithm : we propose TIMECRUNCH	mechanism	2K_dev_219
an effective	mechanism	2K_dev_219
scalable and parameter-free method for finding coherent	mechanism	2K_dev_219
temporal patterns in dynamic graphs and ( c ) practicality : by summarizing important temporal structures and finds patterns that agree with intuition	mechanism	2K_dev_219
	mechanism	2K_dev_219
we apply our method to several large	method	2K_dev_219
diverse real-world datasets with up to 36 million edges and 6	method	2K_dev_219
3 million nodes	method	2K_dev_219
	method	2K_dev_219
Which patterns exist in real-world dynamic graphs	purpose	2K_dev_219
and how can we find and rank them in terms of importance ? These are exactly the problems we focus on in this work	purpose	2K_dev_219
Our main contributions are	purpose	2K_dev_219
Generating three-dimensional ( 3D ) as-is Building Information Models ( BIMs )	background	2K_dev_220
representative of the existing conditions of buildings	background	2K_dev_220
from point cloud data collected by laser scanners is becoming common practice	background	2K_dev_220
The results show that the deviation analysis method is capable of identifying almost six times more errors with more than 40 % time savings compared to the physical measurement method	finding	2K_dev_220
	finding	2K_dev_220
This paper presents a method by analyzing the patterns of geometric deviations between the model and the point cloud data The fundamental assumption is that the point cloud and the as-is BIM generated from the point cloud should corroborate in the depiction of the components and their spatial attributes Major geometric deviations between as-is models and point clouds can indicate potential errors introduced during data collection	mechanism	2K_dev_220
processing and/or model generation The research described in this paper provides a taxonomy for patterns of deviations and sources of errors and demonstrates that it is possible to identify the source	mechanism	2K_dev_220
magnitude	mechanism	2K_dev_220
and nature of errors by analyzing the deviation patterns	mechanism	2K_dev_220
The method is validated through a comparison with the currently adopted physical measurement method in a case study	method	2K_dev_220
	method	2K_dev_220
However	purpose	2K_dev_220
generation of such models currently is mostly performed manually	purpose	2K_dev_220
and errors can be introduced during data collection	purpose	2K_dev_220
pre-processing	purpose	2K_dev_220
and modeling	purpose	2K_dev_220
for assessing the quality of as-is BIMs generated from point cloud data	purpose	2K_dev_220
Learning	background	2K_dev_221
whether motor	background	2K_dev_221
sensory or cognitive	background	2K_dev_221
requires networks of neurons to generate new activity patterns	background	2K_dev_221
As some behaviours are easier to learn than others1	background	2K_dev_221
2	background	2K_dev_221
These results suggest that the existing structure of a network can shape learning	background	2K_dev_221
On a timescale of hours	background	2K_dev_221
it seems to be difficult to learn to generate neural activity patterns that are not consistent with the existing network structure These findings offer a network-level explanation for the observation that we are more readily able to learn new skills when they are related to the skills that we already possess3	background	2K_dev_221
4	background	2K_dev_221
	background	2K_dev_221
Here we show that the animals could readily learn to proficiently control the cursor using neural activity patterns that were within the intrinsic manifold	finding	2K_dev_221
However	finding	2K_dev_221
animals were less able to learn to proficiently control the cursor using activity patterns that were outside of the intrinsic manifold	finding	2K_dev_221
We employed a closed-loop intracortical braincomputer interface learning paradigm in which Rhesus macaques ( Macaca mulatta ) controlled a computer cursor by modulating neural activity patterns in the primary motor cortex	mechanism	2K_dev_221
Using the braincomputer interface paradigm	mechanism	2K_dev_221
we could specify and alter how neural activity mapped to cursor velocity	mechanism	2K_dev_221
The activity of a neural population can be represented in a high-dimensional space ( termed the neural space )	mechanism	2K_dev_221
wherein each dimension corresponds to the activity of one neuron	mechanism	2K_dev_221
These characteristic activity patterns comprise a low-dimensional subspace ( termed the intrinsic manifold ) within the neural space	mechanism	2K_dev_221
The intrinsic manifold presumably reflects constraints imposed by the underlying neural circuitry	mechanism	2K_dev_221
At the start of each session	method	2K_dev_221
we observed the characteristic activity patterns of the recorded neural population	method	2K_dev_221
we asked if some neural activity patterns are easier to generate than others	purpose	2K_dev_221
Here we investigate whether an existing network constrains the patterns that a subset of its neurons is capable of exhibiting	purpose	2K_dev_221
and if so	purpose	2K_dev_221
what principles define this constraint	purpose	2K_dev_221
	purpose	2K_dev_221
AbstractUnderstanding the value that individuals assign to the protection of their personal data is of great importance for business	background	2K_dev_222
law	background	2K_dev_222
and public policy	background	2K_dev_222
The results highlight the sensitivity of privacy valuations to contextual	background	2K_dev_222
nonnormative factors	background	2K_dev_222
Individuals assigned markedly different values to the privacy of their data depending on ( 1 ) whether they were asked to consider how much money they would accept to disclose otherwise private information or how much they would pay to protect otherwise public information and ( 2 ) the order in which they considered different offers for their data The gap between such values is large compared with that observed in comparable studies of consumer goods	finding	2K_dev_222
	finding	2K_dev_222
	mechanism	2K_dev_222
We use a field experiment informed by behavioral economics and decision research	method	2K_dev_222
to investigate individual privacy valuations and find evidence of endowment and order effects	purpose	2K_dev_222
	purpose	2K_dev_222
Modern offices are crowded with personal computers	background	2K_dev_223
While studies have shown these to be idle most of the time	background	2K_dev_223
they remain powered	background	2K_dev_223
consuming up to 60p of their peak power Hardware-based solutions engendered by PC vendors ( e	background	2K_dev_223
g	background	2K_dev_223
	background	2K_dev_223
low-power states	background	2K_dev_223
Wake-on-LAN ) have proved unsuccessful because	background	2K_dev_223
in spite of user inactivity	background	2K_dev_223
these machines often need to remain network active in support of background applications that maintain network presence	background	2K_dev_223
	background	2K_dev_223
can deliver 44 -- 91p energy savings during idle periods of at least 10 minutes	finding	2K_dev_223
while providing low migration latencies of about 4 seconds and migrating minimal state that is under an order of magnitude of the VMs memory footprint	finding	2K_dev_223
We present partial VM migration	mechanism	2K_dev_223
an approach It creates a partial replica of the desktop VM on the consolidation server by copying only VM metadata	mechanism	2K_dev_223
and it transfers pages to the server on-demand	mechanism	2K_dev_223
as the VM accesses them	mechanism	2K_dev_223
This approach places desktop PCs in low-power mode when inactive and switches them to running mode when pages are needed by the VM running on the consolidation server	mechanism	2K_dev_223
To ensure that desktops save energy	mechanism	2K_dev_223
we have developed sleep scheduling and prefetching algorithms	mechanism	2K_dev_223
as well as the context-aware selective resume framework	mechanism	2K_dev_223
a novel approach to reduce the latency of power mode transition operations in commodity PCs	mechanism	2K_dev_223
	mechanism	2K_dev_223
Jettison	method	2K_dev_223
our software prototype of partial VM migration for off-the-shelf PCs	method	2K_dev_223
Recent proposals have advocated the use of consolidation of idle desktop Virtual Machines ( VMs )	purpose	2K_dev_223
However	purpose	2K_dev_223
desktop VMs are often large	purpose	2K_dev_223
requiring gigabytes of memory	purpose	2K_dev_223
Consolidating such VMs creates large network transfers lasting in the order of minutes and utilizes server memory inefficiently	purpose	2K_dev_223
When multiple VMs migrate concurrently	purpose	2K_dev_223
networks become congested	purpose	2K_dev_223
and the resulting migration latencies are prohibitive	purpose	2K_dev_223
that transparently migrates only the working set of an idle VM	purpose	2K_dev_223
Event detection from real surveillance videos with complicated background environment is always a very hard task	background	2K_dev_224
	finding	2K_dev_224
By virtue of such easily-distinguished mid-level patterns	mechanism	2K_dev_224
our framework realizes an effective labor division between computers and human participants	mechanism	2K_dev_224
The task of computers is to train classifiers on a bunch of mid-level discriminative representations	mechanism	2K_dev_224
and to sort all the possible mid-level representations in the evaluation sets based on the classifier scores	mechanism	2K_dev_224
The task of human participants is then to readily search the events based on the clues offered by these sorted mid-level representations	mechanism	2K_dev_224
For computers	mechanism	2K_dev_224
such mid-level representations	mechanism	2K_dev_224
with more concise and consistent patterns	mechanism	2K_dev_224
can be more accurately detected than video fragments utilized in the conventional framework	mechanism	2K_dev_224
and on the other hand	mechanism	2K_dev_224
a human participant can always much more easily search the events of interest implicated by these location-anchored mid-level representations than conventional video fragments containing entire scenes	mechanism	2K_dev_224
Both of these two properties facilitate the availability of our framework in real surveillance event detection applications	mechanism	2K_dev_224
	method	2K_dev_224
Different from the traditional retrospective and interactive systems designed on this task	purpose	2K_dev_224
which are mainly executed on video fragments located within the event-occurrence time	purpose	2K_dev_224
in this paper we propose a new interactive system constructed on the mid-level discriminative representations ( patches/shots ) which are closely related to the event ( might occur beyond the event-occurrence period ) and are easier to be detected than video fragments	purpose	2K_dev_224
	purpose	2K_dev_224
	background	2K_dev_225
	finding	2K_dev_225
	mechanism	2K_dev_225
	method	2K_dev_225
	purpose	2K_dev_225
These problems are motivated by the LASSO framework and have applications in machine learning and computer vision	background	2K_dev_226
	background	2K_dev_226
	finding	2K_dev_226
While this connection demonstrates the difficulties of obtaining runtime guarantees	mechanism	2K_dev_226
it also suggests an approach of using techniques originally developed for graph algorithms We then show that most of these problems can be formulated as a grouped least squares problem	mechanism	2K_dev_226
and give efficient algorithms for this formulation Our algorithms rely on routines for solving quadratic minimization problems	mechanism	2K_dev_226
which in turn are equivalent to solving linear systems	mechanism	2K_dev_226
	mechanism	2K_dev_226
Some preliminary experimental work on image processing tasks are also presented	method	2K_dev_226
We study theoretical runtime guarantees for a class of optimization problems that occur in a wide variety of inference problems	purpose	2K_dev_226
Our work shows a close connection between these problems and core questions in algorithmic graph theory	purpose	2K_dev_226
	purpose	2K_dev_226
Fluctuations in the growth rate of a bacterial culture during unbalanced growth are generally considered undesirable in quantitative studies of bacterial physiology Under well-controlled experimental conditions	background	2K_dev_227
however	background	2K_dev_227
these fluctuations are not random but instead reflect the interplay between intra-cellular networks underlying bacterial growth and the growth environment	background	2K_dev_227
Our method has implications for both basic understanding of bacterial physiology and for the classification of bacterial strains	background	2K_dev_227
	background	2K_dev_227
	finding	2K_dev_227
Here	mechanism	2K_dev_227
we present a method by time-frequency analysis of unbalanced growth curves measured with high temporal resolution	mechanism	2K_dev_227
The signatures are then applied to differentiate amongst different bacterial strains or the same strain under different growth conditions	mechanism	2K_dev_227
and to identify the essential architecture of the gene network underlying the observed growth dynamics	mechanism	2K_dev_227
	method	2K_dev_227
Therefore	purpose	2K_dev_227
these fluctuations could be considered quantitative phenotypes of the bacteria under a specific growth condition to identify phenotypic signatures	purpose	2K_dev_227
At the core of Machine Learning ( ML ) analytics is often an expert-suggested model	background	2K_dev_228
whose parameters are refined by iteratively processing a training dataset until convergence	background	2K_dev_228
The completion time ( i	background	2K_dev_228
e	background	2K_dev_228
convergence time ) and quality of the learned model not only depends on the rate at which the refinements are generated but also the quality of each refinement	background	2K_dev_228
	background	2K_dev_228
show that our mechanism significantly improves upon static communication schedules	finding	2K_dev_228
This paper presents Bosen	mechanism	2K_dev_228
a system that maximizes the network communication efficiency under a given inter-machine network bandwidth budget to minimize parallel error	mechanism	2K_dev_228
while ensuring theoretical convergence guarantees for large-scale data-parallel ML applications	mechanism	2K_dev_228
Furthermore	mechanism	2K_dev_228
Bosen prioritizes messages most significant to algorithm convergence	mechanism	2K_dev_228
further enhancing algorithm convergence	mechanism	2K_dev_228
Finally	mechanism	2K_dev_228
Bosen is the first distributed implementation of the recently presented adaptive revision algorithm	mechanism	2K_dev_228
which provides orders of magnitude improvement over a carefully tuned fixed schedule of step size refinements for some SGD algorithms	mechanism	2K_dev_228
	mechanism	2K_dev_228
Experiments on two clusters with up to 1024 cores	method	2K_dev_228
While data-parallel ML applications often employ a loose consistency model when updating shared model parameters to maximize parallelism	purpose	2K_dev_228
the accumulated error may seriously impact the quality of refinements and thus delay completion time	purpose	2K_dev_228
a problem that usually gets worse with scale	purpose	2K_dev_228
Although more immediate propagation of updates reduces the accumulated error	purpose	2K_dev_228
this strategy is limited by physical network bandwidth	purpose	2K_dev_228
Additionally	purpose	2K_dev_228
the performance of the widely used stochastic gradient descent ( SGD ) algorithm is sensitive to step size	purpose	2K_dev_228
Simply increasing communication often fails to bring improvement without tuning step size accordingly and tedious hand tuning is usually needed to achieve optimal performance	purpose	2K_dev_228
	purpose	2K_dev_228
Autonomous driving will play an important role in the future of transportation	background	2K_dev_229
Various autonomous vehicles have been demonstrated at the DARPA Urban Challenge [ 3 ]	background	2K_dev_229
General Motors has recently unveiled their Electrical-Networked Vehicles ( EN-V ) in Shanghai	background	2K_dev_229
China [ 5 ]	background	2K_dev_229
One of the main challenges of autonomous driving in urban areas is transition through cross-roads and intersections	background	2K_dev_229
In addition to safety concerns	background	2K_dev_229
current intersection management technologies such as stop signs and traffic lights can introduce significant traffic delays even under light traffic conditions	background	2K_dev_229
	background	2K_dev_229
	finding	2K_dev_229
and show significant improvements in throughput	finding	2K_dev_229
We also prove that our protocols avoid deadlock situations inside the intersection area	finding	2K_dev_229
results show that our new proposed V2V intersection protocols provide both safe passage through the intersection and significantly decrease the delay at the intersection and our latest V2V intersection protocol yields over 85 % overall performance improvement over the common traffic light models	finding	2K_dev_229
	finding	2K_dev_229
Our goal is to design and develop efficient and reliable intersection protocols	mechanism	2K_dev_229
We study how our proposed V2V intersection protocols can be beneficial for autonomous driving The simulation	method	2K_dev_229
to avoid vehicle collisions at intersections and increase the traffic throughput The focus of this paper is investigating vehicle-to-vehicle ( V2V ) communications as a part of co-operative driving in the context of autonomous vehicles	purpose	2K_dev_229
	purpose	2K_dev_229
Massive Open Online Courses ( MOOCs ) enable everyone to receive high-quality education	background	2K_dev_230
	background	2K_dev_230
show that ACD and PCD can detect usage of a cheat sheet with good accuracy and can reduce the overall human resources required to monitor MOOCs for cheating	finding	2K_dev_230
	finding	2K_dev_230
In this paper	mechanism	2K_dev_230
we propose a Massive Open Online Proctoring ( MOOP ) framework	mechanism	2K_dev_230
which combines both automatic and collaborative approaches The MOOP framework consists of three major components : Automatic Cheating Detector ( ACD )	mechanism	2K_dev_230
Peer Cheating Detector ( PCD )	mechanism	2K_dev_230
and Final Review Committee ( FRC )	mechanism	2K_dev_230
ACD uses webcam video or other sensors to monitor students and automatically flag suspected cheating behavior	mechanism	2K_dev_230
Ambiguous cases are then sent to the PCD	mechanism	2K_dev_230
where students peer-review flagged webcam video to confirm suspicious cheating behaviors	mechanism	2K_dev_230
Finally	mechanism	2K_dev_230
the list of suspicious cheating behaviors is sent to the FRC to make the final punishing decision	mechanism	2K_dev_230
	mechanism	2K_dev_230
Our experiment	method	2K_dev_230
However	purpose	2K_dev_230
current MOOC creators can not provide an effective	purpose	2K_dev_230
economical	purpose	2K_dev_230
and scalable method to detect cheating on tests	purpose	2K_dev_230
which would be required for any certification	purpose	2K_dev_230
to detect cheating behaviors in online tests	purpose	2K_dev_230
	purpose	2K_dev_230
Visible light communication ( VLC ) between LED light bulbs and smart-phone cameras has already begun to gain traction for identification and indoor localization applications	background	2K_dev_231
To support detection by cameras	background	2K_dev_231
the frequencies and data rates are typically limited to below 1kHz and tens of bytes per second ( Bps )	background	2K_dev_231
We show that we are able to reliably simultaneously transmit low-speed data at 1	finding	2K_dev_231
3 Bps to camera enabled devices and higher-speed data at 104 Bps to low-power embedded devices that consumes less then 204 uA and can be triggered in less then 10ms	finding	2K_dev_231
	finding	2K_dev_231
In this paper	mechanism	2K_dev_231
we present a technique used for interior ambient lighting in a manner that is imperceptible to occupants This allows the camera communication VLC channel to also act as a higher speed downstream link and low-power wakeup mechanism for energy-constrained devices Our approach uses Manchester encoding and Binary Frequency Shift Keying ( BFSK ) to modulate the high-speed data stream and applies duty-cycle adjustment to generate the slower camera communication signal	mechanism	2K_dev_231
We explore the trade-off between the performance of the two communication channels Our hybrid communication protocol is also compatible with existing IR receivers	mechanism	2K_dev_231
This allows lights to communicate with low-cost commodity chipsets and control home appliances such as TVs	mechanism	2K_dev_231
AV receivers	mechanism	2K_dev_231
AC window units	mechanism	2K_dev_231
etc Since the majority of energy in many RF communication protocols often goes towards media access and receiving	mechanism	2K_dev_231
VLC-triggered wakeup can significantly decrease system energy consumption	mechanism	2K_dev_231
	mechanism	2K_dev_231
We also demonstrate a proof-of-concept wakeup circuit	method	2K_dev_231
for transmitting data from solid-state luminaries	purpose	2K_dev_231
simultaneously to both cameras and low-power embedded devices	purpose	2K_dev_231
	background	2K_dev_232
	finding	2K_dev_232
	mechanism	2K_dev_232
	method	2K_dev_232
	purpose	2K_dev_232
Consider networks in harsh environments	background	2K_dev_233
where nodes may be lost due to failure	background	2K_dev_233
attack	background	2K_dev_233
or infection -- how is the topology affected by such events ?	background	2K_dev_233
	finding	2K_dev_233
We propose a new generative model of network evolution in dynamic and harsh environments	mechanism	2K_dev_233
Our model can reproduce the range of topologies observed across known robust and fragile biological networks	mechanism	2K_dev_233
as well as several additional transport	mechanism	2K_dev_233
communication	mechanism	2K_dev_233
and social networks	mechanism	2K_dev_233
We also develop a new optimization measure based on preserving high connectivity following random or adversarial bursty node loss	mechanism	2K_dev_233
propose a new distributed algorithm	mechanism	2K_dev_233
Using this measure	method	2K_dev_233
we evaluate the robustness of several real-world networks and	method	2K_dev_233
Can we mimic and measure the effect ? to evaluate robustness to construct secure networks operating within malicious environments	purpose	2K_dev_233
Such datasets arise in many social	background	2K_dev_234
economic	background	2K_dev_234
biological	background	2K_dev_234
and physical networks As a potential application of the graph Fourier transform	background	2K_dev_234
we consider the efficient representation of structured data that utilizes the sparseness of graph signals in the frequency domain	background	2K_dev_234
	background	2K_dev_234
We demonstrate their relation to the generalized eigenvector basis of the graph adjacency matrix	finding	2K_dev_234
We propose a novel discrete signal processing framework Our framework extends traditional discrete signal processing theory to structured datasets by viewing them as signals represented by graphs	mechanism	2K_dev_234
so that signal coefficients are indexed by graph nodes and relations between them are represented by weighted graph edges We discuss the notions of signals and filters on graphs	mechanism	2K_dev_234
and define the concepts of the spectrum and Fourier transform for graph signals	mechanism	2K_dev_234
and study their properties	method	2K_dev_234
	method	2K_dev_234
for the representation and analysis of datasets with complex structure	purpose	2K_dev_234
Computational methods have been widely used to infer properties of complex systems that one can not directly observe experimentally	background	2K_dev_235
Viral capsid assembly is a key model system for complex self-assembly for which we lack direct experimental data on critical information	background	2K_dev_235
such as kinetic parameters	background	2K_dev_235
needed to build models and reveal detailed assembly pathways	background	2K_dev_235
We previously sought to learn such hidden parameters with a heuristic optimization approach using gradient and response surface methods applied to the light scattering measurements of three in vitro viral assembly systems : human papillomavirus ( HPV )	background	2K_dev_235
hepatitis B virus ( HBV )	background	2K_dev_235
and cowpea chlorotic mottle virus ( CCMV )	background	2K_dev_235
This method successfully learned plausible kinetic parameters for all the three viruses leading to reconstruction of detailed models of assembly pathways Work is continuing on evaluating different DFO methods and customizing them to inference of kinetic parameters in order to determine the best strategies for inferring unobservable physical parameters in complex biological self-assembly systems	background	2K_dev_235
	background	2K_dev_235
Preliminary tests show improvements over our custom gradient-based method using a DFO strategy	finding	2K_dev_235
	finding	2K_dev_235
We explore here improvements based on the idea of derivative free optimization ( DFO )	mechanism	2K_dev_235
a class of optimization algorithm that can achieve faster and more accurate fitting	mechanism	2K_dev_235
especially on systems characterized by costly	mechanism	2K_dev_235
noisy evaluations of quality of fit	mechanism	2K_dev_235
	mechanism	2K_dev_235
	method	2K_dev_235
Significant computational challenges	purpose	2K_dev_235
however	purpose	2K_dev_235
hinder our ability to construct more precise or detailed models and reliably quantify uncertainty in the inferences	purpose	2K_dev_235
First	purpose	2K_dev_235
there is no closed form representation for the quality of fit of models to data	purpose	2K_dev_235
which therefore must be evaluated through computationally costly simulations	purpose	2K_dev_235
Second	purpose	2K_dev_235
the problem requires stochastic simulations	purpose	2K_dev_235
and the resulting simulation trajectories must be averaged over many replicates to suppress noise	purpose	2K_dev_235
Third	purpose	2K_dev_235
optimization of parameters must account for unknown factors and imprecision of experimental measurements	purpose	2K_dev_235
	purpose	2K_dev_235
Background : Intracortical electrode arrays that can record extracellular action potentials from small	background	2K_dev_236
targeted groups of neurons are critical for basic neuroscience research and emerging clinical applications In general	background	2K_dev_236
these electrode devices suffer from reliability and variability issues	background	2K_dev_236
which have led to comparative studies of existing and emerging electrode designs to optimize performance	background	2K_dev_236
Conclusions : A more extensive spatial and temporal insight into the chronic electrophysiological performance over time will help uncover the biological and mechanical failure mechanisms of the neural electrodes and direct future research toward the elucidation of design optimization for specific applications	background	2K_dev_236
	background	2K_dev_236
Results For example	finding	2K_dev_236
performance metrics in Layer V and stratum pyramidale were initially higher than Layer II/III	finding	2K_dev_236
but decrease more rapidly	finding	2K_dev_236
On the other hand	finding	2K_dev_236
Layer II/III maintained recording metrics longer In addition	finding	2K_dev_236
chronic changes at the level of layer IV are evaluated using visually evoked current source density	finding	2K_dev_236
The use of MU and LFP activity for evaluation and tracking biological depth provides a more comprehensive characterization of the electrophysiological performance landscape of microelectrodes	finding	2K_dev_236
	finding	2K_dev_236
New method : In this study	mechanism	2K_dev_236
we optimize the methods and parameters in eight mice visual cortices	mechanism	2K_dev_236
These findings quantify the large recording differences stemming from anatomical differences in depth and the layer dependent relative changes to SU and MU recording performance over 6-months	method	2K_dev_236
Comparison with existing method ( s ) :	method	2K_dev_236
Comparisons of different chronic recording devices have been limited to single-unit ( SU ) activity and employed a bulk averaging approach treating brain architecture as homogeneous with respect to electrode distribution	purpose	2K_dev_236
to quantify evoked multi-unit ( MU ) and local field potential ( LFP ) recordings	purpose	2K_dev_236
Multimedia event detection ( MED ) is an emerging area of research	background	2K_dev_237
	background	2K_dev_237
The results show that our approach outperforms several other state-of-the-art detection algorithms	finding	2K_dev_237
Moreover	mechanism	2K_dev_237
our solution only uses few positive examples since precisely labeled multimedia content is scarce in the real world	mechanism	2K_dev_237
As the information from these few positive examples is limited	mechanism	2K_dev_237
we propose using knowledge adaptation to facilitate event detection Different from the state of the art	mechanism	2K_dev_237
our algorithm is able to adapt knowledge from another source for MED even if the features of the source and the target are partially different	mechanism	2K_dev_237
but overlapping	mechanism	2K_dev_237
Avoiding the requirement that the two domains are consistent in feature types is desirable as data collection platforms change or augment their capabilities and we should be able to respond to this with little or no effort	mechanism	2K_dev_237
We perform extensive experiments on real-world multimedia archives consisting of several challenging events	method	2K_dev_237
Previous work mainly focuses on simple event detection in sports and news videos	purpose	2K_dev_237
or abnormality detection in surveillance videos	purpose	2K_dev_237
In contrast	purpose	2K_dev_237
we focus on detecting more complicated and generic events that gain more users ' interest	purpose	2K_dev_237
and we explore an effective solution for MED	purpose	2K_dev_237
	purpose	2K_dev_237
ABSTRACT In spite of their many advantages	background	2K_dev_238
real -world application of guided -waves for structural health monitoring ( SHM ) of pipelines is still quite limited	background	2K_dev_238
The challenges can be discussed under three headings : ( 1 ) Multiple m odes	background	2K_dev_238
( 2 ) Multi -path reflections	background	2K_dev_238
and ( 3 ) Sensitivity to environmental and operational conditions ( EOCs ) These challenges are UHYLHZHG LQ WKH DXWKRUV SUHYLRXV ZRUN This paper is part of a study whose objective is to overcome these challenges for damage diagnosis of pipes	background	2K_dev_238
while addressing the limitations of the current approaches	background	2K_dev_238
That is	background	2K_dev_238
develop methods that simplify signal while retaining damage information	background	2K_dev_238
and perform well as EOC s vary	background	2K_dev_238
Moreover	background	2K_dev_238
the potential of the proposed met hod for online monitoring is illustrated	background	2K_dev_238
for wide range of temperature variations and different damage scenarios	background	2K_dev_238
	background	2K_dev_238
The results suggest that	finding	2K_dev_238
for practical ranges of monitoring and damage sizes of interest	finding	2K_dev_238
the proposed method has low sensitivity to such training factors	finding	2K_dev_238
High detection performances are obtained for temperature differences up to 14 (	finding	2K_dev_238
The finding s reported in this paper suggest that although the proposed method is a supervised approach	finding	2K_dev_238
labeling of the training data does not require prior knowledge about the damage characteristics ( e	finding	2K_dev_238
g	finding	2K_dev_238
	finding	2K_dev_238
size	finding	2K_dev_238
location )	finding	2K_dev_238
	finding	2K_dev_238
In this paper	mechanism	2K_dev_238
a s upervised method is proposed That is	mechanism	2K_dev_238
a discriminant vector is calculated so that the projection s of undamaged and damaged pipes on this vector is separated	mechanism	2K_dev_238
In the training stage	mechanism	2K_dev_238
data is recorded from intact pipe	mechanism	2K_dev_238
and from a pipe with an artificial structural abnormality ( to simulate any variation from intact condition )	mechanism	2K_dev_238
During the monitoring stage	mechanism	2K_dev_238
test signals are projected on the discriminant vector	mechanism	2K_dev_238
and these projections are used as damage -sensitive features for detection purposes	mechanism	2K_dev_238
Being a supervised metho d	mechanism	2K_dev_238
factors such as EOC variations	mechanism	2K_dev_238
and difference in the characteristics of the structural abnormality in training and test data	mechanism	2K_dev_238
may affect the detection performance	mechanism	2K_dev_238
This paper reports the experiments investigating the extent to which the differences in damage size and damage location	method	2K_dev_238
as well as temperatures	method	2K_dev_238
can influence the discriminatory power of the extracted damage -sensitive features	method	2K_dev_238
	method	2K_dev_238
to extract a sparse subset of the ultrasonic guided -wave signal s that contain optimal damage information for detection purposes	purpose	2K_dev_238
	background	2K_dev_239
	finding	2K_dev_239
We present an adaptive graph filtering approach Adaptive graph filters combine decisions from multiple graph filters using a weighting function that is optimized in a semi-supervised manner	mechanism	2K_dev_239
We also demonstrate the multiresolution property of adaptive graph filters by connecting them to the diffusion wavelets	mechanism	2K_dev_239
In our experiments	method	2K_dev_239
we apply the adaptive graph filters to the classification of online blogs and damage identification in indirect bridge structural health monitoring	method	2K_dev_239
	method	2K_dev_239
to semi-supervised classification	purpose	2K_dev_239
	background	2K_dev_240
Most noticeably	finding	2K_dev_240
the accuracy of our algorithm reaches 51	finding	2K_dev_240
8 % on the challenging HMDB dataset which outperforms the state-of-the-art of 7	finding	2K_dev_240
3 % relatively	finding	2K_dev_240
	finding	2K_dev_240
We propose a novel content driven pooling that leverages space-time context while being robust toward global space-time transformations	mechanism	2K_dev_240
Being robust to such transformations is of primary importance in unconstrained videos where the action localizations can drastically shift between frames	mechanism	2K_dev_240
Our pooling identifies regions of interest using video structural cues estimated by different saliency functions To combine the different structural information	mechanism	2K_dev_240
we introduce an iterative structure learning algorithm	mechanism	2K_dev_240
WSVM ( weighted SVM )	mechanism	2K_dev_240
that determines the optimal saliency layout of an action model through a sparse regularizer	mechanism	2K_dev_240
A new optimization method is proposed to solve the WSVM ' highly non-smooth objective function	mechanism	2K_dev_240
	mechanism	2K_dev_240
We evaluate our approach on standard action datasets ( KTH	method	2K_dev_240
UCF50 and HMDB )	method	2K_dev_240
	method	2K_dev_240
We address the problem of action recognition in unconstrained videos	purpose	2K_dev_240
	purpose	2K_dev_240
Large scale integration of stochastic energy resources in power systems requires probabilistic analysis approaches for comprehensive system analysis	background	2K_dev_241
The large-varying grid condition on the aging and stressed power system infrastructures also requires merging of offline security analyses into online operation Meanwhile in computing	background	2K_dev_241
the recent rapid hardware performance growth comes from the more and more complicated architecture	background	2K_dev_241
	finding	2K_dev_241
Given the challenges and opportunities in both the power system and the computing fields	mechanism	2K_dev_241
this paper presents the unique commodity high performance computing system solutions 1 ) a high performance Monte Carlo simulation ( MCS ) based distribution probabilistic load flow solver 2 ) A high performance MCS based transmission probabilistic load flow solver 3 ) A SIMD accelerated based on Woodbury matrix identity on multi-core CPUs By aggressive algorithm level and computer architecture level performance optimizations including optimized data structures	mechanism	2K_dev_241
optimization for superscalar out-of-order execution	mechanism	2K_dev_241
SIMDization	mechanism	2K_dev_241
and multi-core scheduling	mechanism	2K_dev_241
our software fully utilizes the modern commodity computing systems	mechanism	2K_dev_241
makes the critical and computational intensive power system probabilistic and security analysis problems solvable in real-time on commodity computing systems	mechanism	2K_dev_241
	mechanism	2K_dev_241
	method	2K_dev_241
Fully utilizing the computing power for specific applications becomes very difficult to the following fundamental tools for power system probabilistic and security analysis : for real-time distribution feeder probabilistic solutions for transmission grid probabilistic analysis	purpose	2K_dev_241
AC contingency calculation solver	purpose	2K_dev_241
Lamb waves are powerful tools in nondestructive evaluation and structural health monitoring	background	2K_dev_242
Researchers use Lamb waves to detect and locate damage across large areas	background	2K_dev_242
To best utilize Lamb waves	background	2K_dev_242
they are analyzed through two processing steps : baseline subtraction and velocity calibration	background	2K_dev_242
Baseline subtraction removes background information from our data and velocity calibration tunes our algorithms Yet	background	2K_dev_242
in many scenarios	background	2K_dev_242
these steps are challenging to implement	background	2K_dev_242
We show these combined approaches to be effective	finding	2K_dev_242
we present two approaches that combine environmental compensation with self-calibrating localization We discuss temperature compensation strategies based on the scale transform and singular value decomposition We then integrate these with a localization framework known as data-driven matched field processing	mechanism	2K_dev_242
	mechanism	2K_dev_242
in a variety of scenarios	method	2K_dev_242
	method	2K_dev_242
Baseline subtraction is challenging due to variable environmental conditions	purpose	2K_dev_242
Velocity calibration is challenging due to multi-modal and dispersive velocity behavior in Lamb waves	purpose	2K_dev_242
To address both challenges	purpose	2K_dev_242
Modern robots	background	2K_dev_243
like todays smartphones	background	2K_dev_243
are complex devices with intricate software systems	background	2K_dev_243
	finding	2K_dev_243
This paper focuses on teaching with Tekkotsu	mechanism	2K_dev_243
an open source robot application development framework designed specifically for education But	mechanism	2K_dev_243
the curriculum described here can also be taught using ROS	mechanism	2K_dev_243
the Robot Operating System that is now widely used for robotics research	mechanism	2K_dev_243
	mechanism	2K_dev_243
	method	2K_dev_243
Introductory robot programming courses must evolve to reflect this reality	purpose	2K_dev_243
by teaching students to make use of the sophisticated tools their robots provide rather than reimplementing basic algorithms	purpose	2K_dev_243
	purpose	2K_dev_243
As airspace becomes ever more crowded	background	2K_dev_244
air traffic management must reduce both space and time between aircraft to increase throughput	background	2K_dev_244
making on-board collision avoidance systems ever more important	background	2K_dev_244
These safety-critical systems must be extremely reliable	background	2K_dev_244
and as such	background	2K_dev_244
many resources are invested into ensuring that the protocols they implement are accurate	background	2K_dev_244
Still	background	2K_dev_244
it is challenging to guarantee that such a controller works properly under every circumstance	background	2K_dev_244
This is an important step in formally verified	background	2K_dev_244
flyable	background	2K_dev_244
and distributed air traffic control	background	2K_dev_244
We prove that the controllers never allow the aircraft to get too close to one another	finding	2K_dev_244
even when new planes approach an in-progress avoidance maneuver that the new plane may not be aware of	finding	2K_dev_244
Because these safety guarantees always hold	finding	2K_dev_244
the aircraft are protected against unexpected emergent behavior which simulation and testing may miss	finding	2K_dev_244
	mechanism	2K_dev_244
We consider a class of distributed collision avoidance controllers designed to work even in environments with arbitrarily many aircraft or UAVs	method	2K_dev_244
	method	2K_dev_244
In tough scenarios where a large number of aircraft must execute a collision avoidance maneuver	purpose	2K_dev_244
a human pilot under stress is not necessarily able to understand the complexity of the distributed system and may not take the right course	purpose	2K_dev_244
especially if actions must be taken quickly	purpose	2K_dev_244
	purpose	2K_dev_244
	background	2K_dev_245
	finding	2K_dev_245
	mechanism	2K_dev_245
	method	2K_dev_245
	purpose	2K_dev_245
Brand Associations	background	2K_dev_246
one of central concepts in marketing	background	2K_dev_246
describe customers ' top-of-mind attitudes or feelings toward a brand	background	2K_dev_246
Thus	background	2K_dev_246
this consumer-driven brand equity often attains the grounds for purchasing products or services of the brand	background	2K_dev_246
	background	2K_dev_246
we demonstrate that our approach can discover complementary views on the brand associations that are hardly mined from the text data show that our approach outperforms other candidate methods on the both visualization tasks	finding	2K_dev_246
	finding	2K_dev_246
As a first technical step toward the study of photo-based brand associations	mechanism	2K_dev_246
we aim to jointly achieve the following two visualization tasks in a mutually-rewarding way : ( i ) detecting and visualizing core visual concepts associated with brands	mechanism	2K_dev_246
and ( ii ) localizing the regions of brand in the images	mechanism	2K_dev_246
	mechanism	2K_dev_246
With experiments on about five millions of images of 48 brands crawled from five popular online photo sharing sites	method	2K_dev_246
We also quantitatively	method	2K_dev_246
Traditionally	purpose	2K_dev_246
brand associations are measured by analyzing the text data from consumers ' responses to the survey or their online conversation logs	purpose	2K_dev_246
In this paper	purpose	2K_dev_246
we propose to go beyond text data and leverage large-scale online photo collections contributed by the general public	purpose	2K_dev_246
which have not been explored so far	purpose	2K_dev_246
	purpose	2K_dev_246
the importance of studying the implications of sampling is twofold : First	background	2K_dev_247
sampling is a means of reducing the size of the database hence making it more accessible to researchers ; second	background	2K_dev_247
because every such data collection can be perceived as a sample of the real world To the best of our knowledge	background	2K_dev_247
our work represents the largest study of propagation patterns of executables	background	2K_dev_247
	finding	2K_dev_247
We discover the SharkFin temporal propagation pattern of executable files	mechanism	2K_dev_247
the GeoSplit pattern in the geographical spread of machines that report executables to Symantecs servers	mechanism	2K_dev_247
the Periodic Power Law ( Ppl ) distribution of the lifetime of URLs	mechanism	2K_dev_247
and we show how	mechanism	2K_dev_247
by analyzing patterns from 22 million malicious ( and benign ) files	method	2K_dev_247
found on 1	method	2K_dev_247
6 million hosts worldwide during the month of June 2011 We conduct this study using the WINE database available at Symantec Research Labs Additionally	method	2K_dev_247
we explore the research questions raised by sampling on such large databases of executables ; We further investigate the propagation pattern of benign and malicious executables	method	2K_dev_247
unveiling latent structures in the way these files spread	method	2K_dev_247
	method	2K_dev_247
How does malware propagate ? Does it form spikes over time ? Does it resemble the propagation pattern of benign files	purpose	2K_dev_247
such as software patches ? Does it spread uniformly over countries ? How long does it take for a URL that distributes malware to be detected and shut down ? In this work	purpose	2K_dev_247
we answer these questions to efficiently extrapolate crucial properties of the data from a small sample	purpose	2K_dev_247
	purpose	2K_dev_247
	background	2K_dev_248
and outline ideas for future research in this	background	2K_dev_248
We demonstrate that crowd storage is feasible	finding	2K_dev_248
This paper introduces the concept of crowd storage Similar to human memory	mechanism	2K_dev_248
crowd storage is ephemeral	mechanism	2K_dev_248
which means that storage is temporary and the quality of the stored information degrades over time	mechanism	2K_dev_248
Crowd storage may be preferred over storing information directly in the cloud	mechanism	2K_dev_248
or when it is desirable for information to degrade inline with normal human memories	mechanism	2K_dev_248
we created WeStore	mechanism	2K_dev_248
a system that stores and then later retrieves digital files in the existing memories of crowd workers	mechanism	2K_dev_248
WeStore does not store information directly	mechanism	2K_dev_248
but rather encrypts the files using details of the existing memories elicited from individuals within the crowd as cryptographic keys	mechanism	2K_dev_248
The fidelity of the retrieved information is tied to how well the crowd remembers the details of the memories they provided	mechanism	2K_dev_248
	mechanism	2K_dev_248
using an existing crowd marketplace ( Amazon Mechanical Turk )	method	2K_dev_248
explore design considerations important for building systems that use crowd storage area	method	2K_dev_248
	method	2K_dev_248
	purpose	2K_dev_248
the idea that digital files can be stored and retrieved later from the memories of people in the crowd To explore and validate this idea	purpose	2K_dev_248
	purpose	2K_dev_248
Our approach is not limited to images	background	2K_dev_249
but they provide a convenient query space to test search optimizations	background	2K_dev_249
	background	2K_dev_249
	finding	2K_dev_249
We present a cloud-based approach that is sensitive to bandwidth and energy constraints Our approach is inspired by the long-established practice of photographers using contact sheets to rapidly visualize a new collection of photographs	mechanism	2K_dev_249
and then selecting a subset on which to focus attention	mechanism	2K_dev_249
On behalf of each smartphone	mechanism	2K_dev_249
the cloud maintains a virtual contact sheet of images that have been captured but not yet uploaded	mechanism	2K_dev_249
The virtual contact sheet consists of a set of low-fidelity images as well as full or partial meta-data associated with each image	mechanism	2K_dev_249
If search processing on the cloud indicates that a particular low-fidelity object is relevant	mechanism	2K_dev_249
then its full-fidelity image can be obtained just-in-time from the corresponding smartphone for further search processing or presentation to the user	mechanism	2K_dev_249
	mechanism	2K_dev_249
	method	2K_dev_249
to opportunistic	purpose	2K_dev_249
near real-time search of untagged images on smartphones	purpose	2K_dev_249
	background	2K_dev_250
	finding	2K_dev_250
	mechanism	2K_dev_250
	method	2K_dev_250
	purpose	2K_dev_250
Autonomous driving is likely to be the heart of urban transportation in the future Autonomous vehicles have the potential to increase the safety of passengers and also to make road trips shorter and more enjoyable	background	2K_dev_251
As the first steps toward these goals	background	2K_dev_251
many car manufacturers are investing in designing and equipping their vehicles with advanced driver-assist systems	background	2K_dev_251
Road intersections are considered to be serious bottlenecks of urban transportation	background	2K_dev_251
as more than 44 % of all reported crashes in U	background	2K_dev_251
S	background	2K_dev_251
occur within intersection areas which in turn lead to 8	background	2K_dev_251
500 fatalities and approximately 1 million injuries every year	background	2K_dev_251
Furthermore	background	2K_dev_251
the impact of road intersections on traffic delays leads to enormous waste of human and natural resources	background	2K_dev_251
We show that	finding	2K_dev_251
in addition to intersections	finding	2K_dev_251
these protocols are also applicable to vehicle crossings at roundabouts	finding	2K_dev_251
results show that we are able to avoid collisions and also increase the throughput of the intersections up to 87	finding	2K_dev_251
82 % compared to common traffic-light signalized intersections	finding	2K_dev_251
We have designed and developed efficient and reliable intersection protocols In this paper	mechanism	2K_dev_251
we introduce new V2V intersection protocols and suggest required modifications	mechanism	2K_dev_251
We have been investigating vehicle-to-vehicle ( V2V ) communications as a part of co-operative driving in the context of autonomous driving	method	2K_dev_251
Additionally	method	2K_dev_251
we study the effects of position inaccuracy of commonly-used GPS devices on some of our V2V intersection protocols Our simulation	method	2K_dev_251
In this paper	purpose	2K_dev_251
we therefore focus on intersection management in Intelligent Transportation Systems ( ITS ) research	purpose	2K_dev_251
In the future	purpose	2K_dev_251
when dealing with autonomous vehicles	purpose	2K_dev_251
it is critical to address safety and throughput concerns that arise from autonomous driving through intersections and roundabouts Our goal is to provide vehicles with a safe and efficient passage method through intersections and roundabouts	purpose	2K_dev_251
to avoid vehicle collisions at intersections and increase traffic throughput	purpose	2K_dev_251
to achieve the above goals to guarantee their safety and efficiency despite these impairments	purpose	2K_dev_251
Parameterized probabilistic complex computational ( P 2 C 2 ) models are being increasingly used in computational systems biology for analyzing biological systems	background	2K_dev_252
A key challenge is to build mechanistic P 2 C 2 models by combining prior knowledge and empirical data	background	2K_dev_252
given that certain system properties are unknown	background	2K_dev_252
	background	2K_dev_252
that guarantee a set of desired clinical outcomes with high probability	finding	2K_dev_252
We present a new algorithmic procedure Our approach uses Bayesian model checking	mechanism	2K_dev_252
sequential hypothesis testing	mechanism	2K_dev_252
and stochastic optimization to synthesize parameters of P 2 C 2 models	mechanism	2K_dev_252
	mechanism	2K_dev_252
We demonstrate our algorithm by discovering the amount and schedule of doses of bacterial lipopolysaccharide in a clinical agent-based model of the dynamics of acute inflammation	method	2K_dev_252
These unknown components are incorporated into a model as parameters and determining their values has traditionally been a process of trial and error	purpose	2K_dev_252
for discovering parameters in agent-based models of biological systems against behavioral specifications mined from large data-sets	purpose	2K_dev_252
	background	2K_dev_253
we demonstrate that the proposed joint summarization approach outperforms other baselines and our own methods using videos or images only	finding	2K_dev_253
	finding	2K_dev_253
Starting from the intuition that the characteristics of the two media types are different yet complementary	mechanism	2K_dev_253
we develop a fast and easily-parallelizable approach The storyline graphs can illustrate various events or activities associated with the topic in a form of a branching network	mechanism	2K_dev_253
The video summarization is achieved by diversity ranking on the similarity graphs between images and video frames	mechanism	2K_dev_253
The reconstruction of storyline graphs is formulated as the inference of sparse time-varying directed graphs from a set of photo streams with assistance of videos	mechanism	2K_dev_253
	mechanism	2K_dev_253
For evaluation	method	2K_dev_253
we collect the datasets of 20 outdoor activities	method	2K_dev_253
consisting of 2	method	2K_dev_253
7M Flickr images and 16K YouTube videos	method	2K_dev_253
Due to the large-scale nature of our problem	method	2K_dev_253
we evaluate our algorithm via crowdsourcing using Amazon Mechanical Turk	method	2K_dev_253
In our experiments	method	2K_dev_253
	method	2K_dev_253
In this paper	purpose	2K_dev_253
we address the problem of jointly summarizing large sets of Flickr images and YouTube videos	purpose	2K_dev_253
for creating not only high-quality video summaries but also novel structural summaries of online images as storyline graphs	purpose	2K_dev_253
	purpose	2K_dev_253
Although widely touted as a replacement for glass slides and microscopes in pathology	background	2K_dev_254
digital slides present major challenges in data storage	background	2K_dev_254
transmission	background	2K_dev_254
processing and interoperability OpenSlide is in use today by many academic and industrial organizations world-wide	background	2K_dev_254
including many research sites in the United States that are funded by the National Institutes of Health	background	2K_dev_254
can transparently handle multiple vendor formats	finding	2K_dev_254
In this paper	mechanism	2K_dev_254
we present the design and implementation of OpenSlide	mechanism	2K_dev_254
a vendor-neutral C library The library is extensible and easily interfaced to various programming languages	mechanism	2K_dev_254
	mechanism	2K_dev_254
An application written to the OpenSlide interface	method	2K_dev_254
Since no universal data format is in widespread use for these images today	purpose	2K_dev_254
each vendor defines its own proprietary data formats	purpose	2K_dev_254
analysis tools	purpose	2K_dev_254
viewers and software libraries	purpose	2K_dev_254
This creates issues not only for pathologists	purpose	2K_dev_254
but also for interoperability for reading and manipulating digital slides of diverse vendor formats	purpose	2K_dev_254
	purpose	2K_dev_254
	background	2K_dev_255
we show that these 'skin buttons ' can have high touch accuracy and recognizability	finding	2K_dev_255
while being low cost and power-efficient	finding	2K_dev_255
We propose using tiny projectors integrated into the smartwatch These icons can be made touch sensitive	mechanism	2K_dev_255
significantly expanding the interactive region without increasing device size	mechanism	2K_dev_255
	mechanism	2K_dev_255
Through a series of experiments	method	2K_dev_255
	method	2K_dev_255
Smartwatches are a promising new interactive platform	purpose	2K_dev_255
but their small size makes even basic actions cumbersome	purpose	2K_dev_255
Hence	purpose	2K_dev_255
there is a great need for approaches that expand the interactive envelope around smartwatches	purpose	2K_dev_255
allowing human input to escape the small physical confines of the device	purpose	2K_dev_255
to render icons on the user 's skin	purpose	2K_dev_255
	purpose	2K_dev_255
	background	2K_dev_256
	finding	2K_dev_256
	mechanism	2K_dev_256
	method	2K_dev_256
	purpose	2K_dev_256
	background	2K_dev_257
We demonstrate High Assurance SPIRALs capability	finding	2K_dev_257
In this paper we introduce High Assurance SPIRAL High Assurance SPIRAL is a scalable methodology to translate a high level specification of a high assurance controller into a highly resource-efficient	mechanism	2K_dev_257
platform-adapted	mechanism	2K_dev_257
verified control software implementation for a given platform in a language like C or C++	mechanism	2K_dev_257
High Assurance SPIRAL proves that the implementation is equivalent to the specification written in the control engineers domain language	mechanism	2K_dev_257
Our approach scales to problems involving floating-point calculations and provides highly optimized synthesized code It is possible to estimate the available headroom to enable assurance/performance trade-offs under real-time constraints	mechanism	2K_dev_257
and enables the synthesis of multiple implementation variants to make attacks harder	mechanism	2K_dev_257
At the core of High Assurance SPIRAL is the Hybrid Control Operator Language ( HCOL ) that leverages advanced mathematical constructs expressing the controller specification to provide high quality translation capabilities	mechanism	2K_dev_257
Combined with a verified/certified compiler	mechanism	2K_dev_257
High Assurance SPIRAL provides a comprehensive complete solution to the efficient synthesis of verifiable high assurance controllers	mechanism	2K_dev_257
by co-synthesizing proofs and implementations for attack detection and sensor spoofing algorithms and deploy the code as ROS nodes on the Landshark unmanned ground vehicle and on a Synthetic Car in a real-time simulator	method	2K_dev_257
to solve the last mile problem for the synthesis of high assurance implementations of controllers for vehicular systems that are executed in todays and future embedded and high performance embedded system processors	purpose	2K_dev_257
A responsibility we have as researchers is to disseminate the results of our research widely	background	2K_dev_258
A primary way we do this is through research publications	background	2K_dev_258
We offer thoughts on research challenges and future work that may make our community 's research more accessible	background	2K_dev_258
	background	2K_dev_258
	finding	2K_dev_258
Second	mechanism	2K_dev_258
we reflect on our experience making papers accessible for any CHI 2015 author who requested it	mechanism	2K_dev_258
First	method	2K_dev_258
we report on the accessibility of 1	method	2K_dev_258
811 papers in the technical program of several top conferences related to accessibility and human-computer interaction	method	2K_dev_258
When these publications are not accessible to everyone	purpose	2K_dev_258
some readers will be excluded and the impact of our research limited	purpose	2K_dev_258
In this paper	purpose	2K_dev_258
we explore this problem in two ways	purpose	2K_dev_258
	purpose	2K_dev_258
	background	2K_dev_259
	finding	2K_dev_259
	mechanism	2K_dev_259
	method	2K_dev_259
	purpose	2K_dev_259
	background	2K_dev_260
show that under different clutter backgrounds the proposed method not only works more stably for different target sizes and signal-to-clutter ratio values	finding	2K_dev_260
but also has better detection performance compared with conventional baseline methods	finding	2K_dev_260
A novel small target detection method in a single infrared image is proposed in this paper Initially	mechanism	2K_dev_260
the traditional infrared image model is generalized to a new infrared patch-image model using local patch construction	mechanism	2K_dev_260
Then	mechanism	2K_dev_260
because of the non-local self-correlation property of the infrared background image	mechanism	2K_dev_260
based on the new model small target detection is formulated as an optimization problem of recovering low-rank and sparse matrices	mechanism	2K_dev_260
which is effectively solved using stable principle component pursuit	mechanism	2K_dev_260
Finally	mechanism	2K_dev_260
a simple adaptive segmentation method is used to segment the target image and the segmentation result can be refined by post-processing	mechanism	2K_dev_260
	mechanism	2K_dev_260
Extensive synthetic and real data experiments	method	2K_dev_260
The robust detection of small targets is one of the key techniques in infrared search and tracking applications	purpose	2K_dev_260
	background	2K_dev_261
	finding	2K_dev_261
our experimental results show that the proposed algorithm is more successful in time-sensitive image retrieval than other candidate methods	finding	2K_dev_261
including ranking SVM	finding	2K_dev_261
a PageRank-based image ranking	finding	2K_dev_261
and a generative temporal topic model	finding	2K_dev_261
	finding	2K_dev_261
in which given a query keyword	mechanism	2K_dev_261
a query time point	mechanism	2K_dev_261
and optionally user information	mechanism	2K_dev_261
we retrieve the most relevant and temporally suitable images from the database	mechanism	2K_dev_261
Inspired by recently emerging interests on query dynamics in information retrieval research	mechanism	2K_dev_261
our time-sensitive image retrieval algorithm can infer users ' implicit search intent better and provide more engaging and diverse search results according to temporal trends of Web user photos We model observed image streams as instances of multivariate point processes represented by several different descriptors	mechanism	2K_dev_261
and develop a regularized multi-task regression framework that automatically selects and learns stochastic parametric models to solve the relations between image occurrence probabilities and various temporal factors that influence them	mechanism	2K_dev_261
	mechanism	2K_dev_261
Using Flickr datasets of more than seven million images of 30 topics	method	2K_dev_261
In this paper	purpose	2K_dev_261
we investigate a time-sensitive image retrieval problem	purpose	2K_dev_261
	purpose	2K_dev_261
As part of a collaboration with a major California school district	background	2K_dev_262
	background	2K_dev_262
show that a nontrivial implementation of the leximin mechanism scales gracefully in terms of running time ( even though the problem is intractable in theory )	finding	2K_dev_262
and performs extremely well with respect to a number of efficiency objectives	finding	2K_dev_262
Our approach revolves around the randomized leximin mechanism We extend previous work to the classroom allocation setting	mechanism	2K_dev_262
showing that the leximin mechanism is proportional	mechanism	2K_dev_262
envy-free	mechanism	2K_dev_262
efficient	mechanism	2K_dev_262
and group strategyproof	mechanism	2K_dev_262
We also prove that the leximin mechanism provides a ( worst-case ) 4-approximation to the maximum number of classrooms that can possibly be allocated	mechanism	2K_dev_262
We take great pains to establish the practicability of our approach	mechanism	2K_dev_262
and discuss issues related to its deployment	mechanism	2K_dev_262
Our experiments	method	2K_dev_262
which are based on real data	method	2K_dev_262
	method	2K_dev_262
we study the problem of fairly allocating unused classrooms in public schools to charter schools	purpose	2K_dev_262
	purpose	2K_dev_262
The LD results answer a fundamental question on how to quantify the rate at which the distributed scheme approaches the centralized performance as the inter-sensor communication rate increases	background	2K_dev_263
it is shown that the network achieves weak consensus	finding	2K_dev_263
i	finding	2K_dev_263
e	finding	2K_dev_263
	finding	2K_dev_263
the conditional estimation error covariance at a randomly selected sensor converges weakly ( in distribution ) to a unique invariant measure	finding	2K_dev_263
Further	finding	2K_dev_263
it is proved that as $ \overline { \gamma } \rightarrow \infty $ this invariant measure satisfies the Large Deviation ( LD ) upper and lower bounds	finding	2K_dev_263
implying that this measure converges exponentially fast ( in probability ) to the Dirac measure $ \delta_ { P^* } $	finding	2K_dev_263
where $ P^* $ is the stable error covariance of the centralized ( Kalman ) filtering setup	finding	2K_dev_263
	finding	2K_dev_263
A gossip network protocol termed Modified Gossip Interactive Kalman Filtering ( M-GIKF ) is proposed	mechanism	2K_dev_263
where sensors exchange their filtered states ( estimates and error covariances ) and propagate their observations via inter-sensor communications of rate $ \overline { \gamma } $ ; $ \overline { \gamma } $ is defined as the averaged number of inter-sensor message passages per signal evolution epoch The filtered states are interpreted as stochastic particles swapped through local interaction	mechanism	2K_dev_263
The paper shows that the conditional estimation error covariance sequence at each sensor under M-GIKF evolves as a random Riccati equation ( RRE ) with Markov modulated switching	mechanism	2K_dev_263
By formulating the RRE as a random dynamical system	method	2K_dev_263
	method	2K_dev_263
This paper studies the convergence of the estimation error process and the characterization of the corresponding invariant measure in distributed Kalman filtering for potentially unstable and large linear dynamic systems	purpose	2K_dev_263
	purpose	2K_dev_263
Given a set of k networks	background	2K_dev_264
possibly with different sizes and no overlaps in nodes or links	background	2K_dev_264
how can we quickly assess similarity between them ? Analogously	background	2K_dev_264
are there a set of social theories which	background	2K_dev_264
when represented by a small number of descriptive	background	2K_dev_264
numerical features	background	2K_dev_264
effectively serve as a `` signature '' for the network ?	background	2K_dev_264
NETSIMILE outperforms baseline competitors	finding	2K_dev_264
We propose a novel	mechanism	2K_dev_264
effective	mechanism	2K_dev_264
and scalable method	mechanism	2K_dev_264
called NETSIMILE Our approach has the following desirable properties : ( a ) It is supported by a set of social theories	mechanism	2K_dev_264
( b ) It gives similarity scores that are size-invariant	mechanism	2K_dev_264
( c ) It is scalable	mechanism	2K_dev_264
being linear on the number of links for graph signature extraction our approach enables several mining tasks such as clustering	mechanism	2K_dev_264
visualization	mechanism	2K_dev_264
discontinuity detection	mechanism	2K_dev_264
network transfer learning	mechanism	2K_dev_264
and re-identification across networks	mechanism	2K_dev_264
	mechanism	2K_dev_264
In extensive experiments on numerous synthetic and real networks from disparate domains	method	2K_dev_264
We also demonstrate how	method	2K_dev_264
Having such signatures will enable a wealth of graph mining and social network analysis tasks	purpose	2K_dev_264
including clustering	purpose	2K_dev_264
outlier detection	purpose	2K_dev_264
visualization	purpose	2K_dev_264
etc for solving the above problem	purpose	2K_dev_264
Short-term forecasting is a ubiquitous practice in a wide range of energy systems	background	2K_dev_265
including forecasting demand	background	2K_dev_265
renewable generation	background	2K_dev_265
and electricity pricing	background	2K_dev_265
	background	2K_dev_265
we show that this probabilistic model greatly outperforms other methods on the task of accurately modeling potential distributions of power ( as would be necessary in a stochastic dispatch problem	finding	2K_dev_265
for example )	finding	2K_dev_265
	finding	2K_dev_265
In this paper	mechanism	2K_dev_265
we apply a recently-proposed algorithm for modeling high-dimensional conditional Gaussian distributions to forecasting wind power and extend it to the non-Gaussian case using the copula transform	mechanism	2K_dev_265
On a wind power forecasting task	method	2K_dev_265
Although it is known that probabilistic forecasts ( which give a distribution over possible future outcomes ) can improve planning and control	purpose	2K_dev_265
many forecasting systems in practice are just used as point forecast tools	purpose	2K_dev_265
as it is challenging to represent high-dimensional non-Gaussian distributions over multiple spatial and temporal points	purpose	2K_dev_265
	purpose	2K_dev_265
The omnipresence of indoor lighting makes it an ideal vehicle for pervasive communication with mobile devices	background	2K_dev_266
We show how a binary frequency shift keying modulation scheme can be used to transmit data at 1	finding	2K_dev_266
25 bytes per second ( fast enough to send an ID code ) from up to 29 unique light sources simultaneously in a single collision domain We also show how tags can demodulate the same signals using a light sensor instead of a camera for low-power applications	finding	2K_dev_266
In this paper	mechanism	2K_dev_266
we present a communication scheme that enables interior ambient LED lighting systems using either cameras or light sensors	mechanism	2K_dev_266
By exploiting rolling shutter camera sensors that are common on tablets	mechanism	2K_dev_266
laptops and smartphones	mechanism	2K_dev_266
it is possible to detect high-frequency changes in light intensity reflected off of surfaces and in direct line-of-sight of the camera We present a demodulation approach that allows smartphones to accurately detect frequencies as high as 8kHz with 0	mechanism	2K_dev_266
2kHz channel separation	mechanism	2K_dev_266
In order to avoid humanly perceivable flicker in the lighting	mechanism	2K_dev_266
our system operates at frequencies above 2kHz and compensates for the non-ideal frequency response of standard LED drivers by adjusting the light 's duty-cycle	mechanism	2K_dev_266
By modulating the PWM signal commonly used to drive LED lighting systems	mechanism	2K_dev_266
we are able to encode data that can be used as localization landmarks	mechanism	2K_dev_266
through experiments	method	2K_dev_266
to send data to mobile devices	purpose	2K_dev_266
With the rapid increase in cloud services collecting and using user data to offer personalized experiences	background	2K_dev_267
ensuring that these services comply with their privacy policies has become a business imperative for building user trust	background	2K_dev_267
	background	2K_dev_267
	finding	2K_dev_267
In this paper	mechanism	2K_dev_267
we present our experience building and operating a system Central to the design of the system are ( a ) Legal ease-a language that impose restrictions on how user data is handled	mechanism	2K_dev_267
and ( b ) Grok-a data inventory for Map-Reduce-like big data systems among programs	mechanism	2K_dev_267
Grok maps code-level schema elements to data types in Legal ease	mechanism	2K_dev_267
in essence	mechanism	2K_dev_267
annotating existing programs with information flow types with minimal human input	mechanism	2K_dev_267
Compliance checking is thus reduced to information flow analysis of big data systems	mechanism	2K_dev_267
The system	method	2K_dev_267
bootstrapped by a small team	method	2K_dev_267
checks compliance daily of millions of lines of ever-changing source code written by several thousand developers	method	2K_dev_267
	method	2K_dev_267
However	purpose	2K_dev_267
most compliance efforts in industry today rely on manual review processes and audits designed to safeguard user data	purpose	2K_dev_267
and therefore are resource intensive and lack coverage	purpose	2K_dev_267
to automate privacy policy compliance checking in Bing	purpose	2K_dev_267
that allows specification of privacy policies that tracks how user data flows	purpose	2K_dev_267
Question answering ( Q & A ) communities have been gaining popularity in the past few years	background	2K_dev_268
The success of such sites depends mainly on the contribution of a small number of expert users who provide a significant portion of the helpful answers	background	2K_dev_268
	background	2K_dev_268
Interestingly	finding	2K_dev_268
we find that while the majority of questions on the site are asked by low reputation users	finding	2K_dev_268
on average a high reputation user asks more questions than a user with low reputation and find they are effective in detecting extreme behaviors such as those of spam users we predict who will become influential long-term contributors	finding	2K_dev_268
We consider a number of graph analysis methods	mechanism	2K_dev_268
We present a study of the popular Q & A website StackOverflow ( SO )	method	2K_dev_268
in which users ask and answer questions about software development	method	2K_dev_268
algorithms	method	2K_dev_268
math and other technical topics	method	2K_dev_268
The dataset includes information on 3	method	2K_dev_268
5 million questions and 6	method	2K_dev_268
9 million answers created by 1	method	2K_dev_268
3 million users in the years 2008 -- 2012	method	2K_dev_268
Participation in activities on the site ( such as asking and answering questions ) earns users reputation	method	2K_dev_268
which is an indicator of the value of that user to the site	method	2K_dev_268
We describe an analysis of the SO reputation system	method	2K_dev_268
and the participation patterns of high and low reputation users	method	2K_dev_268
The contributions of very high reputation users to the site indicate that they are the primary source of answers	method	2K_dev_268
and especially of high quality answers	method	2K_dev_268
Lastly	method	2K_dev_268
we show an application of our analysis : by considering user contributions over first months of activity on the site	method	2K_dev_268
	method	2K_dev_268
and so identifying users that have the potential of becoming strong contributers is an important task for owners of such communities	purpose	2K_dev_268
for detecting influential and anomalous users in the underlying user interaction network	purpose	2K_dev_268
	purpose	2K_dev_268
The results suggest that even if a notice contains information users care about	background	2K_dev_269
it is unlikely to be recalled if only shown in the app store	background	2K_dev_269
	background	2K_dev_269
Showing the notice during app use significantly increased recall rates over showing it in the app store	finding	2K_dev_269
which improved recall but did not perform as well as notices shown during app use	finding	2K_dev_269
	finding	2K_dev_269
	mechanism	2K_dev_269
In a series of experiments In a web survey and a field experiment	method	2K_dev_269
we isolated different timing conditions for displaying privacy notices : in the app store	method	2K_dev_269
when an app is started	method	2K_dev_269
during app use	method	2K_dev_269
and after app use Participants installed and played a history quiz app	method	2K_dev_269
either virtually or on their phone	method	2K_dev_269
After a distraction or delay they were asked to recall the privacy notice 's content	method	2K_dev_269
Recall was used as a proxy for the attention paid to and salience of the notice	method	2K_dev_269
In a follow-up web survey	method	2K_dev_269
we tested alternative app store notices	method	2K_dev_269
	method	2K_dev_269
we examined how the timing impacts the salience of smartphone app privacy notices	purpose	2K_dev_269
	purpose	2K_dev_269
In commercial-off-the-shelf ( COTS ) multi-core systems	background	2K_dev_270
a task running on one core can be delayed by other tasks running simultaneously on other cores due to interference in the shared DRAM main memory	background	2K_dev_270
	background	2K_dev_270
results show that our approach provides an upper bound very close to our measured worst-case interference	finding	2K_dev_270
	finding	2K_dev_270
In this paper	mechanism	2K_dev_270
we present techniques in a COTS-based multi-core system We explicitly model the major resources in the DRAM system	mechanism	2K_dev_270
including banks	mechanism	2K_dev_270
buses and the memory controller By considering their timing characteristics	mechanism	2K_dev_270
we analyze the worst-case memory interference delay imposed on a task by other tasks running in parallel	mechanism	2K_dev_270
To the best of our knowledge	mechanism	2K_dev_270
this is the first work bounding the request re-ordering effect of COTS memory controllers Our work also enables the quantification of the extent by which memory interference can be reduced by partitioning DRAM banks	mechanism	2K_dev_270
	mechanism	2K_dev_270
We evaluate our approach on a commodity multi-core platform running Linux/RK Experimental	method	2K_dev_270
Such memory interference delay can be large and highly variable	purpose	2K_dev_270
thereby posing a significant challenge for the design of predictable real-time systems to provide a tight upper bound on the worst-case memory interference	purpose	2K_dev_270
Virus capsid assembly has been widely studied as a biophysical system	background	2K_dev_271
both for its biological and medical significance and as an important model for complex self-assembly processes No current technology can monitor assembly in detail and what information we have on assembly kinetics comes exclusively from invitro studies	background	2K_dev_271
There are many differences between the intracellular environment and that of an invitro assembly assay	background	2K_dev_271
however	background	2K_dev_271
that might be expected to alter assembly pathways These models may help us understand how complicated assembly systems may have evolved to function with high efficiency and fidelity in the densely crowded environment of the cell	background	2K_dev_271
	background	2K_dev_271
Simulations suggest a striking difference depending on whether or not a system uses nucleation-limited assembly	finding	2K_dev_271
with crowding tending to promote off-pathway growth in a nonnucleation-limited model but often enhancing assembly efficiency at high crowding levels even while impeding it at lower crowding levels in a nucleation-limited model	finding	2K_dev_271
We combine prior particle simulation methods for estimating crowding effects with coarse-grained stochastic models of capsid assembly	mechanism	2K_dev_271
using the crowding models to adjust kinetics of capsid simulations	mechanism	2K_dev_271
	method	2K_dev_271
Here	purpose	2K_dev_271
we explore one specific feature characteristic of the intracellular environment and known to have large effects on macromolecular assembly processes : molecular crowding to examine possible effects of crowding on assembly pathways	purpose	2K_dev_271
	purpose	2K_dev_271
	background	2K_dev_272
We demonstrate that the impact of hidden factors can be separated out via convex optimization in these three models demonstrate the the superior performance of our proposed models	finding	2K_dev_272
We also propose a fast greedy algorithm based on the selection of composite atoms in each iteration and provide a performance guarantee for it	mechanism	2K_dev_272
	mechanism	2K_dev_272
In this paper	method	2K_dev_272
we analyze a flexible stochastic process model	method	2K_dev_272
the generalized linear auto-regressive process ( GLARP ) and identify the conditions under which the impact of hidden variables appears as an additive term to the evolution matrix estimated with the maximum likelihood	method	2K_dev_272
In particular	method	2K_dev_272
we examine three examples	method	2K_dev_272
including two popular models for count data	method	2K_dev_272
i	method	2K_dev_272
e	method	2K_dev_272
Poisson and Conwey-Maxwell Poisson vector auto-regressive processes	method	2K_dev_272
and one powerful model for extreme value data	method	2K_dev_272
i	method	2K_dev_272
e	method	2K_dev_272
	method	2K_dev_272
Gumbel vector auto-regressive processes Experiments on two synthetic datasets	method	2K_dev_272
one social network dataset and one climatology dataset	method	2K_dev_272
Understanding and quantifying the impact of unobserved processes is one of the major challenges of analyzing multivariate time series data	purpose	2K_dev_272
Kidney exchanges allow incompatible donor-patient pairs to swap kidneys	background	2K_dev_273
but each donation must pass three tests : blood	background	2K_dev_273
tissue	background	2K_dev_273
and crossmatch In practice a matching is computed based on the first two tests	background	2K_dev_273
and then a single crossmatch test is performed for each matched patient	background	2K_dev_273
	finding	2K_dev_273
Our main result is a polynomial time algorithm that almost surely computes optimal -- - up to lower order terms -- - solutions on random large kidney exchange instances	mechanism	2K_dev_273
	method	2K_dev_273
However	purpose	2K_dev_273
if two crossmatches could be performed per patient	purpose	2K_dev_273
in principle significantly more successful exchanges could take place	purpose	2K_dev_273
In this paper	purpose	2K_dev_273
we ask : If we were allowed to perform two crossmatches per patient	purpose	2K_dev_273
could we harness this additional power optimally and efficiently ? for this problem	purpose	2K_dev_273
The Internet has the potential to accelerate scientific problem solving by engaging a global pool of contributors	background	2K_dev_274
A better understanding of such collaborative strategies can inform the design of tools to support distributed collaboration on complex problems	background	2K_dev_274
Our results indicate a diversity of ways in which mathematicians are reaching a solution	finding	2K_dev_274
including by iteratively advancing a solution	finding	2K_dev_274
	finding	2K_dev_274
-- MathOverflow -- in which contributors communicate and collaborate to solve new mathematical 'micro-problems ' online We contribute a simple taxonomy of collaborative acts derived from a process-level examination of collaborations and a quantitative analysis relating collaborative acts to solution quality	mechanism	2K_dev_274
	mechanism	2K_dev_274
	method	2K_dev_274
Existing approaches focus on broadcasting problems to many independent solvers	purpose	2K_dev_274
We investigate other approaches that may be advantageous by examining a community for mathematical problem solving	purpose	2K_dev_274
Recent computer systems research has proposed using redundant requests to reduce latency	background	2K_dev_275
The idea is to run a request on multiple servers and wait for the first completion ( discarding all remaining copies of the request )	background	2K_dev_275
We find some surprising results	finding	2K_dev_275
First	finding	2K_dev_275
the response time of a fully redundant class follows a simple Exponential distribution and that of the non-redundant class follows a Generalized Hyperexponential	finding	2K_dev_275
Second	finding	2K_dev_275
fully redundant classes are `` immune '' to any pain caused by other classes becoming redundant	finding	2K_dev_275
We find that	finding	2K_dev_275
in many cases	finding	2K_dev_275
redundancy outperforms JSQ and Opt-Split with respect to overall response time	finding	2K_dev_275
making it an attractive solution	finding	2K_dev_275
	finding	2K_dev_275
	mechanism	2K_dev_275
We allow for any number of classes of redundant requests	method	2K_dev_275
any number of classes of non-redundant requests	method	2K_dev_275
any degree of redundancy	method	2K_dev_275
and any number of heterogeneous servers	method	2K_dev_275
In all cases we derive the limiting distribution on the state of the system	method	2K_dev_275
In small ( two or three server ) systems	method	2K_dev_275
we derive simple forms for the distribution of response time of both the redundant classes and non-redundant classes	method	2K_dev_275
and we quantify the `` gain '' to redundant classes and `` pain '' to non-redundant classes caused by redundancy We also compare redundancy with other approaches for reducing latency	method	2K_dev_275
such as optimal probabilistic splitting of a class among servers ( Opt-Split ) and Join-the-Shortest-Queue ( JSQ ) routing of a class	method	2K_dev_275
	method	2K_dev_275
However there is no exact analysis of systems with redundancy	purpose	2K_dev_275
This paper presents the first exact analysis of systems with redundancy	purpose	2K_dev_275
	purpose	2K_dev_275
Detecting dyslexia is crucial so that people who have dyslexia can receive training to avoid associated high rates of academic failure	background	2K_dev_276
These differences suggest that Dytective could be used to help identify those likely to have dyslexia	background	2K_dev_276
show significant differences between groups who played Dytective	finding	2K_dev_276
	finding	2K_dev_276
In this paper we present Dytective	mechanism	2K_dev_276
a game designed	mechanism	2K_dev_276
The results of a within-subjects experiment with 40 children ( 20 with dyslexia )	method	2K_dev_276
to detect dyslexia	purpose	2K_dev_276
	background	2K_dev_277
	finding	2K_dev_277
	mechanism	2K_dev_277
	method	2K_dev_277
	purpose	2K_dev_277
	background	2K_dev_278
we show that the proposed algorithm improves other candidate methods for both storyline reconstruction and image prediction tasks	finding	2K_dev_278
	finding	2K_dev_278
In this paper	mechanism	2K_dev_278
we investigate an approach The storyline graphs can be an effective summary that visualizes various branching narrative structure of events or activities recurring across the input photo sets of a topic class we leverage them to perform the image sequential prediction tasks	mechanism	2K_dev_278
from which photo recommendation applications can benefit	mechanism	2K_dev_278
We formulate the storyline reconstruction problem as an inference of sparse time-varying directed graphs	mechanism	2K_dev_278
and develop an optimization algorithm that successfully addresses a number of key challenges of Web-scale problems	mechanism	2K_dev_278
including global optimality	mechanism	2K_dev_278
linear complexity	mechanism	2K_dev_278
and easy parallelization	mechanism	2K_dev_278
With experiments on more than 3	method	2K_dev_278
3 millions of images of 24 classes and user studies via Amazon Mechanical Turk	method	2K_dev_278
	method	2K_dev_278
for reconstructing storyline graphs from large-scale collections of Internet images	purpose	2K_dev_278
and optionally other side information such as friendship graphs	purpose	2K_dev_278
In order to explore further the usefulness of the storyline graphs	purpose	2K_dev_278
	purpose	2K_dev_278
For example	background	2K_dev_279
the Project Tycho provides open access to the count infections for U	background	2K_dev_279
S	background	2K_dev_279
states from 1888 to 2013	background	2K_dev_279
for 56 contagious diseases ( e	background	2K_dev_279
g	background	2K_dev_279
	background	2K_dev_279
measles	background	2K_dev_279
influenza )	background	2K_dev_279
which include missing values	background	2K_dev_279
possible recording errors	background	2K_dev_279
sudden spikes ( or dives ) of infections	background	2K_dev_279
etc	background	2K_dev_279
	background	2K_dev_279
demonstrate that FUNNELFIT does indeed discover important properties of epidemics : ( P1 ) disease seasonality	finding	2K_dev_279
e	finding	2K_dev_279
g	finding	2K_dev_279
	finding	2K_dev_279
influenza spikes in January	finding	2K_dev_279
Lyme disease spikes in July and the absence of yearly periodicity for gonorrhea ; ( P2 ) disease reduction effect	finding	2K_dev_279
e	finding	2K_dev_279
g	finding	2K_dev_279
	finding	2K_dev_279
the appearance of vaccines ; ( P3 ) local/state-level sensitivity	finding	2K_dev_279
e	finding	2K_dev_279
g	finding	2K_dev_279
	finding	2K_dev_279
many measles cases in NY ; ( P4 ) external shock events	finding	2K_dev_279
e	finding	2K_dev_279
g	finding	2K_dev_279
	finding	2K_dev_279
historical flu pandemics ; ( P5 ) detect incongruous values	finding	2K_dev_279
i	finding	2K_dev_279
e	finding	2K_dev_279
	finding	2K_dev_279
data reporting errors	finding	2K_dev_279
	finding	2K_dev_279
In this paper	mechanism	2K_dev_279
we present FUNNEL	mechanism	2K_dev_279
a unifying analytical model as well as a novel fitting algorithm	mechanism	2K_dev_279
FUNNELFIT	mechanism	2K_dev_279
Our method has the following properties : ( a ) Sense-making : it detects important patterns of epidemics	mechanism	2K_dev_279
such as periodicities	mechanism	2K_dev_279
the appearance of vaccines	mechanism	2K_dev_279
external shock events	mechanism	2K_dev_279
and more ; ( b ) Parameter-free : our modeling framework frees the user from providing parameter values ; ( c ) Scalable : FUNNELFIT is carefully designed to be linear on the input size ; ( d ) General : our model is general and practical	mechanism	2K_dev_279
which can be applied to various types of epidemics	mechanism	2K_dev_279
including computer-virus propagation	mechanism	2K_dev_279
as well as human diseases	mechanism	2K_dev_279
	mechanism	2K_dev_279
Extensive experiments on real data	method	2K_dev_279
Given a large collection of epidemiological data consisting of the count of d contagious diseases for l locations of duration n	purpose	2K_dev_279
how can we find patterns	purpose	2K_dev_279
rules and outliers ? So how can we find a combined model	purpose	2K_dev_279
for all these diseases	purpose	2K_dev_279
locations	purpose	2K_dev_279
and time-ticks ? for large scale epidemiological data which solves the above problem	purpose	2K_dev_279
From Twitter to Facebook to Reddit	background	2K_dev_280
users have become accustomed to sharing the articles they read with friends or followers on their social networks	background	2K_dev_280
demonstrating that our approach is effective	finding	2K_dev_280
we model the content of news articles and blog posts by attributes of the people who are likely to share them	mechanism	2K_dev_280
For example	mechanism	2K_dev_280
many Twitter users describe themselves in a short profile	mechanism	2K_dev_280
labeling themselves with phrases such as `` vegetarian '' or `` liberal	mechanism	2K_dev_280
'' By assuming that a user 's labels correspond to topics in the articles he shares	mechanism	2K_dev_280
we can learn a labeled dictionary from a training corpus of articles shared on Twitter Thereafter	mechanism	2K_dev_280
we can code any new document as a sparse non-negative linear combination of user labels	mechanism	2K_dev_280
where we encourage correlated labels to appear together in the output via a structured sparsity penalty	mechanism	2K_dev_280
Finally	mechanism	2K_dev_280
we show that our approach yields a novel document representation that can be effectively used in many problem settings	mechanism	2K_dev_280
from recommendation to modeling news dynamics For example	mechanism	2K_dev_280
while the top politics stories will change drastically from one month to the next	mechanism	2K_dev_280
the `` politics '' label will still be there to describe them	mechanism	2K_dev_280
	mechanism	2K_dev_280
We evaluate our model on millions of tweeted news articles and blog posts collected between September 2010 and September 2012	method	2K_dev_280
	method	2K_dev_280
While previous work has modeled what these shared stories say about the user who shares them	purpose	2K_dev_280
the converse question remains unexplored : what can we learn about an article from the identities of its likely readers ? To address this question	purpose	2K_dev_280
The M/M/k/setup model	background	2K_dev_281
where there is a penalty for turning servers on	background	2K_dev_281
is common in data centers	background	2K_dev_281
call centers	background	2K_dev_281
and manufacturing systems	background	2K_dev_281
Setup costs take the form of a time delay	background	2K_dev_281
and sometimes there is additionally a power penalty	background	2K_dev_281
as in the case of data centers	background	2K_dev_281
	background	2K_dev_281
	finding	2K_dev_281
by a new way of combining renewal reward theory and recursive techniques to solve Markov chains with a repeating structure	mechanism	2K_dev_281
Our renewal-based approach uses ideas from renewal reward theory and busy period analysis to obtain closed-form expressions for metrics of interest such as the transform of time in system and the transform of power consumed by the system	mechanism	2K_dev_281
The simplicity	mechanism	2K_dev_281
intuitiveness	mechanism	2K_dev_281
and versatility of our renewal-based approach makes it useful for analyzing Markov chains far beyond the M/M/k/setup	mechanism	2K_dev_281
In general	mechanism	2K_dev_281
our renewal-based approach should be used to reduce the analysis of any 2-dimensional Markov chain which is infinite in at most one dimension and repeating to the problem of solving a system of polynomial equations	mechanism	2K_dev_281
In the case where all transitions in the repeating portion of the Markov chain are skip-free and all up/down arrows are unidirectional	mechanism	2K_dev_281
the resulting system of equations will yield a closed-form solution	mechanism	2K_dev_281
	mechanism	2K_dev_281
Our analysis is made possible	method	2K_dev_281
While the M/M/1/setup was exactly analyzed in 1964	purpose	2K_dev_281
no exact analysis exists to date for the M/M/k/setup with $ $ k > 1 $ $ k In this paper	purpose	2K_dev_281
we provide the first exact	purpose	2K_dev_281
closed-form analysis for the M/M/k/setup and some of its important variants including systems in which idle servers delay for a period of time before turning off or can be put to sleep	purpose	2K_dev_281
	purpose	2K_dev_281
Multimedia event detection ( MED ) is an effective technique for video indexing and retrieval	background	2K_dev_282
	background	2K_dev_282
have validated the efficacy of our proposed approach	finding	2K_dev_282
we use a statistical method on both the positive and negative examples Based on these decisive attributes	mechanism	2K_dev_282
we assign the fine-grained labels to negative examples to treat them differently for more effective exploitation	mechanism	2K_dev_282
The resulting fine-grained labels may be not accurate enough to characterize the negative videos	mechanism	2K_dev_282
Hence	mechanism	2K_dev_282
we propose to jointly optimize the fine-grained labels with the knowledge from the visual features and the attributes representations	mechanism	2K_dev_282
which brings mutual reciprocality	mechanism	2K_dev_282
Our model obtains two kinds of classifiers	mechanism	2K_dev_282
one from the attributes and one from the features	mechanism	2K_dev_282
which incorporate the informative cues from the fine-grained labels The outputs of both classifiers on the testing videos are fused for detection	mechanism	2K_dev_282
Extensive experiments on the challenging TRECVID MED 2012 development set	method	2K_dev_282
Current classifier training for MED treats the negative videos equally	purpose	2K_dev_282
However	purpose	2K_dev_282
many negative videos may resemble the positive videos in different degrees	purpose	2K_dev_282
Intuitively	purpose	2K_dev_282
we may capture more informative cues from the negative videos if we assign them fine-grained labels	purpose	2K_dev_282
thus benefiting the classifier learning	purpose	2K_dev_282
Aiming for this	purpose	2K_dev_282
to get the decisive attributes of a specific event	purpose	2K_dev_282
	purpose	2K_dev_282
Autonomous driving technologies have been emerging over the past few years	background	2K_dev_283
and semi-autonomous driving functionalities have been deployed to vehicles available in the market	background	2K_dev_283
Since autonomous driving is realized by the intelligent processing of data from various types of sensors such as LIDAR	background	2K_dev_283
radar	background	2K_dev_283
camera	background	2K_dev_283
etc	background	2K_dev_283
	background	2K_dev_283
the complexity of designing a dependable real-time autonomous driving system is rather high	background	2K_dev_283
Although there has been much research on building a reliable real-time system using hardware replication	background	2K_dev_283
the resulting systems tend to add significant extra cost due to hardware replication	background	2K_dev_283
we summarize SAFER ( System-level Architecture for Failure Evasion in Real-time applications ) our previous work on flexible system design	background	2K_dev_283
	background	2K_dev_283
	finding	2K_dev_283
We then present a conceptual framework for autonomous vehicles	mechanism	2K_dev_283
We motivate our proposed framework with various scenarios	method	2K_dev_283
and we describe how SAFER can be extended to support the proposed conceptual framework	method	2K_dev_283
Therefore	purpose	2K_dev_283
an alternative solution would be helpful in building an autonomous vehicle in a cost-effective way	purpose	2K_dev_283
An autonomous driving system is different from the conventional reliable real-time system because it requires ( 1 ) flexible design	purpose	2K_dev_283
( 2 ) adaptive graceful degradation and ( 3 ) effective use of different modalities of sensors and actuators	purpose	2K_dev_283
To address these characteristics	purpose	2K_dev_283
to provide adaptive graceful degradation and support for using different types of sensors/actuators when a failure happens	purpose	2K_dev_283
	purpose	2K_dev_283
Coding behavioral video is an important method used by researchers to understand social phenomenon	background	2K_dev_284
Recent work has shown that these tasks can be completed quickly by leveraging the parallelism of large online crowds This trade-off between coding quality and privacy protection suggests that researchers can use online crowds to code for some key behaviors in video without compromising participant identity	background	2K_dev_284
We conclude with a discussion of how researchers can balance privacy and accuracy on their own data using a system we introduce called Incognito	background	2K_dev_284
We find accuracy and privacy to be the researchers ' primary concerns	finding	2K_dev_284
	finding	2K_dev_284
and show that the crowd yields accurate results	finding	2K_dev_284
and find	finding	2K_dev_284
as expected	finding	2K_dev_284
that workers ' ability to identify participants decreases as blur level increases The workers ' ability to accurately and reliably code behaviors also decreases	finding	2K_dev_284
but not as steeply as the identity test	finding	2K_dev_284
	finding	2K_dev_284
Then	mechanism	2K_dev_284
we demonstrate a method for obfuscating participant identity with a video blur filter	mechanism	2K_dev_284
	mechanism	2K_dev_284
we conducted interviews with 12 researchers who frequently code behavioral video	method	2K_dev_284
we used sample videos	method	2K_dev_284
Unfortunately	purpose	2K_dev_284
traditional hand-coding approaches can take days or weeks of time to complete	purpose	2K_dev_284
	purpose	2K_dev_284
but using the crowd introduces new concerns about accuracy	purpose	2K_dev_284
reliability	purpose	2K_dev_284
privacy	purpose	2K_dev_284
and cost To explore these issues	purpose	2K_dev_284
to investigate common practices and challenges with video coding	purpose	2K_dev_284
To explore this more concretely	purpose	2K_dev_284
to investigate whether crowds can accurately recognize instances of commonly coded behaviors	purpose	2K_dev_284
For pipe guided wave inspection systems	background	2K_dev_285
it can often be difficult to achieve accurate localization performance due to the pipe 's geometry Many localization techniques focus on the first arrival for processing	background	2K_dev_285
but this often results in a poor circumferential resolution	background	2K_dev_285
Furthermore	background	2K_dev_285
the pipe 's circular geometry generates multipath arrivals that make data interpretation difficult	background	2K_dev_285
	background	2K_dev_285
we show that our method significantly improves circumferential resolution and reduces localization artifacts when compared with the standard delay-and-sum method	finding	2K_dev_285
	finding	2K_dev_285
by combining the standard delay-and-sum localization method with a simple multipath model for a pipe	mechanism	2K_dev_285
	mechanism	2K_dev_285
Using experimental data from a transmitting source	method	2K_dev_285
In this paper	purpose	2K_dev_285
however	purpose	2K_dev_285
we utilize this multipath behavior	purpose	2K_dev_285
If Lisa visits Dr	background	2K_dev_286
Brown	background	2K_dev_286
and there is no record of the drug he prescribed her	background	2K_dev_286
can we find it ? Data sources	background	2K_dev_286
much to analysts ' dismay	background	2K_dev_286
are too often plagued with incompleteness	background	2K_dev_286
making business analytics over the data difficult	background	2K_dev_286
	background	2K_dev_286
	finding	2K_dev_286
We introduce a principled way of performing value imputation on missing values	mechanism	2K_dev_286
allowing a user We achieve this by turning our data into a graph network and performing link prediction on nodes of interest using the belief propagation algorithm	mechanism	2K_dev_286
	method	2K_dev_286
Data entries with incomplete values are ignored	purpose	2K_dev_286
making some analytic queries fail to accurately describe how an organization is performing to choose a correct value after viewing possible values and why they were inferred	purpose	2K_dev_286
	purpose	2K_dev_286
A cognitive assistance application combines a wearable device such as Google Glass with cloudlet processing to provide step-by-step guidance on a complex task	background	2K_dev_287
We then reflect on the difficulties we faced in building these applications	background	2K_dev_287
and suggest future research that could simplify the creation of similar applications	background	2K_dev_287
	finding	2K_dev_287
In this paper	mechanism	2K_dev_287
we focus on user assistance We describe proof-of-concept implementations for four different tasks : assembling 2D Lego models	mechanism	2K_dev_287
freehand sketching	mechanism	2K_dev_287
playing ping-pong	mechanism	2K_dev_287
and recommending context-relevant YouTube tutorials	mechanism	2K_dev_287
	method	2K_dev_287
for narrow and well-defined tasks that require specialized knowledge and/or skills	purpose	2K_dev_287
	purpose	2K_dev_287
The utilization of Building Information Modeling ( BIM ) has been growing significantly and translating into the support of various tasks within the construction industry	background	2K_dev_288
In relation to such a growth	background	2K_dev_288
many approaches that leverage dimensions of information stored in BIM model are being developed	background	2K_dev_288
Through this	background	2K_dev_288
it is possible to allow all stakeholders to retrieve and generate information from the same model	background	2K_dev_288
enabling them to work cohesively It is believed to benefit the industry by providing a computable BIM and enabling all project participants to extract any information required for decision making	background	2K_dev_288
Finally	background	2K_dev_288
the framework is used to identify areas to extend BIM research	background	2K_dev_288
	background	2K_dev_288
and the result reveals a research gap for BIM applications in the project domains of quality	finding	2K_dev_288
safety and environmental management	finding	2K_dev_288
	finding	2K_dev_288
a BIM application framework is developed and discussed in this paper Such a framework gives an overview of BIM applications in the construction industry	mechanism	2K_dev_288
A computable multi-dimensional ( nD ) model is difficult to establish in these areas because with continuously changing conditions	mechanism	2K_dev_288
the decision making rules for evaluating whether an individual component is considered good quality	mechanism	2K_dev_288
or whether a construction site is safe	mechanism	2K_dev_288
also vary as the construction progresses	mechanism	2K_dev_288
A process of expanding from 3D to computable nD models	mechanism	2K_dev_288
specifically	mechanism	2K_dev_288
a possible way to integrate safety	mechanism	2K_dev_288
quality and carbon emission variables into BIM during the construction phase of a project is explained in this paper	mechanism	2K_dev_288
A literature review	method	2K_dev_288
within this framework	method	2K_dev_288
has been conducted As examples	method	2K_dev_288
the processes of utilizing nD models on real construction sites are described	method	2K_dev_288
To identify gaps of existing work and evaluate new studies in this area	purpose	2K_dev_288
Let us consider that someone is starting a research on a topic that is unfamiliar to them	background	2K_dev_289
	background	2K_dev_289
we show the effectiveness and efficiency of our approach	finding	2K_dev_289
	finding	2K_dev_289
First	mechanism	2K_dev_289
we propose an algorithm We also address the performance and scalability issues of this sophisticated algorithm Next	mechanism	2K_dev_289
we discuss the measures to decide how much a paper is influenced by another paper	mechanism	2K_dev_289
Then	mechanism	2K_dev_289
we propose an algorithm by using the influence measure and citation information	mechanism	2K_dev_289
	mechanism	2K_dev_289
Finally	method	2K_dev_289
through extensive experiments with a large volume of a real-world academic literature data	method	2K_dev_289
	method	2K_dev_289
Which seminal papers have influenced the topic the most ? What is the genealogy of the seminal papers in this topic ? These are the questions that they can raise	purpose	2K_dev_289
which we try to answer in this paper	purpose	2K_dev_289
that finds a set of seminal papers on a given topic	purpose	2K_dev_289
that constructs a genealogy of the seminal papers	purpose	2K_dev_289
Online social networks and the World Wide Web lead to large underlying graphs that might not be completely known because of their size	background	2K_dev_290
To compute reliable statistics	background	2K_dev_290
we have to resort to sampling the network	background	2K_dev_290
	background	2K_dev_290
node sampling yields Pareto optimal sample sizes in terms of the Kolomogorov-Smirnov statistic for the degree distribution	finding	2K_dev_290
while node-by-edge sampling yields optimal sample sizes for the biased distribution	finding	2K_dev_290
We also find that random walk sampling performs better than the Metropolis-Hastings random walk	finding	2K_dev_290
	finding	2K_dev_290
	mechanism	2K_dev_290
We measure the quality of our estimates of the degree distributions by using the Kolmogorov-Smirnov statistic	method	2K_dev_290
Among all four sampling methods	method	2K_dev_290
	method	2K_dev_290
In this paper	purpose	2K_dev_290
we investigate four network sampling methods to estimate the network degree distribution and the so-called biased degree distribution of a 3	purpose	2K_dev_290
7 million wireless subscriber network	purpose	2K_dev_290
As kidney exchange programs are growing	background	2K_dev_291
manipulation by hospitals becomes more of an issue	background	2K_dev_291
suggest that in practice our mechanism performs much closer to optimal	finding	2K_dev_291
	finding	2K_dev_291
We study mechanisms for two-way exchanges that are strategyproof	mechanism	2K_dev_291
i	mechanism	2K_dev_291
e	mechanism	2K_dev_291
	mechanism	2K_dev_291
make it a dominant strategy We establish lower bounds on the welfare loss of strategyproof mechanisms	mechanism	2K_dev_291
both deterministic and randomized	mechanism	2K_dev_291
and propose a randomized mechanism that guarantees at least half of the maximum social welfare in the worst case	mechanism	2K_dev_291
Simulations using realistic distributions for blood types and other parameters	method	2K_dev_291
Assuming that hospitals wish to maximize the number of their own patients who receive a kidney	purpose	2K_dev_291
they may have an incentive to withhold some of their incompatible donorpatient pairs and match them internally	purpose	2K_dev_291
thus harming social welfare	purpose	2K_dev_291
for hospitals to report all their incompatible pairs	purpose	2K_dev_291
	purpose	2K_dev_291
AbstractVulnerability assessment serves to identify vulnerabilities	background	2K_dev_292
develop responses	background	2K_dev_292
and drive the risk-management process	background	2K_dev_292
In identifying vulnerabilities	background	2K_dev_292
it is fundamental to identify and rank critical assets	background	2K_dev_292
which include vital systems	background	2K_dev_292
facilities	background	2K_dev_292
processes	background	2K_dev_292
and information necessary to maintain continuity of service	background	2K_dev_292
During emergencies in the facility management domain	background	2K_dev_292
first responders typically search for critical assets	background	2K_dev_292
both related to business continuity and value to the organization	background	2K_dev_292
	finding	2K_dev_292
This paper presents a formalized approach The developed reasoning approach enables a first responder to perform flexible searches and prioritize critical spaces and pieces of equipment that need to be protected in an emergency by leveraging existing building and content representations found in building information models ( BIM )	mechanism	2K_dev_292
	method	2K_dev_292
to reason about building systems and content to support vulnerability assessment in building emergencies caused by failures in building systems ( e	purpose	2K_dev_292
g	purpose	2K_dev_292
	purpose	2K_dev_292
sprinkler line leak	purpose	2K_dev_292
power outage )	purpose	2K_dev_292
	purpose	2K_dev_292
Data locality and parallelism are critical optimization objectives for performance on modern multi-core machines	background	2K_dev_293
	background	2K_dev_293
	finding	2K_dev_293
exhibiting significant performance improvements over existing compilers	finding	2K_dev_293
	finding	2K_dev_293
by proposing a 3-step framework	mechanism	2K_dev_293
which We define the concept of vectorizable codelets	mechanism	2K_dev_293
with properties tailored to achieve effective SIMD code generation for the codelets	mechanism	2K_dev_293
We leverage the power of a modern high-level transformation framework to restructure a program to expose good ISA-independent vectorizable codelets	mechanism	2K_dev_293
exploiting multi-dimensional data reuse	mechanism	2K_dev_293
Then	mechanism	2K_dev_293
we generate ISA-specific customized code for the codelets	mechanism	2K_dev_293
using a collection of lower-level SIMD-focused optimizations	mechanism	2K_dev_293
We demonstrate our approach on a collection of numerical kernels that we automatically tile	method	2K_dev_293
parallelize and vectorize	method	2K_dev_293
Both coarse-grain parallelism ( e	purpose	2K_dev_293
g	purpose	2K_dev_293
	purpose	2K_dev_293
multi-core ) and fine-grain parallelism ( e	purpose	2K_dev_293
g	purpose	2K_dev_293
	purpose	2K_dev_293
vector SIMD ) must be effectively exploited	purpose	2K_dev_293
but despite decades of progress at both ends	purpose	2K_dev_293
current compiler optimization schemes that attempt to address data locality and both kinds of parallelism often fail at one of the three objectives	purpose	2K_dev_293
We address this problem aims for integrated data locality	purpose	2K_dev_293
multi-core parallelism and SIMD execution of programs	purpose	2K_dev_293
	purpose	2K_dev_293
Abstract Guided wave ultrasonics is an attractive monitoring technique for damage diagnosis in large-scale plate and pipe structures	background	2K_dev_294
Damage can be detected by comparing incoming records with baseline records collected on intact structure	background	2K_dev_294
Researchers developed temperature compensation methods to eliminate the effects of temperature variation	background	2K_dev_294
but they have limitations in practical implementations	background	2K_dev_294
	background	2K_dev_294
We show that our method accurately detects the presence of a mass scatterer	finding	2K_dev_294
and is robust to the environmental and operational variations exhibited in the practical system	finding	2K_dev_294
	finding	2K_dev_294
In this paper	mechanism	2K_dev_294
we develop a robust damage detection method based on singular value decomposition ( SVD We show that the orthogonality of singular vectors ensures that the effect of damage and that of environmental and operational variations are separated into different singular vectors	mechanism	2K_dev_294
We report on our field ultrasonic monitoring of a 273	method	2K_dev_294
05mm outer diameter pipe segment	method	2K_dev_294
which belongs to a hot water piping system in continuous operation	method	2K_dev_294
We demonstrate the efficacy of our method on experimental pitchcatch records collected during seven months	method	2K_dev_294
However	purpose	2K_dev_294
during long-term monitoring	purpose	2K_dev_294
environmental and operational conditions often vary significantly and produce large changes in the ultrasonic signals	purpose	2K_dev_294
thereby challenging the baseline comparison based damage detection	purpose	2K_dev_294
	purpose	2K_dev_294
	background	2K_dev_295
	finding	2K_dev_295
We propose a non-intrusive approach At the core of this approach is a mechanism for selective real-time monitoring of guest file updates within VM instances	mechanism	2K_dev_295
This mechanism is agentless	mechanism	2K_dev_295
requiring no guest VM support	mechanism	2K_dev_295
It has low virtual I/O overhead	mechanism	2K_dev_295
low latency for emitting file updates	mechanism	2K_dev_295
and a scalable design	mechanism	2K_dev_295
Its central design principle is distributed streaming of file updates inferred from introspected disk sector writes	mechanism	2K_dev_295
The mechanism	mechanism	2K_dev_295
called DS-VMI	mechanism	2K_dev_295
enables many system administration tasks that involve monitoring files to be performed outside VMs	mechanism	2K_dev_295
	method	2K_dev_295
for monitoring virtual machines ( VMs ) in the cloud	purpose	2K_dev_295
	purpose	2K_dev_295
	background	2K_dev_296
	finding	2K_dev_296
	mechanism	2K_dev_296
	method	2K_dev_296
	purpose	2K_dev_296
In social settings	background	2K_dev_297
individuals interact through webs of relationships	background	2K_dev_297
This paper extends to signals on graphs DSP and its basic tenets	background	2K_dev_297
including filters	background	2K_dev_297
convolution	background	2K_dev_297
z -transform	background	2K_dev_297
impulse response	background	2K_dev_297
spectral representation	background	2K_dev_297
Fourier transform	background	2K_dev_297
frequency response	background	2K_dev_297
and illustrates DSP on graphs by classifying blogs	background	2K_dev_297
linear predicting and compressing data from irregularly located weather stations	background	2K_dev_297
or predicting behavior of customers of a mobile service provider	background	2K_dev_297
	finding	2K_dev_297
We label the data by its source	mechanism	2K_dev_297
or formally stated	mechanism	2K_dev_297
we index the data by the nodes of the graph	mechanism	2K_dev_297
The resulting signals ( data indexed by the nodes ) are far removed from time or image signals indexed by well ordered time samples or pixels DSP	mechanism	2K_dev_297
discrete signal processing	mechanism	2K_dev_297
provides a comprehensive	mechanism	2K_dev_297
elegant	mechanism	2K_dev_297
and efficient methodology	mechanism	2K_dev_297
	method	2K_dev_297
Each individual is a node in a complex network ( or graph ) of interdependencies and generates data	purpose	2K_dev_297
lots of data	purpose	2K_dev_297
to describe	purpose	2K_dev_297
represent	purpose	2K_dev_297
transform	purpose	2K_dev_297
analyze	purpose	2K_dev_297
process	purpose	2K_dev_297
or synthesize these well ordered time or image signals	purpose	2K_dev_297
	purpose	2K_dev_297
Spatial Pyramid Matching ( SPM ) assumes that the spatial Bag-of-Words ( BoW ) representation is independent of data	background	2K_dev_298
	background	2K_dev_298
validate that JS Tiling outperforms the SPM and the state-of-the-art methods	finding	2K_dev_298
The runtime comparison demonstrates that selecting BoW representations by JS Tiling is more than 1	finding	2K_dev_298
000 times faster than running classifiers	finding	2K_dev_298
Besides	finding	2K_dev_298
JS Tiling is an important component contributing to CMU Teams ' final submission in TRECVID 2012 Multimedia Event Detection	finding	2K_dev_298
In this paper	mechanism	2K_dev_298
we propose a novel method called Jensen-Shannon ( JS ) Tiling The proposed JS Tiling is especially appropriate for large-scale datasets as it is orders of magnitude faster than existing methods	mechanism	2K_dev_298
but with comparable or even better classification precision	mechanism	2K_dev_298
Experimental results on four benchmarks including two TRECVID12 datasets	method	2K_dev_298
However	purpose	2K_dev_298
evidence has shown that the assumption usually leads to a suboptimal representation	purpose	2K_dev_298
to learn the BoW representation from data directly at the BoW level	purpose	2K_dev_298
imply improved parallel randomized algorithms for several problems	background	2K_dev_299
including single-source shortest paths	background	2K_dev_299
maximum flow	background	2K_dev_299
minimum-cost flow	background	2K_dev_299
and approximate maximum flow	background	2K_dev_299
	background	2K_dev_299
our results	finding	2K_dev_299
We present the design and analysis of a nearly-linear work parallel algorithm On input an SDD n-by-n matrix A with m nonzero entries and a vector b	mechanism	2K_dev_299
our algorithm computes a vector $ \tilde { x } $ such that $ \|\tilde { x } - A^ { + } b\|_ { A } \leq\varepsilon\cdot\| { A^ { + } b } \|_ { A } $ in $ O ( m\log^ { O ( 1 ) } { n } \log { \frac { 1 } { \varepsilon } } ) $ work and $ O ( m^ { 1/3+\theta } \log\frac { 1 } { \varepsilon } ) $ depth for any ? > 0	mechanism	2K_dev_299
where A + denotes the Moore-Penrose pseudoinverse of A	mechanism	2K_dev_299
The algorithm relies on a parallel algorithm for generating low-stretch spanning trees or spanning subgraphs To this end	mechanism	2K_dev_299
we first develop a parallel decomposition algorithm that in O ( mlog O ( 1 ) n ) work and polylogarithmic depth	mechanism	2K_dev_299
partitions a graph with n nodes and m edges into components with polylogarithmic diameter such that only a small fraction of the original edges are between the components	mechanism	2K_dev_299
This can be used to generate low-stretch spanning trees with average stretch O ( n ? ) in O ( mlog O ( 1 ) n ) work and O ( n ? ) depth for any ? > 0	mechanism	2K_dev_299
Alternatively	mechanism	2K_dev_299
it can be used to generate spanning subgraphs with polylogarithmic average stretch in O ( mlog O ( 1 ) n ) work and polylogarithmic depth	mechanism	2K_dev_299
We apply this subgraph construction to derive a parallel linear solver	mechanism	2K_dev_299
By using this solver in known applications	method	2K_dev_299
	method	2K_dev_299
for solving symmetric diagonally dominant ( SDD ) linear systems	purpose	2K_dev_299
	purpose	2K_dev_299
Heating	background	2K_dev_300
Ventilation and Air-Conditioning ( HVAC ) systems account for more than 15 % of the total energy consumption in the US In order to improve the energy efficiency of HVAC systems	background	2K_dev_300
researchers have developed hundreds of algorithms to automatically analyze their performance	background	2K_dev_300
	background	2K_dev_300
	finding	2K_dev_300
we envision a framework that automatically integrates the required information items and provides them to the performance analysis algorithms for HVAC systems	mechanism	2K_dev_300
This paper presents an approach We extend the Information Delivery Manual ( IDM ) approach so that the identified information requirements can be mapped to multiple information sources that use various formats and schemas	mechanism	2K_dev_300
	method	2K_dev_300
However	purpose	2K_dev_300
the complex information	purpose	2K_dev_300
such as configurations of HVAC systems	purpose	2K_dev_300
layouts and materials of building elements and dynamic data from the control systems	purpose	2K_dev_300
required by these algorithms inhibits the process of deploying them in real-world facilities To address this challenge	purpose	2K_dev_300
to identify and document the information requirements from the publications that describe these algorithms This paper presents the extensions to the IDM approach and the results of using it to identify information requirements for performance analysis algorithms of HVAC systems	purpose	2K_dev_300
	purpose	2K_dev_300
A password composition policy restricts the space of allowable passwords to eliminate weak passwords that are vulnerable to statistical guessing attacks	background	2K_dev_301
	background	2K_dev_301
theoretical results	finding	2K_dev_301
We introduce the first theoretical model Our main positive result is an algorithm that -- with high probability -- - constructs almost optimal policies ( which are specified as a union of subsets of allowed passwords )	mechanism	2K_dev_301
and requires only a small number of samples of users ' preferred passwords	mechanism	2K_dev_301
	mechanism	2K_dev_301
We study the computational and sample complexity of this problem under different assumptions on the structure of policies and on users ' preferences over passwords	method	2K_dev_301
We complement our with simulations using a real-world dataset of 32 million passwords	method	2K_dev_301
Usability studies have demonstrated that existing password composition policies can sometimes result in weaker password distributions ; hence a more principled approach is needed	purpose	2K_dev_301
for optimizing password composition policies	purpose	2K_dev_301
Time synchronization in wireless sensor networks is important for event ordering and efficient communication scheduling	background	2K_dev_302
We show that our new synchronization circuit consumes 60 % less power than the original design and is able to correct clock drift rates to within 0	finding	2K_dev_302
01 ppm without power hungry and expensive precision clocks	finding	2K_dev_302
	finding	2K_dev_302
In this paper	mechanism	2K_dev_302
we introduce an external hardwarebased clock tuning circuit that can be used without waking up the host MCU This is accomplished through two main hardware sub-systems First	mechanism	2K_dev_302
we improve upon the circuit presented in [ 1 ] that synchronizes clocks using the ambient magnetic fields emitted from power lines	mechanism	2K_dev_302
The new circuit uses an electric field front-end as opposed to the original magnetic-field sensor	mechanism	2K_dev_302
which makes the design more compact	mechanism	2K_dev_302
lower-power	mechanism	2K_dev_302
lower-cost	mechanism	2K_dev_302
exhibit less jitter and improves robustness to noise generated by nearby appliances Second	mechanism	2K_dev_302
we present a low-cost hardware tuning circuit that can be used to continuously trim a micro-controller 's low-power clock at runtime	mechanism	2K_dev_302
Most time synchronization approaches require a CPU to periodically adjust internal counters to accommodate for clock drift	mechanism	2K_dev_302
Periodic discrete updates can introduce interpolation errors as compared to continuous update approaches and they require the CPU to expend energy during these wake up periods	mechanism	2K_dev_302
Our hardware-based external clock tuning circuit allows the main CPU to remain in a deep-sleep mode for extended periods while an external circuit compensates for clock drift	mechanism	2K_dev_302
	mechanism	2K_dev_302
	method	2K_dev_302
to improve synchronization and significantly reduce clock drift over long periods of time	purpose	2K_dev_302
Split fabrication	background	2K_dev_303
the process of splitting an IC into an untrusted and trusted tier	background	2K_dev_303
facilitates access to the most advanced semiconductor manufacturing capabilities available in the world without requiring disclosure of design intent	background	2K_dev_303
	background	2K_dev_303
shows that they are vulnerable to recognition attacks at the untrusted foundry due to the use of standardized floorplans and leaf cell layouts	finding	2K_dev_303
	finding	2K_dev_303
and demonstrate their effectiveness using 130nm split fabricated testchips	finding	2K_dev_303
	finding	2K_dev_303
	mechanism	2K_dev_303
Our security analysis of IP block designs	method	2K_dev_303
specifically embedded memory and analog components We propose methodologies	method	2K_dev_303
While researchers have investigated the security of logic blocks in the context of split fabrication	purpose	2K_dev_303
the security of IP blocks	purpose	2K_dev_303
another key component of an SoC	purpose	2K_dev_303
has not been examined to design these blocks efficiently and securely	purpose	2K_dev_303
	background	2K_dev_304
	finding	2K_dev_304
We present a distributed Kalman-type estimator such that The challenges with distributed estimation by a network of sensors lie in the estimation of fields with unstable dynamics Our distributed Kalman filter type estimator	mechanism	2K_dev_304
which includes a consensus step on the pseudo-innovations	mechanism	2K_dev_304
a modified version of the filter innovations	mechanism	2K_dev_304
is able to track arbitrary unstable dynamics	mechanism	2K_dev_304
as long as the sensor network connectivity is above a threshold determined by the degree of instability of the field dynamics	mechanism	2K_dev_304
regardless of the specifics of the local observations	mechanism	2K_dev_304
	method	2K_dev_304
In this paper we address the distributed estimation of a dynamic ( time varying ) random field	purpose	2K_dev_304
The dynamic field is globally observable ( by the entire sensor network )	purpose	2K_dev_304
but not locally observable ( at each sensor )	purpose	2K_dev_304
the estimate at each sensor is unbiased with bounded mean-squared estimation error	purpose	2K_dev_304
Self-powered vehicles that interact with the physical world	background	2K_dev_305
such as spacecraft	background	2K_dev_305
require computing platforms with predictable timing behavior and a low energy demand	background	2K_dev_305
Energy consumption can be reduced by choosing energy-efficient designs for both hardware and software components of the platform	background	2K_dev_305
shows that neither balancing the load nor assigning all load to the cheapest core is the best load distribution strategy	finding	2K_dev_305
unless the cores are extremely alike or extremely different	finding	2K_dev_305
	finding	2K_dev_305
We leverage the state-of-the-art in energy-efficient hardware design by adopting Heterogeneous Multi-core Processors with support for Dynamic Voltage and Frequency Scaling and Dynamic Power Management	mechanism	2K_dev_305
Our approach is to start from an analytically justified target load distribution and find a task assignment heuristic that approximates it	mechanism	2K_dev_305
The optimal load distribution is then formulated as a solution to a convex optimization problem A heuristic that approximates this load distribution and an alternative method that leverages the solution explicitly are proposed as viable task assignment methods	mechanism	2K_dev_305
	mechanism	2K_dev_305
Our analysis The proposed methods are compared to state-of-the-art on simulated problem instances and in a case study of a soft-real-time application on an off-the-shelf ARM big	method	2K_dev_305
LITTLE heterogeneous processor	method	2K_dev_305
	method	2K_dev_305
We address the problem of allocating real-time software components onto heterogeneous cores such that total energy is minimized	purpose	2K_dev_305
	purpose	2K_dev_305
Harnessing crowds can be a powerful mechanism for increasing innovation	background	2K_dev_306
Our results have implications for improving creativity and building systems for distributed crowd innovation	background	2K_dev_306
	background	2K_dev_306
we show that distributed analogical idea generation leads to better ideas than example-based approaches	finding	2K_dev_306
We introduce a new approach called distributed analogical idea generation Drawing from the literature in cognitive science on analogy and schema induction	mechanism	2K_dev_306
our approach decomposes the creative process in a structured way amenable to using crowds	mechanism	2K_dev_306
In three experiments	method	2K_dev_306
and investigate the conditions under which crowds generate good schemas and ideas	method	2K_dev_306
However	purpose	2K_dev_306
current approaches to crowd innovation rely on large numbers of contributors generating ideas independently in an unstructured way	purpose	2K_dev_306
	purpose	2K_dev_306
which aims to make idea generation more effective and less reliant on chance	purpose	2K_dev_306
	purpose	2K_dev_306
	background	2K_dev_307
	finding	2K_dev_307
	mechanism	2K_dev_307
	method	2K_dev_307
	purpose	2K_dev_307
Reranking has been a focal technique in multimedia retrieval due to its efficacy in improving initial retrieval results	background	2K_dev_308
results validate the efficacy and the efficiency of the proposed method on both image and video search tasks	finding	2K_dev_308
Notably	finding	2K_dev_308
SPaR achieves by far the best result on the challenging TRECVID multimedia event search task	finding	2K_dev_308
	finding	2K_dev_308
In this paper	mechanism	2K_dev_308
we propose a novel reranking approach called Self-Paced Reranking ( SPaR ) As its name suggests	mechanism	2K_dev_308
SPaR utilizes samples from easy to more complex ones in a self-paced fashion	mechanism	2K_dev_308
SPaR is special in that it has a concise mathematical objective to optimize and useful properties that can be theoretically verified It on one hand offers a unified framework providing theoretical justifications for current reranking methods	mechanism	2K_dev_308
and on the other hand generates a spectrum of new reranking schemes	mechanism	2K_dev_308
This paper also advances the state-of-the-art self-paced learning research which potentially benefits applications in other fields	mechanism	2K_dev_308
Experimental	method	2K_dev_308
Current reranking methods	purpose	2K_dev_308
however	purpose	2K_dev_308
mainly rely on the heuristic weighting	purpose	2K_dev_308
for multimodal data	purpose	2K_dev_308
	purpose	2K_dev_308
Memory layout transformations via data reorganization are very common operations	background	2K_dev_309
which occur as a part of the computation or as a performance optimization in data-intensive applications	background	2K_dev_309
	background	2K_dev_309
and demonstrate that HAMLeT can achieve close to peak system utilization	finding	2K_dev_309
offering up to an order of magnitude performance improvement compared to the CPU and GPU memory subsystems which does not employ HAMLeT	finding	2K_dev_309
	finding	2K_dev_309
This paper proposes a high-bandwidth and energy-efficient hardware accelerated memory layout transform ( HAMLeT ) system integrated within a 3D-stacked DRAM	mechanism	2K_dev_309
HAMLeT uses a low-overhead hardware that exploits the existing infrastructure in the logic layer of 3D-stacked DRAMs	mechanism	2K_dev_309
and does not require any changes to the DRAM layers	mechanism	2K_dev_309
yet it can fully exploit the locality and parallelism within the stack by implementing efficient layout transform algorithms	mechanism	2K_dev_309
	mechanism	2K_dev_309
We analyze matrix layout transform operations ( such as matrix transpose	method	2K_dev_309
matrix blocking and 3D matrix rotation )	method	2K_dev_309
These operations require inefficient memory access patterns and roundtrip data movement through the memory hierarchy	purpose	2K_dev_309
failing to utilize the performance and energy-efficiency potentials of the memory subsystem	purpose	2K_dev_309
	purpose	2K_dev_309
This paper reports on methods and results of an applied research project by a team consisting of SAIC and four universities	background	2K_dev_310
We defined over 100 data features in seven categories We have achieved area under the ROC curve values of up to 0	finding	2K_dev_310
979 and lift values of 65 on the top 50 user-days identified on two months of real data	finding	2K_dev_310
	finding	2K_dev_310
Our system combines structural and semantic information from a real corporate database of monitored activity on their users ' computers We have developed and applied multiple algorithms for anomaly detection based on suspected scenarios of malicious insider behavior	mechanism	2K_dev_310
indicators of unusual activities	mechanism	2K_dev_310
high-dimensional statistical patterns	mechanism	2K_dev_310
temporal sequences	mechanism	2K_dev_310
and normal graph evolution Algorithms and representations for dynamic graph processing provide the ability to scale as needed for enterprise-level deployments on real-time data streams	mechanism	2K_dev_310
We have also developed a visual language for specifying combinations of features	mechanism	2K_dev_310
baselines	mechanism	2K_dev_310
peer groups	mechanism	2K_dev_310
time periods	mechanism	2K_dev_310
and algorithms to detect anomalies suggestive of instances of insider threat behavior	mechanism	2K_dev_310
based on approximately 5	method	2K_dev_310
5 million actions per day from approximately 5	method	2K_dev_310
500 users	method	2K_dev_310
	method	2K_dev_310
to develop	purpose	2K_dev_310
integrate	purpose	2K_dev_310
and evaluate new approaches to detect the weak signals characteristic of insider threats on organizations ' information systems	purpose	2K_dev_310
to detect independently developed red team inserts of malicious insider activities	purpose	2K_dev_310
	purpose	2K_dev_310
Support for multiple concurrent applications is an important enabler for promoting the use of sensor networks as an infrastructure technology	background	2K_dev_311
where multiple users can deploy their applications independently In such a scenario	background	2K_dev_311
different applications on a node may transmit packets at distinct periods	background	2K_dev_311
causing the node to change from sleep to active state more often	background	2K_dev_311
which negatively impacts the energy consumption of the whole network	background	2K_dev_311
and show how it can achieve a duty-cycle comparable to an ideal TDMA approach	finding	2K_dev_311
by defining a harmonizing period to align the transmissions from multiple applications at periodic boundaries	mechanism	2K_dev_311
This harmonizing period is then leveraged to design a protocol that coordinates the transmissions across nodes and provides real-time guarantees in a multi-hop network This protocol	mechanism	2K_dev_311
which we call Network- Harmonized Scheduling ( NHS )	mechanism	2K_dev_311
takes advantage of the periodicity introduced to assign offsets to nodes at different hop-levels such that collisions are always avoided	mechanism	2K_dev_311
and deterministic behavior is enforced NHS is a light-weight and distributed protocol that does not require any global state-keeping mechanism	mechanism	2K_dev_311
We implemented NHS on the Contiki operating system	method	2K_dev_311
In this paper	purpose	2K_dev_311
we propose to batch the transmissions together	purpose	2K_dev_311
	background	2K_dev_312
	finding	2K_dev_312
We describe a new algorithm The running time of our algorithm is O ( f log n log ) where f is the output complexity of the Voronoi diagram and is the spread of the input	mechanism	2K_dev_312
the ratio of largest to smallest pairwise distances	mechanism	2K_dev_312
Despite the simplicity of the algorithm and its analysis	mechanism	2K_dev_312
it improves on the state of the art for all inputs with polynomial spread and near-linear output size	mechanism	2K_dev_312
The key idea is to first build the Voronoi diagram of a superset of the input points using ideas from Voronoi refinement mesh generation Then	mechanism	2K_dev_312
the extra points are removed in a straightforward way that allows the total work to be bounded in terms of the output complexity	mechanism	2K_dev_312
yielding the output sensitive bound	mechanism	2K_dev_312
The removal only involves local flips and is inspired by kinetic data structures	mechanism	2K_dev_312
	mechanism	2K_dev_312
	method	2K_dev_312
for computing the Voronoi diagram of a set of n points in constant-dimensional Euclidean space	purpose	2K_dev_312
Color descriptors are one of the important features used in content-based image retrieval	background	2K_dev_313
The dominant color descriptor ( DCD ) represents a few perceptually dominant colors in an image through color quantization	background	2K_dev_313
For image retrieval based on DCD	background	2K_dev_313
the earth movers distance ( EMD ) and the optimal color composition distance were proposed to measure the dissimilarity between two images	background	2K_dev_313
	background	2K_dev_313
The results reveal that our approach achieves almost the same results with the EMD in linear time	finding	2K_dev_313
	finding	2K_dev_313
we propose a new distance function that calculates an approximate earth movers distance in linear time To calculate the dissimilarity in linear time	mechanism	2K_dev_313
the proposed approach employs the space-filling curve for multidimensional color space	mechanism	2K_dev_313
To improve the accuracy	mechanism	2K_dev_313
the proposed approach uses multiple curves and adjusts the color positions	mechanism	2K_dev_313
As a result	mechanism	2K_dev_313
our approach achieves order-of-magnitude time improvement but incurs small errors	mechanism	2K_dev_313
We have performed extensive experiments to show the effectiveness and efficiency of the proposed approach	method	2K_dev_313
Although providing good retrieval results	purpose	2K_dev_313
both methods are too time-consuming to be used in a large image database	purpose	2K_dev_313
To solve the problem	purpose	2K_dev_313
In previous work	background	2K_dev_314
we developed the scaled SIS process	background	2K_dev_314
which models the dynamics of SIS epidemics over networks	background	2K_dev_314
With the scaled SIS process	background	2K_dev_314
we can consider networks that are finite-sized and of arbitrary topology ( i	background	2K_dev_314
e	background	2K_dev_314
	background	2K_dev_314
we are not restricted to specific classes of networks )	background	2K_dev_314
We derived for the scaled SIS process a closed-form expression for the time-asymptotic probability distribution of the states of all the agents in the network	background	2K_dev_314
This closed-form solution of the equilibrium distribution explicitly exhibits the underlying network topology through its adjacency matrix	background	2K_dev_314
	background	2K_dev_314
We illustrate our results	finding	2K_dev_314
We prove that	mechanism	2K_dev_314
for a range of epidemics parameters	mechanism	2K_dev_314
this combinatorial problem leads to a submodular optimization problem	mechanism	2K_dev_314
which is exactly solvable in polynomial time	mechanism	2K_dev_314
We relate the most-probable configuration to the network structure	mechanism	2K_dev_314
in particular	mechanism	2K_dev_314
to the existence of high density subgraphs Depending on the epidemics parameters	mechanism	2K_dev_314
subset of agents may be more likely to be infected than others ; these more-vulnerable agents form subgraphs that are denser than the overall network	mechanism	2K_dev_314
with a 193 node social network and the 4941 node Western US power grid under different epidemics parameters	method	2K_dev_314
This paper determines which network configuration is the most probable	purpose	2K_dev_314
	background	2K_dev_315
demonstrate that the proposed approach achieves high classification accuracy	finding	2K_dev_315
	finding	2K_dev_315
We propose a novel discrete signal processing framework Our framework extends traditional discrete signal processing theory to datasets with complex structure that can be represented by graphs	mechanism	2K_dev_315
so that data elements are indexed by graph nodes and relations between elements are represented by weighted graph edges	mechanism	2K_dev_315
We interpret such datasets as signals on graphs	mechanism	2K_dev_315
introduce the concept of graph filters for processing such signals	mechanism	2K_dev_315
and discuss important properties of graph filters	mechanism	2K_dev_315
including linearity	mechanism	2K_dev_315
shift-invariance	mechanism	2K_dev_315
and invertibility We then demonstrate the application of graph filters to data classification by demonstrating that a classifier can be interpreted as an adaptive graph filter	mechanism	2K_dev_315
	mechanism	2K_dev_315
Our experiments	method	2K_dev_315
for structured datasets that arise from social	purpose	2K_dev_315
economic	purpose	2K_dev_315
biological	purpose	2K_dev_315
and physical networks	purpose	2K_dev_315
	purpose	2K_dev_315
Semantic search in video is a novel and challenging problem in information and multimedia retrieval	background	2K_dev_316
We share our observations and lessons in building such a state-of-the-art system	background	2K_dev_316
which may be instrumental in guiding the design of the future system for semantic search in video	background	2K_dev_316
where the proposed system achieves the best performance	finding	2K_dev_316
	finding	2K_dev_316
This paper presents a state-of-the-art system for event search without any textual metadata or example videos	mechanism	2K_dev_316
The system relies on substantial video content understanding and allows for semantic search over a large collection of videos	mechanism	2K_dev_316
	mechanism	2K_dev_316
The novelty and practicality is demonstrated by the evaluation in NIST TRECVID 2014	method	2K_dev_316
	method	2K_dev_316
Existing solutions are mainly limited to text matching	purpose	2K_dev_316
in which the query words are matched against the textual metadata generated by users	purpose	2K_dev_316
	background	2K_dev_317
	finding	2K_dev_317
	mechanism	2K_dev_317
	method	2K_dev_317
	purpose	2K_dev_317
	background	2K_dev_318
We have shown that the proposed ALDA method with the aid of facial asymmetry features significantly outperforms other well-established facial descriptors ( LBP	finding	2K_dev_318
LTP	finding	2K_dev_318
LTrP )	finding	2K_dev_318
and the ALDA subspace method does a much better job in distinguishing identical twins than LDA	finding	2K_dev_318
We are able to achieve 48	finding	2K_dev_318
50 % VR at 0	finding	2K_dev_318
1 % FAR for identifying family membership of identical twin individuals in the crowd and an averaged 82	finding	2K_dev_318
58 % VR at 0	finding	2K_dev_318
1 % FAR for verifying identical twin individuals within the same family	finding	2K_dev_318
a significant improvement over traditional descriptors and traditional LDA method	finding	2K_dev_318
In this work	mechanism	2K_dev_318
we have proposed an Augmented Linear Discriminant Analysis ( ALDA ) approach It learns a common subspace that not only can identify from which family the individual comes	mechanism	2K_dev_318
but also can distinguish between individuals within the same family	mechanism	2K_dev_318
	mechanism	2K_dev_318
We evaluate the ALDA against the traditional LDA approach for subspace learning on the Notre Dame twin database	method	2K_dev_318
to identify identical twins	purpose	2K_dev_318
Accurate inference of molecular and functional interactions among genes	background	2K_dev_319
especially in multicellular organisms such as Drosophila	background	2K_dev_319
often requires statistical analysis of correlations not only between the magnitudes of gene expressions	background	2K_dev_319
but also between their temporal-spatial patterns	background	2K_dev_319
The ISH ( in-situ-hybridization ) -based gene expression micro-imaging technology offers an effective approach to perform large-scale spatial-temporal profiling of whole-body mRNA abundance	background	2K_dev_319
we demonstrate the effectiveness of our approach in network building Furthermore	finding	2K_dev_319
we report results	finding	2K_dev_319
where GINI makes novel and interesting predictions of gene interactions	finding	2K_dev_319
	finding	2K_dev_319
In this paper	mechanism	2K_dev_319
we present GINI	mechanism	2K_dev_319
a machine learning system GINI builds on a computer-vision-inspired vector-space representation of the spatial pattern of gene expression in ISH images	mechanism	2K_dev_319
enabled by our recently developed system ; and a new multi-instance-kernel algorithm that learns a sparse Markov network model	mechanism	2K_dev_319
in which	mechanism	2K_dev_319
every gene ( i	mechanism	2K_dev_319
e	mechanism	2K_dev_319
	mechanism	2K_dev_319
node ) in the network is represented by a vector-valued spatial pattern rather than a scalar-valued gene intensity as in conventional approaches such as a Gaussian graphical model By capturing the notion of spatial similarity of gene expression	mechanism	2K_dev_319
and at the same time properly taking into account the presence of multiple images per gene via multi-instance kernels	mechanism	2K_dev_319
GINI is well-positioned to infer statistically sound	mechanism	2K_dev_319
and biologically meaningful gene interaction networks from image data Software for GINI is available at http : //sailing	mechanism	2K_dev_319
cs	mechanism	2K_dev_319
cmu	mechanism	2K_dev_319
edu/Drosophila_ISH_images/	mechanism	2K_dev_319
Using both synthetic data and a small manually curated data set	method	2K_dev_319
on a large publicly available collection of Drosophila embryonic ISH images from the Berkeley Drosophila Genome Project	method	2K_dev_319
However	purpose	2K_dev_319
analytical tools for discovering gene interactions from such data remain an open challenge due to various reasons	purpose	2K_dev_319
including difficulties in extracting canonical representations of gene activities from images	purpose	2K_dev_319
and in inference of statistically meaningful networks from such representations for inferring gene interaction networks from Drosophila embryonic ISH images	purpose	2K_dev_319
Background : Association analysis using genome-wide expression quantitative trait locus ( eQTL ) data investigates the effect that genetic variation has on cellular pathways and leads to the discovery of candidate regulators Furthermore	background	2K_dev_320
this analysis demonstrates the potential of GFlasso as a powerful computational tool for eQTL studies that exploit the rich structural information among expression traits due to correlation	background	2K_dev_320
regulation	background	2K_dev_320
or other forms of biological dependencies	background	2K_dev_320
	background	2K_dev_320
Results : While eQTL hotspots in yeast have been reported previously as genomic regions controlling multiple genes	finding	2K_dev_320
our analysis reveals additional novel eQTL hotspots and	finding	2K_dev_320
more interestingly	finding	2K_dev_320
uncovers groups of multiple contributing eQTL hotspots that affect the expression level of functional gene modules To our knowledge	finding	2K_dev_320
our study is the first to report this type of gene regulation stemming from multiple eQTL hotspots Additionally	finding	2K_dev_320
we report the results Not only do we find that many of these candidate regulators contain mutations in the promoter and coding regions of the genes	finding	2K_dev_320
in the case of the Ribi group	finding	2K_dev_320
we provide experimental evidence suggesting that the identified candidates do regulate the target genes predicted by GFlasso Conclusions : Thus	finding	2K_dev_320
this structured association analysis of a yeast eQTL dataset via GFlasso	finding	2K_dev_320
coupled with extensive bioinformatics analysis	finding	2K_dev_320
discovers a novel regulation pattern between multiple eQTL hotspots and functional gene modules	finding	2K_dev_320
	finding	2K_dev_320
We employ a new eQTL mapping algorithm	mechanism	2K_dev_320
GFlasso	mechanism	2K_dev_320
which we have previously developed for sparse structured regression	mechanism	2K_dev_320
GFlasso fully takes into account the dependencies among expression traits to suppress false positives and to enhance the signal/noise ratio	mechanism	2K_dev_320
Thus	mechanism	2K_dev_320
GFlasso leverages the gene-interaction network to discover the pleiotropic effects of genetic loci that perturb the expression level of multiple ( rather than individual ) genes	mechanism	2K_dev_320
which enables us to gain more power in detecting previously neglected signals that are marginally weak but pleiotropically significant We suggest candidate regulators for the functional gene modules that map to each group of hotspots	mechanism	2K_dev_320
from in-depth bioinformatics analysis for three groups of these eQTL hotspots : ribosome biogenesis	method	2K_dev_320
telomere silencing	method	2K_dev_320
and retrotransposon biology	method	2K_dev_320
	method	2K_dev_320
Traditional analysis of eQTL data via pairwise statistical significance tests or linear regression does not leverage the availability of the structural information of the transcriptome	purpose	2K_dev_320
such as presence of gene networks that reveal correlation and potentially regulatory relationships among the study genes	purpose	2K_dev_320
to reanalyze a genome-wide yeast dataset	purpose	2K_dev_320
Human action may be observed from multi-view	background	2K_dev_321
which are highly related but sometimes look different from each other	background	2K_dev_321
	background	2K_dev_321
show that the exploring of consistency properties of different views by graph model is very useful	finding	2K_dev_321
moreover	finding	2K_dev_321
GM-GS-DSDL for each view	finding	2K_dev_321
which are learnt simultaneously	finding	2K_dev_321
can further improve the fusion performance	finding	2K_dev_321
demonstrate that our proposed algorithm can obtain competing performance against the state-of-the-art methods	finding	2K_dev_321
	finding	2K_dev_321
Thus	mechanism	2K_dev_321
multi-view discriminative and structured dictionary learning with group sparsity and graph model ( GM-GS-DSDL ) is proposed to fuse different views and recognize human actions	mechanism	2K_dev_321
First	mechanism	2K_dev_321
spatio-temporal interest points are extracted for each view	mechanism	2K_dev_321
and then multi-view bag of words ( MVBoW ) representation is employed	mechanism	2K_dev_321
at the same time	mechanism	2K_dev_321
the graph model is also utilized to fuse different views	mechanism	2K_dev_321
which will remove overlapped interest points to explore their consistency properties	mechanism	2K_dev_321
Furthermore	mechanism	2K_dev_321
GM-GS-DSDL is formulated to discover the latent correlation among multiple views	mechanism	2K_dev_321
In addition	mechanism	2K_dev_321
we also issue a new multi-view action dataset with RGB	mechanism	2K_dev_321
depth and skeleton data ( called CVS-MV-RGBD ) Multi-view bag of words ( MVBoW ) representation is employed	mechanism	2K_dev_321
The graph model is also utilized to fuse different views	mechanism	2K_dev_321
We formulate the multi-view action recognition task as a joint dictionary learning ( DL ) problem	mechanism	2K_dev_321
We release a new multi-view action dataset which contains RGB	mechanism	2K_dev_321
depth and skeleton data	mechanism	2K_dev_321
Large-scale experimental results on multi-view IXMAX and CVS-MV-RGBD datasets Comparative experiments	method	2K_dev_321
Traditional metric learning algorithms have achieved satisfactory performance in single-view	purpose	2K_dev_321
but they often fail or do not satisfy when they are utilized to fuse different views	purpose	2K_dev_321
	purpose	2K_dev_321
Analyzing and interpreting the activity of a heterogeneous population of neurons can be challenging	background	2K_dev_322
especially as the number of neurons	background	2K_dev_322
experimental trials	background	2K_dev_322
and experimental conditions increases	background	2K_dev_322
One approach is to extract a set of latent variables that succinctly captures the prominent co-fluctuation patterns across the neural population	background	2K_dev_322
Significance	background	2K_dev_322
DataHigh was developed to fulfil a need for visualization in exploratory neural data analysis	background	2K_dev_322
which can provide intuition that is critical for building scientific hypotheses and models of population activity	background	2K_dev_322
Main results	finding	2K_dev_322
Approach	mechanism	2K_dev_322
we developed a Matlab graphical user interface ( called DataHigh ) We also implemented a suite of additional visualization tools ( including playing out population activity timecourses as a movie and displaying summary statistics	mechanism	2K_dev_322
such as covariance ellipses and average timecourses ) and an optional tool for performing dimensionality reduction	mechanism	2K_dev_322
To demonstrate the utility and versatility of DataHigh	method	2K_dev_322
we used it to analyze single-trial spike count and single-trial timecourse population activity recorded using a multi-electrode array	method	2K_dev_322
as well as trial-averaged population activity recorded using single electrodes	method	2K_dev_322
	method	2K_dev_322
Objective A key problem is that the number of latent variables needed to adequately describe the population activity is often greater than 3	purpose	2K_dev_322
thereby preventing direct visualization of the latent space	purpose	2K_dev_322
By visualizing a small number of 2-d projections of the latent space or each latent variable individually	purpose	2K_dev_322
it is easy to miss salient features of the population activity	purpose	2K_dev_322
To address this limitation that allows the user to quickly and smoothly navigate through a continuum of different 2-d projections of the latent space	purpose	2K_dev_322
	purpose	2K_dev_322
Current applications have produced graphs on the order of hundreds of thousands of nodes and millions of edges	background	2K_dev_323
To take advantage of such graphs	background	2K_dev_323
one must be able to find patterns	background	2K_dev_323
outliers	background	2K_dev_323
and communities	background	2K_dev_323
These tasks are better performed in an interactive environment	background	2K_dev_323
where human expertise can guide the process	background	2K_dev_323
	background	2K_dev_323
	finding	2K_dev_323
we propose an innovative framework suited for any kind of tree-like graph visual design GMine integrates 1 ) a representation for graphs organized as hierarchies of partitions-the concepts of SuperGraph and Graph-Tree ; and 2 ) a graph summarization methodology-CEPS Our graph representation deals with the problem of tracing the connection aspects of a graph hierarchy with sub linear complexity	mechanism	2K_dev_323
allowing one to grasp the neighborhood of a single node or of a group of nodes in a single click	mechanism	2K_dev_323
	mechanism	2K_dev_323
As a proof of concept	method	2K_dev_323
the visual environment of GMine is instantiated as a system in which large graphs can be investigated globally and locally	method	2K_dev_323
For large graphs	purpose	2K_dev_323
though	purpose	2K_dev_323
there are some challenges : the excessive processing requirements are prohibitive	purpose	2K_dev_323
and drawing hundred-thousand nodes results in cluttered images hard to comprehend	purpose	2K_dev_323
To cope with these problems	purpose	2K_dev_323
	purpose	2K_dev_323
Many content-based video search ( CBVS ) systems have been proposed to analyze the rapidly-increasing amount of user-generated videos on the Internet	background	2K_dev_324
which potentially opens the door to interactive web-scale CBVS for the general public	background	2K_dev_324
	background	2K_dev_324
showed that can achieve an 10	finding	2K_dev_324
000-fold speedup while retaining 80 % accuracy of a state-of-the-art CBVS system	finding	2K_dev_324
demonstrated that our system can complete the search in 0	finding	2K_dev_324
975 seconds with a single core	finding	2K_dev_324
	finding	2K_dev_324
through a combination of effective features	mechanism	2K_dev_324
highly compressed representations	mechanism	2K_dev_324
and one iteration of reranking	mechanism	2K_dev_324
our proposed system	mechanism	2K_dev_324
we perform a comprehensive study on the different components in a CBVS system Directions investigated include exploring different low-level and semantics-based features	method	2K_dev_324
testing different compression factors and approximations during video search	method	2K_dev_324
and understanding the time v	method	2K_dev_324
s	method	2K_dev_324
accuracy trade-off of reranking Extensive experiments on data sets consisting of more than 1	method	2K_dev_324
000 hours of video We further performed search over 1 million videos and	method	2K_dev_324
Though the accuracy of CBVS systems have drastically improved	purpose	2K_dev_324
these high accuracy systems tend to be too inefficient for interactive search	purpose	2K_dev_324
Therefore	purpose	2K_dev_324
to strive for real-time web-scale CBVS	purpose	2K_dev_324
to understand the trade-offs between accuracy and speed of each component	purpose	2K_dev_324
	purpose	2K_dev_324
	background	2K_dev_325
	finding	2K_dev_325
	mechanism	2K_dev_325
	method	2K_dev_325
	purpose	2K_dev_325
	background	2K_dev_326
	finding	2K_dev_326
	mechanism	2K_dev_326
	method	2K_dev_326
	purpose	2K_dev_326
	background	2K_dev_327
	finding	2K_dev_327
We demonstrate a Visual Light Communication ( VLC ) system Each LED pulses at a frequency above the humanly perceivable flicker threshold where cameras and photodiodes can still detect changes in light intensity	mechanism	2K_dev_327
Our modulation scheme supports multiple light sources in a single collision domain	mechanism	2K_dev_327
and works for both	mechanism	2K_dev_327
line-of-sight ( LOS ) operation as well as from reflected surfaces like those found in architectural lighting	mechanism	2K_dev_327
The spatial confinement of light makes this system ideal for use as localization landmarks	mechanism	2K_dev_327
A mobile device receiving and processing the signal displays the ID and RSSI of the closest landmark	mechanism	2K_dev_327
Interacting with the system will allow users to see the practical effects of multiple-access	mechanism	2K_dev_327
frequency of operation	mechanism	2K_dev_327
distance from the lights	mechanism	2K_dev_327
camera parameters and camera motion	mechanism	2K_dev_327
Our demonstration includes four LED ambient lights acting as location landmarks transmitting modulated data	method	2K_dev_327
	method	2K_dev_327
that enables LED lighting luminaires to communicate with cameras on mobile devices	purpose	2K_dev_327
The relationship between occupant activity and electricity consumption is inextricably linked	background	2K_dev_328
It has been difficult to both gather detailed energy data and information about occupants ' daily lives as well as understand their relationship quantitatively	background	2K_dev_328
	background	2K_dev_328
Initial findings include the identification of device groups but highlight the challenges of modeling complex patterns and event rarity	finding	2K_dev_328
	finding	2K_dev_328
Our work begins by characterizing power data as provided by plug-level meters from one household	mechanism	2K_dev_328
Association and sequential rule mining techniques are applied	mechanism	2K_dev_328
	method	2K_dev_328
There is significant past work on activity recognition in homes and load prediction	purpose	2K_dev_328
but there is limited understanding of how activities can inform consumption or vice versa	purpose	2K_dev_328
to extract explicit rules that may be useful for forming the basis of demand patterns	purpose	2K_dev_328
	purpose	2K_dev_328
To reduce costs	background	2K_dev_329
organizations may outsource data storage and data processing to third-party clouds	background	2K_dev_329
This raises confidentiality concerns	background	2K_dev_329
since the outsourced data may have sensitive information	background	2K_dev_329
and observe low to moderate overheads	finding	2K_dev_329
	finding	2K_dev_329
we present two database encryption schemes that reveal just enough information about structured data Our main contribution is a definition and proof of security for the two schemes	mechanism	2K_dev_329
This definition captures confidentiality offered by the schemes using a novel notion of equivalence of databases from the adversary 's perspective	mechanism	2K_dev_329
As a specific application	method	2K_dev_329
we adapt an existing algorithm for finding violations of a rich class of privacy policies to run on logs encrypted under our schemes	method	2K_dev_329
Although semantically secure encryption of the data prior to outsourcing alleviates these concerns	purpose	2K_dev_329
it also renders the outsourced data useless for any relational processing	purpose	2K_dev_329
Motivated by this problem	purpose	2K_dev_329
to support a wide-range of relational queries	purpose	2K_dev_329
	purpose	2K_dev_329
Developers use cryptographic APIs in Android with the intent of securing data such as passwords and personal information on mobile devices These numbers show that applications do not use cryptographic APIs in a fashion that maximizes overall security We then suggest specific remediations based on our analysis towards improving overall cryptographic security in Android applications	background	2K_dev_330
and find that 10	finding	2K_dev_330
327 out of 11	finding	2K_dev_330
748 applications that use cryptographic APIs -- 88 % overall -- make at least one mistake	finding	2K_dev_330
We develop program analysis techniques on the Google Play marketplace	mechanism	2K_dev_330
	mechanism	2K_dev_330
	method	2K_dev_330
In this paper	purpose	2K_dev_330
we ask whether developers use the cryptographic APIs in a fashion that provides typical cryptographic notions of security	purpose	2K_dev_330
e	purpose	2K_dev_330
g	purpose	2K_dev_330
	purpose	2K_dev_330
IND-CPA security	purpose	2K_dev_330
to automatically check programs	purpose	2K_dev_330
As a way to relieve the tedious work of manual annotation	background	2K_dev_331
active learning plays important roles in many applications of visual concept recognition	background	2K_dev_331
In typical active learning scenarios	background	2K_dev_331
the number of labelled data in the seed set is usually small	background	2K_dev_331
demonstrate its advantages	finding	2K_dev_331
	finding	2K_dev_331
In this paper	mechanism	2K_dev_331
we propose a semi-supervised batch mode multi-class active learning algorithm for visual concept recognition	mechanism	2K_dev_331
Our algorithm exploits the whole active pool to evaluate the uncertainty of the data	mechanism	2K_dev_331
Considering that uncertain data are always similar to each other	mechanism	2K_dev_331
we propose to make the selected data as diverse as possible	mechanism	2K_dev_331
for which we explicitly impose a diversity constraint on the objective function	mechanism	2K_dev_331
As a multi-class active learning algorithm	mechanism	2K_dev_331
our algorithm is able to exploit uncertainty across multiple classes	mechanism	2K_dev_331
An efficient algorithm is used to optimize the objective function	mechanism	2K_dev_331
Extensive experiments on action recognition	method	2K_dev_331
object classification	method	2K_dev_331
scene recognition	method	2K_dev_331
and event detection	method	2K_dev_331
However	purpose	2K_dev_331
most existing active learning algorithms only exploit the labelled data	purpose	2K_dev_331
which often suffers from over-fitting due to the small number of labelled examples	purpose	2K_dev_331
Besides	purpose	2K_dev_331
while much progress has been made in binary class active learning	purpose	2K_dev_331
little research attention has been focused on multi-class active learning	purpose	2K_dev_331
	purpose	2K_dev_331
	background	2K_dev_332
	finding	2K_dev_332
	mechanism	2K_dev_332
	method	2K_dev_332
	purpose	2K_dev_332
Existing methods are typically superlinear in space or execution time	background	2K_dev_333
	background	2K_dev_333
Effectiveness : it is accurate	finding	2K_dev_333
providing results with equal or better quality compared to top related works Halite was in average at least 12 times faster than seven representative works	finding	2K_dev_333
and always presented highly accurate results	finding	2K_dev_333
	finding	2K_dev_333
Halite was at least 11 times faster than others	finding	2K_dev_333
increasing their accuracy in up to 35 percent	finding	2K_dev_333
This paper proposes Halite	mechanism	2K_dev_333
a novel	mechanism	2K_dev_333
fast	mechanism	2K_dev_333
and scalable clustering method Halite 's strengths are that it is fast and scalable	mechanism	2K_dev_333
while still giving highly accurate results	mechanism	2K_dev_333
Specifically the main contributions of Halite are : 1 ) Scalability : it is linear or quasi linear in time and space regarding the data size and dimensionality	mechanism	2K_dev_333
and the dimensionality of the clusters ' subspaces ; 2 ) Usability : it is deterministic	mechanism	2K_dev_333
robust to noise	mechanism	2K_dev_333
does n't take the number of clusters as an input parameter	mechanism	2K_dev_333
and detects clusters in subspaces generated by original axes or by their linear combinations	mechanism	2K_dev_333
including space rotation ; 3 ) ; and 4 ) Generality : it includes a soft clustering approach	mechanism	2K_dev_333
	mechanism	2K_dev_333
Experiments on synthetic data ranging from five to 30 axes and up to 1 \rm million points were performed On real data Finally	method	2K_dev_333
we report experiments in a real scenario where soft clustering is desirable	method	2K_dev_333
that looks for clusters in subspaces of multidimensional data	purpose	2K_dev_333
	purpose	2K_dev_333
Analysts synthesize complex	background	2K_dev_334
qualitative data to uncover themes and concepts	background	2K_dev_334
but the process is time-consuming	background	2K_dev_334
cognitively taxing	background	2K_dev_334
and automated techniques show mixed success	background	2K_dev_334
Crowdsourcing could help this process through on-demand harnessing of flexible and powerful human cognition	background	2K_dev_334
but incurs other challenges including limited attention and expertise	background	2K_dev_334
Further	background	2K_dev_334
text data can be complex	background	2K_dev_334
high-dimensional	background	2K_dev_334
and ill-structured	background	2K_dev_334
	background	2K_dev_334
We demonstrate a classification-plus-context approach elicits the most accurate categories at the most useful level of abstraction	finding	2K_dev_334
B ) introduce an iterative clustering approach that provides workers a global overview of data	mechanism	2K_dev_334
	mechanism	2K_dev_334
To address these challenges we present an empirical study of a two-stage approach to enable crowds to create an accurate and useful overview of a dataset : A ) we draw on cognitive theory to assess how re-representing data can shorten and focus the data on salient dimensions ; and	method	2K_dev_334
We address two major challenges unsolved in prior crowd clustering work : scaffolding expertise for novice crowd workers	purpose	2K_dev_334
and creating consistent and accurate categories when each worker only sees a small portion of the data	purpose	2K_dev_334
	purpose	2K_dev_334
Sequencing of RNAs ( RNA-Seq ) has revolutionized the field of transcriptomics	background	2K_dev_335
but the reads obtained often contain errors	background	2K_dev_335
Read error correction can have a large impact on our ability to accurately assemble transcripts	background	2K_dev_335
This is especially true for de novo transcriptome analysis	background	2K_dev_335
where a reference genome is not available	background	2K_dev_335
Supporting website : http : //sb	background	2K_dev_335
cs	background	2K_dev_335
cmu	background	2K_dev_335
edu/seecer/	background	2K_dev_335
	background	2K_dev_335
we show that SEECER greatly improves on previous methods in terms of quality of read alignment to the genome and assembly accuracy Our corrected assembled transcripts shed new light on two important stages in sea cucumber development	finding	2K_dev_335
has also revealed novel transcripts that are unique to sea cucumber	finding	2K_dev_335
some of which we have validated	finding	2K_dev_335
	finding	2K_dev_335
Here we present SEquencing Error CorrEction in Rna-seq data ( SEECER )	mechanism	2K_dev_335
a hidden Markov Model ( HMM ) based method	mechanism	2K_dev_335
which is SEECER efficiently learns hundreds of thousands of HMMs and uses these to correct sequencing errors	mechanism	2K_dev_335
Using human RNA-Seq data	method	2K_dev_335
To illustrate the usefulness of SEECER for de novo transcriptome studies	method	2K_dev_335
we generated new RNA-Seq data to study the development of the sea cucumber Parastichopus parvimensis	method	2K_dev_335
Comparison of the assembled transcripts to known transcripts in other species experimentally	method	2K_dev_335
Current read error correction methods	purpose	2K_dev_335
developed for DNA sequence data	purpose	2K_dev_335
can not handle the overlapping effects of non-uniform abundance	purpose	2K_dev_335
polymorphisms and alternative splicing	purpose	2K_dev_335
the first to successfully address these problems	purpose	2K_dev_335
The HMT3522 progression series of human breast cells have been used to discover how tissue architecture	background	2K_dev_336
microenvironment and signaling molecules affect breast cell growth and behaviors	background	2K_dev_336
Thus	background	2K_dev_336
analysis of various reversion conditions ( including non-reverted ) of HMT3522 cells using Treegl can be a good model system to study drug effects on breast cancer	background	2K_dev_336
We found that different breast cell states contain distinct gene networks	finding	2K_dev_336
The network specific to non-malignant HMT3522-S1 cells is dominated by genes involved in normal processes	finding	2K_dev_336
whereas the T4-2-specific network is enriched with cancer-related genes	finding	2K_dev_336
The networks specific to various conditions of the reverted T4-2 cells are enriched with pathways suggestive of compensatory effects	finding	2K_dev_336
consistent with clinical data showing patient resistance to anticancer drugs	finding	2K_dev_336
and showed that aberrant expression values of certain hubs in the identified networks are associated with poor clinical outcomes	finding	2K_dev_336
We employed a pan-cell-state strategy	mechanism	2K_dev_336
using a tree-lineage multi-network inference algorithm	mechanism	2K_dev_336
Treegl	mechanism	2K_dev_336
	mechanism	2K_dev_336
and analyzed jointly microarray profiles obtained from different state-specific cell populations from this progression and reversion model of the breast cells We validated the findings using an external dataset	method	2K_dev_336
	method	2K_dev_336
However	purpose	2K_dev_336
much remains to be elucidated about malignant and phenotypic reversion behaviors of the HMT3522-T4-2 cells of this series	purpose	2K_dev_336
For urban driving	background	2K_dev_337
knowledge of ego-vehicle 's position is a critical piece of information that enables ad- vanced driver-assistance systems or self-driving cars to execute safety-related	background	2K_dev_337
autonomous driving maneuvers This is because	background	2K_dev_337
without knowing the current location	background	2K_dev_337
it is very hard to autonomously execute any driving maneuvers for the future	background	2K_dev_337
The existing solutions for localization rely on a combination of Global Navigation Satellite System ( GNSS )	background	2K_dev_337
an inertial mea- surement unit	background	2K_dev_337
and a digital map However	background	2K_dev_337
on urban driving environments	background	2K_dev_337
due to poor satellite geometry and disruption of radio signal reception	background	2K_dev_337
their longitudinal and lateral errors are too significant to be used to guide an autonomous system	background	2K_dev_337
	background	2K_dev_337
showed promising results in terms of counting the number of road-lanes and the indices of the current road-lanes	finding	2K_dev_337
this work presents an effort of developing a vision-based lateral localization algorithm The algorithm aims at reliably counting	mechanism	2K_dev_337
with or without observations of lane-markings	mechanism	2K_dev_337
the number road-lanes and identifying the index of the road-lane on the roadway that our vehicle happens to be driving	mechanism	2K_dev_337
Testings the proposed algorithms against inter-city and inter-state highway videos	method	2K_dev_337
To enhance the existing system 's localization capability	purpose	2K_dev_337
	purpose	2K_dev_337
	background	2K_dev_338
This approach outperformed the results of all other teams submissions in TRECVID SED 2012 on four of the seven event types	finding	2K_dev_338
	finding	2K_dev_338
We investigate a statistical approach with spatio-temporal features applied to seven event classes	mechanism	2K_dev_338
which were defined by the SED task	mechanism	2K_dev_338
This approach is based on local spatio-temporal descriptors	mechanism	2K_dev_338
called MoSIFT and generated by pair-wise video frames A Gaussian Mixture Model ( GMM ) is learned to model the distribution of the low level features	mechanism	2K_dev_338
Then for each sliding window	mechanism	2K_dev_338
the Fisher vector encoding [ improvedFV ] is used to generate the sample representation	mechanism	2K_dev_338
The model is learnt using a Linear SVM for each event	mechanism	2K_dev_338
The main novelty of our system is the introduction of Fisher vector encoding into video event detection	mechanism	2K_dev_338
Fisher vector encoding has demonstrated great success in image classification	mechanism	2K_dev_338
The key idea is to model the low level visual features as a Gaussian Mixture Model and to generate an intermediate vector representation for bag of features	mechanism	2K_dev_338
FV encoding uses higher order statistics in place of histograms in the standard BoW	mechanism	2K_dev_338
FV has several good properties : ( a ) it can naturally separate the video specific information from the noisy local features and ( b ) we can use a linear model for this representation	mechanism	2K_dev_338
We build an efficient implementation for FV encoding which can attain a 10 times speed-up over real-time	mechanism	2K_dev_338
We also take advantage of non-trivial object localization techniques to feed into the video event detection	mechanism	2K_dev_338
e	mechanism	2K_dev_338
g	mechanism	2K_dev_338
multi-scale detection and non-maximum suppression	mechanism	2K_dev_338
	method	2K_dev_338
We present a generic event detection system evaluated in the Surveillance Event Detection ( SED ) task of TRECVID 2012	purpose	2K_dev_338
	purpose	2K_dev_338
Background : Drug discovery and development has been aided by high throughput screening methods that detect compound effects on a single target	background	2K_dev_339
However	background	2K_dev_339
when using focused initial screening	background	2K_dev_339
undesirable secondary effects are often detected late in the development process after significant investment has been made	background	2K_dev_339
The methods described are also likely to find widespread application outside drug discovery	background	2K_dev_339
such as for characterizing the effects of a large number of compounds or inhibitory RNAs on a large number of cell or tissue phenotypes	background	2K_dev_339
Results Conclusions : An average of nearly 60 % of all hits in the dataset were found after exploring only 3 % of the experimental space which suggests that active learning can be used to enable more complete characterization of compound effects than otherwise affordable	finding	2K_dev_339
This paper describes methods by constructing predictive models for many target responses to many compounds and using them to guide experimentation We demonstrate for the first time that by jointly modeling targets and compounds using descriptive features and using active machine learning methods	mechanism	2K_dev_339
accurate models can be built by doing only a small fraction of possible experiments	mechanism	2K_dev_339
	mechanism	2K_dev_339
The methods were evaluated by computational experiments using a dataset of 177 assays and 20	method	2K_dev_339
000 compounds constructed from the PubChem database	method	2K_dev_339
An alternative approach would be to screen against undesired effects early in the process	purpose	2K_dev_339
but the number of possible secondary targets makes this prohibitively expensive	purpose	2K_dev_339
for making this global approach practical	purpose	2K_dev_339
With the increasing availability of metropolitan transportation data	background	2K_dev_340
such as those from vehicle Global Positioning Systems ( GPSs ) and road-side sensors	background	2K_dev_340
	background	2K_dev_340
and offer first-hand lessons learned from developing the system VAIT beats state-of-the-art methods and systems in terms of scalability	finding	2K_dev_340
efficiency	finding	2K_dev_340
and effectiveness and offers us an easy-to-use	finding	2K_dev_340
efficient	finding	2K_dev_340
and scalable platform to shed more light on intelligent transportation research	finding	2K_dev_340
	finding	2K_dev_340
We report our experience in building the Visual Analytics for Intelligent Transportation ( VAIT ) system	mechanism	2K_dev_340
which is the first system on real-life large-scale data sets Our key observation is that metropolitan transportation data are inherently visual as they are spatio-temporal around road networks Therefore	mechanism	2K_dev_340
we visualize and manage traffic data	mechanism	2K_dev_340
together with digital maps	mechanism	2K_dev_340
and support analytical queries through this interactive visual interface We discuss the technical challenges in data calibration	mechanism	2K_dev_340
storage	mechanism	2K_dev_340
visualization	mechanism	2K_dev_340
and query processing	mechanism	2K_dev_340
As a case study	method	2K_dev_340
we demonstrate VAIT on real-world taxi GPS and meter data sets from 15 000 taxis running for two months in a Chinese city of over 10 million people Based on our extensive empirical experiment results	method	2K_dev_340
	method	2K_dev_340
it has become viable for authorities	purpose	2K_dev_340
operators	purpose	2K_dev_340
and individuals to analyze the data for better understanding of the transportation system and	purpose	2K_dev_340
possibly	purpose	2K_dev_340
improved utilization and planning of the system	purpose	2K_dev_340
for intelligent transportation	purpose	2K_dev_340
Computers are often used in performance of popular music	background	2K_dev_341
but most often in very restricted ways	background	2K_dev_341
such as keyboard synthesizers where musicians are in complete control	background	2K_dev_341
or pre-recorded or sequenced music where musicians follow the computer 's drums or click track	background	2K_dev_341
An interesting and yet little-explored possibility is the computer as highly autonomous performer of popular music	background	2K_dev_341
capable of joining a mixed ensemble of computers and humans	background	2K_dev_341
and our experience with them	finding	2K_dev_341
We describe a general architecture	mechanism	2K_dev_341
and describe some early implementations	method	2K_dev_341
Considering the skills and functional requirements of musicians leads to a number of predictions about future humancomputer music performance ( HCMP ) systems for popular music for such systems	purpose	2K_dev_341
Fast Fourier transform algorithms on large data sets achieve poor performance on various platforms because of the inefficient strided memory access patterns	background	2K_dev_342
	background	2K_dev_342
we demonstrate that Spiral generated hardware designs achieve close to theoretical peak performance of the targeted platform and offer significant speed-up ( up to 6	finding	2K_dev_342
5x ) compared to naive baseline algorithms	finding	2K_dev_342
	finding	2K_dev_342
In this paper with a two-level memory hierarchy requiring block data transfers	mechanism	2K_dev_342
using custom block data layouts	mechanism	2K_dev_342
Using the Kronecker product formalism	mechanism	2K_dev_342
we integrate our optimizations into Spiral framework	mechanism	2K_dev_342
	mechanism	2K_dev_342
In our evaluations	method	2K_dev_342
These inefficient access patterns need to be reshaped to achieve high performance implementations	purpose	2K_dev_342
we formally restructure 1D	purpose	2K_dev_342
2D and 3D FFTs targeting a generic machine model and derive memory access pattern efficient algorithms	purpose	2K_dev_342
How can we detect suspicious users in large online networks ? Online popularity of a user or product ( via follows	background	2K_dev_343
page-likes	background	2K_dev_343
etc	background	2K_dev_343
) can be monetized on the premise of higher ad click-through rates or increased sales	background	2K_dev_343
Web services and social networks which incentivize popularity thus suffer from a major problem of fake connections from link fraudsters looking to make a quick buck	background	2K_dev_343
Typical methods of catching this suspicious behavior use spectral techniques to spot large groups of often blatantly fraudulent ( but sometimes honest ) users	background	2K_dev_343
( b ) it is shown to be highly effective on real data and and with high precision identify many suspicious accounts which have persisted without suspension even to this day	finding	2K_dev_343
and propose fBox	mechanism	2K_dev_343
an algorithm designed Our algorithm has the following desirable properties : ( a ) it has theoretical underpinnings	mechanism	2K_dev_343
( c ) it is scalable ( linear on the input size )	mechanism	2K_dev_343
	mechanism	2K_dev_343
We evaluate fBox on a large	method	2K_dev_343
public 41	method	2K_dev_343
7 million node	method	2K_dev_343
1	method	2K_dev_343
5 billion edge who-follows-whom social graph from Twitter in 2010	method	2K_dev_343
However	purpose	2K_dev_343
small-scale	purpose	2K_dev_343
stealthy attacks may go unnoticed due to the nature of low-rank Eigen analysis used in practice	purpose	2K_dev_343
In this work	purpose	2K_dev_343
we take an adversarial approach to find and prove claims about the weaknesses of modern	purpose	2K_dev_343
state-of-the-art spectral methods to catch small-scale	purpose	2K_dev_343
stealth attacks that slip below the radar	purpose	2K_dev_343
	purpose	2K_dev_343
As the complexity of software for Cyber-Physical Systems ( CPS ) rapidly increases	background	2K_dev_344
multi-core processors and parallel programming models such as OpenMP become appealing to CPS developers for guaranteeing timeliness Hence	background	2K_dev_344
a parallel task on multi-core processors is expected to become a vital component in CPS such as a self-driving car	background	2K_dev_344
where tasks must be scheduled in real-time	background	2K_dev_344
	background	2K_dev_344
we achieve a resource augmentation bound of 3	finding	2K_dev_344
73 In other words	finding	2K_dev_344
any task set that is feasible on m unit-speed processors can be scheduled by the proposed algorithm on m processors that are 3	finding	2K_dev_344
73 times faster	finding	2K_dev_344
	finding	2K_dev_344
In this paper	mechanism	2K_dev_344
we extend the fork-join parallel task model we develop the task stretch transform Using this transform for global Deadline Monotonic scheduling for fork-join real-time tasks	mechanism	2K_dev_344
	mechanism	2K_dev_344
	mechanism	2K_dev_344
The proposed scheme is implemented on Linux/RK as a proof of concept	method	2K_dev_344
and ported to Boss	method	2K_dev_344
the self-driving vehicle that won the 2007 DARPA Urban Challenge	method	2K_dev_344
We evaluate our scheme on Boss by showing its driving quality	method	2K_dev_344
i	method	2K_dev_344
e	method	2K_dev_344
	method	2K_dev_344
curvature and velocity profiles of the vehicle	method	2K_dev_344
	method	2K_dev_344
to be scheduled in real-time	purpose	2K_dev_344
where the number of parallel threads can vary depending on the physical attributes of the system To efficiently schedule the proposed task model	purpose	2K_dev_344
	purpose	2K_dev_344
A well-studied approach to the design of voting rules views them as maximum likelihood estimators ; given votes that are seen as noisy estimates of a true ranking of the alternatives	background	2K_dev_345
the rule must reconstruct the most likely true ranking	background	2K_dev_345
	background	2K_dev_345
and show that for all rules in this family the number of samples required from the Mallows noise model is logarithmic in the number of alternatives	finding	2K_dev_345
and that no rule can do asymptotically better ( while some rules like plurality do much worse ) and find voting rules that are accurate in the limit for all noise models in such general families	finding	2K_dev_345
	finding	2K_dev_345
We define the family of pairwise-majority consistent rules Taking a more normative point of view	mechanism	2K_dev_345
we consider voting rules that surely return the true ranking as the number of samples tends to infinity ( we call this property accuracy in the limit ) ; this allows us to move to a higher level of abstraction We characterize the distance functions that induce noise models for which pairwise-majority consistent rules are accurate in the limit	mechanism	2K_dev_345
and provide a similar result for another novel family of position-dominance consistent rules These characterizations capture three well-known distance functions	mechanism	2K_dev_345
We study families of noise models that are parametrized by distance functions	method	2K_dev_345
	method	2K_dev_345
We argue that this is too stringent a requirement	purpose	2K_dev_345
and instead ask : How many votes does a voting rule need to reconstruct the true ranking ?	purpose	2K_dev_345
The quality and effectiveness of the load following services provided by centralized control of thermostatically controlled loads depend highly on the communication requirements and the underlying cyberinfrastructure characteristics	background	2K_dev_346
Specifically	background	2K_dev_346
ensuring end-user comfort while providing real-time demand response services depends on the availability of the information provided from the thermostatically controlled loads to the main controller regarding their operating statuses and internal temperatures	background	2K_dev_346
	background	2K_dev_346
The results show that some improvement is possible for scenarios when loads are expected to be toggled frequently	finding	2K_dev_346
	finding	2K_dev_346
In this paper	mechanism	2K_dev_346
we introduce a moving horizon mean squared error state estimator with constraints which assumes a linear model without constraints	mechanism	2K_dev_346
	mechanism	2K_dev_346
	method	2K_dev_346
State estimation techniques can be used to infer the necessary information from the aggregate power consumption of these loads	purpose	2K_dev_346
replacing the need for an upstream communication platform carrying information from appliances to the main controller in real-time	purpose	2K_dev_346
as an alternative to a Kalman filter approach	purpose	2K_dev_346
Reading text on the Web is a challenging task for many people	background	2K_dev_347
such as those with cognitive impairments	background	2K_dev_347
reading difficulties or people who are learning a new language	background	2K_dev_347
	background	2K_dev_347
	finding	2K_dev_347
In this paper we present a web browser plug-in The plug-in is freely available for Chrome and presents definitions and simpler synonyms on demand for the selected web text	mechanism	2K_dev_347
	mechanism	2K_dev_347
The tool was modified following the suggestions of 5 people ( 2 with diagnosed dyslexia ) who tested the tool using the think aloud protocol and undertook a subsequent interview	method	2K_dev_347
	method	2K_dev_347
to help with reading Spanish text on the Web	purpose	2K_dev_347
It also significantly contributes to CMU Team 's final submission in TRECVID-13 Multimedia Event Detection	background	2K_dev_348
	background	2K_dev_348
	finding	2K_dev_348
the approach improves the baseline by up to 158 % in terms of the mean average precision	finding	2K_dev_348
	finding	2K_dev_348
We propose a novel method MultiModal Pseudo Relevance Feedback ( MMPRF which requires no search examples from the user	mechanism	2K_dev_348
Pseudo Relevance Feedback has shown great potential in retrieval tasks	mechanism	2K_dev_348
but previous works are limited to unimodal tasks with only a single ranked list	mechanism	2K_dev_348
To tackle the event search task which is inherently multimodal	mechanism	2K_dev_348
our proposed MMPRF takes advantage of multiple modalities and multiple ranked lists to enhance event search performance in a principled way The approach is unique in that it leverages not only semantic features	mechanism	2K_dev_348
but also non-semantic low-level features for event search in the absence of training data	mechanism	2K_dev_348
	mechanism	2K_dev_348
Evaluated on the TRECVID MEDTest dataset	method	2K_dev_348
for event search in video	purpose	2K_dev_348
Big graphs are everywhere	background	2K_dev_349
ranging from social networks and mobile call networks to biological networks and the World Wide Web Mining big graphs leads to many interesting applications including cyber security	background	2K_dev_349
fraud detection	background	2K_dev_349
Web search	background	2K_dev_349
recommendation	background	2K_dev_349
and many more	background	2K_dev_349
	background	2K_dev_349
Our findings include anomalous spikes in the connected component size distribution	finding	2K_dev_349
the 7 degrees of separation in a Web graph	finding	2K_dev_349
and anomalous adult advertisers in the who-follows-whom Twitter social network	finding	2K_dev_349
	finding	2K_dev_349
In this paper we describe Pegasus built on top of MapReduce	mechanism	2K_dev_349
a modern distributed We introduce GIM-V	mechanism	2K_dev_349
an important primitive that Pegasus uses for its algorithms to analyze structures of large graphs We also introduce HEigen	mechanism	2K_dev_349
a large scale eigensolver which is also a part of Pegasus Both GIM-V and HEigen are highly optimized	mechanism	2K_dev_349
achieving linear scale up on the number of machines and edges	mechanism	2K_dev_349
and providing 9	mechanism	2K_dev_349
2x and 76x faster performance than their naive counterparts	mechanism	2K_dev_349
respectively	mechanism	2K_dev_349
Using Pegasus	method	2K_dev_349
we analyze very large	method	2K_dev_349
real world graphs with billions of nodes and edges	method	2K_dev_349
	method	2K_dev_349
How do we find patterns and anomalies in very large graphs with billions of nodes and edges ? How to mine such big graphs efficiently ? a big graph mining system data processing platform	purpose	2K_dev_349
	purpose	2K_dev_349
	background	2K_dev_350
and it gains promising performance	finding	2K_dev_350
In this paper	mechanism	2K_dev_350
we propose an algorithm which adaptively utilizes the related exemplars by cross-feature learning	mechanism	2K_dev_350
Ordinal labels are used to represent the multiple relevance levels of the related videos	mechanism	2K_dev_350
Label candidates of related exemplars are generated by exploring the possible relevance levels of each related exemplar via a cross-feature voting strategy	mechanism	2K_dev_350
Maximum margin criterion is then applied in our framework to discriminate the positive and negative exemplars	mechanism	2K_dev_350
as well as the related exemplars from different relevance levels	mechanism	2K_dev_350
We test our algorithm using the large scale TRECVID 2011 dataset	method	2K_dev_350
We address the challenging problem of utilizing related exemplars for complex event detection while multiple features are available	purpose	2K_dev_350
Related exemplars share certain positive elements of the event	purpose	2K_dev_350
but have no uniform pattern due to the huge variance of relevance levels among different related exemplars	purpose	2K_dev_350
None of the existing multiple feature fusion methods can deal with the related exemplars	purpose	2K_dev_350
Multi-core CPUs with multiple levels of parallelism ( i	background	2K_dev_351
e	background	2K_dev_351
data level	background	2K_dev_351
instruction level and task/core level ) have become the mainstream CPUs for commodity computing systems	background	2K_dev_351
	background	2K_dev_351
The optimized ACCC solver achieves close to linear speedup ( SIMD width multiply core numbers ) comparing to scalar implementation and is able to solve a complete N-1 line outage AC contingency calculation of the Polish grid within one second on a commodity CPU	finding	2K_dev_351
It enables the complete ACCC as a real-time application on commodity computing systems	finding	2K_dev_351
Based on the multi-core CPUs	mechanism	2K_dev_351
in this paper we developed a high performance computing framework for AC contingency calculation ( ACCC ) Using Woodbury matrix identity based compensation method	mechanism	2K_dev_351
we transform and pack multiple contingency cases of different outages into a fine grained vectorized data parallel programming model	mechanism	2K_dev_351
We implement the data parallel programming model using SIMD instruction extension on x86 CPUs	mechanism	2K_dev_351
therefore	mechanism	2K_dev_351
fully taking advantages of the CPU core with SIMD floating point capability We also implement a thread pool scheduler for ACCC on multi-core CPUs which automatically balances the computing loads across CPU cores to fully utilize the multi-core capability	mechanism	2K_dev_351
	mechanism	2K_dev_351
We test the ACCC solver on the IEEE test systems and on the Polish 3000-bus system using a quad-core Intel Sandy Bridge CPU	method	2K_dev_351
	method	2K_dev_351
to fully utilize the computing power of commodity systems for online and real time applications	purpose	2K_dev_351
	background	2K_dev_352
demonstrate orders of magnitude of performance and power efficiency improvements compared with the traditional multithreaded software implementation on modern CPU	finding	2K_dev_352
	finding	2K_dev_352
This paper introduces a 3D-stacked logic-in-memory ( LiM ) system that integrates the 3D die-stacked DRAM architecture with the application-specific LiM IC The proposed system comprises a fine-grained rank-level 3D die-stacked DRAM device and extra LiM layers implementing logic-enhanced SRAM blocks that are dedicated to a particular application	mechanism	2K_dev_352
Through silicon vias ( TSVs ) are used for vertical interconnections providing the required bandwidth to support the high performance LiM computing We performed a comprehensive 3D DRAM design space exploration and exploit the efficient architectures to accelerate the computing that can balance the performance and power	mechanism	2K_dev_352
Our experiments	method	2K_dev_352
to accelerate important data-intensive computing	purpose	2K_dev_352
	background	2K_dev_353
	finding	2K_dev_353
	mechanism	2K_dev_353
	method	2K_dev_353
	purpose	2K_dev_353
	background	2K_dev_354
illustrate the analytical results	finding	2K_dev_354
for a class of deterministic distributed augmented Lagrangian methods The expressions for the convergence rates show the dependence on the underlying network parameters	mechanism	2K_dev_354
	mechanism	2K_dev_354
Simulations	method	2K_dev_354
This paper presents explicit convergence rates	purpose	2K_dev_354
Brain ? computer interfaces ( BCIs ) are being developed to assist paralyzed people and amputees by translating neural activity into movements of a computer cursor or prosthetic limb	background	2K_dev_355
Significance	background	2K_dev_355
The use of the instructed path task has the potential to accelerate the development of BCI systems and their clinical translation	background	2K_dev_355
	background	2K_dev_355
Main results We demonstrate that monkeys are able to perform the instructed path task in a closed-loop BCI setting	finding	2K_dev_355
Here we introduce a novel BCI task paradigm Through this task	mechanism	2K_dev_355
we can push the performance limits of BCI systems	mechanism	2K_dev_355
we can quantify more accurately how well a BCI system captures the user ? s intent	mechanism	2K_dev_355
and we can increase the richness of the BCI movement repertoire Approach	mechanism	2K_dev_355
We have implemented an instructed path task	mechanism	2K_dev_355
wherein the user must drive a cursor along a visible path The instructed path task provides a versatile framework to increase the difficulty of the task and thereby push the limits of performance	mechanism	2K_dev_355
Relative to traditional point-to-point tasks	mechanism	2K_dev_355
the instructed path task allows more thorough analysis of decoding performance and greater richness of movement kinematics	mechanism	2K_dev_355
We further investigate how the performance under BCI control compares to native arm control	method	2K_dev_355
whether users can decrease their movement variability in the face of a more demanding task	method	2K_dev_355
and how the kinematic richness is enhanced in this task	method	2K_dev_355
	method	2K_dev_355
Objective	purpose	2K_dev_355
intended to help accelerate improvements to BCI systems	purpose	2K_dev_355
	purpose	2K_dev_355
Guided waves	background	2K_dev_356
such as Lamb waves	background	2K_dev_356
are attractive tools for monitoring large civil infrastructures due to their sensitivity to damage	background	2K_dev_356
	background	2K_dev_356
shows that the estimates all correspond to expected paths	finding	2K_dev_356
	finding	2K_dev_356
In this paper	mechanism	2K_dev_356
we present a method by combining sparse wavenumber analysis	mechanism	2K_dev_356
a methodology for accurately recovering multimodal and dispersive properties	mechanism	2K_dev_356
with additional l 1 minimization techniques Its application to experimental Lamb wave data	mechanism	2K_dev_356
	method	2K_dev_356
Yet	purpose	2K_dev_356
interpreting guided wave data and identifying effects resulting from damage is often complicated by the multimodal and dispersive characteristics of guided waves and multipath interference from the medium 's boundaries to decompose guided waves into a collection of multipath arrivals	purpose	2K_dev_356
Pipes carrying fluids under pressure are critical components in infrastructure and industry	background	2K_dev_357
	background	2K_dev_357
	finding	2K_dev_357
We build a singular value decomposition ( SVD ) based change detector that is sensitive to the mass scatterer but insensitive to the changes produced by operational and environmental variations	mechanism	2K_dev_357
and	mechanism	2K_dev_357
we show examples of its successful performance on field experiments data	method	2K_dev_357
Changes in ultrasonic signals detected by piezoelectric transducers can indicate scattering from flaws	purpose	2K_dev_357
but signals also change dramatically from environmental and operational variations	purpose	2K_dev_357
Extensive pitch-catch tests are performed on pressurized pipe segments in a working hot-water supply system that experiences ongoing variations in pressure	purpose	2K_dev_357
temperature	purpose	2K_dev_357
and flow rate	purpose	2K_dev_357
Singular value decomposition is applied to differentiate the change caused by scatterer from the changes produced by benign variations	purpose	2K_dev_357
	purpose	2K_dev_357
	background	2K_dev_358
	finding	2K_dev_358
	mechanism	2K_dev_358
	method	2K_dev_358
	purpose	2K_dev_358
The convergence of mobile computing and cloud computing is predicated on a reliable	background	2K_dev_359
high-bandwidth end-to-end network	background	2K_dev_359
This basic requirement is hard to guarantee in hostile environments such as military operations and disaster recovery This article is part of a special issue on the edge of the cloud	background	2K_dev_359
	background	2K_dev_359
	finding	2K_dev_359
how VM-based cloudlets that are located in close proximity to associated mobile devices	mechanism	2K_dev_359
	method	2K_dev_359
In this article	purpose	2K_dev_359
the authors examine can overcome this challenge	purpose	2K_dev_359
	purpose	2K_dev_359
ABSTRACT One of the main challenges in real-world application of guided-waves based nondestructive evaluation ( NDE ) of pipelines is their sensitivity to changes in environmental and operational conditions ( EOC ) that these structures are subject to In spite of many favorable characteristics of gu ided-waves for NDE of pipes	background	2K_dev_360
their multi-modal	background	2K_dev_360
dispersive	background	2K_dev_360
and multi-path characteristics result in complex signa ls whose interpretation is a difficult task	background	2K_dev_360
	background	2K_dev_360
	finding	2K_dev_360
For damage detection	mechanism	2K_dev_360
a linear supervised classification method	mechanism	2K_dev_360
namely linear discriminant analysis ( LDA )	mechanism	2K_dev_360
Principal components	mechanism	2K_dev_360
obtained through principal component analysis ( PCA )	mechanism	2K_dev_360
and Fourier transforms of the signals are two sets of damage-sensitive features ( DSF ) that are examined for LDA-based classification	mechanism	2K_dev_360
	mechanism	2K_dev_360
is applied to experimental guided-wave data recorded from a hot water piping system under regular operation	method	2K_dev_360
The effects of temperature and flow rate difference among testing and training datasets on ( A ) detection performance and ( B ) goodness of fit of the method to the data are investigated	method	2K_dev_360
Studies that have considered the effects of EOC varia tions either fail to reflect realistic EOC scenarios ( e	purpose	2K_dev_360
g	purpose	2K_dev_360
	purpose	2K_dev_360
limited to particular effects of specific EOCs	purpose	2K_dev_360
like time shifting effects of temperature in plates ) or lack the necessary understanding of the effects of EOC variations on different aspects of the developed damage detection approaches	purpose	2K_dev_360
Such gaps limit the extensibility of these approaches to pipeline applications outside of controlled environments	purpose	2K_dev_360
This paper motivates the idea of analytically incorporating the effects of temperature and flow rate variations into damage diagnosis of pipes	purpose	2K_dev_360
through a number of case studie s	purpose	2K_dev_360
A review of the existing literature on guided-wave based testing is also provided	purpose	2K_dev_360
	background	2K_dev_361
	finding	2K_dev_361
	mechanism	2K_dev_361
	method	2K_dev_361
	purpose	2K_dev_361
Over the last several years there has been an explosion of powerful	background	2K_dev_362
affordable	background	2K_dev_362
multi-touch devices	background	2K_dev_362
	background	2K_dev_362
We describe the results that suggest users of Kinetica were able to explore multiple dimensions of data at once	finding	2K_dev_362
identify outliers	finding	2K_dev_362
and discover trends with minimal training	finding	2K_dev_362
	finding	2K_dev_362
In this paper we describe an approach that uses physics-based affordances that are easy to intuit	mechanism	2K_dev_362
constraints that are easy to apply and visualize	mechanism	2K_dev_362
and a consistent view as data is manipulated in order to promote data exploration and interrogation	mechanism	2K_dev_362
We provide a framework for exploring this problem space	mechanism	2K_dev_362
and	mechanism	2K_dev_362
an example proof of concept system called Kinetica	method	2K_dev_362
of a user study	method	2K_dev_362
This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry	purpose	2K_dev_362
for multivariate data visualization	purpose	2K_dev_362
	background	2K_dev_363
	finding	2K_dev_363
	mechanism	2K_dev_363
	method	2K_dev_363
	purpose	2K_dev_363
Signal recovery from noisy measurements is an important task that arises in many areas of signal processing	background	2K_dev_364
	finding	2K_dev_364
using a recently developed framework of discrete signal processing on graphs	mechanism	2K_dev_364
We formulate graph signal denoising as an optimization problem and derive an exact closed-form solution expressed by an inverse graph filter	mechanism	2K_dev_364
as well as an approximate iterative solution expressed by a standard graph filter	mechanism	2K_dev_364
	mechanism	2K_dev_364
We evaluate the obtained algorithms by applying them to measurement denoising for temperature sensors and opinion combination for multiple experts	method	2K_dev_364
In this paper	purpose	2K_dev_364
we consider this problem for signals represented with graphs	purpose	2K_dev_364
	background	2K_dev_365
	finding	2K_dev_365
	mechanism	2K_dev_365
	method	2K_dev_365
	purpose	2K_dev_365
design Finally	background	2K_dev_366
we summarize key lessons learned and hypothesis about additional hardware that could be used to ease the tracing of faults like short circuits and downed lines within microgrids	background	2K_dev_366
	finding	2K_dev_366
from a wirelessly managed microgrid deployment The system consists of a three-tiered architecture with a cloud-based monitoring and control service	mechanism	2K_dev_366
a local embedded gateway infrastructure and a mesh network of wireless smart meters deployed at 52 buildings Each smart meter device has an 802	mechanism	2K_dev_366
15	mechanism	2K_dev_366
4 radio that enables remote monitoring and control of electrical service The meters communicate over a scalable multi-hop TDMA network back to a central gateway that manages load within the system	mechanism	2K_dev_366
The gateway also provides an 802	mechanism	2K_dev_366
11 interface for an on-site operator and a cellular modem connection to a cloud-backend that manages and stores billing and usage data The cloud backend allows occupants in each home to pre-pay for electricity at a particular peak power limit using a text messaging service	mechanism	2K_dev_366
The system activates each meter within seconds and locally enforces power limits with provisioning for theft detection This paper provides a chronology of our deployment and installation strategy that involved GPS-based site mapping along with various network conditioning actions required as the network evolved	mechanism	2K_dev_366
	method	2K_dev_366
In this paper	purpose	2K_dev_366
we present the architecture	purpose	2K_dev_366
and experiences in rural Les Anglais	purpose	2K_dev_366
Haiti We believe that this fine-grained micro-payment model can enable sustainable power in otherwise unfeasible areas	purpose	2K_dev_366
	purpose	2K_dev_366
Proceedings : AACR 104th Annual Meeting 2013 ; Apr 6-10	background	2K_dev_367
2013 ; Washington	background	2K_dev_367
DC Understanding tumors as evolutionary systems is an important area of study with far-reaching implications in diagnostic and treatment paradigms Computational phylogenetics is a valuable method for inferring tumor evolution in terms of evolutionary trees	background	2K_dev_367
phylogenies	background	2K_dev_367
where paths in a tree correspond to possible tumor progression pathways The location of specific cell-types and patient samples in the tree provide information on tumor sub-types and development of heterogeneity	background	2K_dev_367
We previously developed a tumor phylogeny inference pipeline for array comparative genome hybridization ( aCGH ) -based tumor copy number profiles	background	2K_dev_367
Steps in the pipeline included extraction of robust progression markers from the data	background	2K_dev_367
which could differentiate stages of tumor evolution or the different paths in the tree	background	2K_dev_367
and assigning amplification states to the inferred markers in those stages We introduced a novel multi-sample model for amplicon identification and calling	background	2K_dev_367
HMMCNA	background	2K_dev_367
which jointly extracted markers from and assigned amplification states to small sets of tumor aCGH profiles	background	2K_dev_367
HMMCNA employs a Hidden Markov Model ( HMM )	background	2K_dev_367
a probabilistic model	background	2K_dev_367
to classify data into normal and amplified states based on an underlying distribution for the two copy number states and a hidden state space of possible amplification states We assumed two possible amplification states per sample : normal ( 0 ) or amplified ( 1 )	background	2K_dev_367
Joint segmentation and calling is performed by identifying a most likely sequence of amplification states across all genomic sites probes and samples	background	2K_dev_367
Further steps include tuning the parameters of the HMM to handle noise-levels across different datasets	background	2K_dev_367
Citation Format : Ayshwarya Subramanian	background	2K_dev_367
Stanley Shackney	background	2K_dev_367
Russell Schwartz	background	2K_dev_367
Inference of tumor phylogenetic markers from large copy number datasets	background	2K_dev_367
	background	2K_dev_367
The introduction of this heuristic reduces the state space on average by 99 %	finding	2K_dev_367
gives a further reduction of 80 %	finding	2K_dev_367
Our method was able to quickly segment the data into sets of robust normal and amplified segments suitable for downstream phylogeny building	finding	2K_dev_367
The amplicons inferred carried several known markers of tumor progression	finding	2K_dev_367
	finding	2K_dev_367
We incorporate a heuristic prior to the HMM classification by first screening out amplification states not strongly supported at any individual genome coordinates We further reduce the set of possible amplification states based on the frequency of occurrence of the states by only allowing those states occuring at multiple aCGH probes or array genome coordinate	mechanism	2K_dev_367
This step accounts for the presence of random noise in the data and We demonstrate the method on a breast tumor aCGH dataset comprising copy number profiles derived from sectioned biopsy samples ( NCBI GEO [ GSE16672 ] [ 1 ]	mechanism	2K_dev_367
Navin et al	mechanism	2K_dev_367
	mechanism	2K_dev_367
2010 )	mechanism	2K_dev_367
	method	2K_dev_367
This approach limits in the number of samples the HMM can handle since the number of possible hidden amplification states increases exponentially with the number of samples	purpose	2K_dev_367
Here	purpose	2K_dev_367
we present an extension of the approach to handle large datasets	purpose	2K_dev_367
to reduce the hidden state space	purpose	2K_dev_367
	background	2K_dev_368
	finding	2K_dev_368
	mechanism	2K_dev_368
	method	2K_dev_368
	purpose	2K_dev_368
	background	2K_dev_369
	finding	2K_dev_369
Spliddit is a first-of-its-kind fair division website	mechanism	2K_dev_369
which In this note	mechanism	2K_dev_369
we discuss Spliddit 's goals	mechanism	2K_dev_369
methods	mechanism	2K_dev_369
and implementation	mechanism	2K_dev_369
	mechanism	2K_dev_369
	method	2K_dev_369
offers provably fair solutions for the division of rent	purpose	2K_dev_369
goods	purpose	2K_dev_369
and credit	purpose	2K_dev_369
	purpose	2K_dev_369
Hybrid systems with both discrete and continuous dynamics are an important model for real-world cyber-physical systems	background	2K_dev_370
The key challenge is to ensure their correct functioning w	background	2K_dev_370
r	background	2K_dev_370
t	background	2K_dev_370
safety requirements	background	2K_dev_370
Promising techniques to ensure safety seem to be model-driven engineering to develop hybrid systems in a well-defined and traceable manner	background	2K_dev_370
and formal verification to prove their correctness	background	2K_dev_370
Their combination forms the vision of verification-driven engineering	background	2K_dev_370
Often	background	2K_dev_370
hybrid systems are rather complex in that they require expertise from many domains ( e	background	2K_dev_370
g	background	2K_dev_370
	background	2K_dev_370
robotics	background	2K_dev_370
control systems	background	2K_dev_370
computer science	background	2K_dev_370
software engineering	background	2K_dev_370
and mechanical engineering )	background	2K_dev_370
	background	2K_dev_370
	finding	2K_dev_370
This paper introduces a verification-driven engineering toolset that extends our previous work on hybrid and arithmetic verification with This toolset makes it easier	mechanism	2K_dev_370
	method	2K_dev_370
Moreover	purpose	2K_dev_370
despite the remarkable progress in automating formal verification of hybrid systems	purpose	2K_dev_370
the construction of proofs of complex systems often requires nontrivial human guidance	purpose	2K_dev_370
since hybrid systems verification tools solve undecidable problems	purpose	2K_dev_370
It is	purpose	2K_dev_370
thus	purpose	2K_dev_370
not uncommon for development and verification teams to consist of many players with diverse expertise	purpose	2K_dev_370
tools for ( 1 ) graphical ( UML ) and textual modeling of hybrid systems	purpose	2K_dev_370
( 2 ) exchanging and comparing models and proofs	purpose	2K_dev_370
and ( 3 ) managing verification tasks to tackle large-scale verification tasks	purpose	2K_dev_370
Data imbalance problem often exists in our real life dataset	background	2K_dev_371
especial for massive video dataset	background	2K_dev_371
	background	2K_dev_371
demonstrate that our proposed algorithm has much more powerful performance than that of traditional machine learning algorithms	finding	2K_dev_371
and keeps stable and robust when different kinds of features are employed also prove that our EHS algorithm is efficient and effective	finding	2K_dev_371
and reaches top performance in four of seven events	finding	2K_dev_371
	finding	2K_dev_371
In this paper	mechanism	2K_dev_371
the data imbalance problem in semantic extraction under massive video dataset is exploited	mechanism	2K_dev_371
and enhanced and hierarchical structure ( called EHS ) algorithm is proposed In proposed algorithm	mechanism	2K_dev_371
data sampling	mechanism	2K_dev_371
filtering and model training are considered and integrated together compactly via hierarchical structure algorithm	mechanism	2K_dev_371
thus	mechanism	2K_dev_371
the performance of model can be improved step by step	mechanism	2K_dev_371
and is robust and stability with the change of features and datasets	mechanism	2K_dev_371
	mechanism	2K_dev_371
Experiments on TRECVID2010 Semantic Indexing Extended experiments on TRECVID2010 Surveillance Event Detection	method	2K_dev_371
however	purpose	2K_dev_371
the balanced data distribution and the same misclassification cost are assumed in traditional machine learning algorithms	purpose	2K_dev_371
thus	purpose	2K_dev_371
it will be difficult for them to accurately describe the true data distribution	purpose	2K_dev_371
and resulting in misclassification	purpose	2K_dev_371
	purpose	2K_dev_371
Cake cutting is a common metaphor for the division of a heterogeneous divisible good	background	2K_dev_372
There are numerous papers that study the problem of fairly dividing a cake	background	2K_dev_372
	finding	2K_dev_372
	mechanism	2K_dev_372
where for the first time our notion of dominant strategy truthfulness is the ubiquitous one in social choice and computer science	mechanism	2K_dev_372
We design both deterministic and randomized cake cutting mechanisms that are truthful and fair under different assumptions with respect to the valuation functions of the agents	mechanism	2K_dev_372
	method	2K_dev_372
; a small number of them also take into account self-interested agents and consequent strategic issues	purpose	2K_dev_372
but these papers focus on fairness and consider a strikingly weak notion of truthfulness In this paper we investigate the problem of cutting a cake in a way that is truthful	purpose	2K_dev_372
Pareto-efficient	purpose	2K_dev_372
and fair	purpose	2K_dev_372
Mobile crowdsensing is becoming a vital technique for environment monitoring	background	2K_dev_373
infrastructure management	background	2K_dev_373
and social computing	background	2K_dev_373
	background	2K_dev_373
	finding	2K_dev_373
and to offer our initial thoughts on the potential solutions to lowering the barriers	mechanism	2K_dev_373
	method	2K_dev_373
However	purpose	2K_dev_373
deploying mobile crowdsensing applications in large-scale environments is not a trivial task	purpose	2K_dev_373
It creates a tremendous burden on application developers as well as mobile users	purpose	2K_dev_373
In this paper we try to reveal the barriers hampering the scale-up of mobile crowdsensing applications	purpose	2K_dev_373
	background	2K_dev_374
	finding	2K_dev_374
suggest required modifications	mechanism	2K_dev_374
In this work	method	2K_dev_374
we study the effects of position inaccuracy of commonly-used GPS devices on some of our V2V intersection protocols and	method	2K_dev_374
We have been investigating vehicle-to-vehicle ( V2V ) communications as a part of co-operative driving in the context of autonomous driving	purpose	2K_dev_374
to guarantee their safety and efficiency despite these impairments	purpose	2K_dev_374
Smart metering systems in distribution networks provide near real-time	background	2K_dev_375
two-way information exchange between end users and utilities	background	2K_dev_375
enabling many advanced smart grid technologies	background	2K_dev_375
	background	2K_dev_375
The demonstration shows the feasibility of our proposed privacy preserving protocol for advanced smart grid technologies which includes load management and retail level electricity market support	finding	2K_dev_375
In this work we propose a secure multi-party computation ( SMC ) based Using the proposed SMC protocol	mechanism	2K_dev_375
a utility is able to perform advanced market based demand management algorithms without knowing the actual values of private end user consumption and configuration data	mechanism	2K_dev_375
Using homomorphic encryption	mechanism	2K_dev_375
billing is secure and verifiable	mechanism	2K_dev_375
	mechanism	2K_dev_375
We implemented a demonstration system that includes a graphical user interface and simulates real-world network communication of the proposed SMC-enabled smart meters	method	2K_dev_375
However	purpose	2K_dev_375
the fine grained real-time data as well as the various market functionalities also pose great risks to customer privacy privacy preserving smart metering system	purpose	2K_dev_375
	purpose	2K_dev_375
Rating data is ubiquitous on websites such as Amazon	background	2K_dev_376
TripAdvisor	background	2K_dev_376
or Yelp	background	2K_dev_376
Since ratings are not static but given at various points in time	background	2K_dev_376
a temporal analysis of rating data provides deeper insights into the evolution of a product 's quality	background	2K_dev_376
	background	2K_dev_376
we show the effectiveness of our method and we present interesting discoveries on multiple real world datasets	finding	2K_dev_376
We propose a Bayesian model that represents the rating data as sequence of categorical mixture models	mechanism	2K_dev_376
In contrast to existing methods	mechanism	2K_dev_376
our method does not require any aggregation of the input but it operates on the original time stamped data To capture the dynamic effects of the ratings	mechanism	2K_dev_376
the categorical mixtures are temporally constrained : Anomalies can occur in specific time intervals only and the general rating behavior should evolve smoothly over time	mechanism	2K_dev_376
Our method automatically determines the intervals where anomalies occur	mechanism	2K_dev_376
and it captures the temporal effects of the general behavior by using a state space model on the natural parameters of the categorical distributions we propose an efficient algorithm combining principles from variational inference and dynamic programming	mechanism	2K_dev_376
In our experimental study	method	2K_dev_376
In this work	purpose	2K_dev_376
we tackle the following question : Given the time stamped rating data for a product or service	purpose	2K_dev_376
how can we detect the general rating behavior of users as well as time intervals where the ratings behave anomalous ? For learning our model	purpose	2K_dev_376
	purpose	2K_dev_376
	background	2K_dev_377
	finding	2K_dev_377
We introduce the Plug-Level Appliance Identification Dataset ( PLAID )	mechanism	2K_dev_377
a public and crowd-sourced dataset for load identification research consisting of short voltage and current measurements ( in the order of a few seconds ) for different residential appliances	mechanism	2K_dev_377
PLAID currently contains measurements for more than 200 different appliance instances	mechanism	2K_dev_377
representing 11 appliance classes	mechanism	2K_dev_377
and totaling more than a thousand records	mechanism	2K_dev_377
In this demo we summarize the existing dataset	mechanism	2K_dev_377
demonstrate how new records can be added to the library using a web interface and	mechanism	2K_dev_377
finally	mechanism	2K_dev_377
	mechanism	2K_dev_377
walk through a live example of how the library can be integrated into an existing non-intrusive load monitoring ( NILM ) algorithm framework	method	2K_dev_377
	method	2K_dev_377
The goal of PLAID is to provide a public library for high-resolution appliance measurements that can be integrated into existing or novel appliance identification algorithms	purpose	2K_dev_377
Abstraction has emerged as a key component in solving extensive-form games of incomplete information	background	2K_dev_378
However	background	2K_dev_378
lossless abstractions are typically too large to solve	background	2K_dev_378
so lossy abstraction is needed	background	2K_dev_378
	background	2K_dev_378
show that it finds a lossless abstraction when one is available and lossy abstractions when smaller abstractions are desired	finding	2K_dev_378
We introduce a theoretical framework that can be used The framework uses a new notion for mapping abstract strategies to the original game	mechanism	2K_dev_378
and it leverages a new equilibrium refinement for analysis	mechanism	2K_dev_378
Using this framework	mechanism	2K_dev_378
we develop the first general lossy extensive-form game abstraction method with bounds While our framework can be used for lossy abstraction	mechanism	2K_dev_378
it is also a powerful tool for lossless abstraction if we set the bound to zero	mechanism	2K_dev_378
Prior abstraction algorithms typically operate level by level in the game tree	mechanism	2K_dev_378
We introduce the extensive-form game tree isomorphism and action subset selection problems	mechanism	2K_dev_378
both important problems for computing abstractions on a level-by-level basis We show that the former is graph isomorphism complete	mechanism	2K_dev_378
and the latter NP-complete	mechanism	2K_dev_378
We also prove that level-by-level abstraction can be too myopic and thus fail to find even obvious lossless abstractions	mechanism	2K_dev_378
Experiments	method	2K_dev_378
All prior lossy abstraction algorithms for extensive-form games either 1 ) had no bounds on solution quality or 2 ) depended on specific equilibrium computation approaches	purpose	2K_dev_378
limited forms of abstraction	purpose	2K_dev_378
and only decreased the number of information sets rather than nodes in the game tree to give bounds on solution quality for any perfect-recall extensive-form game	purpose	2K_dev_378
Abstract Image patterns at different spatial levels are well organized	background	2K_dev_379
such as regions within one image and feature points within one region	background	2K_dev_379
These classes of spatial structures are hierarchical in nature	background	2K_dev_379
	background	2K_dev_379
demonstrate that the proposed approach has better performance of region tagging than the current state of the art methods	finding	2K_dev_379
we propose an approach	mechanism	2K_dev_379
called Unified Dictionary Learning and Region Tagging with Hierarchical Sparse Representation This approach consists of two steps : region representation and region reconstruction	mechanism	2K_dev_379
In the first step	mechanism	2K_dev_379
rather than using the l 1 -norm as it is commonly done in sparse coding	mechanism	2K_dev_379
we add a hierarchical structure to the process of sparse coding and form a framework of tree-guided dictionary learning	mechanism	2K_dev_379
In this framework	mechanism	2K_dev_379
the hierarchical structures among feature points	mechanism	2K_dev_379
regions	mechanism	2K_dev_379
and images are encoded by forming a tree-guided multi-task learning process	mechanism	2K_dev_379
With the learned dictionary	mechanism	2K_dev_379
we obtain a better representation of training and testing regions	mechanism	2K_dev_379
In the second step	mechanism	2K_dev_379
we propose to use a sub-hierarchical structure to guide the sparse reconstruction for testing regions	mechanism	2K_dev_379
i	mechanism	2K_dev_379
e	mechanism	2K_dev_379
	mechanism	2K_dev_379
the structure between regions and images	mechanism	2K_dev_379
Thanks to this hierarchy	mechanism	2K_dev_379
the obtained reconstruction coefficients are more discriminate	mechanism	2K_dev_379
Finally	mechanism	2K_dev_379
tags are propagated to testing regions by the learned reconstruction coefficients	mechanism	2K_dev_379
Extensive experiments on three public benchmark image data sets	method	2K_dev_379
The appropriate integration and utilization of such relationship are important to improve the performance of region tagging	purpose	2K_dev_379
Inspired by the recent advances of sparse coding methods	purpose	2K_dev_379
	purpose	2K_dev_379
	background	2K_dev_380
	finding	2K_dev_380
	mechanism	2K_dev_380
	method	2K_dev_380
	purpose	2K_dev_380
ABSTRACT Guided wave ultrasonics is an attractive technique for structural health monitoring	background	2K_dev_381
especially on pressurized pipes	background	2K_dev_381
The results show that the framework can effectively detect the presence of a scatterer and is robust to large environmental and operational variations	finding	2K_dev_381
	finding	2K_dev_381
We developed a damage detection method based on singular value decomposition ( SVD ) that is robust to those benign variations We further develop an online novelty detection framework based on our SVD method	mechanism	2K_dev_381
We examine the framework with both synthetic simulations and field experimental data	method	2K_dev_381
However	purpose	2K_dev_381
civil infrastructure components	purpose	2K_dev_381
including pipes	purpose	2K_dev_381
are often subject to large environmental and operational variations that prevent traditional baseline subtraction-based approaches from detecting damage	purpose	2K_dev_381
We collect ultrasonic data on a large-scale pipe segment in its normal operating conditions and observe large environmental variations to detect the presence of a mass scatterer on the pipe at the same time that we co llect the data	purpose	2K_dev_381
	purpose	2K_dev_381
The execution of an agent 's complex activities	background	2K_dev_382
comprising sequences of simpler actions	background	2K_dev_382
sometimes leads to the clash of conflicting functions that must be optimized	background	2K_dev_382
These functions represent satisfaction	background	2K_dev_382
short-term as well as long-term objectives	background	2K_dev_382
costs and individual preferences	background	2K_dev_382
The way that these functions are weighted is usually unknown even to the decision maker	background	2K_dev_382
But if we were able to understand the individual motivations and compare such motivations among individuals	background	2K_dev_382
then we would be able to actively change the environment so as to increase satisfaction and/or improve performance	background	2K_dev_382
	background	2K_dev_382
Our results show that our method is not only useful	finding	2K_dev_382
but also performs much better than the previous methods	finding	2K_dev_382
in terms of accuracy	finding	2K_dev_382
efficiency and scalability	finding	2K_dev_382
	finding	2K_dev_382
A novel algorithm is proposed	mechanism	2K_dev_382
We also present a methodology that allows researchers through the minimization of an error measure between the current description and the observed behaviors	mechanism	2K_dev_382
based on observations of such an agent during the fulfillment of a series of complex activities ( called sequential decisions in our work )	method	2K_dev_382
This work was validated using not only a synthetic dataset representing the motivations of a passenger in a public transportation network	method	2K_dev_382
but also real taxi drivers ' behaviors from their trips in an urban network	method	2K_dev_382
In this work	purpose	2K_dev_382
we approach the problem of providing highlevel and intelligible descriptions of the motivations of an agent	purpose	2K_dev_382
for the analysis of observational records to converge towards a summary description of an agent 's behaviors	purpose	2K_dev_382
	background	2K_dev_383
	finding	2K_dev_383
We propose a new framework The presented framework leads to a systematic design of iterative algorithms that compute the consensus exactly	mechanism	2K_dev_383
are guaranteed to converge in finite time	mechanism	2K_dev_383
are computationally efficient	mechanism	2K_dev_383
and require no online memory	mechanism	2K_dev_383
We demonstrate that our approach is applicable to a broad class of networks For remaining networks	mechanism	2K_dev_383
our framework leads to the construction of approximating algorithms for consensus that are also guaranteed to compute in finite time	mechanism	2K_dev_383
Our approach is inspired by graph filters introduced by the theoretical framework of signal processing on graphs	mechanism	2K_dev_383
	mechanism	2K_dev_383
	method	2K_dev_383
for distributed computation of average consensus	purpose	2K_dev_383
	purpose	2K_dev_383
The primary goal of a vehicular headlight is to improve safety in low-light and poor weather conditions The typical headlight however has very limited flexibility - switching between high and low beams	background	2K_dev_384
turning off beams toward the opposing lane or rotating the beam as the vehicle turns - and is not designed for all driving environments	background	2K_dev_384
In this talk	finding	2K_dev_384
we will lay out the engineering challenges in building this headlight and share our experiences	finding	2K_dev_384
We will describe a new DMD-based design for a headlight that can be programmed to perform several tasks simultaneously and For example	mechanism	2K_dev_384
we will be able to drive with high-beams without glaring any other driver and we will be able to see better during rain and snowstorms when the road is most treacherous to drive	mechanism	2K_dev_384
The headlight can also increase contrast of lanes	mechanism	2K_dev_384
markings and sidewalks and can alert drivers to sudden obstacles	mechanism	2K_dev_384
	mechanism	2K_dev_384
with the prototypes developed over the past two years	method	2K_dev_384
Thus	purpose	2K_dev_384
despite decades of innovation in light source technology	purpose	2K_dev_384
more than half of the vehicular accidents still happen at night even with much less traffic on the road	purpose	2K_dev_384
that can sense	purpose	2K_dev_384
react and adapt quickly to any environment with the goal of increasing safety for all drivers on the road	purpose	2K_dev_384
	purpose	2K_dev_384
Estimating the number of people within a room is important for a wide variety of applications including : HVAC load management	background	2K_dev_385
scheduling room allocations and guiding first responders to areas with trapped people	background	2K_dev_385
	background	2K_dev_385
we show that our approach is able to capture the number of people in a wide-variety of room configurations with people counting accuracy below 10 % of the maximum room capacity count with as few as two training points	finding	2K_dev_385
In this paper	mechanism	2K_dev_385
we present an active sensing technique that uses changes in a room 's acoustic properties Frequency dependent models of reverberation and room capacity are often used when designing auditoriums and concert halls	mechanism	2K_dev_385
We leverage this property by using measured changes in the ultrasonic spectrum reflected back from a wide-band transmitter to estimate occupancy	mechanism	2K_dev_385
A centrally located beacon transmits an ultrasonic chirp and then records how the signal dissipates over time By analyzing the frequency response over the chirp 's bandwidth at a few known occupancy levels	mechanism	2K_dev_385
we are able to extrapolate the response as the number of people in the room changes We explore the design of an excitation signal that best senses the environment with the fewest number of training samples	mechanism	2K_dev_385
Finally	mechanism	2K_dev_385
we provide a simple mechanism that allows our system	mechanism	2K_dev_385
Through experimentation	method	2K_dev_385
	method	2K_dev_385
to estimate the number of occupants to recalibrate when we know the room is empty so that it can adapt dynamically over time	purpose	2K_dev_385
	purpose	2K_dev_385
Organizations collect personal information from individuals to carry out their business functions	background	2K_dev_386
Federal privacy regulations	background	2K_dev_386
such as the Health Insurance Portability and Accountability Act ( HIPAA )	background	2K_dev_386
mandate how this collected information can be shared by the organizations	background	2K_dev_386
It is thus incumbent upon the organizations to have means to check compliance with the applicable regulations	background	2K_dev_386
Prior work by Barth et	background	2K_dev_386
al	background	2K_dev_386
introduces two notions of compliance	background	2K_dev_386
weak compliance ( WC ) and strong compliance ( SC )	background	2K_dev_386
WC ensures that present requirements of the policy can be met whereas SC also ensures obligations can be met	background	2K_dev_386
An action is compliant with a privacy policy if it is both weakly and strongly compliant	background	2K_dev_386
We prove that checking WC is feasible whereas checking SC is undecidable	finding	2K_dev_386
	finding	2K_dev_386
To this end	mechanism	2K_dev_386
we present a policy specification language based on a restricted subset of first order temporal logic ( FOTL ) We then formally specify WC and SC for policies of our form	mechanism	2K_dev_386
We then formally specify the property WC entails SC	mechanism	2K_dev_386
denoted by	mechanism	2K_dev_386
which requires that each weakly compliant action is also strongly compliant	mechanism	2K_dev_386
To check whether an action is compliant with such a policy	mechanism	2K_dev_386
it is sufficient to only check whether the action is weakly compliant with that policy We also prove that when a policy has the -property	mechanism	2K_dev_386
the present requirements of the policy reduce to the safety requirements imposed by We then develop a sound	mechanism	2K_dev_386
semi-automated technique for checking whether practical policies have the -property	mechanism	2K_dev_386
	mechanism	2K_dev_386
We finally use HIPAA as a case study to demonstrate the efficacy of our policy analysis technique	method	2K_dev_386
	method	2K_dev_386
However	purpose	2K_dev_386
their definitions of compliance are restricted to only propositional linear temporal logic ( pLTL )	purpose	2K_dev_386
which can not feasibly specify HIPAA which can capture the privacy requirements of HIPAA	purpose	2K_dev_386
	purpose	2K_dev_386
The increase in the number of bloggers and the amount of information diffused in the blogosphere makes the blogosphere an important medium through which to communicate and exchange information	background	2K_dev_387
Accordingly	background	2K_dev_387
the interest in understanding the nature of the information diffusion in the blogosphere has also been increased	background	2K_dev_387
	background	2K_dev_387
BlogCast	finding	2K_dev_387
a functionality provided by blog-service providers to expose a high quality post on the portal main page	finding	2K_dev_387
is found to be one of the main causes of the information diffusion without explicit relationships	finding	2K_dev_387
	mechanism	2K_dev_387
We analyze the characteristics of the information diffusion through the BlogCast and its halo effect on the bloggers whose post has been exposed on the portal main page	method	2K_dev_387
In addition	method	2K_dev_387
we examine the sustainability of the halo effect of the BlogCast over time	method	2K_dev_387
	method	2K_dev_387
Existing studies in social networks have mainly focused on the information diffusion through explicit relationships between members	purpose	2K_dev_387
In this paper	purpose	2K_dev_387
we analyze the causes for the information diffusion without explicit relationships in the blogosphere	purpose	2K_dev_387
	purpose	2K_dev_387
Many of the visual questions that blind people ask can not be easily answered with a single image or a short response	background	2K_dev_388
especially when questions are of an exploratory nature	background	2K_dev_388
e	background	2K_dev_388
g	background	2K_dev_388
what is in this area	background	2K_dev_388
or what tools are available on this work bench	background	2K_dev_388
	finding	2K_dev_388
We introduce RegionSpeak with fewer interactions	mechanism	2K_dev_388
RegionSpeak helps blind users capture all of the relevant visual information using an interface designed to support stitching multiple images together We use a parallel crowdsourcing workflow that asks workers to define and describe regions of interest	mechanism	2K_dev_388
allowing even complex images to be described quickly The regions and descriptions are displayed on an auditory touchscreen interface	mechanism	2K_dev_388
allowing users to know what is in a scene and how it is laid out	mechanism	2K_dev_388
	mechanism	2K_dev_388
	method	2K_dev_388
to allow blind users to capture large areas of visual information	purpose	2K_dev_388
identify all of the objects within them	purpose	2K_dev_388
and explore their spatial layout	purpose	2K_dev_388
The proliferation of Bluetooth Low-Energy ( BLE ) chipsets on mobile devices has lead to a wide variety of user-installable tags and beacons designed for location-aware applications	background	2K_dev_389
	background	2K_dev_389
that our system can estimate three-dimensional beacon location with a Euclidean distance error of 16	finding	2K_dev_389
1cm	finding	2K_dev_389
and can generate maps with room measurements with a two-dimensional Euclidean distance error of 19	finding	2K_dev_389
8cm	finding	2K_dev_389
we saw that the system can identify Non-Line-Of-Sight ( NLOS ) signals with over 80 % accuracy and track a user 's location to within less than 100cm	finding	2K_dev_389
In this paper	mechanism	2K_dev_389
we present the Acoustic Location Processing System ( ALPS )	mechanism	2K_dev_389
a platform that augments BLE transmitters with ultrasound in a manner A user places three or more beacons in an environment and then walks through a calibration sequence with their mobile device where they touch key points in the environment like the floor and the corners of the room This process automatically computes the room geometry as well as the precise beacon locations without needing auxiliary measurements	mechanism	2K_dev_389
Once configured	mechanism	2K_dev_389
the system can track a user 's location referenced to a map	mechanism	2K_dev_389
The platform consists of time-synchronized ultrasonic transmitters that utilize the bandwidth just above the human hearing limit	mechanism	2K_dev_389
where mobile devices are still sensitive and can detect ranging signals	mechanism	2K_dev_389
To aid in the mapping process	mechanism	2K_dev_389
the beacons perform inter-beacon ranging during setup	mechanism	2K_dev_389
Each beacon includes a BLE radio that can identify and trigger the ultrasonic signals	mechanism	2K_dev_389
By using differences in propagation characteristics between ultrasound and radio	mechanism	2K_dev_389
the system can classify if beacons are within Line-Of-Sight ( LOS ) to the mobile phone In cases where beacons are blocked	mechanism	2K_dev_389
we show how the phone 's inertial measurement sensors can be used to supplement localization data	mechanism	2K_dev_389
We experimentally evaluate When tested in six different environments	method	2K_dev_389
	method	2K_dev_389
that improves ranging accuracy and can help users configure indoor localization systems with minimal effort	purpose	2K_dev_389
Real-time captioning provides deaf and hard of hearing ( DHH ) users with access to spoken content during live events	background	2K_dev_390
and the web has allowed these services to be provided via remotely- located captioning services	background	2K_dev_390
and for web content itself	background	2K_dev_390
and then suggest future work that builds on these insights	background	2K_dev_390
show that by providing users with a tool to more easily track their place in a transcript while viewing live video	finding	2K_dev_390
it is possible for them to follow visual content that might otherwise have been missed	finding	2K_dev_390
Both pausing and highlighting have a positive impact on students ' scores on comprehension tests	finding	2K_dev_390
but highlighting is preferred to pausing	finding	2K_dev_390
and yields nearly twice as large of an improvement We then discuss several issues with captioning that we observed during our design process and user study	finding	2K_dev_390
	finding	2K_dev_390
We explore methods by allowing users to more easily switch their gaze between multiple visual information sources	mechanism	2K_dev_390
In this paper	mechanism	2K_dev_390
we explore pausing and highlighting as a means of helping DHH students keep up with live classroom content by helping them track their place when reading text involving visual references	mechanism	2K_dev_390
Our experiments	method	2K_dev_390
for improving the readability of real- time captions However	purpose	2K_dev_390
despite caption benefits	purpose	2K_dev_390
spoken language reading rates often result in DHH users falling behind spoken content	purpose	2K_dev_390
especially when the audio is paired with visual references	purpose	2K_dev_390
This is particularly true in classroom settings	purpose	2K_dev_390
where multi-modal content is the norm	purpose	2K_dev_390
and captions are often poorly positioned in the room	purpose	2K_dev_390
relative to speakers	purpose	2K_dev_390
Additionally	purpose	2K_dev_390
this accommodation can benefit other students who face temporary or `` situational '' disabilities such as listening to unfamiliar speech accents	purpose	2K_dev_390
or if a student is in a location with poor acoustics	purpose	2K_dev_390
	purpose	2K_dev_390
	background	2K_dev_391
demonstrates more than two orders of magnitude of performance and energy efficiency improvements compared with the traditional multithreaded software implementation on modern processors	finding	2K_dev_391
	finding	2K_dev_391
This paper introduces a 3D-stacked logic-in-memory ( LiM ) system We build a customized content addressable memory ( CAM ) hardware structure to exploit the inherent sparse data patterns and model the LiM based hardware accelerator layers that are stacked in between DRAM dies for the efficient sparse matrix operations	mechanism	2K_dev_391
Through silicon vias ( TSVs ) are used to provide the required high inter-layer bandwidth Furthermore	mechanism	2K_dev_391
we adapt the algorithm and data structure to fully leverage the underlying hardware capabilities	mechanism	2K_dev_391
and develop the necessary design framework to facilitate the design space evaluation and LiM hardware synthesis	mechanism	2K_dev_391
	mechanism	2K_dev_391
Our simulation	method	2K_dev_391
to accelerate the processing of sparse matrix data that is held in a 3D DRAM system	purpose	2K_dev_391
	purpose	2K_dev_391
	background	2K_dev_392
	finding	2K_dev_392
	mechanism	2K_dev_392
	method	2K_dev_392
	purpose	2K_dev_392
Automatic face recognition performance has been steadily improving over years of research	background	2K_dev_393
We show significant performance improvements in verification rates and also demonstrate the resilience of the proposed method with respect to degrading input quality	finding	2K_dev_393
We find that the proposed technique is able to match non-frontal images to other non-frontal images of varying angles	finding	2K_dev_393
We propose a method that relies on two fundamental components : ( a ) A 3D modeling step For this purpose	mechanism	2K_dev_393
we extend a recent technique for efficient synthesis of 3D face models called 3D Generic Elastic Model	mechanism	2K_dev_393
( b ) A sparse feature extraction step using subspace modeling and l1-minimization to induce pose-tolerance in coefficient space This in return enables the synthesis of an equivalent frontal-looking face	mechanism	2K_dev_393
which can be used towards recognition	mechanism	2K_dev_393
	mechanism	2K_dev_393
compared commercial matchers	method	2K_dev_393
however it remains significantly affected by a number of factors such as illumination	purpose	2K_dev_393
pose	purpose	2K_dev_393
expression	purpose	2K_dev_393
resolution and other factors that can impact matching scores The focus of this paper is the pose problem which remains largely overlooked in most real-world applications	purpose	2K_dev_393
Specifically	purpose	2K_dev_393
we focus on one-to-one matching scenarios where a query face image of a random pose is matched against a set of gallery images	purpose	2K_dev_393
to geometrically correct the viewpoint of the face	purpose	2K_dev_393
	purpose	2K_dev_393
Autonomous agents that operate as components of dynamic spatial systems are becoming increasingly popular and mainstream	background	2K_dev_394
Applications can be found in consumer robotics	background	2K_dev_394
in road	background	2K_dev_394
rail	background	2K_dev_394
and air transportation	background	2K_dev_394
manufacturing	background	2K_dev_394
and military operations	background	2K_dev_394
	finding	2K_dev_394
In this article	mechanism	2K_dev_394
we discuss reasoning approaches	mechanism	2K_dev_394
which requires a sufficiently detailed description of the agents behavior and environment but may still be conducted in a qualitative manner	mechanism	2K_dev_394
We introduce a conceptual reference model	mechanism	2K_dev_394
which summarizes the current understanding of the characteristics of dynamic spatial systems based on a catalog of evaluation criteria derived from the model We provide a comparative summary of the modeling features	mechanism	2K_dev_394
discuss lessons learned	mechanism	2K_dev_394
and introduce a research roadmap	mechanism	2K_dev_394
We survey logic-based qualitative and hybrid modeling and commonsense reasoning approaches with respect to their features for describing and analyzing dynamic spatial systems in general	method	2K_dev_394
and the actions of autonomous agents operating therein in particular	method	2K_dev_394
We assess the modeling features provided by logic-based qualitative commonsense and hybrid approaches for projection	method	2K_dev_394
planning	method	2K_dev_394
simulation	method	2K_dev_394
and verification of dynamic spatial systems	method	2K_dev_394
	method	2K_dev_394
Unfortunately	purpose	2K_dev_394
the approaches to modeling and analyzing the behavior of dynamic spatial systems are just as diverse as these application domains for the medium-term control of autonomous agents in dynamic spatial systems for integrating different approaches of dynamic spatial system analysis to achieve coverage of all required features	purpose	2K_dev_394
	purpose	2K_dev_394
	background	2K_dev_395
with the same asymptotic guarantees as the best sequential algorithm	finding	2K_dev_395
	finding	2K_dev_395
We show an improved parallel algorithm with a small fraction of the edges in between These decompositions form critical subroutines in a number of graph algorithms	mechanism	2K_dev_395
Our algorithm builds upon the shifted shortest path approach introduced in [ Blelloch	mechanism	2K_dev_395
Gupta	mechanism	2K_dev_395
Koutis	mechanism	2K_dev_395
Miller	mechanism	2K_dev_395
Peng	mechanism	2K_dev_395
Tangwongsan	mechanism	2K_dev_395
SPAA 2011 ]	mechanism	2K_dev_395
By combining various stages of the previous algorithm	mechanism	2K_dev_395
we obtain a significantly simpler algorithm	mechanism	2K_dev_395
	method	2K_dev_395
for decomposing an undirected unweighted graph into small diameter pieces	purpose	2K_dev_395
Human computation allows computer systems to leverage human intelligence in computational processes	background	2K_dev_396
	background	2K_dev_396
	finding	2K_dev_396
In this paper	mechanism	2K_dev_396
we present techniques	mechanism	2K_dev_396
and then discuss how and when to use them	mechanism	2K_dev_396
	mechanism	2K_dev_396
	method	2K_dev_396
While it has primarily been used for tasks that are not time-sensitive	purpose	2K_dev_396
recent systems use crowdsourcing to get on-demand	purpose	2K_dev_396
real-time	purpose	2K_dev_396
and even interactive results	purpose	2K_dev_396
for building real-time crowdsourcing systems Our goal is to provide system builders with the tools and insights they need to replicate the success of modern systems in order to further explore this new space	purpose	2K_dev_396
	purpose	2K_dev_396
Large-scale collaboration systems often separate their content from the deliberation around how that content was produced	background	2K_dev_397
	background	2K_dev_397
where we found that surfacing deliberation generally led to decreases in perceptions of quality for the article under consideration	finding	2K_dev_397
especially - but not only - if the discussion revealed conflict The effect size depends on the type of editors ' interactions Finally	finding	2K_dev_397
this decrease in actual article quality rating was accompanied by self-reported improved perceptions of the article and Wikipedia overall	finding	2K_dev_397
	finding	2K_dev_397
	mechanism	2K_dev_397
In this paper we report the results of an experiment	method	2K_dev_397
Surfacing this deliberation may engender trust in the content generation process if the deliberation process appears fair	purpose	2K_dev_397
well-reasoned	purpose	2K_dev_397
and thorough	purpose	2K_dev_397
Alternatively	purpose	2K_dev_397
it could encourage doubts about content quality	purpose	2K_dev_397
especially if the process appears messy or biased	purpose	2K_dev_397
This can potentially lead to a deeper understanding of programming	background	2K_dev_398
bringing students closer to true computational thinking	background	2K_dev_398
	background	2K_dev_398
	finding	2K_dev_398
We describe a three-stage model beginning with a simple	mechanism	2K_dev_398
highly scaffolded programming environment ( Kodu ) and progressing to more challenging frameworks ( Alice and Lego NXT-G )	mechanism	2K_dev_398
In moving between frameworks	mechanism	2K_dev_398
students explore the similarities and differences in how concepts such as variables	mechanism	2K_dev_398
conditionals	mechanism	2K_dev_398
and looping are realized Some novel strategies for teaching with Kodu are outlined	mechanism	2K_dev_398
	mechanism	2K_dev_398
Finally	method	2K_dev_398
we briefly report on our methodology and select preliminary results from a pilot study using this curriculum with students ages 10-17	method	2K_dev_398
including several with disabilities	method	2K_dev_398
	method	2K_dev_398
of computing instruction	purpose	2K_dev_398
Proceedings : AACR Annual Meeting 2014 ; April 5-9	background	2K_dev_399
2014 ; San Diego	background	2K_dev_399
CA Experimental techniques for assessing heterogeneity in tumor cell populations have undergone great advances	background	2K_dev_399
In continuing work	background	2K_dev_399
we are exploring extension of these approaches to better modeling and analysis of tumor evolution using single-cell sequencing data and to more detailed models of tumor evolution	background	2K_dev_399
	background	2K_dev_399
The evolutionary tree models reveal robust features of evolutionary processes distinguishing progression stages and predicting future progression that lead to improved classification accuracy relative to predictions from cellular heterogeneity data alone	finding	2K_dev_399
Our software is freely available at ftp : //ftp	finding	2K_dev_399
ncbi	finding	2K_dev_399
nlm	finding	2K_dev_399
nih	finding	2K_dev_399
gov/pub/FISHtrees	finding	2K_dev_399
	finding	2K_dev_399
We describe computational methods by developing computer algorithms for building phylogenetic trees describing evolution of individual tumors based on copy numbers of fluorescence in situ hybridization ( FISH ) probes from single cells in these tumors	mechanism	2K_dev_399
These algorithms reconstruct evolutionary trees for observed cell populations so as to heuristically minimize the number of mutational events needed to explain the observed combinations of probe counts by evolution from a common diploid ancestral cell We have extended this work from initial simple evolutionary models of evolution by single copy number changes to account for distinct mechanisms of evolution at the gene	mechanism	2K_dev_399
chromosome	mechanism	2K_dev_399
or whole-genome scale	mechanism	2K_dev_399
with potentially different rates of evolution by mutation type	mechanism	2K_dev_399
	mechanism	2K_dev_399
We have applied these algorithms to several FISH data sets	method	2K_dev_399
including cervical cancers probed for four genes ( LAMP3	method	2K_dev_399
PROX1	method	2K_dev_399
PRKAA1 and CCND1 ) measured for up to 250 cells of paired primary and metastatic samples from 16 patients	method	2K_dev_399
head-and-neck cancers probed for four genes ( TERC	method	2K_dev_399
CCND1	method	2K_dev_399
EGFR and TP53 ) measured on up to 250 cells per patient for 65 patients at four tumor stages	method	2K_dev_399
prostate cancers probed for six genes ( TBL1XR1	method	2K_dev_399
CTTNBP2	method	2K_dev_399
MYC	method	2K_dev_399
PTEN	method	2K_dev_399
MEN1 and PDGFB ) measured for up to 407 cells in 6 non-progressive and 7 progressive carcinomas	method	2K_dev_399
and breast cancers probed for eight genes ( COX-2	method	2K_dev_399
MYC	method	2K_dev_399
CCND1	method	2K_dev_399
HER-2	method	2K_dev_399
ZNF217	method	2K_dev_399
DBC2	method	2K_dev_399
CDH1 and TP53 ) measured on up to 220 cells of paired of ductal carcinoma in situ and invasive ductal carcinoma samples from 13 patients We have then applied statistical and machine learning analysis to examine the ability of these trees to classify tumors by stage or potential for progression	method	2K_dev_399
	method	2K_dev_399
to compute likely evolutionary histories from tumor single-cell copy number data and next generation sequencing data and apply the methods to data collected from diverse types of tumors	purpose	2K_dev_399
but these improvements have created a great need for more sophisticated computer algorithms capable of making sense of these data sources in terms of coherent models of tumor evolution We have addressed this problem	purpose	2K_dev_399
These ndings	background	2K_dev_400
coupled with recent results on naturallyrehearsing password schemes	background	2K_dev_400
suggest that 4 PAO stories couldbe used to create usable and strong passwords for 14 sensitiveaccounts following this spaced repetition schedule	background	2K_dev_400
possibly witha few extra upfront rehearsals stories	background	2K_dev_400
These ndings yield concrete advice for improving constructionsof password management schemes and future user studies	background	2K_dev_400
	background	2K_dev_400
the best results were obtained whenusers initially returned after 12 hours and then in 1:5 increasingintervals : 77 % of the participants successfully recalled all 4stories in 10 tests over a period of 158 days Much of theforgetting happened in the rst test period ( 12 hours ) : 89 % of participants who remembered their stories during the rsttest period successfully remembered them in every subsequentround In addition	finding	2K_dev_400
we nd statisticallysignicant evidence that with 8 tests over 64 days users whowere asked to memorize 4 PAO stories outperform users whoare given 4 random action-object pairs	finding	2K_dev_400
but with 9 tests over 128days the advantage is not signicant Furthermore	finding	2K_dev_400
there is aninterference effect across multiple PAO stories : the recall rate of100 % ( resp	finding	2K_dev_400
90 % ) for participants who were asked to memorize1 PAO story ( resp	finding	2K_dev_400
2 PAO stories ) is signicantly better than therate for participants who were asked to memorize 4 PAO	finding	2K_dev_400
	mechanism	2K_dev_400
time	method	2K_dev_400
Remote research participants were asked to memorize 4 Person-Action-Object ( PAO ) stories where they chose a famous personfrom a drop-down list and were given machine-generated randomaction-object pairs Users were also shown a photo of a scene andasked to imagine the PAO story taking place in the scene ( e	method	2K_dev_400
g	method	2K_dev_400
	method	2K_dev_400
Bill Gatesswallowingbike on a beach )	method	2K_dev_400
Subsequently	method	2K_dev_400
theywere asked to recall the action-object pairs when prompted withthe associated scene-person pairs following a spaced repetitionschedule over a period of 127+ days	method	2K_dev_400
While we evaluated severalspaced repetition schedules	method	2K_dev_400
	method	2K_dev_400
AbstractWe report on a user study that provides evidencethat spaced repetition and a specic mnemonic technique enableusers to successfully recall multiple strong passwords over	purpose	2K_dev_400
Non-Intrusive Load Monitoring ( NILM ) is a set of techniques used to estimate the electricity consumed by individual appliances in a building from measurements of the total electrical consumption	background	2K_dev_401
Most commonly	background	2K_dev_401
NILM works by first attributing any significant change in the total power consumption ( also known as an event ) to a specific load and subsequently using these attributions ( i	background	2K_dev_401
e	background	2K_dev_401
the labels for the events ) to estimate energy for each load	background	2K_dev_401
	background	2K_dev_401
show that the framework can learn data-driven models based on event labels and use that to estimate energy with lower error margins ( e	finding	2K_dev_401
g	finding	2K_dev_401
	finding	2K_dev_401
1	finding	2K_dev_401
142	finding	2K_dev_401
3 % ) than when using the heuristic models used by others	finding	2K_dev_401
In this paper	mechanism	2K_dev_401
we present a framework based on classification labels and aggregate power measurements that can help Our framework automatically builds models for appliances to perform energy estimation The model relies on feature extraction	mechanism	2K_dev_401
clustering via affinity propagation	mechanism	2K_dev_401
perturbation of extracted states to ensure that they mimic appliance behavior	mechanism	2K_dev_401
creation of finite state models	mechanism	2K_dev_401
correction of any errors in classification that might violate the model	mechanism	2K_dev_401
and estimation of energy based on corrected labels	mechanism	2K_dev_401
	mechanism	2K_dev_401
We evaluate our framework on 3 houses from standard datasets in the field and	method	2K_dev_401
For this last step	purpose	2K_dev_401
most published work in the field makes simplifying assumptions to make the problem more tractable for creating appliance models to relax many of these assumptions	purpose	2K_dev_401
	purpose	2K_dev_401
It is becoming more and more evident that the mechanical forces previously taken for granted actually play a pivotal role in influencing biological phenomenon from cancer metastases to vasculogenesis	background	2K_dev_402
Recent literature provides strong evidence for a causative link between the mechanical stretching of the cytoskeleton and the release of mechanotransductive signaling molecules	background	2K_dev_402
Our model for the mechanotransductive release of signaling factors represents a potentially versatile mechanistic platform for examining biophysical interactions that link mechanical stimulus at the cellular level to response at the protein level	background	2K_dev_402
	background	2K_dev_402
	finding	2K_dev_402
Here	mechanism	2K_dev_402
we present a model that integrates actin filament network remodeling under stretch with a novel biophysical model of molecular release stretch is applied to a model of the actin filament network	mechanism	2K_dev_402
the distribution of bond angles in the network transitions from a more peaked to a flatter distribution	mechanism	2K_dev_402
High variability is observed from site-to-site within the network upon an applied stretch	mechanism	2K_dev_402
with a nearly uniform distribution of difference between stretched and unstretched angles ( delta angles ) at high levels of stretching	mechanism	2K_dev_402
We used our approach to explore various thresholding models of how actin filament network deformations might influence rates of release of bound signaling molecules These models allow us to project how a biochemical response might appear from a given applied mechanical stimulus	mechanism	2K_dev_402
	mechanism	2K_dev_402
We validate these simulations using experimental data and use our model to then test different predictive capabilities of how mechanotransduction may function	method	2K_dev_402
Understanding the links between mechanical input	purpose	2K_dev_402
the corresponding morphological changes in the actin cytoskeleton	purpose	2K_dev_402
and the resulting biochemical response is not well understood yet is a significant challenge in the field of mechanotransduction	purpose	2K_dev_402
to further elucidate the interplay between actin network morphology and resultant biochemical signaling	purpose	2K_dev_402
As	purpose	2K_dev_402
Large-scale content-based semantic search in video is an interesting and fundamental problem in multimedia analysis and retrieval	background	2K_dev_403
	background	2K_dev_403
results validate the efficacy and the efficiency of the proposed method	finding	2K_dev_403
The results show that our method can scale up the semantic search while maintaining state-of-the-art search performance Specifically	finding	2K_dev_403
the proposed method ( with reranking ) achieves the best result on the challenging TRECVID Multimedia Event Detection ( MED ) zero-example task	finding	2K_dev_403
It only takes 0	finding	2K_dev_403
2 second on a single CPU core to search a collection of 100 million Internet videos	finding	2K_dev_403
This paper proposes a scalable solution	mechanism	2K_dev_403
The key is a novel step called concept adjustment that represents a video by a few salient and consistent concepts that can be efficiently indexed by the modified inverted index	mechanism	2K_dev_403
The proposed adjustment model relies on a concise optimization framework with interpretations	mechanism	2K_dev_403
The proposed index leverages the text-based inverted index for video retrieval	mechanism	2K_dev_403
	mechanism	2K_dev_403
Experimental	method	2K_dev_403
Existing methods index a video by the raw concept detection score that is dense and inconsistent	purpose	2K_dev_403
and thus can not scale to `` big data '' that are readily available on the Internet	purpose	2K_dev_403
	background	2K_dev_404
	finding	2K_dev_404
	mechanism	2K_dev_404
	method	2K_dev_404
	purpose	2K_dev_404
	background	2K_dev_405
we prove that $ { { \cal Q } { \cal D } } $ -learning	finding	2K_dev_405
a $ \rm consensus + innovations $ algorithm with mixed time-scale stochastic dynamics	finding	2K_dev_405
converges asymptotically almost surely to the desired value function and to the optimal stationary control policy at each network agent	finding	2K_dev_405
	finding	2K_dev_405
The paper develops $ { { \cal Q } { \cal D } } $ -learning	mechanism	2K_dev_405
a distributed version of reinforcement $ Q $ -learning	mechanism	2K_dev_405
The network agents minimize a network-averaged infinite horizon discounted cost	mechanism	2K_dev_405
by local processing and by collaborating through mutual information exchange over a sparse ( possibly stochastic ) communication network The agents respond differently ( depending on their instantaneous one-stage random costs ) to a global controlled state and the control actions of a remote controller	mechanism	2K_dev_405
	mechanism	2K_dev_405
When each agent is aware only of its local online cost data and the inter-agent communication network is weakly connected	method	2K_dev_405
	method	2K_dev_405
for multi-agent Markov decision processes ( MDPs ) ; the agents have no prior information on the global state transition and on the local agent cost statistics	purpose	2K_dev_405
	purpose	2K_dev_405
In a Stackelberg Security Game	background	2K_dev_406
a defender commits to a randomized deployment of security resources	background	2K_dev_406
and an attacker best-responds by attacking a target that maximizes his utility	background	2K_dev_406
	background	2K_dev_406
	finding	2K_dev_406
via an online learning approach	mechanism	2K_dev_406
We are interested in algorithms that prescribe a randomized strategy for the defender at each step against an adversarially chosen sequence of attackers	mechanism	2K_dev_406
and obtain feedback on their choices ( observing either the current attacker type or merely which target was attacked We design no-regret algorithms whose regret ( when compared to the best fixed strategy in hindsight ) is polynomial in the parameters of the game	mechanism	2K_dev_406
and sublinear in the number of times steps	mechanism	2K_dev_406
	method	2K_dev_406
While algorithms for computing an optimal strategy for the defender to commit to have had a striking real-world impact	purpose	2K_dev_406
deployed applications require significant information about potential attackers	purpose	2K_dev_406
leading to inefficiencies	purpose	2K_dev_406
We address this problem	purpose	2K_dev_406
Detection of neuronal cell differentiation is essential to study cell fate decisions under various stimuli and/or environmental conditions	background	2K_dev_407
Many tools exist that quantify differentiation by neurite length measurements of single cells	background	2K_dev_407
However	background	2K_dev_407
quantification of differentiation in whole cell populations remains elusive so far	background	2K_dev_407
In conclusion	background	2K_dev_407
this enables long-term	background	2K_dev_407
large-scale studies of cell populations with minimized costs and efforts for detecting effects of external manipulation of neuronal cell differentiation	background	2K_dev_407
which we confirmed	finding	2K_dev_407
by supervised classification	mechanism	2K_dev_407
Using nerve growth factor induced differentiation of PC12 cells	mechanism	2K_dev_407
we monitor the changes in cell morphology over days by phase-contrast live-cell imaging	mechanism	2K_dev_407
For general applicability	mechanism	2K_dev_407
the classification procedure starts out with many features to identify those that maximize discrimination of differentiated and undifferentiated cells and to eliminate features sensitive to systematic measurement artifacts	mechanism	2K_dev_407
The resulting image analysis determines the optimal post treatment day for training and achieves a near perfect classification of differentiation	mechanism	2K_dev_407
Our approach allows to monitor neuronal cell populations repeatedly over days without any interference	mechanism	2K_dev_407
It requires only an initial calibration and training step and is thereafter capable to discriminate further experiments	mechanism	2K_dev_407
in technically and biologically independent as well as differently designed experiments	method	2K_dev_407
Because such populations can consist of both proliferating and differentiating cells	purpose	2K_dev_407
the task to assess the overall differentiation status is not trivial and requires a high-throughput	purpose	2K_dev_407
fully automated approach to analyze sufficient data for a statistically significant discrimination to determine cell differentiation We address the problem of detecting differentiation in a mixed population of proliferating and differentiating cells over time	purpose	2K_dev_407
Mechanotransduction has been divided into mechanotransmission	background	2K_dev_408
mechanosensing	background	2K_dev_408
and mechanoresponse	background	2K_dev_408
Our results suggest that filamin-FilGAP mechanotransduction response is best explained by a bandpass mechanism favoring release when crosslinking angles fall outside of a specific range and finds that a more disordered actin network may allow a cell to more finely tune control of molecular release enabling a more robust response	finding	2K_dev_408
through a multiscale model linking these three phases Our model incorporates a discrete network of actin filaments and associated proteins that responds to stretching through geometric relaxation Our model further investigates the difference between ordered versus disordered networks	mechanism	2K_dev_408
We assess three potential activating mechanisms at mechanosensitive crosslinks as inputs to a mixture model of molecular release and benchmark each using experimental data of mechanically-induced Rho GTPase FilGAP release from actin-filamin crosslinks	method	2K_dev_408
although how a cell performs all three functions using the same set of structural components is still highly debated	purpose	2K_dev_408
Here	purpose	2K_dev_408
we bridge the gap between emerging molecular and systems-level understandings of mechanotransduction	purpose	2K_dev_408
Understanding the unique biochemical and physical differences between typical in vitro experimental systems and the in vivo environment of a living cell is a question of great importance in building and interpreting reliable models of complex reaction systems	background	2K_dev_409
Virus capsids make an excellent model system for such questions because they tend to have few components	background	2K_dev_409
making them amenable to in vitro and modeling studies	background	2K_dev_409
yet their assembly can be described by enormously complex networks of possible reactions that can not be resolved by any current experimental technology We have previously attempted to bridge the gap between the complexity of the system and the limitations of data for tracking detailed assembly pathways using simulation-based model inference	background	2K_dev_409
learning kinetic parameters of coarse-grained rule models by fitting simulations to light scattering data from in vitro capsid assembly systems	background	2K_dev_409
Results suggest surprisingly complex and often counterintuitive mechanisms by which crowding or nucleic acids can alternately promote or inhibit assembly for different virus and assembly conditions	finding	2K_dev_409
using coarse-grained biophysical models and suggest how these adjustments to fine-scale interactions may alter high-level pathway selection	mechanism	2K_dev_409
from a series of virus capsid models	method	2K_dev_409
Here	purpose	2K_dev_409
we describe extensions of that work to attempt to understand the influence of specific features of the cellular environment	purpose	2K_dev_409
individually or in concert	purpose	2K_dev_409
on assembly pathway selection We specifically focus on the effects of macromolecular crowding and nucleic acid on capsid assembly to adjust rate parameters learned from the in vitro system	purpose	2K_dev_409
	background	2K_dev_410
	finding	2K_dev_410
	mechanism	2K_dev_410
	method	2K_dev_410
	purpose	2K_dev_410
Abstract Residential electricity users need more detail than monthly bills to reduce consumption	background	2K_dev_411
Using national average penetration rates	background	2K_dev_411
the Residential Energy Consumption Survey ( RECS )	background	2K_dev_411
estimates that 42 unique appliances account for 93 % of electricity consumption	background	2K_dev_411
while 12 appliances account for 80 % of average household electric load These results can be used to design and maximize the value of residential energy information and management systems	background	2K_dev_411
	background	2K_dev_411
find that eight appliances are responsible for 80 % of a household 's electric load in the United States	finding	2K_dev_411
It is concluded that RECS can not be used as a representative household as it overestimates the number of appliances that contribute to a household electric load	finding	2K_dev_411
The number of significant appliances is affected by appliance ownership and use	finding	2K_dev_411
which is more variable between homes than between census divisions	finding	2K_dev_411
	mechanism	2K_dev_411
A typical scenario is developed from national and regional penetration rates and Four household scenarios are developed : a house that uses electric appliances	method	2K_dev_411
gas appliances	method	2K_dev_411
the average household	method	2K_dev_411
and typical household	method	2K_dev_411
With the emergence of technologies that provide detailed usage estimates for energy consumption	purpose	2K_dev_411
two questions arise	purpose	2K_dev_411
First	purpose	2K_dev_411
how many different energy-consuming appliances contribute to household electricity load	purpose	2K_dev_411
and secondly which appliances ?	purpose	2K_dev_411
A genome-wide association study involves examining a large number of single-nucleotide polymorphisms ( SNPs ) to identify SNPs that are significantly associated with the given phenotype	background	2K_dev_412
while trying to reduce the false positive rate	background	2K_dev_412
show that there is a significant advantage in incorporating the prior knowledge on linkage disequilibrium structure for marker identification under whole-genome association	finding	2K_dev_412
	finding	2K_dev_412
In this paper	mechanism	2K_dev_412
we propose a new approach called stochastic block lasso that exploits prior knowledge on linkage disequilibrium structure in the genome such as recombination rates and distances between adjacent SNPs in order to increase the power of detecting true associations while reducing false positives Following a typical linear regression framework with the genotypes as inputs and the phenotype as output	mechanism	2K_dev_412
our proposed method employs a sparsity-enforcing Laplacian prior for the regression coefficients	mechanism	2K_dev_412
augmented by a first-order Markov process along the sequence of SNPs that incorporates the prior information on the linkage disequilibrium structure	mechanism	2K_dev_412
The Markov-chain prior models the structural dependencies between a pair of adjacent SNPs	mechanism	2K_dev_412
and allows us to look for association SNPs in a coupled manner	mechanism	2K_dev_412
combining strength from multiple nearby SNPs	mechanism	2K_dev_412
Our results on HapMap-simulated datasets and mouse datasets	method	2K_dev_412
Although haplotype-based association methods have been proposed to accommodate correlation information across nearby SNPs that are in linkage disequilibrium	purpose	2K_dev_412
none of these methods directly incorporated the structural information such as recombination events along chromosome	purpose	2K_dev_412
for association mapping	purpose	2K_dev_412
	background	2K_dev_413
	finding	2K_dev_413
The agents are sparsely connected and each of them observes a strict subset of the state vector	mechanism	2K_dev_413
The distributed algorithm that we propose enables each agent with bounded mean-squared error	mechanism	2K_dev_413
To achieve this	mechanism	2K_dev_413
the ratio of the algebraic connectivity and the largest eigenvalue of the graph Laplacian has to be larger than a lower bound determined by the spectral radius of the system 's dynamics matrix This extends the notion of Network Tracking Capacity introduced by other authors in prior work We accomplish this by introducing a new class of estimation algorithm of dynamical systems that	mechanism	2K_dev_413
besides a ( consensus + innovations ) term	mechanism	2K_dev_413
also includes consensus on the innovations	mechanism	2K_dev_413
	mechanism	2K_dev_413
	method	2K_dev_413
In this paper	purpose	2K_dev_413
we consider the problem of state estimation of a dynamical system in a multi-agent network to estimate any arbitrary linear dynamical system	purpose	2K_dev_413
	background	2K_dev_414
	finding	2K_dev_414
	mechanism	2K_dev_414
	method	2K_dev_414
	purpose	2K_dev_414
	background	2K_dev_415
	finding	2K_dev_415
	mechanism	2K_dev_415
	method	2K_dev_415
	method	2K_dev_415
	purpose	2K_dev_415
Acoustruments adds a new method to the toolbox HCI practitioners and researchers can draw upon	background	2K_dev_416
while introducing a cheap and passive method for adding interactive controls to consumer products	background	2K_dev_416
	background	2K_dev_416
show that Acoustruments can achieve 99 % accuracy with minimal training	finding	2K_dev_416
is robust to noise	finding	2K_dev_416
and can be rapidly prototyped	finding	2K_dev_416
	finding	2K_dev_416
We introduce Acoustruments : low-cost	mechanism	2K_dev_416
passive	mechanism	2K_dev_416
and power-less mechanisms	mechanism	2K_dev_416
made from plastic	mechanism	2K_dev_416
Through a structured exploration	mechanism	2K_dev_416
we identified an expansive vocabulary of design primitives	mechanism	2K_dev_416
providing building blocks for the construction of tangible interfaces utilizing smartphones ' existing audio functionality By combining design primitives	mechanism	2K_dev_416
familiar physical mechanisms can all be constructed from passive elements	mechanism	2K_dev_416
On top of these	mechanism	2K_dev_416
we can create end-user applications with rich	mechanism	2K_dev_416
tangible interactive functionalities	mechanism	2K_dev_416
Our experiments	method	2K_dev_416
that can bring rich	purpose	2K_dev_416
tangible functionality to handheld devices	purpose	2K_dev_416
With the widespread availability of video cameras	background	2K_dev_417
we are facing an ever-growing enormous collection of unedited and unstructured video data	background	2K_dev_417
	background	2K_dev_417
demonstrating the effectiveness of online video highlighting	finding	2K_dev_417
In this work	mechanism	2K_dev_417
we propose online video highlighting	mechanism	2K_dev_417
a principled way of generating short video summarizing the most important and interesting contents of an unedited and unstructured video	mechanism	2K_dev_417
costly both time-wise and financially for manual processing	mechanism	2K_dev_417
Specifically	mechanism	2K_dev_417
our method learns a dictionary from given video using group sparse coding	mechanism	2K_dev_417
and updates atoms in the dictionary on-the-fly	mechanism	2K_dev_417
A summary video is then generated by combining segments that can not be sparsely reconstructed using the learned dictionary	mechanism	2K_dev_417
The online fashion of our proposed method enables it to process arbitrarily long videos and start generating summaries before seeing the end of the video	mechanism	2K_dev_417
Moreover	mechanism	2K_dev_417
the processing time required by our proposed method is close to the original video length	mechanism	2K_dev_417
achieving quasi real-time summarization speed	mechanism	2K_dev_417
Theoretical analysis	method	2K_dev_417
together with experimental results on more than 12 hours of surveillance and YouTube videos are provided	method	2K_dev_417
	method	2K_dev_417
Due to lack of an automatic way to generate summaries from this large collection of consumer videos	purpose	2K_dev_417
they can be tedious and time consuming to index or search	purpose	2K_dev_417
	purpose	2K_dev_417
Finally	background	2K_dev_418
we discuss some ramifications of this work for understanding Twitter usage and management of one 's privacy	background	2K_dev_418
Some significant differences were discovered between the two collections	finding	2K_dev_418
namely in the clients used to post them	finding	2K_dev_418
their conversational aspects	finding	2K_dev_418
the sentiment vocabulary present in them	finding	2K_dev_418
and the days of the week they were posted	finding	2K_dev_418
However	finding	2K_dev_418
in other dimensions for which analysis was possible	finding	2K_dev_418
no substantial differences were found	finding	2K_dev_418
	mechanism	2K_dev_418
This paper describes collected over a continuous one-week period from a set of 292K Twitter users We examine several aggregate properties of deleted tweets	method	2K_dev_418
including their connections to other tweets ( e	method	2K_dev_418
g	method	2K_dev_418
	method	2K_dev_418
whether they are replies or retweets )	method	2K_dev_418
the clients used to produce them	method	2K_dev_418
temporal aspects of deletion	method	2K_dev_418
and the presence of geotagging information	method	2K_dev_418
an empirical study of 1	purpose	2K_dev_418
6M deleted tweets	purpose	2K_dev_418
	background	2K_dev_419
	finding	2K_dev_419
	mechanism	2K_dev_419
	method	2K_dev_419
	purpose	2K_dev_419
Background Disease progression in the absence of therapy varies significantly in HIV-1 infected individuals	background	2K_dev_420
	background	2K_dev_420
	finding	2K_dev_420
	mechanism	2K_dev_420
we performed a comparative miRNA and mRNA microarray analysis using PBMCs obtained from infected individuals with distinct viral load and CD4 counts	method	2K_dev_420
	method	2K_dev_420
Both viral and host cellular molecules are implicated ; however	purpose	2K_dev_420
the exact role of these factors and/or the mechanism involved remains elusive	purpose	2K_dev_420
To understand how microRNAs ( miRNAs )	purpose	2K_dev_420
which are regulators of transcription and translation	purpose	2K_dev_420
influence host cellular gene expression ( mRNA ) during HIV-1 infection	purpose	2K_dev_420
In the Architecture	background	2K_dev_421
Engineering	background	2K_dev_421
and Construction ( AEC ) domain	background	2K_dev_421
semantically rich 3D information models are increasingly used throughout a facility 's life cycle for diverse applications	background	2K_dev_421
such as planning renovations	background	2K_dev_421
space usage planning	background	2K_dev_421
and managing building maintenance	background	2K_dev_421
These models	background	2K_dev_421
which are known as building information models ( BIMs )	background	2K_dev_421
are often constructed using dense	background	2K_dev_421
three dimensional ( 3D ) point measurements obtained from laser scanners	background	2K_dev_421
Laser scanners can rapidly capture the as-is conditions of a facility	background	2K_dev_421
which may differ significantly from the design drawings	background	2K_dev_421
	finding	2K_dev_421
This paper presents a method Our algorithm is capable of identifying and modeling the main visible structural components of an indoor environment ( walls	mechanism	2K_dev_421
floors	mechanism	2K_dev_421
ceilings	mechanism	2K_dev_421
windows	mechanism	2K_dev_421
and doorways ) despite the presence of significant clutter and occlusion	mechanism	2K_dev_421
which occur frequently in natural indoor environments	mechanism	2K_dev_421
Our method begins by extracting planar patches from a voxelized version of the input point cloud	mechanism	2K_dev_421
The algorithm learns the unique features of different types of surfaces and the contextual relationships between them and uses this knowledge to automatically label patches as walls	mechanism	2K_dev_421
ceilings	mechanism	2K_dev_421
or floors Then	mechanism	2K_dev_421
we perform a detailed analysis of the recognized surfaces to locate openings	mechanism	2K_dev_421
such as windows and doorways	mechanism	2K_dev_421
This process uses visibility reasoning to fuse measurements from different scan locations and to identify occluded regions and holes in the surface	mechanism	2K_dev_421
Next	mechanism	2K_dev_421
we use a learning algorithm to intelligently estimate the shape of window and doorway openings even when partially occluded Finally	mechanism	2K_dev_421
occluded surface regions are filled in using a 3D inpainting algorithm	mechanism	2K_dev_421
	mechanism	2K_dev_421
We evaluated the method on a large	method	2K_dev_421
highly cluttered data set of a building with forty separate rooms	method	2K_dev_421
Currently	purpose	2K_dev_421
the conversion from laser scan data to BIM is primarily a manual operation	purpose	2K_dev_421
and it is labor-intensive and can be error-prone to automatically convert the raw 3D point data from a laser scanner positioned at multiple locations throughout a facility into a compact	purpose	2K_dev_421
semantically rich information model	purpose	2K_dev_421
	background	2K_dev_422
results confirm that TransPart offers low overhead and startup cost	finding	2K_dev_422
while improving user experience	finding	2K_dev_422
This article investigates the transient use of free local storage We use the term TransientPC systems to refer to these types of systems	mechanism	2K_dev_422
The solution we propose	mechanism	2K_dev_422
called TransPart	mechanism	2K_dev_422
uses the higher-performing local storage of host hardware Our solution constructs a virtual storage device on demand ( which we call transient storage ) by borrowing free disk blocks from the hosts storage	mechanism	2K_dev_422
In this article	mechanism	2K_dev_422
we present the design	mechanism	2K_dev_422
implementation	mechanism	2K_dev_422
and evaluation of a TransPart prototype	method	2K_dev_422
which requires no modifications to the software or hardware of a host computer Experimental	method	2K_dev_422
for improving performance in VM-based mobile computing systems implemented as thick clients on host PCs	purpose	2K_dev_422
to speed up performance-critical operations	purpose	2K_dev_422
	purpose	2K_dev_422
Real-time system level implementations of complex Synthetic Aperture Radar ( SAR ) image reconstruction algorithms have always been challenging due to their data intensive characteristics	background	2K_dev_423
results indicate that this proposed algorithm/hardware co-optimized system can achieve an accuracy of 91 dB PSNR compared to a reference algorithm implemented in Matlab and energy efficiency of 72 GFLOPS/W for a 8k8k SAR image reconstruction	finding	2K_dev_423
In this paper	mechanism	2K_dev_423
we propose a basis vector transform based novel algorithm and a 3D-stacked logic in memory based hardware accelerator as the implementation platform	mechanism	2K_dev_423
Experimental	method	2K_dev_423
to alleviate the data intensity	purpose	2K_dev_423
The findings of this paper provide strategies for harnessing the crowd to perform complex tasks	background	2K_dev_424
as well as insight into crowd workers ' motivation	background	2K_dev_424
	background	2K_dev_424
we show that 1 ) using these strategies together increased workers ' engagement and the quality of their work ; 2 ) a social strategy was most effective for increasing engagement ; 3 ) a learning strategy was most effective in improving quality	finding	2K_dev_424
	finding	2K_dev_424
	mechanism	2K_dev_424
We explore the effects of social	method	2K_dev_424
learning	method	2K_dev_424
and financial strategies	method	2K_dev_424
and their combinations	method	2K_dev_424
on increasing worker retention across tasks and change in the quality of worker output	method	2K_dev_424
Through three experiments	method	2K_dev_424
	method	2K_dev_424
A significant challenge for crowdsourcing has been increasing worker engagement and output quality	purpose	2K_dev_424
	purpose	2K_dev_424
due to the recent penetration of distributed green energy	background	2K_dev_425
distributed intelligence	background	2K_dev_425
and plug-in electric vehicles Finally	background	2K_dev_425
the proposed method can be implemented given recent advances in machine learning	background	2K_dev_425
which are becoming drivers and sources of data previously unavailable in the electric power industry	background	2K_dev_425
	background	2K_dev_425
results of the proposed method show that the new method produces a topology estimate excelling the current industrial approach	finding	2K_dev_425
Instead of taking the traditional complex physical model based approach	mechanism	2K_dev_425
this paper proposes a data-driven method	mechanism	2K_dev_425
leading to an effective Specifically	mechanism	2K_dev_425
we first introduce the data-driven topology estimation problem	mechanism	2K_dev_425
Then	mechanism	2K_dev_425
a novel Logistic Kernel Regression is proposed in a Bayesian framework based on Nearest Neighbors search	mechanism	2K_dev_425
Notably	mechanism	2K_dev_425
unlike many machine learning approaches that do not account for physical constraints	mechanism	2K_dev_425
and distinctive from deterministic engineering modeling defined solely by physical laws	mechanism	2K_dev_425
this paper for the first time combines the two into one single regression modeling for topology estimation	mechanism	2K_dev_425
	mechanism	2K_dev_425
Simulation	method	2K_dev_425
This paper is motivated by major needs for fast and accurate on-line data analysis tools in the emerging electric energy systems topology estimation approach for the smart grid	purpose	2K_dev_425
	purpose	2K_dev_425
We close by identifying several ways in which crowd labor platform operators and/or individual task requestors could improve the accessibility of this increasingly important form of employment	background	2K_dev_426
	background	2K_dev_426
Our findings establish that people with a variety of disabilities currently participate in the crowd labor marketplace	finding	2K_dev_426
despite challenges such as crowdsourcing workflow designs that inadvertently prohibit participation by	finding	2K_dev_426
and may negatively affect the worker reputations of	finding	2K_dev_426
people with disabilities Despite such challenges	finding	2K_dev_426
we find that crowdwork potentially offers different opportunities for people with disabilities relative to the normative office environment	finding	2K_dev_426
such as job flexibility and lack of a need to rely on public transit	finding	2K_dev_426
	finding	2K_dev_426
	mechanism	2K_dev_426
via in-depth open-ended interviews of 17 people ( disabled crowdworkers and job coaches for people with disabilities ) and a survey of 631 adults with disabilities	method	2K_dev_426
	method	2K_dev_426
We present the first formal study of crowdworkers who have disabilities	purpose	2K_dev_426
Effortless one-touch capture of video is a unique capability of wearable devices such as Google Glass	background	2K_dev_427
	background	2K_dev_427
	finding	2K_dev_427
We use this capability in which users receive queries relevant to their current location and opt-in preferences	mechanism	2K_dev_427
In response	mechanism	2K_dev_427
they can send back live video snippets of their surroundings	mechanism	2K_dev_427
A system of result caching	mechanism	2K_dev_427
geolocation and query similarity detection shields users from being overwhelmed by a flood of queries	mechanism	2K_dev_427
	mechanism	2K_dev_427
	method	2K_dev_427
to create a new type of crowd-sourced system	purpose	2K_dev_427
	background	2K_dev_428
	finding	2K_dev_428
In this paper we propose a common file format and API for public Non-Intrusive Load Monitoring ( NILM ) datasets such that The proposed file format enables storing the power demand of the whole house along with individual appliance consumption	mechanism	2K_dev_428
and other relevant metadata in a single compact file	mechanism	2K_dev_428
whereas the API supports the creation and manipulation of individual files and datasets in the proposed format	mechanism	2K_dev_428
	method	2K_dev_428
researchers can easily evaluate their approaches across the different datasets and benchmark their results against prior work	purpose	2K_dev_428
It is known that in this setting both revenue and social welfare can be maximized by a threshold policy	background	2K_dev_429
whereby customers are barred from entry once the queue length reaches a certain threshold	background	2K_dev_429
	background	2K_dev_429
allowing for settings with multiple servers	background	2K_dev_429
	background	2K_dev_429
Finally	finding	2K_dev_429
we present a generalization of our results	finding	2K_dev_429
This paper presents the first derivation of the optimal threshold in closed form	mechanism	2K_dev_429
and a surprisingly simple formula Utilizing properties of the Lambert W function	mechanism	2K_dev_429
we also provide explicit scaling results of the optimal threshold as the customer valuation grows	mechanism	2K_dev_429
	mechanism	2K_dev_429
	method	2K_dev_429
We consider the social welfare model of Naor [ 20 ] and revenue-maximization model of Chen and Frank [ 7 ]	purpose	2K_dev_429
where a single class of delay-sensitive customers seek service from a server with an observable queue	purpose	2K_dev_429
under state dependent pricing	purpose	2K_dev_429
However	purpose	2K_dev_429
no explicit expression for this threshold has been found	purpose	2K_dev_429
for the ( maximum ) revenue under this optimal threshold	purpose	2K_dev_429
	purpose	2K_dev_429
The virtualization of real-time systems has received much attention for its many benefits	background	2K_dev_430
such as the consolidation of individually developed real-time applications while maintaining their implementations	background	2K_dev_430
results indicate that	finding	2K_dev_430
under vMPCP	finding	2K_dev_430
deferrable server outperforms periodic server when overrun is used	finding	2K_dev_430
with as much as 80 % more task sets being schedulable	finding	2K_dev_430
shows that vMPCP yields significant benefits compared to a virtualization-unaware multi-core synchronization protocol	finding	2K_dev_430
with 29 % shorter response time on average	finding	2K_dev_430
	finding	2K_dev_430
In this paper	mechanism	2K_dev_430
we propose vMPCP	mechanism	2K_dev_430
a synchronization framework Vmpcp exposes the executions of critical sections of tasks in a guest virtual machine to the hyper visor	mechanism	2K_dev_430
Using this approach	mechanism	2K_dev_430
vMPCP reduces and bounds blocking time on accessing resources shared within and across virtual CPUs ( VCPUs ) assigned on different physical CPU cores Vmpcp supports periodic server and deferrable server policies for the VCPU budget replenish policy	mechanism	2K_dev_430
with an optional budget overrun to reduce blocking times	mechanism	2K_dev_430
We provide the VCPU and task schedulability analyses under vMPCP	mechanism	2K_dev_430
with different VCPU budget supply policies	mechanism	2K_dev_430
with and without overrun	mechanism	2K_dev_430
	mechanism	2K_dev_430
Experimental The case study using our hyper visor implementation	method	2K_dev_430
However	purpose	2K_dev_430
the current state of the art still lacks properties required for resource sharing among real-time application tasks in a multi-core virtualization environment	purpose	2K_dev_430
for the virtualization of multi-core real-time systems	purpose	2K_dev_430
	background	2K_dev_431
	finding	2K_dev_431
	mechanism	2K_dev_431
	method	2K_dev_431
	purpose	2K_dev_431
Real-time captioning enables deaf and hard of hearing ( DHH ) people to follow classroom lectures and other aural speech by converting it into visual text with less than a five second delay	background	2K_dev_432
These results show the potential to reliably capture speech even during sudden bursts of speed	background	2K_dev_432
as well as for generating enhanced captions	background	2K_dev_432
unlike other human-powered captioning approaches	background	2K_dev_432
	background	2K_dev_432
We show that both hearing and DHH participants preferred and followed collaborative captions better than those generated by automatic speech recognition ( ASR ) or professionals due to the more consistent flow of the resulting captions	finding	2K_dev_432
	finding	2K_dev_432
	mechanism	2K_dev_432
We first surveyed the audio characteristics of 240 one-hour-long captioned lectures on YouTube	method	2K_dev_432
such as speed and duration of speaking bursts We then analyzed how these characteristics impact caption generation and readability	method	2K_dev_432
considering specifically our human-powered collaborative captioning approach	method	2K_dev_432
We note that most of these characteristics are also present in more general domains	method	2K_dev_432
For our caption comparison evaluation	method	2K_dev_432
we transcribed a classroom lecture in real-time using all three captioning approaches	method	2K_dev_432
We recruited 48 participants ( 24 DHH ) to watch these classroom transcripts in an eye-tracking laboratory	method	2K_dev_432
We presented these captions in a randomized	method	2K_dev_432
balanced	method	2K_dev_432
Keeping the delay short allows end-users to follow and participate in conversations	purpose	2K_dev_432
This article focuses on the fundamental problem that makes real-time captioning difficult : sequential keyboard typing is much slower than speaking	purpose	2K_dev_432
	purpose	2K_dev_432
Event detection in social media is an important but challenging problem	background	2K_dev_433
	background	2K_dev_433
and present empirical evaluations illustrating the effectiveness and efficiency of our proposed approach	finding	2K_dev_433
	finding	2K_dev_433
This paper presents Non-Parametric Heterogeneous Graph Scan ( NPHGS )	mechanism	2K_dev_433
a new approach that considers the entire heterogeneous network : we first model the network as a `` sensor '' network	mechanism	2K_dev_433
in which each node senses its `` neighborhood environment '' and reports an empirical p-value measuring its current level of anomalousness for each time interval ( e	mechanism	2K_dev_433
g	mechanism	2K_dev_433
	mechanism	2K_dev_433
hour or day ) Then	mechanism	2K_dev_433
we efficiently maximize a nonparametric scan statistic over connected subgraphs to identify the most anomalous network clusters	mechanism	2K_dev_433
Finally	mechanism	2K_dev_433
the event represented by each cluster is summarized with information such as type of event	mechanism	2K_dev_433
geographical locations	mechanism	2K_dev_433
time	mechanism	2K_dev_433
and participants	mechanism	2K_dev_433
	mechanism	2K_dev_433
As a case study	method	2K_dev_433
we consider two applications using Twitter data	method	2K_dev_433
civil unrest event detection and rare disease outbreak detection	method	2K_dev_433
	method	2K_dev_433
Most existing approaches are based on burst detection	purpose	2K_dev_433
topic modeling	purpose	2K_dev_433
or clustering techniques	purpose	2K_dev_433
which can not naturally model the implicit heterogeneous network structure in social media	purpose	2K_dev_433
As a result	purpose	2K_dev_433
only limited information	purpose	2K_dev_433
such as terms and geographic locations	purpose	2K_dev_433
can be used	purpose	2K_dev_433
for event detection	purpose	2K_dev_433
Clustering is one of the fundamental data mining tasks	background	2K_dev_434
	background	2K_dev_434
we show the strengths of our novel clustering technique	finding	2K_dev_434
In this work	mechanism	2K_dev_434
we present a Bayesian framework We exploit the ideas of subspace clustering where the relevance of dimensions might be different for each cluster	mechanism	2K_dev_434
Combining the relevance of the dimensions with the cluster membership degree of the objects	mechanism	2K_dev_434
we propose a novel type of mixture model able to represent data containing mixed membership subspace clusters	mechanism	2K_dev_434
we develop an efficient algorithm based on variational inference allowing easy parallelization	mechanism	2K_dev_434
In our empirical study on synthetic and real data	method	2K_dev_434
While traditional clustering techniques assign each object to a single cluster only	purpose	2K_dev_434
in many applications it has been observed that objects might belong to multiple clusters with different degrees	purpose	2K_dev_434
to tackle the challenge of mixed membership clustering for vector data For learning our model	purpose	2K_dev_434
	purpose	2K_dev_434
Monte Carlo simulation ( MCS ) is a numerical method to solve the probabilistic load flow ( PLF ) problem	background	2K_dev_435
Comparing to analytical methods	background	2K_dev_435
MCS for PLF has advantages such as flexibility	background	2K_dev_435
general purpose	background	2K_dev_435
able to deal with large nonlinearity and large variances	background	2K_dev_435
and embarrassingly parallelizable	background	2K_dev_435
In this paper	finding	2K_dev_435
we showed that the PLF for radial distribution system has the similar properties and can be a good candidate for QMC method	finding	2K_dev_435
have shown the effectiveness of the proposed method	finding	2K_dev_435
	finding	2K_dev_435
In this paper	mechanism	2K_dev_435
we proposed a Quasi-Monte Carlo ( QMC ) based method QMC uses samples from low-discrepancy sequence intended to cover the high dimension random sample space as uniformly as possible The QMC method is particularly suitable for the high dimension problems with low effective dimensions	mechanism	2K_dev_435
and has been successfully used to solve large scale problems in econometrics and statistical circuit design	mechanism	2K_dev_435
The proposed method possesses the advantage of MCS method and significantly increases the convergence rate and overall speed	mechanism	2K_dev_435
	mechanism	2K_dev_435
Numerical experiment results on IEEE test feeders	method	2K_dev_435
However	purpose	2K_dev_435
MCS also suffers from low convergence speed and high computational burden	purpose	2K_dev_435
especially for problems with multiple random variables to solve the PLF for radial distribution network	purpose	2K_dev_435
People spend an enormous amount of time searching for and saving information online	background	2K_dev_436
Existing tools capture only a small portion of the cognitive processing a user engages in while making sense of a new domain and practical implications for the development of tools to capture and share online information	background	2K_dev_436
Our results contribute empirical knowledge relevant to theories of information seeking and sensemaking	finding	2K_dev_436
	finding	2K_dev_436
In this paper we introduce a novel interface We use this interface as a platform	mechanism	2K_dev_436
to experimentally characterize the costs and benefits of structuring information during the sensemaking process	method	2K_dev_436
for capturing online information in a structured but lightweight way	purpose	2K_dev_436
ABSTRACT Multiple ultrasonic guided -wave modes propagating along a pipe travel with different velocities which are themselves a function of frequency	background	2K_dev_437
Reflections from the features of the structure ( e	background	2K_dev_437
g	background	2K_dev_437
	background	2K_dev_437
boundaries	background	2K_dev_437
pipe welding	background	2K_dev_437
damage	background	2K_dev_437
etc	background	2K_dev_437
)	background	2K_dev_437
and their complex s uperposition	background	2K_dev_437
adds to the complexity of guided -waves	background	2K_dev_437
Guided -wave based damage d iagnosis of pipelines becomes even more challenging when environmental and operational conditions ( EOCs ) vary ( e	background	2K_dev_437
g	background	2K_dev_437
	background	2K_dev_437
temperature	background	2K_dev_437
flow rate	background	2K_dev_437
inner pressure	background	2K_dev_437
etc	background	2K_dev_437
)	background	2K_dev_437
These complexities make guided -wave based damage diagnosis of operating pipelines a challenging task	background	2K_dev_437
	background	2K_dev_437
In this paper	finding	2K_dev_437
the general concept of this method is proved The potential of the proposed method for real -time damage detection is illustrated	finding	2K_dev_437
for wide range of temperature variation scenarios ( i	finding	2K_dev_437
e	finding	2K_dev_437
	finding	2K_dev_437
temperature difference between training and test data varying between -2 ( and 13 ( )	finding	2K_dev_437
	finding	2K_dev_437
A method is proposed while retaining optimal damage information for detection purpose	mechanism	2K_dev_437
	mechanism	2K_dev_437
t hrough an extensive set of experiments	method	2K_dev_437
Effects of temperature variation on detection performnce of the proposed method	method	2K_dev_437
and on discriminatory power of the extracted damage -sensitive features are investigated	method	2K_dev_437
This paper reviews the approaches to -date addressing these challenges	purpose	2K_dev_437
and highlights the preferred characteristics of a method that simplifies guided -wa ve signals for damage diagnosis purposes to extract a sparse subset of guided -wave signals in time -domain	purpose	2K_dev_437
	background	2K_dev_438
Preliminary performance and scalability study is also reported	finding	2K_dev_438
This paper reports the design and development of an HTML5-empowered Virtual Sensor Editor ( VSE ) over Internet of Things cloud VSE is a scalable tool by visually aggregating existing sensors	mechanism	2K_dev_438
either physical sensors or user-defined virtual sensors	mechanism	2K_dev_438
VSE supports a real-time and historical visualization of sensor values and analytical studies	mechanism	2K_dev_438
and is a cross-platform and customizable tool equipped with ability to support verifiable sensor data service compos ability A discussion on design decisions is presented	mechanism	2K_dev_438
	mechanism	2K_dev_438
Our preliminary work has been applied to NASA Sustainability Base for Smart Building monitoring	method	2K_dev_438
that allows users to design virtual sensors with user-defined dataflow logic	purpose	2K_dev_438
	purpose	2K_dev_438
	background	2K_dev_439
results are provided to demonstrate the advantages and properties of the proposed sensor selection approach	finding	2K_dev_439
	finding	2K_dev_439
Kernel-based minimization framework with a weighted kernel is adopted	mechanism	2K_dev_439
where the kernel weight parameters represent sensors ' contributions to decision making	mechanism	2K_dev_439
L 1 regularization on weight parameters is introduced into the risk function so that the resulting optimal decision rule contains a sparse vector of nonzero weight parameters	mechanism	2K_dev_439
In this way	mechanism	2K_dev_439
sensor selection is naturally performed because only sensors corresponding to nonzero weight parameters contribute to decision making	mechanism	2K_dev_439
A gradient projection algorithm and a Gauss-Seidel algorithm are developed to jointly perform weight selection ( i	mechanism	2K_dev_439
e	mechanism	2K_dev_439
	mechanism	2K_dev_439
sensor selection ) and optimize decision rules	mechanism	2K_dev_439
Both algorithms are shown to converge to critical points for this non-convex optimization problem	mechanism	2K_dev_439
Numerical	method	2K_dev_439
Sensor selection in nonparametric decentralized detection is investigated	purpose	2K_dev_439
	background	2K_dev_440
	finding	2K_dev_440
	mechanism	2K_dev_440
	method	2K_dev_440
	purpose	2K_dev_440
	background	2K_dev_441
	finding	2K_dev_441
	mechanism	2K_dev_441
	method	2K_dev_441
	purpose	2K_dev_441
ABSTRACT Guided waves can propagate long distances and are sensitive to subtle structural damage Guided-wave based damage localization often requires extracting the scatter signal ( s ) produced by damage	background	2K_dev_442
which is typically obtained by subtracting an intact baseline record from a record to be tested However	background	2K_dev_442
in practical applications	background	2K_dev_442
environmental and operational conditions ( EOC ) dramatically affect guided wave si gnals	background	2K_dev_442
In this case	background	2K_dev_442
the baseline subtraction process can no longer perfectly remove the baseline	background	2K_dev_442
thereby defeating localization algorithms	background	2K_dev_442
In previous work	background	2K_dev_442
we showed that singular value decomposition ( SVD ) can be used to detect the presence of damage under large EOC variations	background	2K_dev_442
because it can differentiate the tr ends of damage from other EO C variations	background	2K_dev_442
We show that our SVD-based approach successfully localize damage while current temperature-compensated baseline subtraction methods fail	finding	2K_dev_442
In this work	mechanism	2K_dev_442
we use to approach We collect pitch-catch records from randomly placed PZT transducers on an aluminum plate while undergoing temperature variations	mechanism	2K_dev_442
Damage is introduced to the plate during the monitoring period	mechanism	2K_dev_442
We then use our SVD method to extract the scatter signal from the records	mechanism	2K_dev_442
and use the scatter signal to localize damage using the delay-and-sum method	mechanism	2K_dev_442
To compare results	method	2K_dev_442
we also apply several temperature compensation methods to the records and then perform baseline subtraction	method	2K_dev_442
This capability of differentiation implies that SVD can also robustly extract a scatter signal	purpose	2K_dev_442
originating from damage in the structure	purpose	2K_dev_442
that is not affected by temperature vari ation	purpose	2K_dev_442
This process allows us to extract a scatterer signal without the challenges associated with traditional temperature compensation and baseline subtraction routines	purpose	2K_dev_442
to localize structural damage in large	purpose	2K_dev_442
spatially and temporally varying EOCs	purpose	2K_dev_442
	purpose	2K_dev_442
	background	2K_dev_443
	finding	2K_dev_443
We use exponential start time clustering Previous algorithms usually rely on graph decomposition routines with strict restrictions on the diameters of the decomposed pieces	mechanism	2K_dev_443
We weaken these bounds in favor of stronger local probabilistic guarantees	mechanism	2K_dev_443
This allows more direct analyses of the overall process	mechanism	2K_dev_443
giving : Linear work parallel algorithms that construct spanners with O ( k ) stretch and size O ( n 1+1/ k ) in unweighted graphs	mechanism	2K_dev_443
and size O ( n 1+1/ k log k ) in weighted graphs Hopsets that lead to the first parallel algorithm for approximating shortest paths in undirected graphs with O ( m poly log n ) work	mechanism	2K_dev_443
	method	2K_dev_443
to design faster parallel graph algorithms involving distances	purpose	2K_dev_443
Testing Cyber-Physical Systems is becoming increasingly challenging as they incorporate advanced autonomy features	background	2K_dev_444
	background	2K_dev_444
Beyond demonstrating feasibility	finding	2K_dev_444
the experience emphasized a number of remaining research challenges	finding	2K_dev_444
including : approximating system intent based on limited system state observability	finding	2K_dev_444
how to best balance the simplicity and expressiveness of the specification language used to define monitored properties	finding	2K_dev_444
how to warm up monitoring of system variable state after mode change discontinuities	finding	2K_dev_444
and managing the differences between simulation and real vehicles when conducting such tests	finding	2K_dev_444
	finding	2K_dev_444
We investigate using an external runtime monitor as a partial test oracle Despite limited source code access and using only existing network messages	mechanism	2K_dev_444
we were able to monitor a hardware-in-the-loop vehicle simulator and analyze prototype vehicle log data to detect violations of high-level critical properties Interface robustness testing was useful to further exercise the monitors	mechanism	2K_dev_444
	method	2K_dev_444
to detect violations of critical system behavioral requirements on an automotive development platform	purpose	2K_dev_444
Disparity tuning measured in the primary visual cortex ( V1 ) is described well by the disparity energy model	background	2K_dev_445
but not all aspects of disparity tuning are fully explained by the model	background	2K_dev_445
	background	2K_dev_445
Our model predicted sharper disparity tuning for larger stimuli	finding	2K_dev_445
In this case	finding	2K_dev_445
our model predicted reduced sharpening and strength of inverted disparity tuning	finding	2K_dev_445
the dynamics of disparity tuning observed from the neurophysiological recordings in macaque V1 matched model simulation predictions	finding	2K_dev_445
Overall	finding	2K_dev_445
the results of this study support the notion that	finding	2K_dev_445
while the disparity energy model provides a primary account of disparity tuning in V1 neurons	finding	2K_dev_445
neural disparity processing in V1 neurons is refined by recurrent interactions among elements in the neural circuit	finding	2K_dev_445
Here	mechanism	2K_dev_445
we propose a neuronal circuit model with recurrent connections The model is based on recurrent connections inferred from neurophysiological observations on spike timing correlations	mechanism	2K_dev_445
and is in good accord with existing data on disparity tuning dynamics	mechanism	2K_dev_445
We further performed two additional experiments to test predictions of the model	method	2K_dev_445
First	method	2K_dev_445
we increased the size of stimuli to drive more neurons and provide a stronger recurrent input Second	method	2K_dev_445
we displayed anti-correlated stereograms	method	2K_dev_445
where dots of opposite luminance polarity are matched between the left- and right-eye images and result in inverted disparity tuning in the disparity energy model	method	2K_dev_445
For both experiments	method	2K_dev_445
Such deviations from the disparity energy model provide us with insight into how network interactions may play a role in disparity processing and help to solve the stereo correspondence problem	purpose	2K_dev_445
that provides a simple account of the observed deviations	purpose	2K_dev_445
	purpose	2K_dev_445
Behavioral researchers spend considerable amount of time coding video data to systematically extract meaning from subtle human actions and emotions	background	2K_dev_446
- opening up new possibilities for naturally exploring video data	background	2K_dev_446
Our show that Glance can code nearly 50 minutes of video in 5 minutes by recruiting over 60 workers simultaneously	finding	2K_dev_446
and can get initial feedback to analysts in under 10 seconds for most clips	finding	2K_dev_446
Glance 's rapid responses to natural language queries	finding	2K_dev_446
feedback regarding question ambiguity and anomalies in the data	finding	2K_dev_446
and ability to build on prior context in followup queries allow users to have a conversation-like interaction with their data	finding	2K_dev_446
In this paper	mechanism	2K_dev_446
we present Glance	mechanism	2K_dev_446
a tool Glance takes advantage of the parallelism available in paid online crowds to interpret natural language queries and then aggregates responses in a summary view of the video data	mechanism	2K_dev_446
Glance provides analysts with rapid responses when initially exploring a dataset	mechanism	2K_dev_446
and reliable codings when refining an analysis	mechanism	2K_dev_446
We present and compare new methods for accurately aggregating the input of multiple workers marking the spans of events in video data	mechanism	2K_dev_446
and for measuring the quality of their coding in real-time before a baseline is established by measuring the variance between workers	mechanism	2K_dev_446
	mechanism	2K_dev_446
experiments	method	2K_dev_446
that allows researchers to rapidly query sample	purpose	2K_dev_446
and analyze large video datasets for behavioral events that are hard to detect automatically	purpose	2K_dev_446
	purpose	2K_dev_446
Inference of gene interaction networks from expression data usually focuses on either supervised or unsupervised edge prediction from a single data source	background	2K_dev_447
	background	2K_dev_447
Results are reported	finding	2K_dev_447
where NP-MuScL outperforms baseline algorithms significantly	finding	2K_dev_447
even in the presence of noisy data sources where NP-MuScL predicts a higher number of known gene interactions than existing techniques	finding	2K_dev_447
We propose ISH	mechanism	2K_dev_447
which are expected to reflect the same underlying relationships between the genes	mechanism	2K_dev_447
NP-MuScL casts the network estimation problem as estimating the structure of a sparse undirected graphical model We use the semiparametric Gaussian copula to model the distribution of the different data sources	mechanism	2K_dev_447
with the different copulas sharing the same precision ( i	mechanism	2K_dev_447
e	mechanism	2K_dev_447
	mechanism	2K_dev_447
inverse covariance ) matrix	mechanism	2K_dev_447
and we present an efficient algorithm to estimate such a model in the high-dimensional scenario	mechanism	2K_dev_447
on synthetic data Experiments are also run on two real-world scenarios : two yeast microarray datasets and three Drosophila embryonic gene expression datasets	method	2K_dev_447
	method	2K_dev_447
However	purpose	2K_dev_447
in many real world applications	purpose	2K_dev_447
multiple data sources	purpose	2K_dev_447
such as microarray and ISH ( in situ hybridization ) measurements of mRNA abundances	purpose	2K_dev_447
are available to offer multiview information about the same set of genes	purpose	2K_dev_447
to estimate a gene interaction network that is consistent with such multiple data sources	purpose	2K_dev_447
Intracortical braincomputer interface ( BCI ) decoders are typically retrained daily to maintain stable performance Significance	background	2K_dev_448
We believe that the development of classifiers that require no daily retraining will accelerate the clinical translation of BCI systems	background	2K_dev_448
Future work should test these results in a closed-loop setting	background	2K_dev_448
	background	2K_dev_448
Main results	finding	2K_dev_448
Further	finding	2K_dev_448
drift is constrained across time	finding	2K_dev_448
which is reflected in the performance of a standard classifier which does not progressively worsen if it is not retrained daily	finding	2K_dev_448
though overall performance is reduced by more than 10 % compared to a daily retrained classifier	finding	2K_dev_448
produce a increase in classification accuracy over that achieved by the non-retrained classifier to nearly recover the performance of the daily retrained classifier	finding	2K_dev_448
We show that for the purposes of developing a self-recalibrating classifier	mechanism	2K_dev_448
tuning parameters can be considered as fixed within days and that parameters on the same electrode move up and down together between days	mechanism	2K_dev_448
Two novel self-recalibrating classifiers	mechanism	2K_dev_448
Approach	method	2K_dev_448
We recorded threshold crossings from 96-electrode arrays implanted in the motor cortex of two rhesus macaques performing center-out reaches in 7 directions over 41 and 36 separate days spanning 48 and 58days in total for offline analysis	method	2K_dev_448
	method	2K_dev_448
Objective Self-recalibrating decoders aim to remove the burden this may present in the clinic by training themselves autonomously during normal use but have only been developed for continuous control	purpose	2K_dev_448
Here we address the problem for discrete decoding ( classifiers )	purpose	2K_dev_448
	purpose	2K_dev_448
Low-cost genetic sequencing	background	2K_dev_449
coupled with novel social media platforms and visualization techniques	background	2K_dev_449
present a new frontier for scientific participation	background	2K_dev_449
whereby people can learn	background	2K_dev_449
share	background	2K_dev_449
and act on data embedded within their own bodies	background	2K_dev_449
Our findings show that personal genetics serves as a site for public engagement with science	finding	2K_dev_449
whereby communities of biological citizens creatively interpret	finding	2K_dev_449
debate	finding	2K_dev_449
and act on professional research	finding	2K_dev_449
	finding	2K_dev_449
We conclude with design trajectories at the intersection of genetics and creativity support tools : platforms for aggregating hybrid knowledge ; tools for creative reflection on professional science ; and strategies for supporting collaborations across communities	mechanism	2K_dev_449
	mechanism	2K_dev_449
Our study of 23andMe	method	2K_dev_449
a popular genetic testing service	method	2K_dev_449
We frame user groups as citizen science publics groups that coalesce around scientific issues and work towards resolving shared concerns	method	2K_dev_449
	method	2K_dev_449
reveals how users make sense of and contextualize their genetic results	purpose	2K_dev_449
critique and evaluate the underlying research	purpose	2K_dev_449
and reflect on the broader implications of genetic testing	purpose	2K_dev_449
	purpose	2K_dev_449
In the real-world unconstrained face recognition scenarios	background	2K_dev_450
automatic facial landmarking scheme using the active shape model ( ASM ) usually gives non-ideal results	background	2K_dev_450
especially at the facial boundary This is because the local subspace methods such as the principal component analysis ( PCA ) used in the ASM does not properly discern skin texture and background with very similar photometric and textual properties	background	2K_dev_450
thus fails to accurately locate the facial boundary	background	2K_dev_450
We have shown the effectiveness of our proposed methods where the refined landmarks yield much lower MSE from the ground truth	finding	2K_dev_450
In this work	mechanism	2K_dev_450
we have novelly developed a robust image statistics approach Moreover	mechanism	2K_dev_450
with the aid of banana wavelets to highlight the facial boundary	mechanism	2K_dev_450
our proposed approach can deal with even more difficult task This algorithm can dramatically increase the accuracy of landmarks on facial boundary for unconstrained facial images with minimum computational expense since this method is purely based on image statistics with no training stages involved at all	mechanism	2K_dev_450
on the GBU database	method	2K_dev_450
to efficiently refine the landmarks on facial boundary	purpose	2K_dev_450
	purpose	2K_dev_450
One of the most significant challenges for many online communities is increasing members ' contributions over time	background	2K_dev_451
Prior studies on peer feedback in online communities have suggested its impact on contribution	background	2K_dev_451
but have been limited by their correlational nature This research provides insights into the mechanisms underlying peer feedback in online communities and practical guidance to design more effective peer feedback systems	background	2K_dev_451
	background	2K_dev_451
Our results characterize the effects of different feedback types	finding	2K_dev_451
and suggest trade-offs in the effects of feedback between the focal task and general motivation	finding	2K_dev_451
as well as differences in how newcomers and experienced editors respond to peer feedback	finding	2K_dev_451
	mechanism	2K_dev_451
In this paper	method	2K_dev_451
we conducted a field experiment on Wikipedia	method	2K_dev_451
to test the effects of different feedback types ( positive feedback	purpose	2K_dev_451
negative feedback	purpose	2K_dev_451
directive feedback	purpose	2K_dev_451
and social feedback ) on members ' contribution	purpose	2K_dev_451
	purpose	2K_dev_451
In commercial-off-the-shelf ( COTS ) multi-core systems	background	2K_dev_452
the execution times of tasks become hard to predict because of contention on shared resources in the memory hierarchy	background	2K_dev_452
In particular	background	2K_dev_452
a task running in one processor core can delay the execution of another task running in another processor core	background	2K_dev_452
This is due to the fact that tasks can access data in the same cache set shared among processor cores or in the same memory bank in the DRAM memory ( or both )	background	2K_dev_452
Such cache and bank interference effects have motivated the need to create isolation mechanisms for resources accessed by more than one One popular isolation mechanism is cache coloring that divides the cache into multiple partitions	background	2K_dev_452
With cache coloring	background	2K_dev_452
each task can be assigned exclusive cache partitions	background	2K_dev_452
thereby preventing cache interference from other tasks	background	2K_dev_452
Similarly	background	2K_dev_452
bank coloring allows assigning exclusive bank partitions to tasks	background	2K_dev_452
While cache coloring and some bank coloring mechanisms have been studied separately	background	2K_dev_452
interactions between the two schemes have not been studied	background	2K_dev_452
Specifically	background	2K_dev_452
while memory accesses to two different bank colors do not interfere with each other at the bank level	background	2K_dev_452
they may interact at the cache level	background	2K_dev_452
Similarly	background	2K_dev_452
two different cache colors avoid cache interference but may not prevent bank interference	background	2K_dev_452
	background	2K_dev_452
we observed that the execution time can increase by 60 % due to inter-task interference when we use only cache Our coordinated approach can reduce this figure down to 12 % ( an 80 % reduction )	finding	2K_dev_452
In this paper	mechanism	2K_dev_452
we present a coordinated cache and bank coloring scheme We also developed color allocation algorithms	mechanism	2K_dev_452
which has been implemented in the Linux kernel	method	2K_dev_452
In our experiments	method	2K_dev_452
	method	2K_dev_452
Therefore it is necessary to coordinate cache and bank coloring approaches	purpose	2K_dev_452
that is designed to prevent cache and bank interference simultaneously for configuring a virtual memory system to support our scheme	purpose	2K_dev_452
Anecdotal evidence and scholarly research have shown that Internet users may regret some of their online disclosures	background	2K_dev_453
We discuss implications and challenges for designing and evaluating systems to assist users with online disclosures	background	2K_dev_453
	background	2K_dev_453
We found that reminders about the audience of posts can prevent unintended disclosures without major burden ; however	finding	2K_dev_453
introducing a time delay before publishing users ' posts can be perceived as both beneficial and annoying On balance	finding	2K_dev_453
some participants found the nudges helpful while others found them unnecessary or overly intrusive	finding	2K_dev_453
we designed two modifications to the Facebook web interface	mechanism	2K_dev_453
We implemented and evaluated these two nudges in a 6-week field trial with 28 Facebook users We analyzed participants ' interactions with the nudges	method	2K_dev_453
the content of their posts	method	2K_dev_453
and opinions collected through surveys	method	2K_dev_453
To help individuals avoid such regrets that nudge users to consider the content and audience of their online disclosures more carefully	purpose	2K_dev_453
	purpose	2K_dev_453
	background	2K_dev_454
	finding	2K_dev_454
	mechanism	2K_dev_454
	method	2K_dev_454
	purpose	2K_dev_454
	background	2K_dev_455
	finding	2K_dev_455
	mechanism	2K_dev_455
	method	2K_dev_455
	purpose	2K_dev_455
Virus capsid assembly has been a powerful model system for biological self-assembly in general due to the combination of experimental tractability but complicated pathway space	background	2K_dev_456
Detailed experimental resolution of viral assembly processes	background	2K_dev_456
however	background	2K_dev_456
has so far proven impossible	background	2K_dev_456
Computational approaches have provided a solution	background	2K_dev_456
allowing us to learn models of assembly consistent with indirect experimental measures of bulk in vitro assembly and thus fill the gaps between coarse-grained experimental measurements and detailed theoretical models	background	2K_dev_456
We previously developed a heuristic optimization approach to learn rate parameters of coat-coat interactions by minimizing the deviation between real and simulated static light scattering measurements	background	2K_dev_456
Advancing such simulation-based data fitting methods provides a general technology for greatly enhancing our ability to learn fine-scale details of complex assembly processes from experimental data	background	2K_dev_456
a strategy with potential application to developing accurate quantitative models of numerous other assembly systems found through biology	background	2K_dev_456
	background	2K_dev_456
suggest that other feasible technologies providing richer data on assembly progress can more precisely pin down true parameters and assembly pathways	finding	2K_dev_456
Here	mechanism	2K_dev_456
we describe progress in learning accurate kinetic models of capsid assembly systems by computationally fitting assembly simulations to experimental data	mechanism	2K_dev_456
using an alternative class of methods called derivative-free optimization	mechanism	2K_dev_456
designed	mechanism	2K_dev_456
Simultaneously	method	2K_dev_456
simulated exploration of potential alternative sources of experimental data for monitoring bulk assembly ( e	method	2K_dev_456
g	method	2K_dev_456
non-covalent mass spectrometry )	method	2K_dev_456
Nonetheless	purpose	2K_dev_456
accurate simulation predictions rely on building accurate models	purpose	2K_dev_456
which has proven to be a challenging data-fitting problem due to the high computational cost of simulating capsid assembly trajectories	purpose	2K_dev_456
high stochastic noise inherent to the system	purpose	2K_dev_456
and limited and generally noisy experimental data available	purpose	2K_dev_456
We now show that one can substantially improve fitting to light scattering data to deal with challenges of costly	purpose	2K_dev_456
noisy computations	purpose	2K_dev_456
	purpose	2K_dev_456
	background	2K_dev_457
	finding	2K_dev_457
	mechanism	2K_dev_457
	method	2K_dev_457
	purpose	2K_dev_457
Automatic understanding of human activities is a huge challenge in multimedia analysis field	background	2K_dev_458
This challenge is especially critical in small-scale activities	background	2K_dev_458
such as finger motions	background	2K_dev_458
and activities in complex scenes	background	2K_dev_458
For typical camera views	background	2K_dev_458
both global feature and local feature analysis methods are unsuitable	background	2K_dev_458
To solve this problem	background	2K_dev_458
many studies focus on using spatio-temporal features and feature selection methods to get video representation	background	2K_dev_458
	background	2K_dev_458
validate our activity analysis approach is more effective than state-of-the-art methods	finding	2K_dev_458
In this paper	mechanism	2K_dev_458
we propose a graph based Co-Attention model Without reducing the dimensionality	mechanism	2K_dev_458
our Co-Attention model considers the number of interest points	mechanism	2K_dev_458
Our model is derived from correlations among individual tiny activities	mechanism	2K_dev_458
whose salient regions are identified by combining an integrated top-down and bottom-up visual attention model	mechanism	2K_dev_458
and a motion attention model built by spatio-temporal features instead of optical flow directly	mechanism	2K_dev_458
Different from typical attention models	mechanism	2K_dev_458
the Co-Attention model allows multiple regions of interest in video co-existing for further analysis	mechanism	2K_dev_458
Experimental results on the KTH dataset	method	2K_dev_458
YouTube dataset and a new tiny activity dataset	method	2K_dev_458
Pump dataset which consist of visual observation data from patients operating an infusion pump	method	2K_dev_458
	method	2K_dev_458
However	purpose	2K_dev_458
these spatio-temporal features are problematic for two reasons	purpose	2K_dev_458
First	purpose	2K_dev_458
we are not sure whether these features are meaningful foreground or noise	purpose	2K_dev_458
Second	purpose	2K_dev_458
we are unable to foresee where an activity will occur based on these features	purpose	2K_dev_458
Therefore	purpose	2K_dev_458
a biological feature selection method is needed to reorganize these spatio-temporal features and represent the video in a feature space to select more efficient features for activity analysis	purpose	2K_dev_458
Machine-learning ( ML ) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices	background	2K_dev_459
making medical diagnoses	background	2K_dev_459
and facial recognition	background	2K_dev_459
In a model inversion attack	background	2K_dev_459
recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al	background	2K_dev_459
	background	2K_dev_459
adversarial access to an ML model is abused to learn sensitive genomic information about individuals	background	2K_dev_459
	background	2K_dev_459
show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and	finding	2K_dev_459
in the other context	finding	2K_dev_459
show how to recover recognizable images of people 's faces given only their name and access to the ML model The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility	finding	2K_dev_459
	finding	2K_dev_459
We develop a new class of model inversion attack that exploits confidence values revealed along with predictions	mechanism	2K_dev_459
Our new attacks are applicable in a variety of settings	mechanism	2K_dev_459
and we explore two in depth : decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition	mechanism	2K_dev_459
In both cases confidence values are revealed to those with the ability to make prediction queries to models	mechanism	2K_dev_459
	mechanism	2K_dev_459
We experimentally We also initiate experimental exploration of natural countermeasures	method	2K_dev_459
investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning	method	2K_dev_459
as well as revealing only rounded confidence values	method	2K_dev_459
Whether model inversion attacks apply to settings outside theirs	purpose	2K_dev_459
however	purpose	2K_dev_459
is unknown	purpose	2K_dev_459
In our previous work	background	2K_dev_460
we derived the closed form description of the equilibrium distribution that explicitly accounts for the network topology and showe dt hat themost probable equilibrium statedemonstrates threshol db ehavior	background	2K_dev_460
	finding	2K_dev_460
We model a over as tatic	mechanism	2K_dev_460
fi nite-sized network as ac ontinuous-time Markov process using the scaled SIS epidemics model	mechanism	2K_dev_460
	mechanism	2K_dev_460
	method	2K_dev_460
SIS ( susceptible-infected-susceptible ) epidemics In this paper	purpose	2K_dev_460
we will show how subgraph structures in the network topology impact the most probable state of the long run behavior of aS IS epidemics ( i	purpose	2K_dev_460
e	purpose	2K_dev_460
	purpose	2K_dev_460
stochastic diffusion process ) over any static	purpose	2K_dev_460
finite-sized	purpose	2K_dev_460
network	purpose	2K_dev_460
	purpose	2K_dev_460
Multimedia Event Detection ( MED ) is a multimedia retrieval task with the goal of finding videos of a particular event in a large-scale Internet video archive	background	2K_dev_461
given example videos and text descriptions	background	2K_dev_461
	finding	2K_dev_461
based on their visual semantics using a Visual Concept Signature ( VCS ) generated for each event only derived from the event description provided as the query	mechanism	2K_dev_461
Visual semantics are described using the Semantic INdexing ( SIN ) feature which represents the likelihood of predefined visual concepts in a video	mechanism	2K_dev_461
To generate a VCS for an event	mechanism	2K_dev_461
we project the given event description to a visual concept list using the proposed textual semantic similarity	mechanism	2K_dev_461
Exploring SIN feature properties	mechanism	2K_dev_461
we harmonize the generated visual concept signature and the SIN feature to improve retrieval performance	mechanism	2K_dev_461
We conduct different experiments to assess the quality of generated visual concept signatures with respect to human expectation	method	2K_dev_461
and in the context of the MED task to retrieve the SIN feature of videos in the test dataset when we have no or only very few training videos	method	2K_dev_461
	method	2K_dev_461
In this paper	purpose	2K_dev_461
we mainly focus on an 'ad-hoc ' scenario in MED where we do not use any example video	purpose	2K_dev_461
We aim to retrieve test videos	purpose	2K_dev_461
Given a large graph	background	2K_dev_462
like who-calls-whom	background	2K_dev_462
or who-likes-whom	background	2K_dev_462
what behavior is normal and what should be surprising	background	2K_dev_462
possibly due to fraudulent activity ? How do graphs evolve over time ? How does influence/news/viruses propagate	background	2K_dev_462
over time ? We conclude with some open research questions for graph mining	background	2K_dev_462
as well as some discoveries such settings	finding	2K_dev_462
For the third	finding	2K_dev_462
we show that for virus propagation	finding	2K_dev_462
a single number is enough to characterize the connectivity of graph	finding	2K_dev_462
and	finding	2K_dev_462
For the first	mechanism	2K_dev_462
we present a list of static and temporal laws	mechanism	2K_dev_462
including advances patterns like 'eigenspokes ' ; we show how to use them to spot suspicious activities	mechanism	2K_dev_462
in on-line buyer-and-seller settings	mechanism	2K_dev_462
in FaceBook	mechanism	2K_dev_462
in twitter-like networks	mechanism	2K_dev_462
For the second	mechanism	2K_dev_462
we show how to handle time-evolving graphs as tensors	mechanism	2K_dev_462
how to handle large tensors in map-reduce environments	mechanism	2K_dev_462
thus we show how to do efficient immunization for almost any type of virus ( SIS - no immunity ; SIR - lifetime immunity ; etc )	mechanism	2K_dev_462
	method	2K_dev_462
We focus on three topics : ( a ) anomaly detection in large static graphs ( b ) patterns and anomalies in large time-evolving graphs and ( c ) cascades and immunization	purpose	2K_dev_462
	purpose	2K_dev_462
	background	2K_dev_463
	finding	2K_dev_463
	mechanism	2K_dev_463
	method	2K_dev_463
	purpose	2K_dev_463
The space around the body provides a large interaction volume that can allow for big interactions on small mobile devices	background	2K_dev_464
	finding	2K_dev_464
We demonstrate three types of around-body interaction including canvas	mechanism	2K_dev_464
modal and context-aware interactions in six demonstration applications We also present using standard smartphone hardware : a phone 's front camera	mechanism	2K_dev_464
accelerometer and inertia measurement units	mechanism	2K_dev_464
Our solution allows a person to interact with a mobile device by holding and positioning it between a normal field of view and its vicinity around the body By leveraging a user 's proprioceptive sense	mechanism	2K_dev_464
around-body Interaction opens a new input channel that enhances conventional interaction on a mobile device without requiring additional hardware	mechanism	2K_dev_464
	mechanism	2K_dev_464
	method	2K_dev_464
However	purpose	2K_dev_464
interaction techniques making use of this opportunity are underexplored	purpose	2K_dev_464
primarily focusing on distributing information in the space around the body	purpose	2K_dev_464
a sensing solution	purpose	2K_dev_464
Recent improvements in content-based video search have led to systems with promising accuracy	background	2K_dev_465
	background	2K_dev_465
shows that our system is capable of assisting users to incrementally build effective queries over complex event topics	finding	2K_dev_465
We present an interactive system based on a state-of-the-art content-based video search pipeline which enables users through relevance feedback and model visualization	mechanism	2K_dev_465
Also	mechanism	2K_dev_465
the comprehensive functionalities enhance a flexible formulation of multimodal queries with different characteristics	mechanism	2K_dev_465
Quantitative and qualitative analysis	method	2K_dev_465
thus opening up the possibility for interactive content-based video search to the general public	purpose	2K_dev_465
to do multimodal text-to-video and video-to-video search in large video collections	purpose	2K_dev_465
and to incrementally refine queries	purpose	2K_dev_465
	background	2K_dev_466
We show that offload shaping can produce significant reduction in resource demand	finding	2K_dev_466
with little loss of application-level fidelity	finding	2K_dev_466
	finding	2K_dev_466
When offloading computation from a mobile device	mechanism	2K_dev_466
we show that it can pay to perform additional on-device work We call this offload shaping	mechanism	2K_dev_466
and	mechanism	2K_dev_466
demonstrate its application at many different levels of abstraction using a variety of techniques	method	2K_dev_466
	method	2K_dev_466
in order to reduce the offloading workload	purpose	2K_dev_466
	purpose	2K_dev_466
In recent years	background	2K_dev_467
progresses in data mining and business analytics have fostered the advent of recommender systems	background	2K_dev_467
behavioral advertising	background	2K_dev_467
and other ways of using consumer data to personalize offers and products	background	2K_dev_467
Copyright Springer Science+Business Media New York 2014	background	2K_dev_467
We find that there are two types of equilibria : sellers will target all potential buyers	finding	2K_dev_467
hence their targeted ads or purchase recommendations provide no benefit to the consumer	finding	2K_dev_467
ads and recommendations will be accurate will be inversely related	finding	2K_dev_467
	mechanism	2K_dev_467
For some parameter values	method	2K_dev_467
But for other values In particular	method	2K_dev_467
the incentive for the seller to provide accurate ads and recommendations to the difference between the cost of producing the good and its average market evaluation	method	2K_dev_467
	method	2K_dev_467
We investigate the incentives for sellers to invest in systems that allow the tracking of consumers and then to truthfully report whether potential buyers will enjoy yet untried products	purpose	2K_dev_467
These interrelated issues underpin advanced correctness analysis in models of structured communications	background	2K_dev_468
	background	2K_dev_468
	finding	2K_dev_468
we prove that all proof conversions induced by the logic interpretation actually express observational equivalences	finding	2K_dev_468
and explain how type isomorphisms resulting from linear logic equivalences are realized by coercions between interface types of session-based concurrent systems	finding	2K_dev_468
by developing a theory of logical relations	mechanism	2K_dev_468
Defined upon a linear type structure	mechanism	2K_dev_468
our logical relations remain remarkably similar to those for functional languages	mechanism	2K_dev_468
We also introduce a natural notion of observational equivalence Strong normalization and confluence come in handy in the associated coinductive reasoning :	mechanism	2K_dev_468
The starting point for our study is an interpretation of linear logic propositions as session types for communicating processes	method	2K_dev_468
proposed in prior work	method	2K_dev_468
as applications	method	2K_dev_468
We investigate strong normalization	purpose	2K_dev_468
confluence	purpose	2K_dev_468
and behavioral equality in the realm of session-based concurrency	purpose	2K_dev_468
Strong normalization and confluence are established for session-typed processes	purpose	2K_dev_468
	purpose	2K_dev_468
Given a large social graph	background	2K_dev_469
what can we say about its robustness ? Broadly speaking	background	2K_dev_469
the property of robustness is crucial in real graphs	background	2K_dev_469
since it is related to the structural behavior of graphs to retain their connectivity properties after losing a portion of their edges/nodes	background	2K_dev_469
Can we estimate a robustness index for a graph quickly ? Additionally	background	2K_dev_469
if the graph evolves over time	background	2K_dev_469
how this property changes ?	background	2K_dev_469
and we observe interesting properties for both static and time-evolving social graphs	finding	2K_dev_469
	finding	2K_dev_469
we show how to spot outliers and anomalies in graphs over time	finding	2K_dev_469
Finally	finding	2K_dev_469
we examine how graph generating models that mimic several properties of real-world graphs and behave in terms of robustness dynamics	finding	2K_dev_469
	finding	2K_dev_469
First	mechanism	2K_dev_469
we present a measure that characterizes the robustness properties of a graph and also serves as global measure of the community structure ( or lack thereof )	mechanism	2K_dev_469
We show how to compute this measure efficiently by exploiting the special spectral properties of real-world networks	mechanism	2K_dev_469
	mechanism	2K_dev_469
We apply our method on several diverse real networks with millions of nodes	method	2K_dev_469
As an application example	method	2K_dev_469
In this work	purpose	2K_dev_469
we are trying to answer the above questions studying the expansion properties of large social graphs	purpose	2K_dev_469
	purpose	2K_dev_469
User provided rating data about products and services is one key feature of websites such as Amazon	background	2K_dev_470
TripAdvisor	background	2K_dev_470
or Yelp	background	2K_dev_470
Since these ratings are rather static but might change over time	background	2K_dev_470
a temporal analysis of rating distributions provides deeper insights into the evolution of a products ' quality	background	2K_dev_470
and we present interesting findings	finding	2K_dev_470
we model the base behavior of users regarding a product as a latent multivariate autoregressive process	mechanism	2K_dev_470
This latent behavior is mixed with a sparse anomaly signal finally leading to the observed data We propose an efficient algorithm	mechanism	2K_dev_470
on various real world datasets	method	2K_dev_470
Given a time-series of rating distributions	purpose	2K_dev_470
in this work	purpose	2K_dev_470
we answer the following questions : ( 1 ) How to detect the base behavior of users regarding a product 's evaluation over time ? ( 2 ) How to detect points in time where the rating distribution differs from this base behavior	purpose	2K_dev_470
e	purpose	2K_dev_470
g	purpose	2K_dev_470
	purpose	2K_dev_470
due to attacks or spontaneous changes in the product 's quality ? To achieve these goals solving our objective	purpose	2K_dev_470
Self-reported behavioral data is frequently relied upon to understand the population of social network users	background	2K_dev_471
These data often consist of self-reported posting	background	2K_dev_471
commenting or general engagement frequency within the social network over the last few days or a month	background	2K_dev_471
	background	2K_dev_471
we show that these data can be quite inaccurate Indeed	finding	2K_dev_471
the regularity of the behavior is a strong predictor of self-report accuracy	finding	2K_dev_471
are the most accurate in their reporting our study suggests that questions should only refer to a very narrow and recent time window to improve response accuracy	finding	2K_dev_471
Our study also highlights the importance of considering the granularity of privacy concern measurements when investigating the so-called privacy paradox	finding	2K_dev_471
do take more privacy actions In particular	finding	2K_dev_471
this group is less likely to enter profile information	finding	2K_dev_471
more likely to limit the visibility of their posts and more likely to delete posts	finding	2K_dev_471
	mechanism	2K_dev_471
Using a sample of 397 Google+ users Users who exhibit a behavior either very frequently or very infrequently For social networks	method	2K_dev_471
in which it is often the case that most users are `` lurkers '' who do not post or comment much	method	2K_dev_471
Within our sample	method	2K_dev_471
those users who report that the ability to control post visibility and/or delete posts are more important than other	method	2K_dev_471
non-privacy related	method	2K_dev_471
features	method	2K_dev_471
	method	2K_dev_471
when asking users to report on actions that tend to occur infrequently and irregularly ( e	purpose	2K_dev_471
g	purpose	2K_dev_471
profile field editing )	purpose	2K_dev_471
	purpose	2K_dev_471
	background	2K_dev_472
demonstrate that HYDRA correctly identifies real user linkage across different platforms	finding	2K_dev_472
and outperforms existing state-of-the-art algorithms by at least 20 % under different settings	finding	2K_dev_472
and 4 times better in most settings	finding	2K_dev_472
This paper proposes HYDRA	mechanism	2K_dev_472
a solution framework which consists of three key steps : ( I ) modeling heterogeneous behavior by long-term behavior distribution analysis and multi-resolution temporal information matching ; ( II ) constructing structural consistency graph to measure the high-order structure consistency on users ' core social structures across different platforms ; and ( III ) learning the mapping function by multi-objective optimization composed of both the supervised learning on pair-wise ID linkage information and the cross-platform structure consistency maximization	mechanism	2K_dev_472
	mechanism	2K_dev_472
Extensive experiments on 10 million users across seven popular social network platforms	method	2K_dev_472
We study the problem of large-scale social identity linkage across different social media platforms	purpose	2K_dev_472
which is of critical importance to business intelligence by gaining from social data a deeper understanding and more accurate profiling of users	purpose	2K_dev_472
	purpose	2K_dev_472
	background	2K_dev_473
have demonstrated the effectiveness of the proposed algorithm	finding	2K_dev_473
In this paper	mechanism	2K_dev_473
we propose a new multi-task feature selection algorithm and apply it to multimedia ( e	mechanism	2K_dev_473
g	mechanism	2K_dev_473
	mechanism	2K_dev_473
video and image ) analysis	mechanism	2K_dev_473
Instead of evaluating the importance of each feature individually	mechanism	2K_dev_473
our algorithm selects features in a batch mode	mechanism	2K_dev_473
by which the feature correlation is considered	mechanism	2K_dev_473
While feature selection has received much research attention	mechanism	2K_dev_473
less effort has been made on improving the performance of feature selection by leveraging the shared knowledge from multiple related tasks	mechanism	2K_dev_473
Our algorithm builds upon the assumption that different related tasks have common structures	mechanism	2K_dev_473
Multiple feature selection functions of different tasks are simultaneously learned in a joint framework	mechanism	2K_dev_473
which enables our algorithm to utilize the common knowledge of multiple tasks as supplementary information to facilitate decision making	mechanism	2K_dev_473
An efficient iterative algorithm is proposed to optimize it	mechanism	2K_dev_473
whose convergence is guaranteed	mechanism	2K_dev_473
	mechanism	2K_dev_473
Experiments on different databases	method	2K_dev_473
While much progress has been made to multi-task classification and subspace learning	purpose	2K_dev_473
multi-task feature selection has long been largely unaddressed	purpose	2K_dev_473
	purpose	2K_dev_473
	background	2K_dev_474
	finding	2K_dev_474
We present an architecture for the Security Behavior Observatory ( SBO )	mechanism	2K_dev_474
a client-server infrastructure from hundreds of participants over several years	mechanism	2K_dev_474
The SBO infrastructure had to be carefully designed to fulfill several requirements	mechanism	2K_dev_474
First	mechanism	2K_dev_474
the SBO must scale with the desired length	mechanism	2K_dev_474
breadth	mechanism	2K_dev_474
and depth of data collection Second	mechanism	2K_dev_474
we must take extraordinary care to ensure the security of the collected data	mechanism	2K_dev_474
which will inevitably include intimate participant behavioral data	mechanism	2K_dev_474
Third	mechanism	2K_dev_474
the SBO must serve our research interests	mechanism	2K_dev_474
which will inevitably change as collected data is analyzed and interpreted This short paper summarizes some of our design and implementation benefits and discusses a few hurdles and trade-offs to consider when designing such a data collection system	mechanism	2K_dev_474
	method	2K_dev_474
designed to collect a wide array of data on user and computer behavior	purpose	2K_dev_474
Very recently	background	2K_dev_475
there has been a perfect storm of technical advances that has culminated in the emergence of a new interaction modality : on-body interfaces	background	2K_dev_475
Such systems enable the wearer to use their body as an input and output platform with interactive graphics	background	2K_dev_475
Projects such as PALMbit and Skinput sought to answer the initial and fundamental question : whether or not on-body interfaces were technologically possible	background	2K_dev_475
	background	2K_dev_475
point the way towards more comfortable	background	2K_dev_475
efficacious	background	2K_dev_475
and enjoyable on-body user experiences	background	2K_dev_475
The results of this complimentary	finding	2K_dev_475
structured exploration	finding	2K_dev_475
	mechanism	2K_dev_475
we employed a mixed-methods research process involving more than two thousand individuals	method	2K_dev_475
This started with high-resolution	method	2K_dev_475
but low-detail crowdsourced data	method	2K_dev_475
We then combined this with rich	method	2K_dev_475
expert interviews	method	2K_dev_475
exploring aspects ranging from aesthetics to kinesthetics	method	2K_dev_475
	method	2K_dev_475
Although considerable technical work remains	purpose	2K_dev_475
we believe it is important to begin shifting the question away from how and what	purpose	2K_dev_475
and towards where	purpose	2K_dev_475
and ultimately why	purpose	2K_dev_475
These are the class of questions that inform the design of next generation systems	purpose	2K_dev_475
To better understand and explore this expansive space	purpose	2K_dev_475
	purpose	2K_dev_475
	background	2K_dev_476
QuMinS scales linearly on the data size	finding	2K_dev_476
being up to 40 times faster than top competitors ( GCap )	finding	2K_dev_476
still achieving better or equal accuracy	finding	2K_dev_476
it spots images that potentially require unpredicted labels	finding	2K_dev_476
and it works even with tiny initial label sets	finding	2K_dev_476
i	finding	2K_dev_476
e	finding	2K_dev_476
	finding	2K_dev_476
nearly five examples to show that QuMinS is a viable tool for automatic coffee crop detection from remote sensing images	finding	2K_dev_476
	finding	2K_dev_476
Specifically	mechanism	2K_dev_476
we propose QuMinS	mechanism	2K_dev_476
a fast	mechanism	2K_dev_476
scalable - given an image set	mechanism	2K_dev_476
very few images have labels in the same setting	mechanism	2K_dev_476
find clusters	mechanism	2K_dev_476
the top-N '' O outlier images	mechanism	2K_dev_476
and the N '' R images	mechanism	2K_dev_476
Experiments on satellite images spanning up to 2	method	2K_dev_476
25 GB show that	method	2K_dev_476
contrasting to the state-of-the-art labeling techniques	method	2K_dev_476
We also report a case study of our method 's practical usage	method	2K_dev_476
Given a large image set	purpose	2K_dev_476
in which very few images have labels	purpose	2K_dev_476
how to guess labels for the remaining majority ? How to spot images that need brand new labels different from the predefined ones ? How to summarize these data to route the user 's attention to what really matters ? Here we answer all these questions	purpose	2K_dev_476
solution to two problems : ( i ) Low-labor labeling ( LLL )	purpose	2K_dev_476
find the most appropriate labels for the rest ; and ( ii ) Mining and attention routing - that best represent the data	purpose	2K_dev_476
	background	2K_dev_477
	finding	2K_dev_477
by extending todays unmodified cloud to a second level consisting of self-managed data centers with no hard state called cloudlets These are located at the edge of the Internet	mechanism	2K_dev_477
just one wireless hop away from associated mobile devices By leveraging lowlatency offload	mechanism	2K_dev_477
cloudlets enable a new class of real-time cognitive assistive applications on wearable devices By processing high data rate sensor inputs such as video close to the point of capture	mechanism	2K_dev_477
cloudlets can reduce ingress bandwidth demand into the cloud By serving as proxies for distant cloud services that are unavailable due to failures or cyberattacks	mechanism	2K_dev_477
cloudlets can improve robustness and availability	mechanism	2K_dev_477
We caution that proprietary software ecosytems surrounding cloudlets will lead to a fragmented marketplace that fails to realize the full business potential of mobile-cloud convergence	mechanism	2K_dev_477
Instead	mechanism	2K_dev_477
we urge that the software ecosystem surrounding cloudlets be based on the same principles of openness and end-to-end design that have made the Internet so successful	mechanism	2K_dev_477
	method	2K_dev_477
We show how a disruptive force in mobile computing can be created	purpose	2K_dev_477
Introductory programming activities for students often include graphical user interfaces or other visual media that are inaccessible to students with visual impairments	background	2K_dev_478
and suggests future directions for integrating data analysis and 3D printing into programming instruction for blind students	background	2K_dev_478
This paper describes outcomes from our workshop	finding	2K_dev_478
This paper describes the planning and execution of a four-day computer science education workshop in which blind and visually impaired students wrote Ruby programs to analyze data from Twitter regarding a fictional ecological crisis	mechanism	2K_dev_478
Students then wrote code to produce accessible tactile visualizations of that data	mechanism	2K_dev_478
	method	2K_dev_478
Digital fabrication techniques such as 3D printing offer an opportunity for students to write programs that produce tactile objects	purpose	2K_dev_478
providing an accessible way of exploring program output	purpose	2K_dev_478
	purpose	2K_dev_478
Botnets are large networks of bots ( compromised machines ) that are under the control of a small number of bot masters	background	2K_dev_479
They pose a significant threat to Internets communications and applications	background	2K_dev_479
A botnet relies on command and control ( C2 ) communications channels traffic between its members for its attack execution	background	2K_dev_479
C2 traffic occurs prior to any attack ; hence	background	2K_dev_479
the detection of botnets C2 traffic enables the detection of members of the botnet before any real harm happens	background	2K_dev_479
This is due to the pre-programmed behavior of bots that check for updates to download them every T seconds	background	2K_dev_479
	background	2K_dev_479
and find that it exhibits a periodic behavior	finding	2K_dev_479
	finding	2K_dev_479
We exploit this periodic behavior The detection involves evaluating the periodogram of the monitored traffic	mechanism	2K_dev_479
Then applying Walkers large sample test to the periodograms maximum ordinate in order to determine if it is due to a periodic component or not If the periodogram of the monitored traffic contains a periodic component	mechanism	2K_dev_479
then it is highly likely that it is due to a bots C2 traffic	mechanism	2K_dev_479
The test looks only at aggregate control plane traffic behavior	mechanism	2K_dev_479
which makes it more scalable than techniques that involve deep packet inspection ( DPI ) or tracking the communication flows of different hosts	mechanism	2K_dev_479
	mechanism	2K_dev_479
We apply the test to two types of botnet	method	2K_dev_479
tinyP2P and IRC that are generated by SLINGbot	method	2K_dev_479
We verify the periodic behavior of their C2 traffic and compare it to the results we get on real traffic that is obtained from a secured enterprise network	method	2K_dev_479
We further study the characteristics of the test in the presence of injected HTTP background traffic and the effect of the duty cycle on the periodic behavior	method	2K_dev_479
	method	2K_dev_479
We analyze C2 traffic to detect C2 traffic	purpose	2K_dev_479
	purpose	2K_dev_479
Memory reservations are used to provide real-time tasks with guaranteed memory access to a specified amount of physical memory However	background	2K_dev_480
previous work on memory reservation primarily focused on private pages	background	2K_dev_480
and did not pay attention to shared pages	background	2K_dev_480
which are widely used in current operating systems	background	2K_dev_480
With previous schemes	background	2K_dev_480
a real-time task may experience unexpected timing delays from other tasks through shared pages that are shared by another process	background	2K_dev_480
even though the task has enough free pages in its own reservation	background	2K_dev_480
	finding	2K_dev_480
We then propose which enhances the temporal isolation provided by memory reservations in resource kernels that use the resource reservation approach	mechanism	2K_dev_480
Our proposed solution consists of two schemes	mechanism	2K_dev_480
Shared-Page Conservation ( SPC ) and Shared-Page Eviction Lock ( SPEL )	mechanism	2K_dev_480
each of which prevents timing penalties caused by the seemingly arbitrary eviction of shared pages	mechanism	2K_dev_480
The framework can manage shared data for inter-process communication and shared libraries	mechanism	2K_dev_480
as well as pages shared by the kernel 's copy-on-write technique and file caches	mechanism	2K_dev_480
We have implemented and evaluated our schemes on the Linux/RK platform	method	2K_dev_480
but it can also be applied to other operating systems with paged virtual memory	method	2K_dev_480
In this paper	purpose	2K_dev_480
we first describe the problems that arise when real-time tasks share pages a shared-page management framework	purpose	2K_dev_480
The promise of affordable	background	2K_dev_481
automatic approaches to real-time captioning imagines a future in which deaf and hard of hearing ( DHH ) users have immediate access to speech in the world around them my simply picking up their phone or other mobile device	background	2K_dev_481
This is in contrast to current human-powered approaches	background	2K_dev_481
which use highly-trained professional captionists who can type up to 250 words per minute ( WPM )	background	2K_dev_481
but also can cost over $ 100/hr	background	2K_dev_481
	background	2K_dev_481
	finding	2K_dev_481
In this paper	mechanism	2K_dev_481
we describe a real-time demo of Legion : Scribe ( or just `` Scribe '' )	mechanism	2K_dev_481
a crowd-powered captioning system that allows untrained participants and volunteers by computationally merging their input into a single collective answer that is more accurate and more complete than any one worker could have generated alone	mechanism	2K_dev_481
	method	2K_dev_481
While the challenges of processing highly variable natural language has prevented automated approaches from completing this task reliably enough for use in settings such as classrooms or workplaces [ 4 ]	purpose	2K_dev_481
recent work in crowd-powered approaches have allowed groups of non-expert captionists to provide a similarly-flexible source of captions for DHH users to provide reliable captions with less than 5 seconds of latency	purpose	2K_dev_481
Distributed augmented Lagrangian ( AL ) methods have good empirical performance on several signal processing and learning applications	background	2K_dev_482
illustrate our analytical findings	finding	2K_dev_482
	finding	2K_dev_482
This paper establishes globally linear ( geometric ) convergence rates of a class of deterministic and randomized distributed AL methods	mechanism	2K_dev_482
when the $ f_ { i } $ 's are twice continuously differentiable and have a bounded Hessian We give explicit dependence of the convergence rates on the underlying network parameters	mechanism	2K_dev_482
	mechanism	2K_dev_482
Simulations	method	2K_dev_482
We study distributed optimization where nodes cooperatively minimize the sum of their individual	purpose	2K_dev_482
locally known	purpose	2K_dev_482
convex costs $ f_ { i } ( x ) $ 's ; $ x\in\BBR^ { d } $ is global	purpose	2K_dev_482
	purpose	2K_dev_482
but there is limited understanding of their convergence rates and how it depends on the underlying network	purpose	2K_dev_482
	purpose	2K_dev_482
Dispersion curves characterize many propagation mediums	background	2K_dev_483
When known	background	2K_dev_483
many methods use these curves to analyze waves	background	2K_dev_483
	background	2K_dev_483
In the results	finding	2K_dev_483
orthogonal matching pursuit provides two to three orders of magnitude improvement in speed and a small average reduction in prediction capability	finding	2K_dev_483
The analysis is demonstrated	finding	2K_dev_483
This paper presents a fast implementation of sparse wavenumber analysis	mechanism	2K_dev_483
a method	mechanism	2K_dev_483
This approach	method	2K_dev_483
based on orthogonal matching pursuit	method	2K_dev_483
is compared with a prior implementation	method	2K_dev_483
based on basis pursuit denoising across multiple scenarios and parameters	method	2K_dev_483
Yet	purpose	2K_dev_483
in many scenarios	purpose	2K_dev_483
their exact values are unknown due to material and environmental uncertainty for recovering dispersion curves from data	purpose	2K_dev_483
	purpose	2K_dev_483
	background	2K_dev_484
Experimental results show that our method outperforms several state-of-the-art algorithms	finding	2K_dev_484
Most notably	finding	2K_dev_484
much better performances have been achieved when there are only a few labeled training samples	finding	2K_dev_484
This paper presents a semi-supervised method using multiple visual features	mechanism	2K_dev_484
The proposed algorithm simultaneously learns multiple features from a small number of labeled videos	mechanism	2K_dev_484
and automatically utilizes data distributions between labeled and unlabeled data to boost the recognition performance	mechanism	2K_dev_484
Shared structural analysis is applied in our approach to discover a common subspace shared by each type of feature	mechanism	2K_dev_484
In the subspace	mechanism	2K_dev_484
the proposed algorithm is able to characterize more discriminative information of each feature type	mechanism	2K_dev_484
Additionally	mechanism	2K_dev_484
data distribution information of each type of feature has been preserved The aforementioned attributes make our algorithm robust for action recognition	mechanism	2K_dev_484
especially when only limited labeled training samples are provided	mechanism	2K_dev_484
	mechanism	2K_dev_484
Extensive experiments have been conducted on both the choreographed and the realistic video datasets	method	2K_dev_484
including KTH	method	2K_dev_484
Youtube action and UCF50	method	2K_dev_484
	method	2K_dev_484
for categorizing human actions	purpose	2K_dev_484
Such performance guarantee makes the greedy algorithm very attractive in the practical scenario of multi-stage installations for utilities with limited budgets	background	2K_dev_485
	finding	2K_dev_485
and show that it achieves an approximation ratio of ( 1-1/ e ) for any PMU placement budget We further show that the performance is the best that one can achieve	finding	2K_dev_485
in the sense that it is NP-hard to achieve any approximation ratio beyond ( 1-1/ e ) results demonstrate near-optimal performance of the proposed PMU placement algorithm	finding	2K_dev_485
This paper presents an information-theoretic approach Different from the conventional `topological observability ' based approaches	mechanism	2K_dev_485
this paper advocates a much more refined	mechanism	2K_dev_485
information-theoretic criterion	mechanism	2K_dev_485
namely the mutual information ( MI ) between PMU measurements and power system states	mechanism	2K_dev_485
The proposed MI criterion not only includes observability as a special case	mechanism	2K_dev_485
but also rigorously models the uncertainty reduction on power system states from PMU measurements	mechanism	2K_dev_485
Thus	mechanism	2K_dev_485
it can generate highly informative PMU configurations	mechanism	2K_dev_485
The MI criterion can also facilitate robust PMU placement by explicitly modeling probabilistic PMU outages We propose a greedy PMU placement algorithm	mechanism	2K_dev_485
Finally	method	2K_dev_485
simulation	method	2K_dev_485
to address the phasor measurement unit ( PMU ) placement problem in electric power systems	purpose	2K_dev_485
	purpose	2K_dev_485
Robust facial hair detection and segmentation is a highly valued soft biometric attribute for carrying out forensic facial analysis	background	2K_dev_486
results demonstrate the effectiveness of our proposed system in detecting and segmenting facial hair regions	finding	2K_dev_486
In this paper	mechanism	2K_dev_486
we propose a novel and fully automatic system	mechanism	2K_dev_486
called SparCLeS	mechanism	2K_dev_486
SparCLeS uses the multiscale self-quotient ( MSQ ) algorithm to preprocess facial images and deal with illumination variation	mechanism	2K_dev_486
Histogram of oriented gradients ( HOG ) features are extracted from the preprocessed images and a dynamic sparse classifier is built using these features to classify a facial region as either containing skin or facial A level set based approach	mechanism	2K_dev_486
which makes use of the advantages of both global and local information	mechanism	2K_dev_486
is then used to segment the regions of a face containing	mechanism	2K_dev_486
Experimental in images drawn from three databases	method	2K_dev_486
i	method	2K_dev_486
e	method	2K_dev_486
	method	2K_dev_486
the NIST Multiple Biometric Grand Challenge ( MBGC ) still face database	method	2K_dev_486
the NIST Color Facial Recognition Technology FERET database	method	2K_dev_486
and the Labeled Faces in the Wild ( LFW ) database	method	2K_dev_486
	method	2K_dev_486
for beard/moustache detection and segmentation in challenging facial images	purpose	2K_dev_486
	purpose	2K_dev_486
A descending ( multi-item ) clock auction ( DCA ) is a mechanism for buying items from multiple potential sellers	background	2K_dev_487
In the DCA	background	2K_dev_487
bidder-specific prices are decremented over the course of the auction	background	2K_dev_487
In each round	background	2K_dev_487
each bidder might accept or decline his offer price	background	2K_dev_487
Accepting means the bidder is willing to sell at that price	background	2K_dev_487
Rejecting means the bidder will not sell at that price or a lower price DCAs have been proposed as the method for procuring spectrum from existing holders in the FCC 's imminent incentive auctions so spectrum can be repurposed to higher-value uses	background	2K_dev_487
	background	2K_dev_487
An unexpected paradox about DCAs is that sometimes when the number of rounds allowed increases	finding	2K_dev_487
the final payment increases	finding	2K_dev_487
We provide an explanation for this	finding	2K_dev_487
	finding	2K_dev_487
We develop a percentile-based approach which provides a means We also develop an optimization model for setting prices so as while stochastically satisfying the feasibility constraint	mechanism	2K_dev_487
( The DCA has a final adjustment round that obtains feasibility after feasibility has been lost in the final round of the main DCA	mechanism	2K_dev_487
) We prove attractive properties of this	mechanism	2K_dev_487
such as symmetry and monotonicity	mechanism	2K_dev_487
We develop computational methods for solving the model	mechanism	2K_dev_487
( We also develop optimization models with recourse	mechanism	2K_dev_487
but they are not computationally practical	mechanism	2K_dev_487
)	mechanism	2K_dev_487
We present experiments both on the homogeneous items case and the case of FCC incentive auctions	method	2K_dev_487
where we use real interference constraint data to get a fully faithful model of feasibility	method	2K_dev_487
However	purpose	2K_dev_487
the DCA design has lacked a way to determine the prices to offer the bidders in each round	purpose	2K_dev_487
This is a recognized	purpose	2K_dev_487
important	purpose	2K_dev_487
and timely problem	purpose	2K_dev_487
We present	purpose	2K_dev_487
to our knowledge	purpose	2K_dev_487
the first techniques for this	purpose	2K_dev_487
to naturally reduce the offer prices to the bidders through the bidding rounds to minimize expected payment	purpose	2K_dev_487
Aggregations of thermostatically controlled loads ( TCLs ) have been shown to hold promise as demand response resources	background	2K_dev_488
Our results show that the effects of invalid assumptions about the disturbances and time-invariant properties of individual HRUs may be mitigated by a faster sampling of the state variables and that	finding	2K_dev_488
when this is not possible	finding	2K_dev_488
the proposed LTI system reduces the plant-model mismatch	finding	2K_dev_488
In this paper	mechanism	2K_dev_488
we first propose a data-driven modeling strategy Specifically	mechanism	2K_dev_488
we fit probability distributions to a year-long dataset of power measurements for HRUs and use these models to create more realistic simulations We then derive the aggregate system equations using a bottom-up approach that results in a more flexible [ linear time invariant ( LTI ) ] system	mechanism	2K_dev_488
Finally	method	2K_dev_488
we quantify the plant-model mismatch and evaluate the proposed strategy with the more realistic simulation	method	2K_dev_488
	method	2K_dev_488
However	purpose	2K_dev_488
the evaluation of these promises has relied on simulations of individual TCLs that make important assumptions about the thermal dynamics and properties of the loads	purpose	2K_dev_488
the end-users interactions with individual TCLs and the disturbances to their operation to simulate individual TCLsspecifically	purpose	2K_dev_488
household refrigeration units ( HRUs ) that allows us to relax some of these assumptions and evaluate the validity of the approaches proposed to date	purpose	2K_dev_488
	background	2K_dev_489
	finding	2K_dev_489
We show an algorithm Our approach follows the recursive preconditioning framework	mechanism	2K_dev_489
which aims to reduce graphs to trees using iterative methods	mechanism	2K_dev_489
We improve two key components of this framework : random sampling and tree embeddings	mechanism	2K_dev_489
Both of these components are used in a variety of other algorithms	mechanism	2K_dev_489
and our approach also extends to the dual problem of computing electrical flows	mechanism	2K_dev_489
We show that preconditioners constructed by random sampling can perform well without meeting the standard requirements of iterative methods	mechanism	2K_dev_489
In the graph setting	mechanism	2K_dev_489
this leads to ultra-sparsifiers that have optimal behavior in expectation The improved running time makes previous low stretch embedding algorithms the running time bottleneck in this framework In our analysis	mechanism	2K_dev_489
we relax the requirement of these embeddings to snowflake spaces	mechanism	2K_dev_489
We then obtain a two-pass approach algorithm This algorithm is also readily parallelizable	mechanism	2K_dev_489
	mechanism	2K_dev_489
	method	2K_dev_489
for solving symmetric diagonally dominant ( SDD ) linear systems with m non-zero entries to a relative error of e in O ( m log 1/2 n log c n log ( 1/ e ) ) time	purpose	2K_dev_489
for constructing optimal embeddings in snowflake spaces that runs in O ( m log log n ) time	purpose	2K_dev_489
	purpose	2K_dev_489
Social media offers a targeted way for mainstream technology companies to communicate with people with disabilities about the accessibility problems that they face	background	2K_dev_490
and suggests the extent to which a company is able to leverage this input depends greatly on how they choose to present themselves and interact on social media	background	2K_dev_490
We find that while many users want to interact directly with companies about accessibility	finding	2K_dev_490
companies prefer to redirect them to other channels and use Twitter for broadcast messages promoting their accessibility work instead Our analysis demonstrates that users want to use social media to become part of the process of improving accessibility of mainstream technology	finding	2K_dev_490
	finding	2K_dev_490
	mechanism	2K_dev_490
In this paper	method	2K_dev_490
we describe current use patterns of six corporate accessibility teams and their users on Twitter	method	2K_dev_490
and present an analysis of these interactions	method	2K_dev_490
	method	2K_dev_490
While companies have started to engage with users on social media about accessibility	purpose	2K_dev_490
they differ greatly in terms of their approach and how well they support the ways in which their users want to engage	purpose	2K_dev_490
	purpose	2K_dev_490
We motivate the necessity of this framework in the context of self-driving technologies	background	2K_dev_491
and we believe that our frameworks for GPU programming are useful contributions given the increasing emphasis on parallel heterogeneous computing	background	2K_dev_491
	finding	2K_dev_491
In this paper	mechanism	2K_dev_491
we present two conceptual frameworks for GPU applications These frameworks enable smart GPU resource management when many applications share GPU resources while the workloads of those applications vary Application developers can explicitly adjust the number of GPU cores depending on their needs An implicit adjustment will be supported by a run-time framework	mechanism	2K_dev_491
which dynamically allocates the number of cores to tasks based on the total workload	mechanism	2K_dev_491
The runtime support of the proposed system can be realized using functions which measure the execution times of the tasks on GPU and change the number of GPU cores	mechanism	2K_dev_491
	method	2K_dev_491
to adjust their task execution times based on total workload	purpose	2K_dev_491
For very large dynamic networks	background	2K_dev_492
monitoring the behavior of a subset of agents provides an efficient framework for detecting changes in network topology In addition	background	2K_dev_492
we show how well-known tools in dynamic control systems may be useful for identifying abnormal events ; in particular	background	2K_dev_492
as a proof of concept	finding	2K_dev_492
In general	mechanism	2K_dev_492
we assume that the temporal behavior of a network agent is captured by a ( local ) dynamic state	mechanism	2K_dev_492
which may reflect either a physical property such as the number of connections or an abstract quantity such as opinions or beliefs	mechanism	2K_dev_492
Further	mechanism	2K_dev_492
assuming coupled linear inter-agent dynamics in which the local agent states evolve as weighted linear combinations of the neighboring agents ' states	mechanism	2K_dev_492
we focus on tracking network-wide agent dynamics	mechanism	2K_dev_492
Due to the large-scale nature of the problem	mechanism	2K_dev_492
directly monitoring data streams of the state dynamics for every individual agent is infeasible	mechanism	2K_dev_492
we propose a method that identifies a relatively small subset of agents whose state streams enable us Using structural properties of the coupled inter-agent dynamics	mechanism	2K_dev_492
we provide an algorithm	mechanism	2K_dev_492
which is polynomial in the number of agents	mechanism	2K_dev_492
we use a fault detection and isolation scheme	mechanism	2K_dev_492
	method	2K_dev_492
	method	2K_dev_492
Finally	method	2K_dev_492
we illustrate our method and algorithms in a small test network	method	2K_dev_492
For example	purpose	2K_dev_492
in mobile caller networks with millions of subscribers	purpose	2K_dev_492
we would like to monitor the dynamics of the smallest possible set of subscribers and still be able to infer abnormal events that occur over the entire network	purpose	2K_dev_492
To address this issue to reconstruct the dynamic state evolution of all the network agents at any given time and	purpose	2K_dev_492
simultaneously	purpose	2K_dev_492
detect agent departure events to identify a small subset of agents that ensures such network observability regardless of any agent leaving	purpose	2K_dev_492
to identify agent departures	purpose	2K_dev_492
	background	2K_dev_493
this method demonstrated promising results	finding	2K_dev_493
in terms of the accuracy of the initial detection accuracy and the reliability of the tracking	finding	2K_dev_493
	finding	2K_dev_493
This paper presents a computer vision algorithm	mechanism	2K_dev_493
by analyzing lane-marking detection results using an unscented Kalman filter To detect lateral and longitudinal lane-markings	mechanism	2K_dev_493
this method applies a spatial filter emphasizing the intensity contrast between lane-marking pixels and their neighboring pixels The authors then examine the detected lane-markings to identify perpendicular	mechanism	2K_dev_493
geometry layouts between longitudinal and lateral lane-markings for stop-line detection	mechanism	2K_dev_493
To provide reliable stop-line recognition	mechanism	2K_dev_493
the authors developed an unscented Kalman filter to track the detected stop-line over frames	mechanism	2K_dev_493
	mechanism	2K_dev_493
Through the tests with real-world	method	2K_dev_493
busy urban street videos	method	2K_dev_493
that detects stop-lines and tracks the detected stop-line over time	purpose	2K_dev_493
	background	2K_dev_494
results show significant performance improvements over the baseline methods by using the estimated ROI for action recognition	finding	2K_dev_494
	finding	2K_dev_494
we introduce a cognitive assistive system Being able to accurately recognize user operations is one of the most important functionalities of the proposed system	mechanism	2K_dev_494
However	mechanism	2K_dev_494
even though various action recognition algorithms have been proposed in recent years	mechanism	2K_dev_494
it is still unknown whether they are adequate for recognizing operations in using home medical devices	mechanism	2K_dev_494
Since the lack of the corresponding database is the main reason causing the situation	mechanism	2K_dev_494
at the first part of this paper	mechanism	2K_dev_494
we present a database specially designed for studying the use of home medical devices	mechanism	2K_dev_494
Then	mechanism	2K_dev_494
we evaluate the performance of the existing approaches on the proposed database	mechanism	2K_dev_494
Although using state-of-art approaches which have demonstrated near perfect performance in recognizing certain general human actions	mechanism	2K_dev_494
we observe significant performance drop when applying it to recognize device operations	mechanism	2K_dev_494
We conclude that the tiny action involved in using devices is one of the most important reasons leading to the performance decrease	mechanism	2K_dev_494
To accurately recognize tiny actions	mechanism	2K_dev_494
it 's critical to focus on where the target action happens	mechanism	2K_dev_494
namely the region of interest ( ROI ) and have more elaborate action modeling based on the ROI	mechanism	2K_dev_494
Therefore	mechanism	2K_dev_494
in the second part of this paper	mechanism	2K_dev_494
we introduce a simple but effective approach to estimating ROI for recognizing tiny actions	mechanism	2K_dev_494
The key idea of this method is to analyze the correlation between an action and the sub-regions of a frame	mechanism	2K_dev_494
The estimated ROI is then used as a filter for building more accurate action representations	mechanism	2K_dev_494
Experimental	method	2K_dev_494
Despite the popularity of home medical devices	purpose	2K_dev_494
serious safety concerns have been raised	purpose	2K_dev_494
because the use-errors of home medical devices have linked to a large number of fatal hazards	purpose	2K_dev_494
To resolve the problem	purpose	2K_dev_494
to automatically monitor the use of home medical devices	purpose	2K_dev_494
Given a real world graph	background	2K_dev_495
how should we lay-out its edges ? How can we compress it ? These questions are closely related	background	2K_dev_495
and the typical approach so far is to find clique-like communities	background	2K_dev_495
like the cavemen graph	background	2K_dev_495
and compress them	background	2K_dev_495
	background	2K_dev_495
we show that SlashBurn consistently outperforms other methods for all data sets	finding	2K_dev_495
resulting in better compression and faster running time	finding	2K_dev_495
Moreover	finding	2K_dev_495
we show that SlashBurn with the appropriate spokes ordering can further improve compression while hardly sacrificing the running time	finding	2K_dev_495
	finding	2K_dev_495
Based on the idea	mechanism	2K_dev_495
we propose the SlashBurn method to recursively split a graph into hubs and spokes connected only by the hubs	mechanism	2K_dev_495
We also propose techniques to select the hubs and give an ordering to the spokes	mechanism	2K_dev_495
in addition to the basic SlashBurn	mechanism	2K_dev_495
We give theoretical analysis of the proposed hub selection methods	mechanism	2K_dev_495
Our view point has several advantages : ( a ) it avoids the no good cuts problem	mechanism	2K_dev_495
( b ) it gives better compression	mechanism	2K_dev_495
and ( c ) it leads to faster execution times for matrix-vector operations	mechanism	2K_dev_495
which are the back-bone of most graph processing tools	mechanism	2K_dev_495
	mechanism	2K_dev_495
Through experiments	method	2K_dev_495
	method	2K_dev_495
We show that the block-diagonal mental image of the cavemen graph is the wrong paradigm	purpose	2K_dev_495
in full agreement with earlier results that real world graphs have no good cuts Instead	purpose	2K_dev_495
we propose to envision graphs as a collection of hubs connecting spokes	purpose	2K_dev_495
with super-hubs connecting the hubs	purpose	2K_dev_495
and so on	purpose	2K_dev_495
recursively	purpose	2K_dev_495
	purpose	2K_dev_495
	background	2K_dev_496
	finding	2K_dev_496
	mechanism	2K_dev_496
	method	2K_dev_496
	purpose	2K_dev_496
	background	2K_dev_497
	finding	2K_dev_497
We propose and study a new distributed Kalman filter algorithm The Network Tracking Capacity ( NTC ) of this algorithm depends only on the diffusion rate of the network and is independent of the local observation patterns	mechanism	2K_dev_497
only requiring global observability	mechanism	2K_dev_497
We analyze and compare the NTC for different network models	method	2K_dev_497
	method	2K_dev_497
that can track unstable dynamics with bounded mean-squared error ( MSE )	purpose	2K_dev_497
Big data has been becoming ubiquitous and applied in numerous fields recently	background	2K_dev_498
	background	2K_dev_498
Our method achieves very high classification accuracies in face recognition in the presence of occlusions It also outperforms the state of the art methods in object recognition It hence shows its applicability to general computer vision and pattern recognition problems show our distributed method achieves high speedup of 7	finding	2K_dev_498
85x with just 10 machine nodes and can gain even more with more computing resources	finding	2K_dev_498
we propose a new machine learning approach named Distributed Class-dependent Feature Analysis ( DCFA ) The classifier is based on the estimation of class-specific optimal filters	mechanism	2K_dev_498
by solving an i-norm optimization problem We demonstrate how this problem is solved using the Alternating Direction Method of Multipliers and also explore relevant convergency details	mechanism	2K_dev_498
More importantly	mechanism	2K_dev_498
our proposed framework can be efficiently implemented on a robust distributed framework	mechanism	2K_dev_498
Thus	mechanism	2K_dev_498
it improves both accuracy and computational time in large-scale databases	mechanism	2K_dev_498
on AR database on two challenging large-scale object databases	method	2K_dev_498
i	method	2K_dev_498
e	method	2K_dev_498
Caltech101 and Caltech256	method	2K_dev_498
In addition	method	2K_dev_498
computational time experiments on Caltech256 databases compared to the non-distributed version	method	2K_dev_498
The challenges to solve a large-scale machine learning problem in big data scenario generally lie in three aspects	purpose	2K_dev_498
Firstly	purpose	2K_dev_498
a proposed machine learning algorithm has to be appropriated for the distributed optimization problem	purpose	2K_dev_498
Secondly	purpose	2K_dev_498
it needs a platform for the distributed implementation	purpose	2K_dev_498
Finally	purpose	2K_dev_498
the communication delays different machines may cause problems in convergence even though the non-distributed algorithm shows a good convergence rate	purpose	2K_dev_498
In order to solve these challenges	purpose	2K_dev_498
	purpose	2K_dev_498
to combine the advantages of sparse representation in an over-complete dictionary	purpose	2K_dev_498
	purpose	2K_dev_498
	background	2K_dev_499
	finding	2K_dev_499
Our model is underpinned by two key concepts	mechanism	2K_dev_499
a structural graph model ( composite network ) and a viral propagation model ( SI 1 I 2 S )	mechanism	2K_dev_499
Using this framework	mechanism	2K_dev_499
we formulate a non-linear dynamic system and perform an eigenvalue analysis to identify the tipping point of the epidemic behavior Based on insights gained from this analysis	mechanism	2K_dev_499
we demonstrate an effective and accurate prediction method to determine viral dominance	mechanism	2K_dev_499
which we call the EigenPredictor	mechanism	2K_dev_499
	mechanism	2K_dev_499
Next	method	2K_dev_499
using a combination of synthetic and real composite networks	method	2K_dev_499
we evaluate the effectiveness of various viral suppression techniques by either a ) concurrently suppressing both memes or b ) unilaterally suppressing a single meme while leaving the other relatively unaffected	method	2K_dev_499
	method	2K_dev_499
In this paper	purpose	2K_dev_499
we study the intertwined propagation of two competing `` memes '' ( or data	purpose	2K_dev_499
rumors	purpose	2K_dev_499
etc	purpose	2K_dev_499
) in a composite network	purpose	2K_dev_499
Within the constraints of this scenario	purpose	2K_dev_499
we ask two key questions : ( a ) which meme will prevail ? and ( b ) can one influence the outcome of the propagations ?	purpose	2K_dev_499
The Gates Hillman prediction market ( GHPM ) was an internet prediction market designed to predict the opening day of the Gates and Hillman Centers	background	2K_dev_500
the new computer science complex at Carnegie Mellon University Unlike a traditional continuous double auction format	background	2K_dev_500
the GHPM was mediated by an automated market maker	background	2K_dev_500
a central agent responsible for pricing transactions with traders over the possible opening days	background	2K_dev_500
The GHPMs event partition was	background	2K_dev_500
at the time	background	2K_dev_500
the largest ever elicited in any prediction market by an order of magnitude	background	2K_dev_500
and dealing with the markets size required new advances	background	2K_dev_500
including a novel span-based elicitation interface that simplified interactions with the market maker	background	2K_dev_500
	finding	2K_dev_500
	mechanism	2K_dev_500
We use the large set of identity-linked trades generated by the GHPM	method	2K_dev_500
to examine issues of trader performance and market microstructure	purpose	2K_dev_500
including how the market both reacted to and anticipated official news releases about the buildings opening day	purpose	2K_dev_500
	purpose	2K_dev_500
Braincomputer interfaces ( BCIs ) are a promising technology for restoring motor ability to paralyzed patients	background	2K_dev_501
Spiking-based BCIs have successfully been used in clinical trials to control multi-degree-of-freedom robotic devices	background	2K_dev_501
Current implementations of these devices require a lengthy spike-sorting step	background	2K_dev_501
which is an obstacle to moving this technology from the lab to the clinic	background	2K_dev_501
Significance	background	2K_dev_501
Our results indicate that simple automated spike-sorting performs as well as the more computationally or manually intensive methods used here	background	2K_dev_501
Even basic spike-sorting adds value to the low-threshold waveform-crossing methods often employed in BCI decoding	background	2K_dev_501
	background	2K_dev_501
Main results no spikes should be discarded spike-sorting is useful a fast and simple method is competitive	finding	2K_dev_501
Decoding using the joint waveform and tuning model shows promise but is not consistently superior	finding	2K_dev_501
Approach We present a full analysis of the effects of spike-sorting schemes on decoding performance	mechanism	2K_dev_501
Specifically	mechanism	2K_dev_501
we compare how well two common decoders	mechanism	2K_dev_501
the optimal linear estimator and the Kalman filter	mechanism	2K_dev_501
reconstruct the arm movements of non-human primates performing reaching tasks	mechanism	2K_dev_501
when receiving input from various sorting schemes The schemes we tested included : using threshold crossings without spike-sorting ; expert-sorting discarding the noise ; expert-sorting	mechanism	2K_dev_501
including the noise as if it were another neuron ; and automatic spike-sorting using waveform features	mechanism	2K_dev_501
We also decoded from a joint statistical model for the waveforms and tuning curves	mechanism	2K_dev_501
which does not involve an explicit spike-sorting step	mechanism	2K_dev_501
	mechanism	2K_dev_501
Discarding the threshold crossings that can not be assigned to neurons degrades decoding Decoding based on spike-sorted units outperforms decoding based on electrodes voltage crossings The four waveform based spike-sorting methods tested here yield similar decoding efficiencies	method	2K_dev_501
Objective A viable alternative is to avoid spike-sorting	purpose	2K_dev_501
treating all threshold crossings of the voltage waveform on an electrode as coming from one putative neuron	purpose	2K_dev_501
It is not known	purpose	2K_dev_501
however	purpose	2K_dev_501
how much decoding information might be lost by ignoring spike identity	purpose	2K_dev_501
	purpose	2K_dev_501
A common approach in crowdsourcing is to break large tasks into small microtasks so that they can be parallelized across many crowd workers and so that redundant work can be more easily compared for quality control	background	2K_dev_502
	background	2K_dev_502
that non-sequential microtasks and the introduction of delays significantly decreases worker performance	finding	2K_dev_502
We show that interruptions where a large delay occurs between two related tasks can cause up to a 102 % slowdown in completion time	finding	2K_dev_502
and interruptions where workers are asked to perform different tasks in sequence can slow down completion time by 57 %	finding	2K_dev_502
We conclude with a set of design guidelines and instructions for implementing these changes in existing interfaces for crowd work	mechanism	2K_dev_502
	mechanism	2K_dev_502
In this paper	method	2K_dev_502
we demonstrate in a study of 338 crowd workers	method	2K_dev_502
In practice	purpose	2K_dev_502
this can result in the microtasks being presented out of their natural order and often introduces delays between individual microtasks to improve both worker performance and realized pay	purpose	2K_dev_502
	purpose	2K_dev_502
	background	2K_dev_503
	finding	2K_dev_503
We describe a new algorithm The running time of our algorithm is $ $ O ( f \log n \log \varDelta ) $ $ O ( flognlog ) where $ $ f $ $ f is the output complexity of the Voronoi diagram and $ $ \varDelta $ $ is the spread of the input	mechanism	2K_dev_503
the ratio of largest to smallest pairwise distances Despite the simplicity of the algorithm and its analysis	mechanism	2K_dev_503
it improves on the state of the art for all inputs with polynomial spread and near-linear output size	mechanism	2K_dev_503
The key idea is to first build the Voronoi diagram of a superset of the input points using ideas from Voronoi refinement mesh generation	mechanism	2K_dev_503
Then	mechanism	2K_dev_503
the extra points are removed in a straightforward way that allows the total work to be bounded in terms of the output complexity	mechanism	2K_dev_503
yielding the output sensitive bound	mechanism	2K_dev_503
The removal only involves local flips and is inspired by kinetic data structures	mechanism	2K_dev_503
	method	2K_dev_503
for computing the Voronoi diagram of a set of $ $ n $ $ n points in constant-dimensional Euclidean space	purpose	2K_dev_503
	background	2K_dev_504
We prove our results we prove the result for general networks	finding	2K_dev_504
( ODE ) that models the dynamics of bi-virus epidemics over bilayer networks	mechanism	2K_dev_504
Each layer is a weighted digraph associated with a strain of virus ; the weights $ \gamma ^ { z } _ { ij } $ represent the rates of infection from node $ i $ to node $ j $ of strain $ z $	mechanism	2K_dev_504
We establish a sufficient condition on the $ \gamma $ s that guarantees survival of the fittestonly one strain survives	mechanism	2K_dev_504
We propose an ordering of the weighted digraphs	mechanism	2K_dev_504
the $ \star $ -order	mechanism	2K_dev_504
and show that if the weighted digraph of strain $ y $ is $ \star $ -dominated by the weighted digraph of strain $ x $	mechanism	2K_dev_504
then $ y $ dies out in the long run	mechanism	2K_dev_504
We prove that the orbits of the ODE accumulate to an attractor that captures the survival of the fittest phenomenon	mechanism	2K_dev_504
Due to the coupled nonlinear high-dimension nature of the ODEs	mechanism	2K_dev_504
there is no natural Lyapunov function to study their global qualitative behavior	mechanism	2K_dev_504
	mechanism	2K_dev_504
by combining two important properties of these ODEs : ( i ) monotonicity under a partial ordering on the set of graphs ; and ( ii ) dimension-reduction under symmetry of the graphs	method	2K_dev_504
Property ( ii ) allows us to fully address the survival of the fittest for regular graphs	method	2K_dev_504
Then	method	2K_dev_504
by bounding the epidemics dynamics for generic networks by the dynamics on regular networks	method	2K_dev_504
	method	2K_dev_504
The paper studies the qualitative behavior of a set of ordinary differential equations	purpose	2K_dev_504
The Internet of Things ( IoT ) offers the promise of integrating the digital world of the Internet with the physical world in which we live	background	2K_dev_505
	background	2K_dev_505
	finding	2K_dev_505
This paper reports the design and development of an open community-oriented platform aiming	mechanism	2K_dev_505
featuring interoperability and reusability of heterogeneous sensor data and data services The concepts of virtual sensors and virtual devices are identified as central autonomic units to model scalable and context-aware configurable/reconfigurable sensor data and services The decoupling of the storage and management of sensor data and platform-oriented metadata enables the handling of both discrete and streaming sensor data	mechanism	2K_dev_505
	mechanism	2K_dev_505
A cloud computing-empowered prototyping system has been established as a proof of concept to host smart community-oriented sensor data and services	method	2K_dev_505
But realizing this promise necessitates a systematic approach to integrating the sensors	purpose	2K_dev_505
actuators	purpose	2K_dev_505
and information on which they operate into the Internet we know today to support federated sensor data as a service	purpose	2K_dev_505
	background	2K_dev_506
	finding	2K_dev_506
	mechanism	2K_dev_506
	method	2K_dev_506
	purpose	2K_dev_506
	background	2K_dev_507
has an approximation ratio of 3/2 to the maximum cardinality matching	finding	2K_dev_507
This is an improvement over a recent upper bound of 2 ( Ashlagi et al	finding	2K_dev_507
	finding	2K_dev_507
2010 2 ] ) and	finding	2K_dev_507
furthermore	finding	2K_dev_507
our mechanism beats for the first time the lower bound on the approximation ratio of deterministic truthful mechanisms We complement our positive result with new lower bounds	finding	2K_dev_507
Among other statements	finding	2K_dev_507
we prove that the weaker incentive compatibility property of truthfulness in expectation in our mechanism is necessary ; universally truthful mechanisms that have an inclusion-maximality property have an approximation ratio of at least 2	finding	2K_dev_507
We study a mechanism design version of matching computation in graphs that models We present a new randomized matching mechanism for two agents which is truthful in expectation and	mechanism	2K_dev_507
	method	2K_dev_507
the game played by hospitals participating in pairwise kidney exchange programs	purpose	2K_dev_507
	purpose	2K_dev_507
Self-powered systems that interact with the physical world require computing platforms with predictable timing behavior and a low energy demand	background	2K_dev_508
	background	2K_dev_508
we expose the hardware characteristics that violate assumptions of conventional energy models Our analysis shows that neither balancing the load nor assigning all load to the `` cheapest '' core is the best load distribution strategy	finding	2K_dev_508
unless the cores are extremely alike or extremely different	finding	2K_dev_508
We leverage the state-of-the-art in hardware design by adopting Heterogeneous Multi-core Processors with support for Dynamic Voltage and Frequency Scaling and Dynamic Power Management and propose a revised model suitable We then address the problem of allocating real-time software components onto heterogeneous cores such that total energy is minimized	mechanism	2K_dev_508
Our approach is to start from an analytically justified target load distribution and find a task assignment heuristic that approximates it	mechanism	2K_dev_508
The optimal load distribution is then formulated as a solution to a convex optimization problem A heuristic that approximates this load distribution and an alternative method that leverages the solution explicitly are proposed as viable task assignment methods	mechanism	2K_dev_508
	mechanism	2K_dev_508
Through experiments on one such platform The proposed methods are compared to state-of-the-art on simulated problem instances and in a case study of a soft-real-time application on an off-the-shelf ARM big	method	2K_dev_508
LITTLE heterogeneous processor	method	2K_dev_508
	method	2K_dev_508
Energy consumption can be reduced by choosing energy-efficient designs for both hardware and software components of the platform	purpose	2K_dev_508
for identifying the energy-efficient frequency range	purpose	2K_dev_508
	purpose	2K_dev_508
Poor posture and incorrect muscle usage are a leading cause of many injuries in sports and fitness	background	2K_dev_509
For this reason	background	2K_dev_509
non- invasive	background	2K_dev_509
fine-grained sensing and monitoring of human motion and muscles is important for mitigating injury and improving fitness efficacy	background	2K_dev_509
Current sensing systems either de- pend on invasive techniques or unscalable approaches whose accuracy is highly dependent on body sensor placement	background	2K_dev_509
	background	2K_dev_509
the system achieves greater than 95 % accuracy in identifying muscle groups	finding	2K_dev_509
	finding	2K_dev_509
We present MARS	mechanism	2K_dev_509
a system that by only using unobtrusive	mechanism	2K_dev_509
non-invasive in- ertial sensors MARS not only accurately senses and recreates human motion down to the muscles	mechanism	2K_dev_509
but also allows for fast personalized system setup by determining the individual identities of the instrumented muscles	mechanism	2K_dev_509
obtained with minimal system training	mechanism	2K_dev_509
	mechanism	2K_dev_509
In a real world human study con- ducted to evaluate MARS	method	2K_dev_509
	method	2K_dev_509
As a result these systems are not suitable for use in active sports or fitness training where sensing needs to be scalable	purpose	2K_dev_509
accurate and un-inhibitive to the activity being performed	purpose	2K_dev_509
detects both body motion and individual muscle group activity during physical human activity	purpose	2K_dev_509
The openness of wireless communication and the recent development of software-defined radio technology	background	2K_dev_510
respectively	background	2K_dev_510
provide a low barrier and a wide range of capabilities for misbehavior	background	2K_dev_510
attacks	background	2K_dev_510
and defenses against attacks	background	2K_dev_510
	background	2K_dev_510
Matching our intuition	finding	2K_dev_510
the aggressiveness of an attacker is related to how much of a discount is placed on data delay	finding	2K_dev_510
This results in the defender often choosing to sleep despite the latency implication	finding	2K_dev_510
because the threat of jamming is high	finding	2K_dev_510
We also present several other findings	finding	2K_dev_510
In this work we present finite-energy jamming games	mechanism	2K_dev_510
a game model We also allow the jammer A major addition in finite-energy jamming games is that the jammer and sender both have a limited amount of energy which is drained according to the actions a player takes We develop a model of our system as a zero-sum finite-horizon stochastic game with deterministic transitions	mechanism	2K_dev_510
We leverage the zero-sum and finite-horizon properties of our model to design a simple polynomial-time algorithm to compute optimal randomized strategies for both players	mechanism	2K_dev_510
The utility function of our game model can be decoupled into a recursive equation	mechanism	2K_dev_510
Our algorithm exploits this fact to use dynamic programming to construct solutions in a bottom-up fashion	mechanism	2K_dev_510
For each state of energy levels	mechanism	2K_dev_510
a linear program is solved to find Nash equilibrium strategies for the subgame	mechanism	2K_dev_510
With these techniques	mechanism	2K_dev_510
our algorithm has only a linear dependence on the number of states	mechanism	2K_dev_510
and quadratic dependence on the number of actions	mechanism	2K_dev_510
allowing us to solve very large instances	mechanism	2K_dev_510
By computing Nash equilibria for our game models	mechanism	2K_dev_510
we explore what kind of performance guarantees can be achieved both for the sender and jammer	mechanism	2K_dev_510
when playing against an optimal opponent	mechanism	2K_dev_510
We also use the optimal strategies to simulate finite-energy jamming games and provide insights into robust communication among reconfigurable	mechanism	2K_dev_510
yet energy-limited	mechanism	2K_dev_510
radio systems	mechanism	2K_dev_510
	mechanism	2K_dev_510
To test the performance of the optimal strategies we compare their performance with a random and adaptive strategy from simulations where we vary the strategies for one or both of the players	method	2K_dev_510
that allows a jammer and sender to choose ( 1 ) whether to transmit or sleep	purpose	2K_dev_510
( 2 ) a power level to transmit with	purpose	2K_dev_510
and ( 3 ) what channel to transmit on	purpose	2K_dev_510
to choose on how many channels it simultaneously attacks	purpose	2K_dev_510
Multimedia event detection ( MED ) and multimedia event recounting ( MER ) are fundamental tasks in managing large amounts of unconstrained web videos	background	2K_dev_511
and have attracted a lot of attention in recent years	background	2K_dev_511
	background	2K_dev_511
and obtain very promising results for both MED and MER	finding	2K_dev_511
we propose a joint framework that simultaneously detects high-level events and localizes the indicative concepts of the events	mechanism	2K_dev_511
Our premise is that a good recounting algorithm should not only explain the detection result	mechanism	2K_dev_511
but should also be able to assist detection in the first place	mechanism	2K_dev_511
Coupled in a joint optimization framework	mechanism	2K_dev_511
recounting improves detection by pruning irrelevant noisy concepts while detection directs recounting to the most discriminative evidences	mechanism	2K_dev_511
To better utilize the powerful and interpretable semantic video representation	mechanism	2K_dev_511
we segment each video into several shots and exploit the rich temporal structures at shot level	mechanism	2K_dev_511
The consequent computational challenge is carefully addressed through a significant improvement of the current ADMM algorithm	mechanism	2K_dev_511
which	mechanism	2K_dev_511
after eliminating all inner loops and equipping novel closed-form solutions for all intermediate steps	mechanism	2K_dev_511
enables us to efficiently process extremely large video corpora	mechanism	2K_dev_511
We test the proposed method on the large scale TRECVID MEDTest 2014 and MEDTest 2013 datasets	method	2K_dev_511
Most existing systems perform MER as a post-processing step on top of the MED results	purpose	2K_dev_511
In order to leverage the mutual benefits of the two tasks	purpose	2K_dev_511
Despite persistent effort	background	2K_dev_512
many web pages are still not accessible to everyone	background	2K_dev_512
	background	2K_dev_512
We also present our user study results where web developers who had varying knowledge of web accessibility all found our system an effective and interesting platform to learning web accessibility	finding	2K_dev_512
	finding	2K_dev_512
In this paper	mechanism	2K_dev_512
we present the design	mechanism	2K_dev_512
development and study of CAN ( Composable Accessibility Infrastructure )	mechanism	2K_dev_512
a crowdsourcing infrastructure that collects web accessibility issues and their fixes	mechanism	2K_dev_512
dynamically composes solutions on-the-fly	mechanism	2K_dev_512
and delivers the crowd-sourced content as teaching materials Our unique CAN user interaction and system design enables end users with disabilities to both benefit from and contribute to the system without additional effort in their daily web browsing	mechanism	2K_dev_512
and allows web developers to experience real accessibility issues and initiate a learning process with first-hand materials CAN also provides an opportunity for data-driven discovery of the common implementation practices that cause accessibility issues	mechanism	2K_dev_512
We show how CAN addresses a set of accessibility issues on the top 100 popular websites	method	2K_dev_512
	method	2K_dev_512
Fixing web accessibility problems can be complicated	purpose	2K_dev_512
Developers need to have extensive knowledge not only of possible accessibility problems but also of approaches for fixing them	purpose	2K_dev_512
This paper is about using the large number of accessibility issues on real websites and crowd-sourced fixes for them as a unique source of learning materials for web developers to learn how to build accessible components in a cost-efficient manner	purpose	2K_dev_512
	background	2K_dev_513
	finding	2K_dev_513
	mechanism	2K_dev_513
	method	2K_dev_513
	purpose	2K_dev_513
If the people belong to multiple online communities	background	2K_dev_514
their joint membership can influence the survival of each of the communities to which they belong	background	2K_dev_514
Communities with many joint memberships may struggle to get enough of their members ' time and attention	background	2K_dev_514
but find it easy to import best practices from other communities	background	2K_dev_514
Our contributions are two-fold	background	2K_dev_514
Theoretically	background	2K_dev_514
by examining the impact of membership overlap on the survival of online communities we identified an important mechanism underlying the success of online communities	background	2K_dev_514
Practically	background	2K_dev_514
our findings may guide community creators on how to effectively manage their members	background	2K_dev_514
and tool designers on how to support this task	background	2K_dev_514
	finding	2K_dev_514
we find that higher levels of membership overlap are positively associated with higher survival rates of online communities	finding	2K_dev_514
Furthermore	finding	2K_dev_514
we find that it is beneficial for young communities to have shared members who play a central role in other mature communities	finding	2K_dev_514
	finding	2K_dev_514
	mechanism	2K_dev_514
By analyzing the historical data of 5673 Wikia communities	method	2K_dev_514
In this paper	purpose	2K_dev_514
we study the effects of membership overlap on the survival of online communities	purpose	2K_dev_514
	purpose	2K_dev_514
	background	2K_dev_515
	finding	2K_dev_515
	mechanism	2K_dev_515
	method	2K_dev_515
	purpose	2K_dev_515
	background	2K_dev_516
	finding	2K_dev_516
	mechanism	2K_dev_516
	method	2K_dev_516
	purpose	2K_dev_516
	background	2K_dev_517
	finding	2K_dev_517
We demonstrate the Acoustic Location Processing System ( ALPS )	mechanism	2K_dev_517
a platform that augments BLE proximity beacons with ultrasonic transmitters in a manner { \em ALPS } uses Time-Difference-Of-Arrival ( TDOA ) and Time-Of-Flight ( TOF ) ranging to accurately localize mobile devices such as off-the-shelf smartphones and tablets in 2D space	mechanism	2K_dev_517
Users inside the demo area will be able to determine their location and can directly plot it relatively to a map of the area using our app Once a receiving device has determined its initial position	mechanism	2K_dev_517
it can synchronize its audio clock with the transmission infrastructure to perform TOF-based localization	mechanism	2K_dev_517
which provides similar position accuracy to TDOA based localization with fewer beacons	mechanism	2K_dev_517
Multilateration and trilateration processing for each device 's location is offloaded onto a cloud-based solver that can provide localization as a service to ALPS and similar TOF/TDOA based systems	mechanism	2K_dev_517
	method	2K_dev_517
that allows for precise and robust indoor localization	purpose	2K_dev_517
	purpose	2K_dev_517
These results suggest that the instantaneous details of single-trial movement speed are difficult to extract using commonly assumed coding schemes	background	2K_dev_518
This apparent paucity of speed information takes particular importance in the context of brain-machine interfaces ( BMIs )	background	2K_dev_518
which rely on extracting kinematic information from motor cortex Previous studies have highlighted subjects ' difficulties in holding a BMI cursor stable at targets	background	2K_dev_518
These studies	background	2K_dev_518
along with our finding of relatively little speed information in motor cortex	background	2K_dev_518
BMI systems enabling stable stops will be more effective and user-friendly when translated into clinical applications	background	2K_dev_518
	background	2K_dev_518
we found that single units carry relatively little speed-related information compared with direction-related information This result is not mitigated at the population level : simultaneously recorded population activity predicted speed with significantly lower accuracy relative to direction predictions revealed that speed accuracy would likely remain lower than direction accuracy	finding	2K_dev_518
even given larger populations	finding	2K_dev_518
SDKF improved success rates by a factor of 1	finding	2K_dev_518
7 relative to a standard Kalman filter in a closed-loop BMI task requiring stable stops at targets	finding	2K_dev_518
	finding	2K_dev_518
inspired a speed-dampening Kalman filter ( SDKF ) that automatically slows the cursor upon detecting changes in decoded movement direction Effectively	mechanism	2K_dev_518
SDKF by using prevalent directional signals	mechanism	2K_dev_518
rather than requiring speed to be directly decoded from neural activity	mechanism	2K_dev_518
Using information theoretic techniques	method	2K_dev_518
Furthermore	method	2K_dev_518
a unit-dropping analysis	method	2K_dev_518
Motor cortex plays a substantial role in driving movement	purpose	2K_dev_518
yet the details underlying this control remain unresolved We analyzed the extent to which movement-related information could be extracted from single-trial motor cortical activity recorded while monkeys performed center-out reaching enhances speed control	purpose	2K_dev_518
Traditional hard real-time scheduling algorithms require the use of the worst-case execution times to guarantee that deadlines will be met	background	2K_dev_519
	background	2K_dev_519
showing that ZS-QRAM is able to obtain 4 as much UDR as ZSRM	finding	2K_dev_519
a previous overbooking approach	finding	2K_dev_519
and almost 2 as much UDR as Rate-Monotonic with Period Transformation ( RM/TP We show that	finding	2K_dev_519
by using our approach	finding	2K_dev_519
we are able to keep the tasks that render the most utility by degrading lower-utility ones even in the presence of highly dynamic execution times	finding	2K_dev_519
In this article	mechanism	2K_dev_519
we present ZS-QRAM	mechanism	2K_dev_519
a scheduling approach that enables the use of flexible execution times and application-derived utility to tasks in order In particular	mechanism	2K_dev_519
we provide a detailed description of the algorithm	mechanism	2K_dev_519
the formal proofs for its temporal protection	mechanism	2K_dev_519
and a detailed	mechanism	2K_dev_519
evaluation	mechanism	2K_dev_519
	mechanism	2K_dev_519
Our evaluation uses the Utility Degradation Resilience ( UDR ) We then evaluate a Linux kernel module implementation of our scheduler on an Unmanned Air Vehicle ( UAV ) platform	method	2K_dev_519
Unfortunately	purpose	2K_dev_519
many algorithms with parameters derived from sensing the physical world suffer large variations in execution time	purpose	2K_dev_519
leading to pessimistic overall utilization	purpose	2K_dev_519
such as visual recognition tasks to maximize total system utility	purpose	2K_dev_519
	purpose	2K_dev_519
Complex events essentially include human	background	2K_dev_520
scenes	background	2K_dev_520
objects and actions that can be summarized by visual attributes	background	2K_dev_520
so leveraging relevant attributes properly could be helpful for event detection	background	2K_dev_520
Many works have exploited attributes at image level for various applications	background	2K_dev_520
	background	2K_dev_520
validate the efficacy of the proposed approach	finding	2K_dev_520
Hence	mechanism	2K_dev_520
we propose to leverage attributes at video level ( named as video attributes in this work )	mechanism	2K_dev_520
i	mechanism	2K_dev_520
e	mechanism	2K_dev_520
	mechanism	2K_dev_520
the semantic labels of external videos are used as attributes	mechanism	2K_dev_520
Compared to complex event videos	mechanism	2K_dev_520
these external videos contain simple contents such as objects	mechanism	2K_dev_520
scenes and actions which are the basic elements of complex events	mechanism	2K_dev_520
Specifically	mechanism	2K_dev_520
building upon a correlation vector which correlates the attributes and the complex event	mechanism	2K_dev_520
we incorporate video attributes latently as extra informative cues into the event detector learnt from complex event videos	mechanism	2K_dev_520
	mechanism	2K_dev_520
Extensive experiments on a real-world large-scale dataset	method	2K_dev_520
However	purpose	2K_dev_520
attributes at image level are possibly insufficient for complex event detection in videos due to their limited capability in characterizing the dynamic properties of video data	purpose	2K_dev_520
	purpose	2K_dev_520
Traditional power system state estimation methods lack the ability to track and manage increasing uncertainties inherent in the new technologies	background	2K_dev_521
such as recent and ongoing massive penetration of renewable energy	background	2K_dev_521
distribution intelligence	background	2K_dev_521
and plug-in electric vehicles	background	2K_dev_521
To deal with the inability	background	2K_dev_521
a recent work proposes to utilize the unused historical data for power system state estimation First	background	2K_dev_521
because the power systems are with periodic patterns	background	2K_dev_521
which create clustered measurement data	background	2K_dev_521
results show that the new method can dramatically reduce the necessary computational time for online data-driven state estimation	finding	2K_dev_521
while producing a highly accurate state estimate	finding	2K_dev_521
	finding	2K_dev_521
dimension reduction is proposed	mechanism	2K_dev_521
but still able to retrieve similar measurements the k-dimensional tree indexing approach is employed in step two resulting in a log-reduction over searching time	mechanism	2K_dev_521
	mechanism	2K_dev_521
Finally	method	2K_dev_521
we verify the obtained historical power system states via AC power system model and the current measurements to filter out bad historical data	method	2K_dev_521
Simulation	method	2K_dev_521
Although able to achieve much higher accuracy	purpose	2K_dev_521
the new approach is slow due to the burden by sequential similarity check over large volumes of high dimensional historical measurements	purpose	2K_dev_521
making it unsuitable for online services	purpose	2K_dev_521
This calls for a general approach to preprocess the historical data	purpose	2K_dev_521
In this paper	purpose	2K_dev_521
we propose to achieve such a goal with three steps	purpose	2K_dev_521
to remove redundancy To further reduce the computational time to group the clustered power system data into a tree structure	purpose	2K_dev_521
	purpose	2K_dev_521
	background	2K_dev_522
	finding	2K_dev_522
	mechanism	2K_dev_522
	method	2K_dev_522
	purpose	2K_dev_522
The Internet of Things ( IoT ) aims to integrate the digital world of the Internet with our encompassing physical world	background	2K_dev_523
	background	2K_dev_523
	finding	2K_dev_523
This paper reports our on-going work developing a sensor service federation and provisioning infrastructure novel approach has been presented to build social sensor networks A two-way publish/subscribe pattern on top of a message bus is established Workflow provenance is carried by a dynamic virtual device concept that we have introduced	mechanism	2K_dev_523
	mechanism	2K_dev_523
A case study is reported A case study is reported	method	2K_dev_523
However	purpose	2K_dev_523
existing IoT lacks to provide considerate services	purpose	2K_dev_523
meaning that sensors dynamically `` collaborate '' to provide context-aware federated sensor data	purpose	2K_dev_523
to record and study historical interaction patterns among sensors	purpose	2K_dev_523
to leverage in-memory database to monitor and manage real-time sensor service provisioning	purpose	2K_dev_523
to assure scalability of sensor service communication	purpose	2K_dev_523
to leverage in-memory database to monitor and manage real-time sensor service provisioning	purpose	2K_dev_523
A key idea in object-oriented programming is that objects encapsulate state and interact with each other by message exchange This perspective suggests a model of computation that is inherently concurrent ( to facilitate simultaneous message exchange ) and that accounts for the effect of message exchange on an object 's state ( to express valid sequences of state transitions )	background	2K_dev_524
we show that our language supports the typical patterns of object-oriented programming ( e	finding	2K_dev_524
g	finding	2K_dev_524
	finding	2K_dev_524
encapsulation	finding	2K_dev_524
dynamic dispatch	finding	2K_dev_524
and subtyping ) while guaranteeing session fidelity in a concurrent setting In addition	finding	2K_dev_524
we show that our language facilitates new forms of expression ( e	finding	2K_dev_524
g	finding	2K_dev_524
	finding	2K_dev_524
type-directed reuse	finding	2K_dev_524
internal choice )	finding	2K_dev_524
which are not available in current object-oriented languages	finding	2K_dev_524
	finding	2K_dev_524
We introduce an object-oriented programming language that has processes as its only objects and employs linear session types	mechanism	2K_dev_524
Based on various examples We have implemented our language in a prototype compiler	method	2K_dev_524
In this paper we show that such a model of computation arises naturally from session-based communication to express the protocols of message exchange and to reason about concurrency and state	purpose	2K_dev_524
	purpose	2K_dev_524
The Pascaline was the first working mechanical calculator	background	2K_dev_525
created in 1642 by the French polymath Blaise Pascal	background	2K_dev_525
Over the next two decades Pascal built 40 of these machines	background	2K_dev_525
of which nine survive today	background	2K_dev_525
Several good web resources describe the Pascaline	background	2K_dev_525
but to properly appreciate the sautoir	background	2K_dev_525
Pascal 's kinetic energy solution to jam-free ripple carry	background	2K_dev_525
building a working replica is invaluable	background	2K_dev_525
The Pascaline kit	finding	2K_dev_525
designed in SolidWorks	finding	2K_dev_525
is open source and available at http : //www	finding	2K_dev_525
cs	finding	2K_dev_525
cmu	finding	2K_dev_525
edu/~dst/Pascaline	finding	2K_dev_525
I 've created a Pascaline kit using laser-cut acrylic and standard fasteners that can be assembled with just a screwdriver	mechanism	2K_dev_525
pliers	mechanism	2K_dev_525
and Loctite High school or college students with minimal skills can put it together in a few hours and have a functioning calculator	mechanism	2K_dev_525
Exploring the Pascaline 's design is an engaging way to connect a milestone in the early history of computing with more modern theoretical concepts	mechanism	2K_dev_525
Students can investigate questions such as : What makes a device `` digital '' ? ( Slide rules have numeric scales but are analog devices	mechanism	2K_dev_525
) How does nonlinearity produce discrete states in a continuous world ? How are nonlinearities induced in the Pascaline vs	mechanism	2K_dev_525
in digital electronics ? How do the logic design concepts `` half adder '' and `` full adder '' map onto the components of the Pascaline ? Is the Pascaline really adding	mechanism	2K_dev_525
or merely counting ? How does the Pascaline use nines complement arithmetic to perform subtraction	mechanism	2K_dev_525
and why is n't it tens complement ?	mechanism	2K_dev_525
	method	2K_dev_525
Thanks to the growing availability of rapid prototyping tools	purpose	2K_dev_525
it has become relatively easy for CS educators to fabricate physical artifacts to help students explore computational ideas	purpose	2K_dev_525
	purpose	2K_dev_525
User review is a crucial component of open mobile app markets such as the Google Play Store	background	2K_dev_526
How do we automatically summarize millions of user reviews and make sense out of them ? We discuss how the techniques presented herein can be deployed to help a mobile app market operator such as Google as well as individual app developers and end-users	background	2K_dev_526
Results using our techniques are reported	finding	2K_dev_526
In this paper	mechanism	2K_dev_526
we propose Wiscom	mechanism	2K_dev_526
a system that can analyze tens of millions user ratings and comments in mobile app markets at three different levels of detail	mechanism	2K_dev_526
Our system is able to ( a ) discover inconsistencies in reviews ; ( b ) identify reasons why users like or dislike a given app	mechanism	2K_dev_526
and provide an interactive	mechanism	2K_dev_526
zoomable view of how users ' reviews evolve over time ; and ( c ) provide valuable insights into the entire app market	mechanism	2K_dev_526
identifying users ' major concerns and preferences of different types of apps	mechanism	2K_dev_526
	mechanism	2K_dev_526
on a 32GB dataset consisting of over 13 million user reviews of 171	method	2K_dev_526
493 Android apps in the Google Play Store	method	2K_dev_526
	method	2K_dev_526
Unfortunately	purpose	2K_dev_526
beyond simple summaries such as histograms of user ratings	purpose	2K_dev_526
there are few analytic tools that can provide insights into user reviews	purpose	2K_dev_526
In an effort to address persistent consumer privacy concerns	background	2K_dev_527
policy makers and the data industry seem to have found common grounds in proposals that aim at making online privacy more `` transparent	background	2K_dev_527
'' Such self-regulatory approaches rely on	background	2K_dev_527
among other things	background	2K_dev_527
providing more and better information to users of Internet services about how their data is used These findings cast doubts on the likelihood of initiatives predicated around notices and transparency to address	background	2K_dev_527
by themselves	background	2K_dev_527
online privacy concerns	background	2K_dev_527
	background	2K_dev_527
we demonstrate that the impact of privacy notices on disclosure is sensitive to relative judgments	finding	2K_dev_527
even when the objective risks of disclosure actually stay constant	finding	2K_dev_527
we show that the impact of privacy notices on disclosure can be muted by introducing simple misdirections that do not alter the objective risk of disclosure	finding	2K_dev_527
	finding	2K_dev_527
	mechanism	2K_dev_527
in a series of experiments In a first experiment	method	2K_dev_527
In a second experiment	method	2K_dev_527
	method	2K_dev_527
However	purpose	2K_dev_527
we illustrate that even simple privacy notices do not consistently impact disclosure behavior	purpose	2K_dev_527
and may in fact be used to nudge individuals to disclose variable amounts of personal information	purpose	2K_dev_527
	purpose	2K_dev_527
The commoditization of wireless sensing systems makes it feasible to include BAS functionality in small and medium-sized buildings	background	2K_dev_528
	background	2K_dev_528
	finding	2K_dev_528
In this demo we introduce a platform called Mortar	mechanism	2K_dev_528
io	mechanism	2K_dev_528
which Unlike cloud-reliant systems	mechanism	2K_dev_528
Mortar	mechanism	2K_dev_528
io distributes storage and control functionality across end devices making it robust to network and internet outages The system	mechanism	2K_dev_528
once initialized	mechanism	2K_dev_528
can run autonomously on a low-cost controller within a building or connect to the cloud for remote monitoring and configuration	mechanism	2K_dev_528
We will also show our efficient multi-resolution data store that buffers data locally and replicates aggregate data across devices for reliability	mechanism	2K_dev_528
A publish-subscribe model built on top of XMPP is used for messaging with per-device access control and a transducer schema	mechanism	2K_dev_528
Finally	mechanism	2K_dev_528
a web portal provides an interface to monitor and schedule lighting	mechanism	2K_dev_528
plug-loads	mechanism	2K_dev_528
environmental sensors and HVAC from a single uniform interface	mechanism	2K_dev_528
	mechanism	2K_dev_528
	method	2K_dev_528
The configuration complexity and cost of installation is now the dominant barrier to adoption focuses on ease-of-installation	purpose	2K_dev_528
secure configuration	purpose	2K_dev_528
and management of BAS sub-systems in a manner that can scale from small to large installations	purpose	2K_dev_528
	purpose	2K_dev_528
ApplianceReader broadly demonstrates the potential of hybrid approaches that combine human and machine intelligence to effectively realize intelligent	background	2K_dev_529
interactive access technology today	background	2K_dev_529
	finding	2K_dev_529
we present ApplianceReader - a system that combines a wearable point-of-view camera with on-demand crowdsourcing and computer vision ApplianceReader sends photos of appliance interfaces that it has not seen previously to the crowd	mechanism	2K_dev_529
who work in parallel to quickly label and describe elements of the interface	mechanism	2K_dev_529
Computer vision techniques then track the user 's finger pointing at the controls and read out the labels previously provided by the crowd This enables visually impaired users to interactively explore and use appliances without asking the crowd repetitively	mechanism	2K_dev_529
	method	2K_dev_529
Visually impaired people can struggle to use everyday appliances with inaccessible control panels	purpose	2K_dev_529
To address this problem	purpose	2K_dev_529
to make appliance interfaces accessible	purpose	2K_dev_529
	purpose	2K_dev_529
Advances in real-time	background	2K_dev_530
embedded and distributed systems along with control and communication theory have catalyzed the rapid emergence of cyber-physical systems such as a self-driving car The importance of fault-tolerance support on a cyber-physical system ( CPS ) has been greatly emphasized by recent research due to the nature of CPS that senses its surroundings	background	2K_dev_530
processes sensor data	background	2K_dev_530
and reacts using its actuators	background	2K_dev_530
In order to tackle this challenge	background	2K_dev_530
we proposed SAFER ( System-level Architecture for Failure Evasion in Real-time Applications ) in our previous work	background	2K_dev_530
SAFER is able to tolerate fail-stop processor and/or task failures for distributed embedded real-time systems	background	2K_dev_530
	finding	2K_dev_530
This paper provides a method by ( 1 ) deploying a small piece of hardware to avoid a dedicated connection between a processor and an actuator	mechanism	2K_dev_530
( 2 ) adding a software module that monitors and controls the hardware	mechanism	2K_dev_530
and ( 3 ) enhancing the failure detection and recovery mechanisms of SAFER to support these changes	mechanism	2K_dev_530
The detailed implementation and evaluation of the SAFER extension is on-going work	method	2K_dev_530
	method	2K_dev_530
One of its limitations	purpose	2K_dev_530
however	purpose	2K_dev_530
is that SAFER is not capable of tolerating a failure of a processor with a dedicated connection to an actuator	purpose	2K_dev_530
that relaxes this limitation	purpose	2K_dev_530
Behavioral coding is a common technique in the social sciences and human computer interaction for extracting meaning from video data [ 3 Rapid coding allows participants to have a `` conversation with their data '' to rapidly develop and refine research hypotheses in ways not previously possible	background	2K_dev_531
	background	2K_dev_531
We show that Glance can accurately code events in video in a fraction of the time it would take a single person showing that Glance is able to code 80 % of an hour-long video in just 5 minutes	finding	2K_dev_531
	finding	2K_dev_531
We present Glance	mechanism	2K_dev_531
a tool Glance uses the crowd to interpret natural language queries	mechanism	2K_dev_531
and then aggregates and summarizes the content of the video	mechanism	2K_dev_531
	mechanism	2K_dev_531
We also investigate speed improvements made possible by recruiting large crowds	method	2K_dev_531
Since computer vision can not yet reliably interpret human actions and emotions	purpose	2K_dev_531
video coding remains a time-consuming manual process done by a small team of researchers	purpose	2K_dev_531
that allows researchers to rapidly analyze video datasets for behavioral events that are difficult to detect automatically	purpose	2K_dev_531
	purpose	2K_dev_531
	background	2K_dev_532
The model checker CBMC automatically verifies 5208 lines of C code in about 80 seconds using less than 2GB of RAM indicate that XMHF 's performance is comparable to popular high-performance general-purpose hypervisors for the single guest that it supports	finding	2K_dev_532
	finding	2K_dev_532
We present the design	mechanism	2K_dev_532
implementation	mechanism	2K_dev_532
and verification of XMHF- an eXtensible and Modular Hypervisor Framework XMHF is designed XMHF includes a core that provides functionality common to many hypervisor-based security architectures and supports extensions that augment the core with additional security or functional properties while preserving the fundamental hypervisor security property of memory integrity ( i	mechanism	2K_dev_532
e	mechanism	2K_dev_532
	mechanism	2K_dev_532
ensuring that the hypervisor 's memory is not modified by software running at a lower privilege level )	mechanism	2K_dev_532
We verify the memory integrity of the XMHF core -- 6018 lines of code -- using a combination of automated and manual techniques We manually audit the remaining 422 lines of C code and 388 lines of assembly language code that are stable and unlikely to change as development proceeds	method	2K_dev_532
Our experiments	method	2K_dev_532
to achieve three goals -- modular extensibility	purpose	2K_dev_532
automated verification	purpose	2K_dev_532
and high performance	purpose	2K_dev_532
The promise of `` smart '' homes	background	2K_dev_533
workplaces	background	2K_dev_533
schools	background	2K_dev_533
and other environments has long been championed	background	2K_dev_533
Unattractive	background	2K_dev_533
however	background	2K_dev_533
has been the cost to run wires and install sensors	background	2K_dev_533
More critically	background	2K_dev_533
raw sensor data tends not to align with the types of questions humans wish to ask	background	2K_dev_533
e	background	2K_dev_533
g	background	2K_dev_533
	background	2K_dev_533
do I need to restock my pantry ? Through our API	background	2K_dev_533
Zensors can enable a variety of rich end-user applications and moves us closer to the vision of responsive	background	2K_dev_533
intelligent environments	background	2K_dev_533
	background	2K_dev_533
	finding	2K_dev_533
We propose Zensors	mechanism	2K_dev_533
a new sensing approach that fuses real-time human intelligence from online crowd workers with automatic approaches With Zensors	mechanism	2K_dev_533
users can go from question to live sensor feed in less than 60 seconds	mechanism	2K_dev_533
	mechanism	2K_dev_533
	method	2K_dev_533
Although techniques like computer vision can answer some of these questions	purpose	2K_dev_533
it requires significant effort to build and train appropriate classifiers	purpose	2K_dev_533
Even then	purpose	2K_dev_533
these systems are often brittle	purpose	2K_dev_533
with limited ability to handle new or unexpected situations	purpose	2K_dev_533
including being repositioned and environmental changes ( e	purpose	2K_dev_533
g	purpose	2K_dev_533
	purpose	2K_dev_533
lighting	purpose	2K_dev_533
furniture	purpose	2K_dev_533
seasons ) to provide robust	purpose	2K_dev_533
adaptive	purpose	2K_dev_533
and readily deployable intelligent sensors	purpose	2K_dev_533
	purpose	2K_dev_533
Video analysis has been attracting increasing research due to the proliferation of internet videos	background	2K_dev_534
	background	2K_dev_534
and the comparison to other state-of-the-art multi-feature learning algorithms has validated the efficacy of our framework	finding	2K_dev_534
For better exploitation of multiple features	mechanism	2K_dev_534
we propose to mine the importance of different features and cast it into the learning of the classification model	mechanism	2K_dev_534
Our method is based on multiple graphs from different features and uses the Riemannian metric to evaluate the feature importance	mechanism	2K_dev_534
On the other hand	mechanism	2K_dev_534
to be able to use limited labeled training videos for a respectable accuracy we formulate our method in a semi-supervised way The main contribution of this paper is a novel scheme of evaluating the feature importance that is further casted into a unified framework of harnessing multiple weighted features with limited labeled training videos	mechanism	2K_dev_534
We perform extensive experiments on video action recognition and multimedia event recognition	method	2K_dev_534
In this paper	purpose	2K_dev_534
we investigate how to improve the performance on internet quality video analysis	purpose	2K_dev_534
Particularly	purpose	2K_dev_534
we work on the scenario of few labeled training videos being provided	purpose	2K_dev_534
which is less focused in multimedia	purpose	2K_dev_534
To being with	purpose	2K_dev_534
we consider how to more effectively harness the evidences from the low-level features Researchers have developed several promising features to represent videos to capture the semantic information	purpose	2K_dev_534
However	purpose	2K_dev_534
as videos usually characterize rich semantic contents	purpose	2K_dev_534
the analysis performance by using one single feature is potentially limited	purpose	2K_dev_534
Simply combining multiple features through early fusion or late fusion to incorporate more informative cues is doable but not optimal due to the heterogeneity and different predicting capability of these features	purpose	2K_dev_534
	purpose	2K_dev_534
	background	2K_dev_535
the proposed distributed algorithms are shown to achieve optimal learning asymptotically	finding	2K_dev_535
i	finding	2K_dev_535
e	finding	2K_dev_535
	finding	2K_dev_535
almost surely ( a	finding	2K_dev_535
s	finding	2K_dev_535
) each network agent is shown to learn the value function and the optimal stationary control policy of the collaborative MDP asymptotically Further	finding	2K_dev_535
convergence rate estimates for the proposed class of distributed learning algorithms are obtained	finding	2K_dev_535
	finding	2K_dev_535
Distributed reinforcement learning algorithms The networked setup consists of a collection of agents ( learners ) which respond differently ( depending on their instantaneous one-stage random costs ) to a global controlled state and the control actions of a remote controller	mechanism	2K_dev_535
the paper presents distributed variants of Q-learning of the consensus + innovations type in which each agent sequentially refines its learning parameters by locally processing its instantaneous payoff data and the information received from neighboring agents	mechanism	2K_dev_535
	mechanism	2K_dev_535
Under broad conditions on the multi-agent decision model and mean connectivity of the inter-agent communication network	method	2K_dev_535
	method	2K_dev_535
for collaborative multi-agent Markov decision processes ( MDPs ) are presented and analyzed With the objective of jointly learning the optimal stationary control policy ( in the absence of global state transition and local agent cost statistics ) that minimizes network-averaged infinite horizon discounted cost	purpose	2K_dev_535
	background	2K_dev_536
	finding	2K_dev_536
	mechanism	2K_dev_536
	method	2K_dev_536
	purpose	2K_dev_536
With the advancement of information systems	background	2K_dev_537
means of communications are becoming cheaper	background	2K_dev_537
faster	background	2K_dev_537
and more available	background	2K_dev_537
Today	background	2K_dev_537
millions of people carrying smartphones or tablets are able to communicate practically any time and anywhere they want	background	2K_dev_537
They can access their e-mails	background	2K_dev_537
comment on weblogs	background	2K_dev_537
watch and post videos and photos ( as well as comment on them )	background	2K_dev_537
and make phone calls or text messages almost ubiquitously	background	2K_dev_537
We also show three potential applications of the SFP : as a framework to generate a synthetic dataset containing realistic communication events of any one of the analyzed means of communications	background	2K_dev_537
as a technique to detect anomalies	background	2K_dev_537
and as a building block for more specific models that aim to encompass the particularities seen in each of the analyzed systems	background	2K_dev_537
	background	2K_dev_537
	finding	2K_dev_537
Moreover	mechanism	2K_dev_537
we propose the use of the Self-Feeding Process ( SFP ) The SFP is an extremely parsimonious point process that requires at most two parameters and is able to generate inter-event times with all the universal properties we observed in the data	mechanism	2K_dev_537
	mechanism	2K_dev_537
we analyzed eight different datasets from real and modern communication data and found four well-defined patterns seen in all the eight datasets	method	2K_dev_537
	method	2K_dev_537
Given this scenario	purpose	2K_dev_537
in this article	purpose	2K_dev_537
we tackle a fundamental aspect of this new era of communication : How the time intervals between communication events behave for different technologies and means of communications Are there universal patterns for the Inter-Event Time Distribution ( IED ) q How do inter-event times behave differently among particular technologiesq To answer these questions to generate inter-event times between communications	purpose	2K_dev_537
	purpose	2K_dev_537
	background	2K_dev_538
	finding	2K_dev_538
	mechanism	2K_dev_538
	method	2K_dev_538
	purpose	2K_dev_538
Multimedia Event Detection ( MED ) is a multimedia retrieval task with the goal of finding videos of a particular event in video archives	background	2K_dev_539
given example videos and event descriptions ; different from MED	background	2K_dev_539
multimedia classification is a task that classifies given videos into specified classes Generally	background	2K_dev_539
early fusion and late fusion are two popular combination strategies	background	2K_dev_539
The former one fuses features before performing classification and the latter one combines output of classifiers from different features	background	2K_dev_539
Early fusion can better capture the relationship among features yet is prone to over-fit the training data	background	2K_dev_539
Late fusion deals with the over-fitting problem better but does not allow classifiers to train on all the data at the same time	background	2K_dev_539
Results are reported For the MED 2010 dataset	finding	2K_dev_539
we get a mean minimal normalized detection cost ( MMNDC ) of 0	finding	2K_dev_539
49	finding	2K_dev_539
which exceeds the state-of-the-art performance by more than 12 percent	finding	2K_dev_539
On the TRECVID MED 2011 test dataset	finding	2K_dev_539
we achieve a MMNDC of 0	finding	2K_dev_539
51	finding	2K_dev_539
which is the second best among all 19 participants	finding	2K_dev_539
On UCF50 and HMDB51	finding	2K_dev_539
we obtain classification accuracy of 88	finding	2K_dev_539
1 % and 48	finding	2K_dev_539
7 % respectively	finding	2K_dev_539
which are the best reported results to date	finding	2K_dev_539
In this paper	mechanism	2K_dev_539
we introduce a fusion scheme named double fusion	mechanism	2K_dev_539
which simply combines early fusion and late fusion together to incorporate their advantages	mechanism	2K_dev_539
	mechanism	2K_dev_539
on the TRECVID MED 2010	method	2K_dev_539
MED 2011	method	2K_dev_539
UCF50 and HMDB51 datasets	method	2K_dev_539
Both tasks require mining features of example videos to learn the most discriminative features	purpose	2K_dev_539
with best performance resulting from a combination of multiple complementary features	purpose	2K_dev_539
How to combine different features is the focus of this paper	purpose	2K_dev_539
	background	2K_dev_540
demonstrate that AutoPlait does indeed detect meaningful patterns correctly	finding	2K_dev_540
and it outperforms state-of-the-art competitors as regards accuracy and speed : AutoPlait achieves near-perfect	finding	2K_dev_540
over 95 % precision and recall	finding	2K_dev_540
and it is up to 472 times faster than its competitors	finding	2K_dev_540
In this paper we present AutoPlait	mechanism	2K_dev_540
a fully automatic mining algorithm Our method has the following properties : ( a ) effectiveness : it operates on large collections of time-series	mechanism	2K_dev_540
and finds similar segment groups that agree with human intuition ; ( b ) scalability : it is linear with the input size	mechanism	2K_dev_540
and thus scales up very well ; and ( c ) AutoPlait is parameter-free	mechanism	2K_dev_540
and requires no user intervention	mechanism	2K_dev_540
no prior training	mechanism	2K_dev_540
and no parameter tuning	mechanism	2K_dev_540
	mechanism	2K_dev_540
Extensive experiments on 67GB of real datasets	method	2K_dev_540
Given a large collection of co-evolving multiple time-series	purpose	2K_dev_540
which contains an unknown number of patterns of different durations	purpose	2K_dev_540
how can we efficiently and effectively find typical patterns and the points of variation ? How can we statistically summarize all the sequences	purpose	2K_dev_540
and achieve a meaningful segmentation ? for co-evolving time sequences	purpose	2K_dev_540
	background	2K_dev_541
For the various test cases	finding	2K_dev_541
in-memory data reorganization provides orders of magnitude performance and energy efficiency improvements via low overhead hardware	finding	2K_dev_541
This paper presents a two pronged approach	mechanism	2K_dev_541
which combines ( i ) a proposed DRAM-aware reshape accelerator integrated within 3D-stacked DRAM	mechanism	2K_dev_541
and ( ii ) a mathematical framework that is used to represent and optimize the reorganization operations	mechanism	2K_dev_541
We evaluate our proposed system through two major use cases First	method	2K_dev_541
we demonstrate the reshape accelerator in performing a physical address remapping via data layout transform to utilize the internal parallelism/locality of the 3D-stacked DRAM structure more efficiently for general purpose workloads Then	method	2K_dev_541
we focus on offloading and accelerating commonly used data reorganization routines selected from the Intel Math Kernel Library package We evaluate the energy and performance benefits of our approach by comparing it against existing optimized implementations on state-of-the-art GPUs and CPUs	method	2K_dev_541
	method	2K_dev_541
In this paper we focus on common data reorganization operations such as shuffle	purpose	2K_dev_541
pack/unpack	purpose	2K_dev_541
swap	purpose	2K_dev_541
transpose	purpose	2K_dev_541
and layout transformations Although these operations simply relocate the data in the memory	purpose	2K_dev_541
they are costly on conventional systems mainly due to inefficient access patterns	purpose	2K_dev_541
limited data reuse and roundtrip data traversal throughout the memory hierarchy for efficient data reorganization	purpose	2K_dev_541
Can we identify patterns of temporal activities caused by human communications in social media ? Is it possible to model these patterns and tell if a user is a human or a bot based only on the timing of their postings ? Social media services allow users to make postings	background	2K_dev_542
generating large datasets of human activity time-stamps	background	2K_dev_542
	background	2K_dev_542
and find that the distribution of postings inter-arrival times ( IAT ) is characterized by four patterns : ( i ) positive correlation between consecutive IATs	finding	2K_dev_542
( ii ) heavy tails	finding	2K_dev_542
( iii ) periodic spikes and ( iv ) bimodal distribution	finding	2K_dev_542
by showing that it can accurately fit real time-stamp data from Reddit and Twitter	finding	2K_dev_542
We also show that RSC can be used to spot outliers and detect users with non-human behavior	finding	2K_dev_542
such as bots	finding	2K_dev_542
RSC consistently provides a better fit to real data and clearly outperform existing models for human dynamics	finding	2K_dev_542
RSC was also able to detect bots with a precision higher than 94 %	finding	2K_dev_542
	finding	2K_dev_542
Based on our findings	mechanism	2K_dev_542
we propose Rest-Sleep-and-Comment ( RSC )	mechanism	2K_dev_542
a generative model	mechanism	2K_dev_542
We demonstrate the utility of RSC We validate RSC using real data consisting of over 35 million postings from Twitter and Reddit	method	2K_dev_542
	method	2K_dev_542
In this paper we analyze time-stamp data from social media services that is able to match all four discovered patterns	purpose	2K_dev_542
	purpose	2K_dev_542
Detecting and quantifying the timing and the genetic contributions of parental populations to a hybrid population is an important but challenging problem in reconstructing evolutionary histories from genetic variation data	background	2K_dev_543
With the advent of high throughput genotyping technologies	background	2K_dev_543
new methods suitable for large-scale data are especially needed	background	2K_dev_543
	background	2K_dev_543
On simulated sequences	finding	2K_dev_543
our methods show better accuracy and faster runtime than leading competitive methods in estimating admixture fractions and divergence times Analysis on the real data further shows our methods to be effective at matching our best current knowledge about the relevant populations	finding	2K_dev_543
	finding	2K_dev_543
Here	mechanism	2K_dev_543
we propose a novel method that combines prior work for inferring nonreticulate population structures with an MCMC scheme for sampling over admixture scenarios using genome-scale admixed genetic variation data	mechanism	2K_dev_543
	mechanism	2K_dev_543
We validated our method using coalescent simulations and a collection of real bovine and human variation data	method	2K_dev_543
	method	2K_dev_543
Furthermore	purpose	2K_dev_543
existing methods typically assume the assignment of individuals into subpopulations is known	purpose	2K_dev_543
when that itself is a difficult problem often unresolved for real data	purpose	2K_dev_543
to both identify population assignments and learn divergence times and admixture proportions for those populations	purpose	2K_dev_543
From a technical viewpoint	background	2K_dev_544
the proposed distributed estimator leads to non-Markovian mixed timescale stochastic recursions and the analytical methods developed in the paper contribute to the general theory of distributed stochastic approximation	background	2K_dev_544
is shown to yield consistent parameter estimates at each network agent	finding	2K_dev_544
Further	finding	2K_dev_544
it is shown that the distributed estimator is asymptotically efficient	finding	2K_dev_544
in that	finding	2K_dev_544
the asymptotic covariances of the agent estimates coincide with that of the optimal centralized estimator	finding	2K_dev_544
i	finding	2K_dev_544
e	finding	2K_dev_544
	finding	2K_dev_544
the inverse of the centralized Fisher information rate	finding	2K_dev_544
	finding	2K_dev_544
in multi-agent networks with exponential family observation statistics A certainty-equivalence type distributed estimator of the consensus + innovations form is proposed in which	mechanism	2K_dev_544
at each each observation sampling epoch agents update their local parameter estimates by appropriately combining the data received from their neighbors and the locally sensed new information ( innovation )	mechanism	2K_dev_544
Under global observability of the networked sensing model	mechanism	2K_dev_544
i	mechanism	2K_dev_544
e	mechanism	2K_dev_544
	mechanism	2K_dev_544
the ability to distinguish between different instances of the parameter value based on the joint observation statistics	mechanism	2K_dev_544
and mean connectivity of the inter-agent communication network	mechanism	2K_dev_544
the proposed estimator	mechanism	2K_dev_544
	method	2K_dev_544
The paper studies the problem of distributed parameter estimation	purpose	2K_dev_544
Thus	background	2K_dev_545
it appears that disorders of the Rb/E2F axis can arise at multiple organ sites and produce tumors that simultaneously overexpress multiple E2F-responsive genes	background	2K_dev_545
	background	2K_dev_545
In breast cancer	finding	2K_dev_545
a group of tumors was identified	finding	2K_dev_545
each of which simultaneously overexpressed multiple E2F-responsive genes	finding	2K_dev_545
Seventy percent of these genes were concerned with cell cycle progression	finding	2K_dev_545
DNA repair	finding	2K_dev_545
or mitosis These E2F-responsive gene overexpressing ( ERGO ) tumors frequently exhibited additional evidence of Rb/E2F axis dysfunction	finding	2K_dev_545
were mostly triple negative	finding	2K_dev_545
and preferentially overexpressed multiple basal cytokeratins	finding	2K_dev_545
suggesting that they overlapped substantially with the basal-like tumor subset	finding	2K_dev_545
ERGO tumors were also identified in serous ovarian cancer and prostate cancer	finding	2K_dev_545
In these cancer types	finding	2K_dev_545
there was no evidence for a tumor subset comparable to the breast cancer basal-like subset	finding	2K_dev_545
A core group of about 30 E2F-responsive genes were overexpressed in all three cancer types	finding	2K_dev_545
	mechanism	2K_dev_545
we compiled a list of E2F-responsive genes from the literature and evaluated their expression in publicly available gene expression microarray data of patients with breast cancer	method	2K_dev_545
serous ovarian cancer	method	2K_dev_545
and prostate cancer	method	2K_dev_545
	method	2K_dev_545
Reasoning that overexpression of multiple E2F-responsive genes might be a useful marker for RB1 dysfunction	purpose	2K_dev_545
	purpose	2K_dev_545
We conclude with example applications and thoughts on future avenues of research	background	2K_dev_546
	background	2K_dev_546
	finding	2K_dev_546
which demonstrate the feasibility of our approach	finding	2K_dev_546
	finding	2K_dev_546
In particular	mechanism	2K_dev_546
by manipulating the internal air pressure of various pneumatic elements	mechanism	2K_dev_546
we can create mechanisms that require different levels of actuation force and can also change their shape	mechanism	2K_dev_546
We describe the challenges that we faced and the methods that we used to overcome some of the limitations of current 3D printing technology	mechanism	2K_dev_546
	mechanism	2K_dev_546
We introduce and discuss a series of example 3D printed pneumatic controls This includes conventional controls	method	2K_dev_546
such as buttons	method	2K_dev_546
knobs and sliders	method	2K_dev_546
but also extends to domains such as toys and deformable interfaces	method	2K_dev_546
We explore 3D printing physical controls whose tactile response can be manipulated programmatically through pneumatic actuation	purpose	2K_dev_546
	purpose	2K_dev_546
Many people would find the Web easier to use if content was a little bigger	background	2K_dev_547
even those who already find the Web possible to use now We believe this concept applies generally across a wide range of accessibility improvements designed to help people with diverse abilities	background	2K_dev_547
by magnifying existing web pages 1	finding	2K_dev_547
6x on average without introducing negative side effects	finding	2K_dev_547
	finding	2K_dev_547
This paper introduces the idea of opportunistic accessibility improvement in which We explore this idea with oppaccess	mechanism	2K_dev_547
js	mechanism	2K_dev_547
an easily-deployed system for magnifying web pages that iteratively increases magnification until it notices negative side effects	mechanism	2K_dev_547
such as horizontal scrolling or overlapping text	mechanism	2K_dev_547
We validate this approach	method	2K_dev_547
improvements intended to make a web page easier to access	purpose	2K_dev_547
such as magnification	purpose	2K_dev_547
are automatically applied to the extent that they can be without causing negative side effects	purpose	2K_dev_547
	purpose	2K_dev_547
These theoretical results have direct practical implications	background	2K_dev_548
	finding	2K_dev_548
we show that such allocations may not exist	finding	2K_dev_548
but allocations guaranteeing each player 2/3 of the above value always exist	finding	2K_dev_548
	finding	2K_dev_548
and can be computed in polynomial time when the number of players is constant	mechanism	2K_dev_548
Assuming additive valuation functions	method	2K_dev_548
We consider the problem of fairly allocating indivisible goods	purpose	2K_dev_548
focusing on a recently-introduced notion of fairness called maximin share guarantee : Each player 's value for his allocation should be at least as high as what he can guarantee by dividing the items into as many bundles as there are players and receiving his least desirable bundle	purpose	2K_dev_548
	background	2K_dev_549
	finding	2K_dev_549
	mechanism	2K_dev_549
	method	2K_dev_549
	purpose	2K_dev_549
	background	2K_dev_550
	finding	2K_dev_550
	mechanism	2K_dev_550
	method	2K_dev_550
	purpose	2K_dev_550
	background	2K_dev_551
In particular	finding	2K_dev_551
while our generic procedure is computationally inefficient	finding	2K_dev_551
for the specific definition of H as graphs of bounded degree	finding	2K_dev_551
we exhibit efficient ways of constructing f H using different projection-based techniques	finding	2K_dev_551
We demonstrate that the restricted sensitivity of such queries can be significantly lower than their smooth sensitivity Thus	finding	2K_dev_551
using restricted sensitivity we can maintain privacy whether or not D HH	finding	2K_dev_551
while providing more accurate results in the event that HH holds true	finding	2K_dev_551
We introduce the notion of restricted sensitivity as an alternative to global and smooth sensitivity The definition of restricted sensitivity is similar to that of global sensitivity except that instead of quantifying over all possible datasets	mechanism	2K_dev_551
we take advantage of any beliefs about the dataset that a querier may have	mechanism	2K_dev_551
to quantify over a restricted class of datasets	mechanism	2K_dev_551
Specifically	mechanism	2K_dev_551
given a query f and a hypothesis HH about the structure of a dataset D	mechanism	2K_dev_551
we show generically how to transform f into a new query f HH whose global sensitivity ( over all datasets including those that do not satisfy HH ) matches the restricted sensitivity of the query f	mechanism	2K_dev_551
Moreover	mechanism	2K_dev_551
if the belief of the querier is correct ( i	mechanism	2K_dev_551
e	mechanism	2K_dev_551
	mechanism	2K_dev_551
D HH ) then f HH ( D ) 0 f ( D ) If the belief is incorrect	mechanism	2K_dev_551
then f HH ( D ) may be inaccurate which we model as a combination of a graph and a labeling of its vertices	mechanism	2K_dev_551
	mechanism	2K_dev_551
We demonstrate the usefulness of this notion by considering the task of answering queries regarding social-networks	method	2K_dev_551
We then analyze two important query classes : subgraph counting queries ( e	method	2K_dev_551
g	method	2K_dev_551
	method	2K_dev_551
number of triangles ) and local profile queries ( e	method	2K_dev_551
g	method	2K_dev_551
	method	2K_dev_551
number of people who know a spy and a computer-scientist who know each other )	method	2K_dev_551
	method	2K_dev_551
to improve accuracy in differentially private data analysis	purpose	2K_dev_551
Activity recognition can provide computers with the context underlying user inputs	background	2K_dev_552
enabling more relevant responses and more fluid interaction	background	2K_dev_552
Prior work has enabled the crowd to provide labels in real-time to train automated systems on-the-fly	background	2K_dev_552
but numerous examples are still needed before the system can recognize an activity on its own	background	2K_dev_552
show that over seven times as many examples can be collected using our approach versus relying on direct observation alone	finding	2K_dev_552
demonstrating that by leveraging the understanding of the crowd	finding	2K_dev_552
it is possible to more easily train automated systems	finding	2K_dev_552
	finding	2K_dev_552
we introduce ARchitect	mechanism	2K_dev_552
a system that uses the crowd to capture the dependency structure of the actions that make up activities	mechanism	2K_dev_552
	mechanism	2K_dev_552
Our tests	method	2K_dev_552
However	purpose	2K_dev_552
training these systems is difficult because it requires observing every possible sequence of actions that comprise a given activity	purpose	2K_dev_552
To reduce the need to collect this data by observing users	purpose	2K_dev_552
	purpose	2K_dev_552
Multimedia event detection ( MED ) plays an important role in many applications such as video indexing and retrieval	background	2K_dev_553
	background	2K_dev_553
demonstrate the effectiveness of the proposed approach	finding	2K_dev_553
	finding	2K_dev_553
In this paper	mechanism	2K_dev_553
we propose an approach that exploits the external concepts-based videos and event-based videos simultaneously to learn an intermediate representation from video features	mechanism	2K_dev_553
Our algorithm integrates the classifier inference and latent intermediate representation into a joint framework	mechanism	2K_dev_553
The joint optimization of the intermediate representation and the classifier makes them mutually beneficial and reciprocal	mechanism	2K_dev_553
Effectively	mechanism	2K_dev_553
the intermediate representation and the classifier are tightly correlated	mechanism	2K_dev_553
The classifier dependent intermediate representation not only accurately reflects the task semantics but is also more suitable for the specific classifier	mechanism	2K_dev_553
Thus we have created a discriminative semantic analysis framework based on a tightly coupled intermediate representation	mechanism	2K_dev_553
Extensive experiments on multimedia event detection using real-world videos	method	2K_dev_553
Current event detection works mainly focus on sports and news event detection or abnormality detection in surveillance videos	purpose	2K_dev_553
Differently	purpose	2K_dev_553
our research aims to detect more complicated and generic events within a longer video sequence	purpose	2K_dev_553
In the past	purpose	2K_dev_553
researchers have proposed using intermediate concept classifiers with concept lexica to help understand the videos	purpose	2K_dev_553
Yet it is difficult to judge how many and what concepts would be sufficient for the particular video analysis task	purpose	2K_dev_553
Additionally	purpose	2K_dev_553
obtaining robust semantic concept classifiers requires a large number of positive training examples	purpose	2K_dev_553
which in turn has high human annotation cost	purpose	2K_dev_553
	purpose	2K_dev_553
Ultrasonic guided-waves propagating in pipes with varying environmental and operational conditions ( EOCs ) are usually the results of complex superposition of multiple modes travelling in multiple paths	background	2K_dev_554
Among all of the components forming a complex guided-wave signal	background	2K_dev_554
the arrivals scattered by damage ( so called scatter signal ) are of importance for damage diagnosis purposes	background	2K_dev_554
Current approaches for extracting scatter signal can be categorized as ( A ) baseline subtraction methods	background	2K_dev_554
and ( B ) linear decomposition	background	2K_dev_554
The simulation results show that different wave modes may have significantly different sensitivities to temperature variations This brings about challenges such as shape distortion and nonlinear relations between the signals recorded at different temperatures	finding	2K_dev_554
which prevent the aforementioned methods to be extensible to wide range of temperatures	finding	2K_dev_554
It is observed that NLPCA can successfully remove nonlinear relations between the signal bases	finding	2K_dev_554
hence extract scatter signal	finding	2K_dev_554
for temperature variations up to 10	finding	2K_dev_554
with detection accuracies above 99 %	finding	2K_dev_554
	finding	2K_dev_554
we examine the potential of a nonlinear decomposition method	mechanism	2K_dev_554
namely nonlinear principal component analysis ( NLPCA )	mechanism	2K_dev_554
	mechanism	2K_dev_554
To better analyze the experimental results	method	2K_dev_554
the effects of temperature on multi-modal signals are simulated Ultrasonic pitch-catch measurements from an aluminum pipe segment in a thermally controlled laboratory are used to evaluate the detection performance of the damage-sensitive features extracted by the proposed approach	method	2K_dev_554
	method	2K_dev_554
This paper evaluates the potentials of nonlinear decomposition methods for extracting the scatter signal from a multi-modal signal recorded from a pipe under varying temperatures In this paper	purpose	2K_dev_554
we first illustrate	purpose	2K_dev_554
experimentally	purpose	2K_dev_554
the challenges for applying these methods on multi-modal signals at varying temperatures	purpose	2K_dev_554
In this paper	purpose	2K_dev_554
for removing the nonlinear relation between the components of a multi-modal guided-wave signal	purpose	2K_dev_554
and thus	purpose	2K_dev_554
extracting the scatter signal	purpose	2K_dev_554
Abstract In case of an emergency in a building	background	2K_dev_555
first responders need to know current blockages in the building ( e	background	2K_dev_555
g	background	2K_dev_555
	background	2K_dev_555
blocked passageways and exits ) and safe evacuating paths so that the occupants can be guided to the unblocked exits and safe paths toward those exits The estimated blockage information can be used to create a topological map of the damaged building	background	2K_dev_555
indicating safe paths toward available unblocked exits	background	2K_dev_555
	background	2K_dev_555
The results demonstrated the technical feasibility of the proposed system and the findings of the decision tree highlight that by using less number of sensors	finding	2K_dev_555
a cost-effective configuration can be achieved	finding	2K_dev_555
	finding	2K_dev_555
a system that fuses data from multiple sensors and video camera was proposed A prototype was developed and a decision tree method was used	mechanism	2K_dev_555
and tested on an experimental model of a pilot building 's hallway	method	2K_dev_555
A series of damage tests were conducted on the hallway model and recorded by the sensors and the video camera	method	2K_dev_555
Individual performances of sensors and video camera were evaluated	method	2K_dev_555
	method	2K_dev_555
To automatically determine blockage levels at buildings to fuse sensor and video camera data for estimating the level of blockage in the hallway for different damage combinations applied on building components	purpose	2K_dev_555
	purpose	2K_dev_555
Topic models are effective probabilistic tools for processing large collections of unstructured data	background	2K_dev_556
The open-source C++ implementation of the proposed algorithm is available at https : //github	background	2K_dev_556
com/xunzheng/light_medlda	background	2K_dev_556
	background	2K_dev_556
	finding	2K_dev_556
We focus on the Gibbs MedLDA model [ 27 ] that is able to simultaneously discover latent structures and make accurate predictions	mechanism	2K_dev_556
By combining a set of sampling techniques we are able to reduce the O ( K 3 + DK 2 + DNK complexity in [ 27 ] to O ( DK + DN ) when there are K topics and D documents with average length N	mechanism	2K_dev_556
To our best knowledge	mechanism	2K_dev_556
this is the first linear time sampling algorithm for supervised topic models	mechanism	2K_dev_556
Our algorithm requires minimal modifications to incorporate most loss functions in a variety of supervised tasks	mechanism	2K_dev_556
and we observe in our experiments an order of magnitude speedup over the current state-of-the-art implementation	mechanism	2K_dev_556
while achieving similar prediction performances	mechanism	2K_dev_556
	mechanism	2K_dev_556
	method	2K_dev_556
With the exponential growth of modern industrial data	purpose	2K_dev_556
and consequentially also with our ambition to explore much bigger models	purpose	2K_dev_556
there is a real pressing need to significantly scale up topic modeling algorithms	purpose	2K_dev_556
which has been taken up in lots of previous works	purpose	2K_dev_556
culminating in the recent fast Markov chain Monte Carlo sampling algorithms in [ 10	purpose	2K_dev_556
23 ] for the unsupervised latent Dirichlet allocation ( LDA ) formulations	purpose	2K_dev_556
In this work we extend the recent sampling advances for unsupervised LDA models to supervised tasks	purpose	2K_dev_556
	purpose	2K_dev_556
for	background	2K_dev_557
extending prior work where both are assumed to be deterministic	background	2K_dev_557
	background	2K_dev_557
We show that the Time Reversal Likelihood Ratio Test performs much better than the conventional Weighted Energy Detector	finding	2K_dev_557
results show that the Linear Quadratic detector is a good approximation to the Time Reversal Likelihood Ratio Test and that both show a significant improvement of 4 to 7 dB effective signal-to-noise ratio gain over the Weighted Energy Detector	finding	2K_dev_557
This gain is dependent on the target and clutter power spectral densities	finding	2K_dev_557
	finding	2K_dev_557
We derive the time reversal likelihood ratio optimal detector We suppress the stationary clutter through adaptive power allocation	mechanism	2K_dev_557
	mechanism	2K_dev_557
We provide analytical on the performance of the time reversal detector by approximating it with the Time Reversal Linear Quadratic detector	method	2K_dev_557
which models the received signal as a Complex Gaussian Our simulations	method	2K_dev_557
a target in stationary random multipath clutter	purpose	2K_dev_557
	background	2K_dev_558
	finding	2K_dev_558
	mechanism	2K_dev_558
	method	2K_dev_558
	purpose	2K_dev_558
Text can often be complex and difficult to read	background	2K_dev_559
especially for people with cognitive impairments or low literacy skills	background	2K_dev_559
Text simplification is a process that reduces the complexity of both wording and structure in a sentence	background	2K_dev_559
while retaining its meaning	background	2K_dev_559
This may allow simplification systems and system builders to get better feedback about how well content is being simplified	background	2K_dev_559
as compared to standard measures which classify content into 'simplified ' or 'not simplified ' categories Our study provides evidence that the crowd could be used to evaluate English text simplification	background	2K_dev_559
as well as to create simplified text in future work	background	2K_dev_559
	background	2K_dev_559
We show that leveraging crowds can result in a collective decision that is accurate and converges to a consensus rating	finding	2K_dev_559
show that the crowd can effectively rate levels of simplicity	finding	2K_dev_559
	finding	2K_dev_559
	mechanism	2K_dev_559
This paper focuses on the evaluation of English text simplification using the crowd	method	2K_dev_559
Our results from 2	method	2K_dev_559
500 crowd annotations	method	2K_dev_559
However	purpose	2K_dev_559
this is currently a challenging task for machines	purpose	2K_dev_559
and thus	purpose	2K_dev_559
providing effective on-demand text simplification to those who need it remains an unsolved problem	purpose	2K_dev_559
Even evaluating the simplicity of text remains a challenging problem for both computers	purpose	2K_dev_559
which can not understand the meaning of text	purpose	2K_dev_559
and humans	purpose	2K_dev_559
who often struggle to agree on what constitutes a good simplification	purpose	2K_dev_559
Seeking solutions from one domain to solve problems in another is an effective process of innovation	background	2K_dev_560
This work provides a useful method for finding analogies	background	2K_dev_560
and can streamline innovation for both novices and professional designers	background	2K_dev_560
we show the benefits of using abstract structural representations to search for ideas that are analogous to a source problem	finding	2K_dev_560
and that these analogies result in better solutions than alternative approaches	finding	2K_dev_560
	finding	2K_dev_560
In this paper	mechanism	2K_dev_560
we present a novel approach We propose a crowdsourcing process that helps people navigate a large dataset to find analogies	mechanism	2K_dev_560
Through two experiments	method	2K_dev_560
	method	2K_dev_560
This process of analogy searching is difficult for both humans and machines for re-presenting a problem in terms of its abstract structure	purpose	2K_dev_560
and then allowing people to use this structural representation to find analogies	purpose	2K_dev_560
	purpose	2K_dev_560
	background	2K_dev_561
	finding	2K_dev_561
	mechanism	2K_dev_561
	method	2K_dev_561
	purpose	2K_dev_561
In 1876	background	2K_dev_562
Charles Lutwidge Dodgson suggested the intriguing voting rule that today bears his name Although Dodgsons rule is one of the most well-studied voting rules	background	2K_dev_562
it suffers from serious deficiencies	background	2K_dev_562
both from the computational point of viewit is NP-hard even to approximate the Dodgson score within sublogarithmic factorsand from the social choice point of viewit fails basic social choice desiderata such as monotonicity and homogeneity	background	2K_dev_562
	background	2K_dev_562
Furthermore	finding	2K_dev_562
we show that a slight variation on a known voting rule yields a monotonic	finding	2K_dev_562
homogeneous	finding	2K_dev_562
polynomial-time O ( m log m ) -approximation algorithm and establish that it is impossible to achieve a better approximation ratio even if one just asks for homogeneity we prove that algorithms with an approximation ratio that depends only on m do not exist	finding	2K_dev_562
We design a monotonic exponential-time algorithm that yields a 2-approximation to the Dodgson score	mechanism	2K_dev_562
while matching this result with a tight lower bound We also present a monotonic polynomial-time O ( log m ) -approximation algorithm ( where m is the number of alternatives ) ; this result is tight as well due to a complexity-theoretic lower bound	mechanism	2K_dev_562
We complete the picture by studying several additional social choice properties ; for these properties	method	2K_dev_562
	method	2K_dev_562
However	purpose	2K_dev_562
this does not preclude the existence of approximation algorithms for Dodgson that are monotonic or homogeneous	purpose	2K_dev_562
and indeed it is natural to ask whether such algorithms exist	purpose	2K_dev_562
In this article	purpose	2K_dev_562
we give definitive answers to these questions	purpose	2K_dev_562
	purpose	2K_dev_562
	background	2K_dev_563
shows high accuracy in the detection of seed nodes	finding	2K_dev_563
in addition to the correct automatic identification of their number Moreover	finding	2K_dev_563
NetSleuth scales linearly in the number of nodes of the graph	finding	2K_dev_563
	finding	2K_dev_563
and give an efficient method called NetSleuth for the well-known susceptible-infected virus propagation model	mechanism	2K_dev_563
We propose to employ the minimum description length principle as the one by which we can most succinctly describe the infected graph	mechanism	2K_dev_563
We give an highly efficient algorithm given a snapshot	mechanism	2K_dev_563
Then	mechanism	2K_dev_563
given these seed nodes	mechanism	2K_dev_563
we show we can optimize the virus propagation ripple in a principled way by maximizing likelihood	mechanism	2K_dev_563
With all three combined	mechanism	2K_dev_563
NetSleuth can automatically identify the correct number of seed nodes	mechanism	2K_dev_563
as well as which nodes are the culprits	mechanism	2K_dev_563
	mechanism	2K_dev_563
Experimentation on our method	method	2K_dev_563
Given a snapshot of a large graph	purpose	2K_dev_563
in which an infection has been spreading for some time	purpose	2K_dev_563
can we identify those nodes from which the infection started to spread ? In other words	purpose	2K_dev_563
can we reliably tell who the culprits are ? In this paper	purpose	2K_dev_563
we answer this question affirmatively Essentially	purpose	2K_dev_563
we are after that set of seed nodes that best explain the given snapshot	purpose	2K_dev_563
to identify the best set of seed nodes and virus propagation ripple to identify likely sets of seed nodes	purpose	2K_dev_563
	background	2K_dev_564
	finding	2K_dev_564
	mechanism	2K_dev_564
	method	2K_dev_564
	purpose	2K_dev_564
	background	2K_dev_565
	finding	2K_dev_565
	mechanism	2K_dev_565
	method	2K_dev_565
	purpose	2K_dev_565
	background	2K_dev_566
that Respawn is able to run on ARM-based edge node devices connected to a cloud-backend with the ability to serve thousands of clients and terabytes of data with sub-second latencies	finding	2K_dev_566
In this paper	mechanism	2K_dev_566
we present a cloud-to-edge partitioned architecture called Respawn Respawn targets sensing systems where resource-constrained edge node devices may only have limited or intermittent network connections linking them to a cloud-backend	mechanism	2K_dev_566
The cloud-backend provides aggregate storage and transparent dispatching of data queries to edge node devices	mechanism	2K_dev_566
Data is downsampled as it enters the system creating a multi-resolution representation capable of lowlatency range-base queries	mechanism	2K_dev_566
Lower-resolution aggregate data is automatically migrated from edge nodes to the cloud-backend both for improved consistency and caching	mechanism	2K_dev_566
In order to further mask latency from users	mechanism	2K_dev_566
edge nodes automatically identify and migrate blocks of data that contain statistically interesting features	mechanism	2K_dev_566
	mechanism	2K_dev_566
We show through simulation and micro-benchmarking	method	2K_dev_566
As sensor networks gain traction and begin to scale	purpose	2K_dev_566
we will be increasingly faced with challenges associated with managing large-scale time-series data	purpose	2K_dev_566
that is capable of serving large amounts of time-series data from a continuously updating datastore with access latencies low enough to support interactive real-time visualization	purpose	2K_dev_566
Online instructional videos have become a popular way for people to learn new skills encompassing art	background	2K_dev_567
cooking and sports	background	2K_dev_567
	background	2K_dev_567
show that the examples harvested are of reasonably good quality	finding	2K_dev_567
and action detectors trained on data collected by our unsupervised method yields comparable performance with detectors trained with manually collected data on the TRECVID Multimedia Event Detection task	finding	2K_dev_567
	finding	2K_dev_567
We propose to utilize the large amount of instructional videos available online The key observation is that in instructional videos	mechanism	2K_dev_567
the instructor 's action is highly correlated with the instructor 's narration	mechanism	2K_dev_567
By leveraging this correlation	mechanism	2K_dev_567
we can exploit the timing of action corresponding terms in the speech transcript to temporally localize actions in the video and harvest action examples The proposed method is scalable as it requires no human intervention	mechanism	2K_dev_567
Experiments	method	2K_dev_567
As watching instructional videos is a natural way for humans to learn	purpose	2K_dev_567
analogously	purpose	2K_dev_567
machines can also gain knowledge from these videos	purpose	2K_dev_567
to harvest examples of various actions in an unsupervised fashion	purpose	2K_dev_567
	background	2K_dev_568
	finding	2K_dev_568
We introduce GOTCHAs ( Generating panOptic Turing Tests to Tell Computers and Humans Apart ) as A GOTCHA is a randomized puzzle generation protocol	mechanism	2K_dev_568
which involves interaction between a computer and a human	mechanism	2K_dev_568
Informally	mechanism	2K_dev_568
a GOTCHA should satisfy two key properties : ( 1 ) The puzzles are easy for the human to solve	mechanism	2K_dev_568
( 2 ) The puzzles are hard for a computer to solve even if it has the random bits used by the computer to generate the final puzzle -- - unlike a CAPTCHA [ 44 ]	mechanism	2K_dev_568
Our main theorem demonstrates that GOTCHAs can be used to mitigate the threat of offline dictionary attacks against passwords by ensuring that a password cracker must receive constant feedback from a human being while mounting an attack Finally	mechanism	2K_dev_568
we provide a candidate construction of GOTCHAs based on Inkblot images	mechanism	2K_dev_568
Our construction relies on the usability assumption that users can recognize the phrases that they originally used to describe each Inkblot image -- - a much weaker usability assumption than previous password systems based on Inkblots which required users to recall their phrase exactly	mechanism	2K_dev_568
	mechanism	2K_dev_568
We conduct a user study to evaluate the usability of our GOTCHA construction	method	2K_dev_568
We also generate a GOTCHA challenge where we encourage artificial intelligence and security researchers to try to crack several passwords protected with our scheme	method	2K_dev_568
	method	2K_dev_568
a way of preventing automated offline dictionary attacks against user selected passwords	purpose	2K_dev_568
Viral videos that gain popularity through the process of Internet sharing are having a profound impact on society The application of our work is not only important for advertising agencies to plan advertising campaigns and estimate costs	background	2K_dev_569
but also for companies to be able to quickly respond to rivals in viral marketing campaigns The proposed method is unique in that it is the first attempt to incorporate video metadata into the peak day prediction	background	2K_dev_569
we discover some interesting characteristics of viral videos	finding	2K_dev_569
The empirical results demonstrate that the proposed method outperforms the state-of-the-art methods	finding	2K_dev_569
with statistically significant differences	finding	2K_dev_569
	finding	2K_dev_569
Based on our analysis	mechanism	2K_dev_569
in the second half of the paper	mechanism	2K_dev_569
we propose a model	mechanism	2K_dev_569
We collect by far the largest open benchmark for viral video study called CMU Viral Video Dataset	method	2K_dev_569
and share it with researchers from both academia and industry	method	2K_dev_569
Having verified existing observations on the dataset	method	2K_dev_569
	method	2K_dev_569
Existing studies on viral videos have only been on small or confidential datasets to forecast the future peak day of viral videos	purpose	2K_dev_569
Space-Time Adaptive Processing ( STAP ) is a technique for processing signals from multiple antenna elements over multiple time periods for target detection	background	2K_dev_570
As STAP algorithms are typical run on airborne platforms	background	2K_dev_570
they need to be both high performance and energy-efficient Due to the high rate of processing required	background	2K_dev_570
many existing algorithms focus on reducing the dimensionality of the data	background	2K_dev_570
or exploiting structure in the underlying mathematical formulation in order to reduce the total number of floating-point operations ( FLOPs )	background	2K_dev_570
and consequently	background	2K_dev_570
the time for computation	background	2K_dev_570
We show that more than 11x improvement in time	finding	2K_dev_570
and 77x improvement in energy efficiency can be expected when a 3D stack is used together with memory-side accelerators to target the memory-bounded operations within STAP	finding	2K_dev_570
	finding	2K_dev_570
In this paper using a 3D stacked Logic-in-Memory system The imminent arrival of 3D stacked memory makes avail high memory bandwidth	mechanism	2K_dev_570
which opens up a new and orthogonal dimension for optimizing STAP algorithms	mechanism	2K_dev_570
	method	2K_dev_570
While such algorithms target the FLOPs-intensive operations within the STAP algorithm	purpose	2K_dev_570
a significant portion of the compute time for most STAP algorithms is actually spent in low-FLOPs	purpose	2K_dev_570
memory-bounded operations we address the computation of these memory-bounded operations within the STAP algorithm	purpose	2K_dev_570
For deeply scaled digital integrated systems	background	2K_dev_571
the power required for transporting data between memory and logic can exceed the power needed for computation	background	2K_dev_571
thereby limiting the efficacy of synthesizing logic and compiling memory independently Logic-in-Memory ( LiM ) architectures address this challenge by embedding logic within the memory block to perform basic operations on data locally for specific functions	background	2K_dev_571
	background	2K_dev_571
results shown in this paper demonstrate a 250x performance improvement and 310x energy savings for a data-intensive application example	finding	2K_dev_571
In this paper we present a tool and design methodology for LiM physical synthesis The resulting layouts and timing models can be incorporated within any physical synthesis tool	mechanism	2K_dev_571
	mechanism	2K_dev_571
Silicon	method	2K_dev_571
While custom smart memories have been successfully constructed for various applications	purpose	2K_dev_571
a fully automated LiM synthesis flow enables architectural exploration that has heretofore not been possible that performs co-design of algorithms and architectures to explore system level trade-offs	purpose	2K_dev_571
	background	2K_dev_572
	finding	2K_dev_572
We consider an adaptive cruise control system in which based on position and velocity information received from other vehicles via V2V wireless communication If the vehicles follow each other at a close distance	mechanism	2K_dev_572
they have better wireless reception but collisions may occur when a follower car does not receive notice about the decelerations of the leader car fast enough to react before it is too late	mechanism	2K_dev_572
If the vehicles are farther apart	mechanism	2K_dev_572
they would have a bigger safety margin	mechanism	2K_dev_572
but the wireless communication drops out more often	mechanism	2K_dev_572
so that the follower car no longer receives what the leader car is doing	mechanism	2K_dev_572
In order to guarantee safety	mechanism	2K_dev_572
such a system must return control to the driver if it does not receive an update from a nearby vehicle within some timeout period	mechanism	2K_dev_572
The value of this timeout parameter encodes a tradeoff between the likelihood that an update is received and the maximum safe acceleration Combining formal verification techniques for hybrid systems with a wireless communication model	mechanism	2K_dev_572
	mechanism	2K_dev_572
we analyze how the expected efficiency of a provably-safe adaptive cruise control system is affected by the value of this timeout	method	2K_dev_572
control decisions are made	purpose	2K_dev_572
Accurate models of the cross-talk between signaling pathways and transcriptional regulatory networks within cells are essential to understand complex response programs	background	2K_dev_573
Consequently	background	2K_dev_573
our method is widely applicable and can be used to derive accurate	background	2K_dev_573
dynamic response models in several species	background	2K_dev_573
	background	2K_dev_573
demonstrate the predictive power of our method	finding	2K_dev_573
We present a new computational method that combines condition-specific time-series expression data with general protein interaction data These networks characterize the pathways involved in the response	mechanism	2K_dev_573
their time of activation	mechanism	2K_dev_573
and the affected genes The signaling and regulatory components of our networks are linked via a set of common transcription factors that serve as targets in the signaling network and as regulators of the transcriptional response network	mechanism	2K_dev_573
Our method correctly identifies the core signaling proteins and transcription factors of the response programs	mechanism	2K_dev_573
It further predicts the involvement of additional transcription factors and other proteins not previously implicated in the response pathways	mechanism	2K_dev_573
Our approach requires little condition-specific data : only a partial set of upstream initiators and time-series gene expression data	mechanism	2K_dev_573
which are readily available for many conditions and species	mechanism	2K_dev_573
	mechanism	2K_dev_573
Detailed case studies of stress responses in budding yeast We experimentally verify several of these predictions for the osmotic stress response network	method	2K_dev_573
	method	2K_dev_573
to reconstruct dynamic and causal stress response networks	purpose	2K_dev_573
	purpose	2K_dev_573
People spend an enormous amount of time searching for complex information online ; for example	background	2K_dev_574
consumers researching new purchases or patients learning about their conditions	background	2K_dev_574
we show that having access to others ' schemas while foraging for information helps new users to induce more useful	finding	2K_dev_574
prototypical	finding	2K_dev_574
and better-structured schemas than gathering information alone	finding	2K_dev_574
In this paper we introduce a novel approach	mechanism	2K_dev_574
Through a controlled experiment	method	2K_dev_574
As they search	purpose	2K_dev_574
people build up rich mental schemas about their target domains ; which	purpose	2K_dev_574
if effectively shared	purpose	2K_dev_574
could accelerate learning for others with similar interests	purpose	2K_dev_574
for integrating the schemas individuals develop as they gather information online and surfacing them for others with similar interests	purpose	2K_dev_574
	purpose	2K_dev_574
Multimedia event detection ( MED ) is a retrieval task with the goal of finding videos of a particular event in a large scale internet video archive	background	2K_dev_575
given example videos and text descriptions	background	2K_dev_575
show that our proposed method outperforms the state-of-the-art methods by up to 4 %	finding	2K_dev_575
	finding	2K_dev_575
In this paper	mechanism	2K_dev_575
we investigate the possibility of using the high-level face information to assist multimedia event detection	mechanism	2K_dev_575
Moreover	mechanism	2K_dev_575
since the labeled data in TRECVID MED dataset are limited	mechanism	2K_dev_575
we propose a semi-supervised kernel ridge regression which works well in practice to explore the useful information from unlabeled data to assist the event detection	mechanism	2K_dev_575
	mechanism	2K_dev_575
Extensive experimental results on TRECVID MED dataset	method	2K_dev_575
Nowadays	purpose	2K_dev_575
different multimodal fusion schemes of low-level and high-level features are extensively investigated and evaluated for MED	purpose	2K_dev_575
For most of events in MED	purpose	2K_dev_575
people are usually the central subjects in videos	purpose	2K_dev_575
The face of a person can be considered as the most important factor which brings a lot of information describing the video events	purpose	2K_dev_575
However	purpose	2K_dev_575
face information has not been systematically investigated in the previous research for MED	purpose	2K_dev_575
Current research is interested in identifying how topology impacts epidemics in networks	background	2K_dev_576
We show that for k-regular graph topologies	finding	2K_dev_576
the most probable network state transitions from the state where everyone is healthy to one where everyone is infected at a threshold that depends on k but not on the size of the graph	finding	2K_dev_576
In this paper	mechanism	2K_dev_576
we model SIS ( susceptible-infected-susceptible ) epidemics as a continuous-time Markov process and for which Such distribution describes the long-run behavior of the epidemics	mechanism	2K_dev_576
The adjacency matrix of the network topology is reflected explicitly in the formulation of the equilibrium distribution	mechanism	2K_dev_576
Secondly	method	2K_dev_576
we are interested in analyzing the model in the regime where the topology dependent infection process opposes the topology independent healing process	method	2K_dev_576
Specifically	method	2K_dev_576
how will network topology affect the most probable long-run network state ?	method	2K_dev_576
we can obtain a closed form description of the equilibrium distribution	purpose	2K_dev_576
	purpose	2K_dev_576
Provision of training data sets is one of the core requirements for event-based supervised NILM ( Non-Intrusive Load Monitoring ) algorithms	background	2K_dev_577
Due to diversity in appliances ' technologies	background	2K_dev_577
in-situ training by users is often required	background	2K_dev_577
This process might require continuous user-interaction to ensure that a high quality training data set is provided	background	2K_dev_577
	background	2K_dev_577
The algorithm performance in accurate partitioning of the feature space and the effect of different feature extraction techniques were presented and discussed	finding	2K_dev_577
In this study	mechanism	2K_dev_577
a heuristic unsupervised clustering algorithm is presented and evaluated The algorithm is based on hierarchical clustering and uses the characteristics of a cluster binary tree to determine the distance threshold for pruning the tree without a priori information	mechanism	2K_dev_577
The algorithm determines the partition of a feature space recursively to account for multi-scale nature of the binary cluster tree	mechanism	2K_dev_577
	mechanism	2K_dev_577
Evaluation of the algorithm was carried out using metrics for accuracy and cluster quality ( proposed in this study ) on a fully labeled data set that was collected and processed in a real residential setting	method	2K_dev_577
	method	2K_dev_577
Pre-populating a training data set could potentially reduce the need for user-system interaction to enable autonomous partitioning of appliances signature space ( i	purpose	2K_dev_577
e feature space ) for applications in electricity consumption disaggregation	purpose	2K_dev_577
	background	2K_dev_578
demonstrate the effectiveness and intuitiveness of our discovered patterns	finding	2K_dev_578
We propose TSum	mechanism	2K_dev_578
a method ordered by their `` representativeness It can decide both which these patterns are	mechanism	2K_dev_578
as well as how many are necessary to properly summarize the data	mechanism	2K_dev_578
Our main contribution is formulating a general framework	mechanism	2K_dev_578
TSum	mechanism	2K_dev_578
using compression principles	mechanism	2K_dev_578
TSum can easily accommodate different optimization strategies for selecting and refining patterns	mechanism	2K_dev_578
The discovered patterns can be used to both represent the data efficiently	mechanism	2K_dev_578
as well as interpret it quickly	mechanism	2K_dev_578
	mechanism	2K_dev_578
Extensive experiments	method	2K_dev_578
Given a table where rows correspond to records and columns correspond to attributes	purpose	2K_dev_578
we want to find a small number of patterns that succinctly summarize the dataset	purpose	2K_dev_578
For example	purpose	2K_dev_578
given a set of patient records with several attributes each	purpose	2K_dev_578
how can we find ( a ) that the `` most representative '' pattern is	purpose	2K_dev_578
say	purpose	2K_dev_578
( male	purpose	2K_dev_578
adult	purpose	2K_dev_578
* )	purpose	2K_dev_578
followed by ( *	purpose	2K_dev_578
child	purpose	2K_dev_578
low-cholesterol )	purpose	2K_dev_578
etc ? that provides a sequence of patterns	purpose	2K_dev_578
Matched field processing is a powerful tool for accurately localizing targets in dispersive media	background	2K_dev_579
However	background	2K_dev_579
matched field processing requires a precise model of the medium under test	background	2K_dev_579
In underwater acoustics	background	2K_dev_579
where matched field processing has been extensively studied	background	2K_dev_579
authors often resort to extremely detailed numerical models of the propagation medium	background	2K_dev_579
which are computationally expensive and impractical for many applications	background	2K_dev_579
We demonstrate the effectiveness of this model The results visually illustrate our approach to significantly improve localization accuracy and reduce artifacts when compared to a conventional narrowband technique	finding	2K_dev_579
As an alternative	mechanism	2K_dev_579
this paper uses convex sparse recovery techniques directly from measured data based on its dispersion characteristics	mechanism	2K_dev_579
From this data-driven model	mechanism	2K_dev_579
the Green 's function between two points can be readily predicted	mechanism	2K_dev_579
	mechanism	2K_dev_579
by localizing a source in a dispersive plate medium	method	2K_dev_579
	method	2K_dev_579
to construct an accurate model of a plate medium	purpose	2K_dev_579
Restricted Boltzmann Machine ( RBM ) has shown great effectiveness in document modeling	background	2K_dev_580
It utilizes hidden units to discover the latent topics and can learn compact semantic representations for documents which greatly facilitate document retrieval	background	2K_dev_580
clustering and classification	background	2K_dev_580
demonstrate that with diversification	finding	2K_dev_580
the document modeling power of DRBM can be greatly improved	finding	2K_dev_580
	finding	2K_dev_580
we propose Diversified RBM ( DRBM ) which diversifies the hidden units	mechanism	2K_dev_580
to make them cover not only the dominant topics	mechanism	2K_dev_580
but also those in the long-tail region	mechanism	2K_dev_580
We define a diversity metric and use it as a regularizer to encourage the hidden units to be diverse	mechanism	2K_dev_580
Since the diversity metric is hard to optimize directly	mechanism	2K_dev_580
we instead optimize its lower bound and prove that maximizing the lower bound with projected gradient ascent can increase this diversity metric	mechanism	2K_dev_580
	mechanism	2K_dev_580
Experiments on document retrieval and clustering	method	2K_dev_580
The popularity ( or frequency ) of topics in text corpora usually follow a power-law distribution where a few dominant topics occur very frequently while most topics ( in the long-tail region ) have low probabilities	purpose	2K_dev_580
Due to this imbalance	purpose	2K_dev_580
RBM tends to learn multiple redundant hidden units to best represent dominant topics and ignore those in the long-tail region	purpose	2K_dev_580
which renders the learned representations to be redundant and non-informative	purpose	2K_dev_580
To solve this problem	purpose	2K_dev_580
	purpose	2K_dev_580
	background	2K_dev_581
	finding	2K_dev_581
	mechanism	2K_dev_581
	method	2K_dev_581
	purpose	2K_dev_581
Despite benefits and uses of social networking sites ( SNSs ) users are not always satisfied with their behaviors on the sites	background	2K_dev_582
Based on these results we provide insights both into how participants perceive different SNSs	background	2K_dev_582
as well as potential designs for behavior-change mechanisms to target SNS behaviors	background	2K_dev_582
	background	2K_dev_582
While some participants want to reduce site use	finding	2K_dev_582
others want to improve their use or increase a range of behaviors	finding	2K_dev_582
These desired changes differ by SNS	finding	2K_dev_582
and	finding	2K_dev_582
for Twitter	finding	2K_dev_582
by participants ' levels of site use Participants also expect a range of benefits from these goals	finding	2K_dev_582
including increased time	finding	2K_dev_582
contact with others	finding	2K_dev_582
intrinsic benefits	finding	2K_dev_582
better security/privacy	finding	2K_dev_582
and improved self presentation	finding	2K_dev_582
	finding	2K_dev_582
	mechanism	2K_dev_582
We use a 604-participant online survey	method	2K_dev_582
These desires for behavior change both provide insight into users ' perceptions of how SNSs impact their lives ( positively or negatively ) and can inform tools for helping users achieve desired behavior changes to explore SNS users ' behavior-change goals for Facebook	purpose	2K_dev_582
Instagram	purpose	2K_dev_582
and Twitter	purpose	2K_dev_582
	purpose	2K_dev_582
Non-Intrusive Load Monitoring ( NILM ) has been studied for a few decades now as a method of disaggregating information about appliance level power consumption in a building from aggregate measurements of voltage and/or current obtained at a centralized location in the electrical system When such information is provided to the electricity consumer as feedback	background	2K_dev_583
they can then take the necessary steps to modify their behavior and conserve Research has shown potential for savings of up to 20 % through this kind of feedback	background	2K_dev_583
The training phase required to allow the algorithms to recognize appliances in the home at the beginning of a NILM setup is a big hindrance to wide adoption of the technique	background	2K_dev_583
One of the recent advances in this research area includes the addition of an Electro-Magnetic Field ( EMF ) sensor that measures the electric and magnetic field nearby an appliance to detect its operational state	background	2K_dev_583
This information	background	2K_dev_583
when coupled with the aggregate power consumption data for the home	background	2K_dev_583
can help to train a NILM system	background	2K_dev_583
which is a significant step forward in automating the training phase	background	2K_dev_583
Possible reasons behind the findings are discussed and areas for further exploration are proposed	background	2K_dev_583
	background	2K_dev_583
A vector subspace obtained using Independent Component Analysis ( ICA )	finding	2K_dev_583
along with a k-NN classifier	finding	2K_dev_583
was found to perform best among the different alternatives explored	finding	2K_dev_583
	finding	2K_dev_583
automating the training and classification process using these devices	mechanism	2K_dev_583
Various dimensionality reduction techniques are applied to the collected data	mechanism	2K_dev_583
and the resulting feature vectors are used to train a variety of common machine learning classifiers	mechanism	2K_dev_583
	mechanism	2K_dev_583
A case study is presented	method	2K_dev_583
where magnetic field measurements of eight appliances are analyzed to determine the viability of using these signals alone to determine the type of appliance that the EMF sensor has been placed next to	method	2K_dev_583
This paper explores the theory behind the operation of the EMF sensor and discusses the feasibility of	purpose	2K_dev_583
High-data-rate sensors	background	2K_dev_584
such as video cameras	background	2K_dev_584
are becoming ubiquitous in the Internet of Things	background	2K_dev_584
This article is part of a special issue on smart spaces	background	2K_dev_584
	background	2K_dev_584
	finding	2K_dev_584
This article describes GigaSight	mechanism	2K_dev_584
	mechanism	2K_dev_584
with strong enforcement of privacy preferences and access controls The GigaSight architecture is a federated system of VM-based cloudlets that perform video analytics at the edge of the Internet	mechanism	2K_dev_584
thus reducing the demand for ingress bandwidth into the cloud	mechanism	2K_dev_584
Denaturing	mechanism	2K_dev_584
which is an owner-specific reduction in fidelity of video content to preserve privacy	mechanism	2K_dev_584
is one form of analytics on cloudlets	mechanism	2K_dev_584
Content-based indexing for search is another form of cloudlet-based analytics	mechanism	2K_dev_584
	method	2K_dev_584
an Internet-scale repository of crowd-sourced video content	purpose	2K_dev_584
	background	2K_dev_585
	finding	2K_dev_585
	mechanism	2K_dev_585
	method	2K_dev_585
	purpose	2K_dev_585
Many vision tasks require a multi-class classifier to discriminate multiple categories	background	2K_dev_586
on the order of hundreds or thousands	background	2K_dev_586
	background	2K_dev_586
Empirical results demonstrate the effectiveness of our proposed approach	finding	2K_dev_586
	finding	2K_dev_586
In this paper	mechanism	2K_dev_586
we propose sparse output coding	mechanism	2K_dev_586
by turning high-cardinality multi-class categorization into a bit-by-bit decoding problem	mechanism	2K_dev_586
Specifically	mechanism	2K_dev_586
sparse output coding is composed of two steps : efficient coding matrix learning with scalability to thousands of classes	mechanism	2K_dev_586
and probabilistic decoding	mechanism	2K_dev_586
	mechanism	2K_dev_586
on object recognition and scene classification	method	2K_dev_586
a principled way for large-scale multi-class classification	purpose	2K_dev_586
	purpose	2K_dev_586
Computers have the potential to significantly extend the practice of popular music based on steady tempo and mostly determined form	background	2K_dev_587
	finding	2K_dev_587
We describe an approach to synchronization across media that We also address with repeats and other structures to an actual performance	mechanism	2K_dev_587
which can involve both flattening the score and rearranging it	mechanism	2K_dev_587
as is common in popular music	mechanism	2K_dev_587
Finally	mechanism	2K_dev_587
we illustrate the possibilities of the score as a bidirectional user interface in a real-time system for music performance	mechanism	2K_dev_587
allowing the user to direct the computer through a digitally displayed score	mechanism	2K_dev_587
and allowing the computer to indicate score position back to human performers	mechanism	2K_dev_587
	mechanism	2K_dev_587
	method	2K_dev_587
There are significant challenges to overcome	purpose	2K_dev_587
however	purpose	2K_dev_587
due to constraints including accurate timing based on beats and adherence to a form or structure despite possible changes that may occur	purpose	2K_dev_587
possibly even during performance	purpose	2K_dev_587
takes into account latency due to communication delays and audio buffering	purpose	2K_dev_587
the problem of mapping from a conventional score	purpose	2K_dev_587
Noisy	background	2K_dev_588
high-dimensional time series observations can often be described by a set of low-dimensional latent variables	background	2K_dev_588
Commonly used methods to extract these latent variables typically assume instantaneous relationships between the latent and observed variables	background	2K_dev_588
In many physical systems	background	2K_dev_588
changes in the latent variables manifest as changes in the observed variables after time delays	background	2K_dev_588
demonstrate that when time delays are present	finding	2K_dev_588
TD-GPFA is able to correctly identify these delays and recover the latent space	finding	2K_dev_588
TD-GPFA is able to better describe the neural activity using a more parsimonious latent space than GPFA	finding	2K_dev_588
a method that has been used to interpret motor cortex data but does not account for time delays	finding	2K_dev_588
In this work	mechanism	2K_dev_588
we introduce a novel probabilistic technique	mechanism	2K_dev_588
time-delay gaussian-process factor analysis TD-GPFA in the presence of a different time delay between each pair of latent and observed variables We demonstrate how using a gaussian process to model the evolution of each latent variable allows us to tractably learn these delays over a continuous domain	mechanism	2K_dev_588
Additionally	mechanism	2K_dev_588
we show how TD-GPFA combines temporal smoothing and dimensionality reduction into a common probabilistic framework	mechanism	2K_dev_588
We present an expectation/conditional maximization either ECME algorithm to learn the model parameters More broadly	mechanism	2K_dev_588
TD-GPFA can help to unravel the mechanisms underlying high-dimensional time series data by taking into account physical delays in the system	mechanism	2K_dev_588
	mechanism	2K_dev_588
Our simulations We then applied TD-GPFA to the activity of tens of neurons recorded simultaneously in the macaque motor cortex during a reaching task	method	2K_dev_588
Techniques that do not account for these delays can recover a larger number of latent variables than are present in the system	purpose	2K_dev_588
thereby making the latent representation more difficult to interpret that performs dimensionality reduction	purpose	2K_dev_588
There has been significant interest and progress recently in algorithms that solve regression problems involving tall and thin matrices in input sparsity time	background	2K_dev_589
Our results build upon the close connection between randomized matrix algorithms	background	2K_dev_589
iterative methods	background	2K_dev_589
and graph sparsification	background	2K_dev_589
	finding	2K_dev_589
We show these iterative methods can be adapted Our approaches are based on computing the importances of the rows	mechanism	2K_dev_589
known as leverage scores	mechanism	2K_dev_589
in an iterative manner We show that alternating between computing a short matrix estimate and finding more accurate approximate leverage scores leads to a series of geometrically smaller instances	mechanism	2K_dev_589
This gives an algorithm whose runtime is input sparsity plus an overhead comparable to the cost of solving a regression problem on the smaller approximation	mechanism	2K_dev_589
	mechanism	2K_dev_589
	method	2K_dev_589
Given a n * d matrix where n g d	purpose	2K_dev_589
these algorithms find an approximation with fewer rows	purpose	2K_dev_589
allowing one to solve a poly ( d ) sized problem instead	purpose	2K_dev_589
In practice	purpose	2K_dev_589
the best performances are often obtained by invoking these routines in an iterative fashion to give theoretical guarantees comparable to and better than the current state of the art	purpose	2K_dev_589
	purpose	2K_dev_589
Abstract Genes are often combinatorially regulated by multiple transcription factors ( TFs )	background	2K_dev_590
Such combinatorial regulation plays an important role in development and facilitates the ability of cells to respond to different stresses	background	2K_dev_590
we show that the predicted combinatorial sets agree with other high throughput genomic datasets and improve upon prior methods	finding	2K_dev_590
Here we present cDREM	mechanism	2K_dev_590
a new method cDREM integrates time series gene expression data with ( static ) protein interaction data	mechanism	2K_dev_590
The method is based on a hidden Markov model and utilizes the sparse group Lasso to identify small subsets of combinatorially active TFs	mechanism	2K_dev_590
their time of activation	mechanism	2K_dev_590
and the logical function they implement	mechanism	2K_dev_590
We tested cDREM on yeast and human data sets Using yeast	method	2K_dev_590
While a number of approaches have utilized sequence and ChIP-based datasets to study combinational regulation	purpose	2K_dev_590
these have often ignored the combinational logic and the dynamics associated with such regulation	purpose	2K_dev_590
for reconstructing dynamic models of combinatorial regulation	purpose	2K_dev_590
	background	2K_dev_591
	finding	2K_dev_591
Finally	mechanism	2K_dev_591
we design a dynamic attack detector	mechanism	2K_dev_591
We assume the attack detector has access to a linear function of the initial system state that can not be altered by an attacker	method	2K_dev_591
First	method	2K_dev_591
we provide a necessary and sufficient condition for an attack to be undetectable by any dynamic attack detector under each specific side information pattern	method	2K_dev_591
Second	method	2K_dev_591
we characterize attacks that can be sustained for arbitrarily long periods without being detected	method	2K_dev_591
Third	method	2K_dev_591
we define the zero state inducing attack	method	2K_dev_591
the only type of attack that remains dynamically undetectable regardless of the side initial state information available to the attack detector	method	2K_dev_591
	method	2K_dev_591
This technical note studies the impact of side initial state information on the detectability of data deception attacks against cyber-physical systems	purpose	2K_dev_591
that detects detectable attacks	purpose	2K_dev_591
	purpose	2K_dev_591
	background	2K_dev_592
	finding	2K_dev_592
	mechanism	2K_dev_592
	method	2K_dev_592
	purpose	2K_dev_592
Several researchers proposed using non-Euclidean metrics on point sets in Euclidean space for clustering noisy data	background	2K_dev_593
Almost always	background	2K_dev_593
a distance function is desired that recognizes the closeness of the points in the same cluster	background	2K_dev_593
even if the Euclidean cluster diameter is large	background	2K_dev_593
	background	2K_dev_593
	finding	2K_dev_593
which we call the nearest neighbor metric	mechanism	2K_dev_593
Given a point set P and a path	mechanism	2K_dev_593
t his metric is the integral of the distance to P along	mechanism	2K_dev_593
W e describe a ( 3 +e ) - approximation algorithm and a more intricate ( 1 + e ) -approximation algorithm to compute the nearest neighbor metric Both approximation algorithms work in near-linear time	mechanism	2K_dev_593
The former uses shortest paths on a sparse graph defined over the input points	mechanism	2K_dev_593
The latter uses a sparse sample of the ambient space	mechanism	2K_dev_593
to find good approximate geodesic paths	mechanism	2K_dev_593
	method	2K_dev_593
There- fore	purpose	2K_dev_593
it is preferred to assign smaller costs to the paths that stay close to the input points	purpose	2K_dev_593
In this paper	purpose	2K_dev_593
we consider a natural metric with this property	purpose	2K_dev_593
	purpose	2K_dev_593
	background	2K_dev_594
	finding	2K_dev_594
We present an algorithm that The algorithm runs in time $ \tilde { O } ( ( m \log { n } + n\log^2 { n } ) \log ( 1/p ) )	mechanism	2K_dev_594
$ As a result	mechanism	2K_dev_594
we obtain an algorithm that on input of an $ n\times n $ symmetric diagonally dominant matrix $ A $ with $ m $ nonzero entries and a vector $ b $ computes a vector $ { x } $ satisfying $ || { x } -A^ { + } b||_A < \epsilon ||A^ { + } b||_A $	mechanism	2K_dev_594
in expected time $ \tilde { O } ( m\log^2 { n } \log ( 1/\epsilon ) )	mechanism	2K_dev_594
$ The solver is based on repeated applications of the incremental sparsifier that produces a chain of graphs which is then used as input to the recursive preconditioned Chebyshev iteration	mechanism	2K_dev_594
	method	2K_dev_594
on input of an $ n $ -vertex $ m $ -edge weighted graph $ G $ and a value $ k $ produces an incremental sparsifier $ \hat { G } $ with $ n-1 + m/k $ edges	purpose	2K_dev_594
such that the relative condition number of $ G $ with $ \hat { G } $ is bounded above by $ \tilde { O } ( k\log^2 n ) $	purpose	2K_dev_594
with probability $ 1-p $ ( we use the $ \tilde { O } ( ) $ notation to hide a factor of at most $ ( \log\log n ) ^4 $ )	purpose	2K_dev_594
Linear subspace learning methods such as Fisher 's Linear Discriminant Analysis ( LDA )	background	2K_dev_595
Unsupervised Discriminant Projection ( UDP )	background	2K_dev_595
and Locality Preserving Projections ( LPP ) have been widely used in face recognition applications as a tool to capture low dimensional discriminant information However	background	2K_dev_595
when these methods are applied in the context of face recognition	background	2K_dev_595
they often encounter the small-sample-size problem	background	2K_dev_595
In order to overcome this problem	background	2K_dev_595
a separate Principal Component Analysis ( PCA ) step is usually adopted to reduce the dimensionality of the data	background	2K_dev_595
that our proposed FKDA significantly outperforms traditional linear discriminant subspace learning methods as well as five other competing algorithms	finding	2K_dev_595
	finding	2K_dev_595
In this work	mechanism	2K_dev_595
we propose a new idea which we named Multi-class Fukunaga Koontz Discriminant Analysis ( FKDA ) by incorporating the Fukunaga Koontz Transform within the optimization In contrast to traditional LDA	mechanism	2K_dev_595
UDP	mechanism	2K_dev_595
and LPP	mechanism	2K_dev_595
our approach can work with very high dimensional data as input	mechanism	2K_dev_595
without requiring a separate dimensionality reduction step to make the scatter matrices full rank In addition	mechanism	2K_dev_595
the FKDA formulation seeks optimal projection direction vectors that are orthogonal which the existing methods can not guarantee	mechanism	2K_dev_595
and it has the capability of finding the exact solutions to the `` trace ratio '' objective in discriminant analysis problems while traditional methods can only deal with a relaxed and inexact `` ratio trace '' objective	mechanism	2K_dev_595
HighlightsSolve small-sample-size problem in LDA	mechanism	2K_dev_595
UDP	mechanism	2K_dev_595
LPP using FKT formulation	mechanism	2K_dev_595
Can work with high dimensional data without inverting any scatter matrices	mechanism	2K_dev_595
Finds optimal projection direction vectors that are orthogonal	mechanism	2K_dev_595
Finds exact solutions to the objective in the form of trace ratio	mechanism	2K_dev_595
Improvement in unconstrained face recognition scenarios	mechanism	2K_dev_595
We have shown using six face database	method	2K_dev_595
in the context of large scale unconstrained face recognition	method	2K_dev_595
face recognition with occlusions	method	2K_dev_595
and illumination invariant face recognition	method	2K_dev_595
under `` closed set ''	method	2K_dev_595
`` semi-open set ''	method	2K_dev_595
and `` open set '' recognition scenarios	method	2K_dev_595
	method	2K_dev_595
However	purpose	2K_dev_595
such a step may discard dimensions that contain important discriminative information that can aid classification performance for maximizing class separation criteria in LDA	purpose	2K_dev_595
UDP	purpose	2K_dev_595
and LPP	purpose	2K_dev_595
Online consumers are uncertain about subjective product quality e	background	2K_dev_596
g	background	2K_dev_596
	background	2K_dev_596
fit and feel of clothing and texture of materials because of the absence of experiential information	background	2K_dev_596
This implies that online consumers are reluctant to buy expensive products with only digitally transferred information	background	2K_dev_596
whereas they tend to purchase more of the cheaper products online along with their accumulated online shopping experience	background	2K_dev_596
Our study on the dynamics in the set of products purchased online expands the understanding of consumer purchase behavior under uncertainty	background	2K_dev_596
we find that consumers purchase products with a high degree of product uncertainty as their online shopping experiences help them better estimate product quality	finding	2K_dev_596
Our results also show that the average and highest prices of market baskets decrease around 1 % when online shopping experience increases 10 %	finding	2K_dev_596
When online consumers buy products priced under $ 50	finding	2K_dev_596
they readily buy products with a high degree of product uncertainty regardless of their online shopping experience	finding	2K_dev_596
But consumers are unlikely to buy expensive products online if there is a high degree of product uncertainty	finding	2K_dev_596
even when they have accumulated much online shopping experience	finding	2K_dev_596
In addition	finding	2K_dev_596
we find that online vendors can effectively overcome product-level uncertainty by taking advantage of retailer reputation in the physical world and through the use of digitized video commercials This paper was accepted by Lorin Hitt	finding	2K_dev_596
information systems	finding	2K_dev_596
	mechanism	2K_dev_596
Using individual-level transaction data We also verify the interaction effects of product uncertainty and product price on online consumers ' purchase decision	method	2K_dev_596
In this paper	purpose	2K_dev_596
we examine the dynamic change of the products purchased online over time in the presence of this type of uncertainty	purpose	2K_dev_596
	background	2K_dev_597
the systems and methods determine that resources associated with an execution client performing symbolic execution of a target program are below	finding	2K_dev_597
at	finding	2K_dev_597
or above a threshold performance level	finding	2K_dev_597
generate checkpoints for active executing paths of the online symbolic execution	finding	2K_dev_597
and cause the execution client to perform symbolic execution in response to the determination that the resources are at or above the threshold performance level	finding	2K_dev_597
Systems and methods are described	mechanism	2K_dev_597
In some example embodiments	method	2K_dev_597
for performing hybrid symbolic execution to detect exploitable bugs in binary code	purpose	2K_dev_597
	background	2K_dev_598
reveal the bottlenecks for video upload	finding	2K_dev_598
denaturing	finding	2K_dev_598
indexing	finding	2K_dev_598
and content-based search	finding	2K_dev_598
They also provide insight on how parameters such as frame rate and resolution impact scalability	finding	2K_dev_598
	finding	2K_dev_598
We propose a scalable Internet system from devices such as Google Glass	mechanism	2K_dev_598
Our hybrid cloud architecture	mechanism	2K_dev_598
GigaSight	mechanism	2K_dev_598
is effectively a Content Delivery Network ( CDN ) in reverse It achieves scalability by decentralizing the collection infrastructure using cloudlets based on virtual machines~ ( VMs )	mechanism	2K_dev_598
Based on time	mechanism	2K_dev_598
location	mechanism	2K_dev_598
and content	mechanism	2K_dev_598
privacy sensitive information is automatically removed from the video	mechanism	2K_dev_598
This process	mechanism	2K_dev_598
which we refer to as denaturing	mechanism	2K_dev_598
is executed in a user-specific VM on the cloudlet Users can perform content-based searches on the total catalog of denatured videos	mechanism	2K_dev_598
	mechanism	2K_dev_598
Our experiments	method	2K_dev_598
for continuous collection of crowd-sourced video	purpose	2K_dev_598
Self-paced learning ( SPL ) is a recently proposed learning regime inspired by the learning process of humans and animals that gradually incorporates easy to more complex samples into training	background	2K_dev_599
	background	2K_dev_599
We demonstrate that our method significantly outperforms the conventional SPL Specifically	finding	2K_dev_599
SPLD achieves the best MAP so far reported in literature on the Hollywood2 and Olympic Sports datasets	finding	2K_dev_599
we propose an approach called self-paced learning with diversity ( SPLD ) which formalizes the preference for both easy and diverse samples into a general regularizes This regularization term is independent of the learning objective	mechanism	2K_dev_599
and thus can be easily generalized into various learning tasks	mechanism	2K_dev_599
Albeit non-convex	mechanism	2K_dev_599
the optimization of the variables included in this SPLD regularization term for sample selection can be globally solved in linearithmic time	mechanism	2K_dev_599
on three real-world datasets	method	2K_dev_599
Existing methods are limited in that they ignore an important aspect in learning : diversity	purpose	2K_dev_599
To incorporate this information	purpose	2K_dev_599
	purpose	2K_dev_599
Suspicious graph patterns show up in many applications	background	2K_dev_600
from Twitter users who buy fake followers	background	2K_dev_600
manipulating the social network	background	2K_dev_600
to botnet members performing distributed denial of service attacks	background	2K_dev_600
disturbing the network traffic graph	background	2K_dev_600
	background	2K_dev_600
CatchSync consistently outperforms existing competitors	finding	2K_dev_600
both in detection accuracy by 36 % on Twitter and 20 % on Tencent Weibo	finding	2K_dev_600
as well as in speed	finding	2K_dev_600
We propose a fast and effective method	mechanism	2K_dev_600
CatchSync	mechanism	2K_dev_600
which exploits two of the tell-tale signs left in graphs by fraudsters : ( a ) synchronized behavior : suspicious nodes have extremely similar behavior pattern	mechanism	2K_dev_600
because they are often required to perform some task together ( such as follow the same user ) ; and ( b ) rare behavior : their connectivity patterns are very different from the majority	mechanism	2K_dev_600
We introduce novel measures and we propose a parameter-free algorithm that works on the resulting synchronicity-normality plots Thanks to careful design	mechanism	2K_dev_600
CatchSync has the following desirable properties : ( a ) it is scalable to large datasets	mechanism	2K_dev_600
being linear on the graph size ; ( b ) it is parameter free ; and ( c ) it is side-information-oblivious : it can operate using only the topology	mechanism	2K_dev_600
without needing labeled data	mechanism	2K_dev_600
nor timing information	mechanism	2K_dev_600
etc	mechanism	2K_dev_600
	mechanism	2K_dev_600
while still capable of using side information	mechanism	2K_dev_600
if available	mechanism	2K_dev_600
We applied CatchSync on two large	method	2K_dev_600
real datasets 1-billion-edge Twitter social graph and 3-billion-edge Tencent Weibo social graph	method	2K_dev_600
and several synthetic ones	method	2K_dev_600
Given a directed graph of millions of nodes	purpose	2K_dev_600
how can we automatically spot anomalous	purpose	2K_dev_600
suspicious nodes	purpose	2K_dev_600
judging only from their connectivity patterns ? to quantify both concepts ( `` synchronicity '' and `` normality '' )	purpose	2K_dev_600
Regularization has played a key role in deriving sensible estimators in high dimensional statistical inference	background	2K_dev_601
A substantial amount of recent works has argued for nonconvex regularizers in favor of their superior theoretical properties and excellent practical performances	background	2K_dev_601
In a dierent but analogous vein	background	2K_dev_601
nonconvex loss functions are promoted because of their robustness against \outliers ''	background	2K_dev_601
	background	2K_dev_601
prove its nice convergence properties	finding	2K_dev_601
and illustrate its eectiveness demonstrate that our method compares favorably against other alternatives	finding	2K_dev_601
we propose a new proximal gradient meta-algorithm by rigorously extending the proximal average to the nonconvex setting	mechanism	2K_dev_601
We formally on two applications : multi-task graph-guided fused lasso and robust support vector machines Experiments	method	2K_dev_601
However	purpose	2K_dev_601
these nonconvex formulations are computationally more challenging	purpose	2K_dev_601
especially in the presence of nonsmoothness and nonseparability	purpose	2K_dev_601
To address this issue	purpose	2K_dev_601
	purpose	2K_dev_601
	background	2K_dev_602
that a uniform team	finding	2K_dev_602
consisting of multiple instances of any single agent	finding	2K_dev_602
must make a significant number of mistakes	finding	2K_dev_602
whereas a diverse team converges to perfection as the number of agents grows provide evidence for the effectiveness of voting when agents are diverse	finding	2K_dev_602
	finding	2K_dev_602
With teams of computer Go agents in mind	mechanism	2K_dev_602
we develop a novel theoretical model of two-stage noisy voting that builds on recent work in machine learning	mechanism	2K_dev_602
This model	mechanism	2K_dev_602
which	mechanism	2K_dev_602
furthermore	mechanism	2K_dev_602
apply randomized algorithms to evaluate alternatives and produce votes ( captured by the second-stage noise models )	mechanism	2K_dev_602
	mechanism	2K_dev_602
We analytically demonstrate Our experiments	method	2K_dev_602
which pit teams of computer Go agents against strong agents	method	2K_dev_602
	method	2K_dev_602
We investigate the power of voting among diverse	purpose	2K_dev_602
randomized software agents allows us to reason about a collection of agents with different biases ( determined by the first-stage noise models )	purpose	2K_dev_602
Navigation models are explicit representations of geometrical and topological information of physical environments that can be utilized for map-matching of indoor positioning data	background	2K_dev_603
	finding	2K_dev_603
This research paper presents algorithms The abovementioned navigation models have been generated in an automated fashion from Industry Foundation Classes ( IFC ) -based building information models ( BIM )	mechanism	2K_dev_603
Specifically	mechanism	2K_dev_603
we have 1 ) built on and targeted addressing limitations of existing algorithms that generate centerline-based network navigation models for polygonal shapes	mechanism	2K_dev_603
2 ) developed an approach for creating metric-based navigation models	mechanism	2K_dev_603
and 3 ) modified an existing algorithm using geometry and topology extracted from BIM	mechanism	2K_dev_603
The abovementioned three types of navigation models have been generated for six different testbeds with varying shape	method	2K_dev_603
size and density of spaces We have validated the generality of the developed algorithms by evaluating the accuracy of geometrical and topological information contained within the three types of navigation models generated from testbeds with varying spatial characteristics	method	2K_dev_603
for automated generation of three different types of navigation models	purpose	2K_dev_603
namely	purpose	2K_dev_603
centerline-based network	purpose	2K_dev_603
metric-based and grid-based navigation models	purpose	2K_dev_603
for map-matching of indoor positioning data	purpose	2K_dev_603
to extract 2D geometry and topology from IFC-based BIM to generate grid-based navigation models	purpose	2K_dev_603
	background	2K_dev_604
	finding	2K_dev_604
	mechanism	2K_dev_604
	method	2K_dev_604
	purpose	2K_dev_604
	background	2K_dev_605
	finding	2K_dev_605
	mechanism	2K_dev_605
	method	2K_dev_605
	purpose	2K_dev_605
Motivation : Synaptic connections underlie learning and memory in the brain and are dynamically formed and eliminated during development and in response to stimuli	background	2K_dev_606
Quantifying changes in overall density and strength of synapses is an important pre-requisite for studying connectivity and plasticity in these cases or in diseased conditions	background	2K_dev_606
Results We detected thousands of synapses in these images and Our algorithms are highly efficient and scalable and are freely available for others to use	finding	2K_dev_606
Availability : Code is available at http : //www	finding	2K_dev_606
cs	finding	2K_dev_606
cmu	finding	2K_dev_606
edu/ saketn/detect_synapses/	finding	2K_dev_606
and we developed a machine-learning framework We also used a semi-supervised algorithm that leverages unlabeled data	mechanism	2K_dev_606
we used a 50-year-old experimental technique to selectively stain for synapses in electron microscopy images	method	2K_dev_606
To validate our method	method	2K_dev_606
we experimentally imaged brain tissue of the somatosensory cortex in six mice	method	2K_dev_606
demonstrate the accuracy of our approach using crossvalidation with manually labeled data and by comparing against existing algorithms and against tools that process standard electron microscopy images	method	2K_dev_606
Unfortunately	purpose	2K_dev_606
most techniques to detect such changes are either low-throughput ( e	purpose	2K_dev_606
g	purpose	2K_dev_606
electrophysiology )	purpose	2K_dev_606
prone to error and difficult to automate ( e	purpose	2K_dev_606
g	purpose	2K_dev_606
standard electron microscopy ) or too coarse ( e	purpose	2K_dev_606
g	purpose	2K_dev_606
magnetic resonance imaging ) to provide accurate and large-scale measurements	purpose	2K_dev_606
: To facilitate high-throughput analyses	purpose	2K_dev_606
to automatically detect synapses in these images	purpose	2K_dev_606
to overcome sample heterogeneity and improve performance	purpose	2K_dev_606
	background	2K_dev_607
which demonstrate that our method scales well with large data and model sizes	finding	2K_dev_607
while beating learning strategies that fail to take both data and model partitioning into account	finding	2K_dev_607
We present a scheme Unlike algorithms that focus on distributed learning in either the big data or big model setting ( but not both )	mechanism	2K_dev_607
our scheme partitions both the data and model variables simultaneously This not only leads to faster learning on distributed clusters	mechanism	2K_dev_607
but also enables machine learning applications where both data and model are too large to fit within the memory of a single machine	mechanism	2K_dev_607
Furthermore	mechanism	2K_dev_607
our scheme allows worker machines to perform additional updates while waiting for slow workers to finish	mechanism	2K_dev_607
which provides users with a tunable synchronization strategy that can be set based on learning needs and cluster conditions	mechanism	2K_dev_607
	mechanism	2K_dev_607
We prove the correctness of such strategies	method	2K_dev_607
as well as provide bounds on the variance of the model variables under our scheme	method	2K_dev_607
Finally	method	2K_dev_607
we present empirical results for latent space models such as topic models	method	2K_dev_607
	method	2K_dev_607
for fast	purpose	2K_dev_607
distributed learning on big ( i	purpose	2K_dev_607
e	purpose	2K_dev_607
high-dimensional ) models applied to big datasets	purpose	2K_dev_607
The integration of synthetic and cell-free biology has made tremendous strides towards creating artificial cellular nanosystems using concepts from solution-based chemistry : only the concentrations of reacting species modulate gene expression rates However	background	2K_dev_608
it is known that macromolecular crowding	background	2K_dev_608
a key feature of natural cells	background	2K_dev_608
can dramatically influence biochemical kinetics by volume exclusion effects that reduce diffusion rates and enhance binding rates of macromolecules	background	2K_dev_608
our work has implications for efficient and robust control of both synthetic and natural cellular circuits	background	2K_dev_608
	finding	2K_dev_608
through integrating synthetic cellular components of biological circuits and artificial cellular nanosystems	mechanism	2K_dev_608
	mechanism	2K_dev_608
	method	2K_dev_608
Here	purpose	2K_dev_608
we demonstrate that macromolecular crowding can increase the robustness of gene expression In addition	purpose	2K_dev_608
we reveal how ubiquitous cellular modules	purpose	2K_dev_608
including genetic components	purpose	2K_dev_608
a negative feedback loop	purpose	2K_dev_608
and the size of crowding molecules	purpose	2K_dev_608
can fine tune gene circuit response to molecular crowding	purpose	2K_dev_608
By bridging a key gap between artificial and living cells	purpose	2K_dev_608
Phylogenetic algorithms have begun to see widespread use in cancer research to reconstruct processes of evolution in tumor progression	background	2K_dev_609
Developing reliable phylogenies for tumor data requires quantitative models of cancer evolution that include the unusual genetic mechanisms by which tumors evolve	background	2K_dev_609
such as chromosome abnormalities	background	2K_dev_609
and allow for heterogeneity between tumor types and individual patients	background	2K_dev_609
	background	2K_dev_609
Results identifies key genomic events in disease progression consistent with prior literature	finding	2K_dev_609
lead to improved prediction accuracy for the metastasis of primary cervical cancers and for tongue cancer survival	finding	2K_dev_609
Availability and implementation : Our software ( FISHtrees ) and two datasets are available at ftp : //ftp	finding	2K_dev_609
ncbi	finding	2K_dev_609
nlm	finding	2K_dev_609
nih	finding	2K_dev_609
gov/pub/FISHtrees	finding	2K_dev_609
We propose a framework from single-cell gene copy number data	mechanism	2K_dev_609
including variable rates for different gain and loss events We propose a new algorithm We extend it via dynamic programming to include genome duplications	mechanism	2K_dev_609
We implement an expectation maximization ( EM ) -like method	mechanism	2K_dev_609
Application of our algorithms to real cervical cancer data Classification experiments on cervical and tongue cancer datasets	method	2K_dev_609
Motivation Previous work on inferring phylogenies of single tumors by copy number evolution assumed models of uniform rates of genomic gain and loss across different genomic sites and scales	purpose	2K_dev_609
a substantial oversimplification necessitated by a lack of algorithms and quantitative parameters for fitting to more realistic tumor evolution models	purpose	2K_dev_609
for inferring models of tumor progression for identification of most parsimonious combinations of single gene and single chromosome events to estimate mutation-specific and tumor-specific event rates concurrently with tree reconstruction	purpose	2K_dev_609
Studying temporal dynamics of topics in social media is very useful to understand online user behaviors	background	2K_dev_610
Most of the existing work on this subject usually monitors the global trends	background	2K_dev_610
ignoring variation among communities Since users from different communities tend to have varying tastes and interests	background	2K_dev_610
capturing communitylevel temporal change can improve the understanding and management of social content	background	2K_dev_610
Additionally	background	2K_dev_610
it can further facilitate the applications such as community discovery	background	2K_dev_610
temporal prediction and online marketing	background	2K_dev_610
	finding	2K_dev_610
and demonstrate the superiority of proposed model on tasks of time stamp prediction	finding	2K_dev_610
link prediction and topic perplexity	finding	2K_dev_610
In this paper	mechanism	2K_dev_610
we take a unified solution towards the communitylevel topic dynamic extraction	mechanism	2K_dev_610
A probabilistic model	mechanism	2K_dev_610
CosTot ( Community Specific Topics-over-Time ) is proposed to uncover the hidden topics and communities	mechanism	2K_dev_610
as well as capture community-specific temporal dynamics	mechanism	2K_dev_610
Specifically	mechanism	2K_dev_610
CosTot considers text	mechanism	2K_dev_610
time	mechanism	2K_dev_610
and network information simultaneously	mechanism	2K_dev_610
and well discovers the interactions between community and topic over time We then discuss the approximate inference implementation to enable scalable computation of model parameters	mechanism	2K_dev_610
especially for large social data	mechanism	2K_dev_610
	mechanism	2K_dev_610
Based on this	method	2K_dev_610
the application layer support for multi-scale temporal analysis and community exploration is also investigated	method	2K_dev_610
We conduct extensive experimental studies on a large real microblog dataset	method	2K_dev_610
However	purpose	2K_dev_610
this kind of extraction becomes challenging due to the intricate interactions between community and topic	purpose	2K_dev_610
and intractable computational complexity	purpose	2K_dev_610
	purpose	2K_dev_610
The goal of supervised feature selection is to find a subset of input features that are responsible for predicting output values	background	2K_dev_611
	background	2K_dev_611
	finding	2K_dev_611
In this paper	mechanism	2K_dev_611
we consider a feature-wise kernelized Lasso We first show that	mechanism	2K_dev_611
with particular choices of kernel functions	mechanism	2K_dev_611
non-redundant features with strong statistical dependence on output values can be found in terms of kernel-based independence measures such as the Hilbert-Schmidt independence criterion ( HSIC ) We then show that the globally optimal solution can be efficiently computed ; this makes the approach scalable to high-dimensional problems	mechanism	2K_dev_611
	mechanism	2K_dev_611
The effectiveness of the proposed method is demonstrated through feature selection experiments for classification and regression with thousands of features	method	2K_dev_611
	method	2K_dev_611
The least absolute shrinkage and selection operator ( Lasso ) allows computationally efficient feature selection based on linear dependency between input features and output values	purpose	2K_dev_611
for capturing non-linear input-output dependency	purpose	2K_dev_611
We also discuss potential future research directions in this area	background	2K_dev_612
demonstrate the proposed approach is effective for human activity analysis	finding	2K_dev_612
	finding	2K_dev_612
In this paper	mechanism	2K_dev_612
we focus on automatic human activities analysis in video surveillance recorded in complicated environments at a nursing home	mechanism	2K_dev_612
This will enable the automatic exploration of the statistical patterns between patients ' daily activities and their clinical diagnosis	mechanism	2K_dev_612
	mechanism	2K_dev_612
Experiment	method	2K_dev_612
As our society is increasingly aging	purpose	2K_dev_612
it is urgent to develop computer aided techniques to improve the quality-of-care ( QoC ) and quality-of-life ( QoL ) of geriatric patients	purpose	2K_dev_612
	purpose	2K_dev_612
	background	2K_dev_613
	finding	2K_dev_613
We present an autonomous driving research vehicle with minimal appearance modifications including smooth and comfortable trajectory generation and following ; lane keeping and lane changing ; intersection handling with or without V2I and V2V ; and pedestrian	mechanism	2K_dev_613
bicyclist	mechanism	2K_dev_613
and workzone detection	mechanism	2K_dev_613
Safety and reliability features include a fault-tolerant computing system ; smooth and intuitive autonomous-manual switching ; and the ability to fully disengage and power down the drive-by-wire and computing system upon E-stop	mechanism	2K_dev_613
	mechanism	2K_dev_613
The vehicle has been tested extensively on both a closed test field and public roads	method	2K_dev_613
that is capable of a wide range of autonomous and intelligent behaviors	purpose	2K_dev_613
Game-theoretic algorithms for physical security have made an impressive real-world impact These algorithms compute an optimal strategy for the defender to commit to in a Stackelberg game	background	2K_dev_614
where the attacker observes the defender 's strategy and best-responds	background	2K_dev_614
	background	2K_dev_614
	finding	2K_dev_614
We design an algorithm	mechanism	2K_dev_614
by observing the attacker 's responses to randomized deployments of resources and learning his priorities In contrast to previous work	mechanism	2K_dev_614
our algorithm requires a number of queries that is polynomial in the representation of the game	mechanism	2K_dev_614
	mechanism	2K_dev_614
	method	2K_dev_614
In order to build the game model	purpose	2K_dev_614
though	purpose	2K_dev_614
the payoffs of potential attackers for various outcomes must be estimated ; inaccurate estimates can lead to significant inefficiencies that optimizes the defender 's strategy with no prior information	purpose	2K_dev_614
	background	2K_dev_615
	finding	2K_dev_615
The paper explains how to use sensors as the eyes	mechanism	2K_dev_615
ears	mechanism	2K_dev_615
hands	mechanism	2K_dev_615
and feet for the cloud This paper describes the opportunities and challenges	mechanism	2K_dev_615
	method	2K_dev_615
when integrating sensors and cloud computing	purpose	2K_dev_615
	purpose	2K_dev_615
Tablet computers are often called upon to emulate classical pen-and-paper input	background	2K_dev_616
	background	2K_dev_616
Our system improves upon previous approaches	finding	2K_dev_616
reducing accidental palm inputs to 0	finding	2K_dev_616
016 per pen stroke	finding	2K_dev_616
while correctly passing 98 % of stylus inputs	finding	2K_dev_616
	finding	2K_dev_616
We present a probabilistic touch filtering approach that uses the temporal evolution of touch contacts	mechanism	2K_dev_616
	method	2K_dev_616
However	purpose	2K_dev_616
touchscreens typically lack the means to distinguish between legitimate stylus and finger touches and touches with the palm or other parts of the hand	purpose	2K_dev_616
This forces users to rest their palms elsewhere or hover above the screen	purpose	2K_dev_616
resulting in ergonomic and usability problems	purpose	2K_dev_616
to reject palms	purpose	2K_dev_616
Most algorithmic matches in fielded kidney exchanges do not result in an actual transplant	background	2K_dev_617
	background	2K_dev_617
We show that failure-aware kidney exchange can significantly increase the expected number of lives saved and show that this new solver scales well	finding	2K_dev_617
From the computational viewpoint	mechanism	2K_dev_617
we design a branch-and-price-based optimal clearing algorithm specifically	mechanism	2K_dev_617
( i ) in theory	method	2K_dev_617
on random graph models ; ( ii ) on real data from kidney exchange match runs between 2010 and 2012 ; ( iii ) on synthetic data generated via a model of dynamic kidney exchange on large simulated data	method	2K_dev_617
unlike prior clearing algorithms	method	2K_dev_617
In this paper	purpose	2K_dev_617
we address the problem of cycles and chains in a proposed match failing after the matching algorithm has committed to them	purpose	2K_dev_617
for the probabilistic exchange clearing problem	purpose	2K_dev_617
Cloud offload is an important technique in mobile computing	background	2K_dev_618
VM-based cloudlets have been proposed as offload sites for the resource-intensive and latency-sensitive computations typically associated with mobile multimedia applications	background	2K_dev_618
we demonstrate a prototype system that is capable of provisioning a cloudlet with a non-trivial VM image in 10 seconds	finding	2K_dev_618
	finding	2K_dev_618
we describe just-in-time ( JIT ) provisioning of cloudlets under the control of an associated mobile device This speed is achieved through dynamic VM synthesis and a series of optimizations to aggressively reduce transfer costs and startup latency	mechanism	2K_dev_618
Using a suite of five representative mobile applications	method	2K_dev_618
	method	2K_dev_618
Since cloud offload relies on precisely-configured back-end software	purpose	2K_dev_618
it is difficult to support at global scale across cloudlets in multiple domains To address this problem	purpose	2K_dev_618
The average person can skillfully manipulate a plethora of tools	background	2K_dev_619
from hammers to tweezers	background	2K_dev_619
	background	2K_dev_619
	finding	2K_dev_619
users were able to summon a variety of virtual tools by replicating their corresponding real-world grasps	finding	2K_dev_619
	finding	2K_dev_619
We propose that touch gesture design be inspired by the manipulation of physical tools from the real world	mechanism	2K_dev_619
In this way	mechanism	2K_dev_619
we can leverage user familiarity and fluency with such tools	mechanism	2K_dev_619
With only a few minutes of training on a proof-of-concept system	method	2K_dev_619
However	purpose	2K_dev_619
despite this remarkable dexterity	purpose	2K_dev_619
gestures on today 's touch devices are simplistic	purpose	2K_dev_619
relying primarily on the chording of fingers : one -finger pan	purpose	2K_dev_619
two -finger pinch	purpose	2K_dev_619
four -finger swipe and similar	purpose	2K_dev_619
to build a rich set of gestures for touch interaction	purpose	2K_dev_619
	purpose	2K_dev_619
Location sharing is a popular feature of online social networks	background	2K_dev_620
but challenges remain in the effective presentation of privacy choices to users	background	2K_dev_620
whose location sharing preferences are complex and diverse	background	2K_dev_620
One proposed approach for capturing these nuances builds on the observation that key attributes of users ' location sharing preferences can be represented by a small number of privacy profiles	background	2K_dev_620
which can provide a basis for configuring individual preferences	background	2K_dev_620
This further suggests that the provision of profiles for privacy settings must be carefully considered	background	2K_dev_620
as they can substantially alter sharing behavior	background	2K_dev_620
The results suggest that this approach can influence users to share significantly more without a substantial difference in comfort	finding	2K_dev_620
	mechanism	2K_dev_620
We present a study	method	2K_dev_620
However	purpose	2K_dev_620
the impact of this approach on how users view their privacy is relatively unknown evaluating the impact of this approach on users ' location sharing preferences and their satisfaction with the decisions made by their resulting settings	purpose	2K_dev_620
The proliferation of touchscreen devices has made soft keyboards a routine part of life	background	2K_dev_621
	background	2K_dev_621
After eight practice trials	finding	2K_dev_621
users achieved an average of 9	finding	2K_dev_621
3 words per minute	finding	2K_dev_621
with accuracy comparable to a full-sized physical keyboard This compares favorably to existing mobile text input methods	finding	2K_dev_621
	finding	2K_dev_621
In this work	mechanism	2K_dev_621
we present a soft keyboard interaction technique called ZoomBoard Our approach uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size	mechanism	2K_dev_621
We based our design on a QWERTY layout	mechanism	2K_dev_621
so that it is immediately familiar to users and leverages existing skill	mechanism	2K_dev_621
	mechanism	2K_dev_621
As the ultimate test	method	2K_dev_621
we ran a text entry experiment on a keyboard measuring just 16 x 6mm - smaller than a US penny	method	2K_dev_621
	method	2K_dev_621
However	purpose	2K_dev_621
ultra-small computing platforms like the Sony SmartWatch and Apple iPod Nano lack a means of text entry	purpose	2K_dev_621
This limits their potential	purpose	2K_dev_621
despite the fact they are quite capable computers	purpose	2K_dev_621
that enables text entry on ultra-small devices	purpose	2K_dev_621
	purpose	2K_dev_621
	background	2K_dev_622
PriorityMeister outperforms most recent reactive request scheduling approaches	finding	2K_dev_622
with more workloads satisfying latency SLOs at higher latency percentiles	finding	2K_dev_622
	finding	2K_dev_622
This paper describes PriorityMeister -- a system that employs a combination of per-workload priorities and rate limits	mechanism	2K_dev_622
even with bursty workloads	mechanism	2K_dev_622
PriorityMeister automatically and proactively configures workload priorities and rate limits across multiple stages ( e	mechanism	2K_dev_622
g	mechanism	2K_dev_622
	mechanism	2K_dev_622
a shared storage stage followed by a shared network stage ) to meet end-to-end tail latency SLOs PriorityMeister is also robust to mis-estimation of underlying storage device performance and contains the effect of misbehaving workloads	mechanism	2K_dev_622
In real system experiments and under production trace workloads	method	2K_dev_622
	method	2K_dev_622
Meeting service level objectives ( SLOs ) for tail latency is an important and challenging open problem in cloud computing infrastructures	purpose	2K_dev_622
The challenges are exacerbated by burstiness in the workloads to provide tail latency QoS for shared networked storage	purpose	2K_dev_622
With an explosion of popularity of online photo sharing	background	2K_dev_623
we can trivially collect a huge number of photo streams for any interesting topics such as scuba diving as an outdoor recreational activity class	background	2K_dev_623
our empirical results show that the proposed algorithms are more successful than other candidate methods for both tasks	finding	2K_dev_623
In this paper	mechanism	2K_dev_623
we propose an approach The alignment task discovers the matched images between different photo streams	mechanism	2K_dev_623
and the image segmentation task parses each image into multiple meaningful regions to facilitate the image understanding	mechanism	2K_dev_623
We close a loop between the two tasks so that solving one task helps enhance the performance of the other in a mutually rewarding way	mechanism	2K_dev_623
To this end	mechanism	2K_dev_623
we design a scalable message-passing based optimization framework to jointly achieve both tasks for the whole input image set at	mechanism	2K_dev_623
With evaluation on the new Flickr dataset of 15 outdoor activities that consist of 1	method	2K_dev_623
5 millions of images of 13 thousands of photo streams	method	2K_dev_623
	method	2K_dev_623
Obviously	purpose	2K_dev_623
the retrieved photo streams are neither aligned nor calibrated since they are taken in different temporal	purpose	2K_dev_623
spatial	purpose	2K_dev_623
and personal perspectives	purpose	2K_dev_623
However	purpose	2K_dev_623
at the same time	purpose	2K_dev_623
they are likely to share common storylines that consist of sequences of events and activities frequently recurred within the topic	purpose	2K_dev_623
as a first technical step to detect such collective storylines	purpose	2K_dev_623
to jointly aligning and segmenting uncalibrated multiple photo streams	purpose	2K_dev_623
	purpose	2K_dev_623
Regret-based methods have largely been favored in practice	background	2K_dev_624
in spite of their theoretically inferior convergence rates	background	2K_dev_624
	finding	2K_dev_624
we find that mirror prox and the excessive gap technique outperform the prior regret-based methods for finding medium accuracy solutions	finding	2K_dev_624
In this paper we investigate the acceleration of first-order methods both theoretically and experimentally An important component of many first-order methods is a distance-generating function	mechanism	2K_dev_624
Motivated by this	mechanism	2K_dev_624
we investigate a specific distance-generating function	mechanism	2K_dev_624
namely the dilated entropy function	mechanism	2K_dev_624
over treeplexes	mechanism	2K_dev_624
which are convex polytopes that encompass the strategy spaces of perfect-recall extensive-form games	mechanism	2K_dev_624
We develop significantly stronger bounds on the associated strong convexity parameter	mechanism	2K_dev_624
In terms of extensive-form game solving	mechanism	2K_dev_624
this improves the convergence rate of several first-order methods by a factor of O ( ( # information sets depth M ) / ( 2 depth ) ) where M is the maximum value of the l 1 norm over the treeplex encoding the strategy spaces	mechanism	2K_dev_624
In order to instantiate stochastic mirror prox	mechanism	2K_dev_624
we develop a class of gradient sampling schemes for game trees	mechanism	2K_dev_624
Equipped with our distance-generating function and sampling scheme	mechanism	2K_dev_624
Experimentally	method	2K_dev_624
we investigate the performance of three first-order methods ( the excessive gap technique	method	2K_dev_624
mirror prox	method	2K_dev_624
and stochastic mirror prox ) and compare their performance to the regret-based algorithms	method	2K_dev_624
	method	2K_dev_624
We study the problem of computing a Nash equilibrium in large-scale two-player zero-sum extensive-form games While this problem can be solved in polynomial time	purpose	2K_dev_624
first-order or regret-based methods are usually preferred for large games	purpose	2K_dev_624
	purpose	2K_dev_624
How does a new startup drive the popularity of competing websites into oblivion like Facebook famously did to MySpace ? This question is of great interest to academics	background	2K_dev_625
technologists	background	2K_dev_625
and financial investors alike	background	2K_dev_625
	background	2K_dev_625
The resulting model not only accurately fits the observed Daily Active Users ( DAU ) of Facebook and its competitors but also predicts their fate four years into the future	finding	2K_dev_625
Our model provides new insights into what Nobel Laure- ate Herbert A	mechanism	2K_dev_625
Simon called the `` marketplace of attention	mechanism	2K_dev_625
'' which we recast as the attention-activity marketplace	mechanism	2K_dev_625
Our model design is further substantiated by user-level activity of 250	method	2K_dev_625
000 MySpace users obtained between 2004 and 2009	method	2K_dev_625
	method	2K_dev_625
In this work we exploit the singular way in which Facebook wiped out the popularity of MySpace	purpose	2K_dev_625
Hi5	purpose	2K_dev_625
Friendster	purpose	2K_dev_625
and Multiply to guide the design of a new popularity competition model	purpose	2K_dev_625
	purpose	2K_dev_625
	background	2K_dev_626
	finding	2K_dev_626
We present a new method the `` Non-Parametric Heterogeneous Graph Scan ( NPHGS ) ''	mechanism	2K_dev_626
NPHGS enables fast and accurate detection of emerging space-time clusters using Twitter and other social media streams where standard parametric model assumptions are incorrect	mechanism	2K_dev_626
	method	2K_dev_626
for disease outbreak detection	purpose	2K_dev_626
	purpose	2K_dev_626
Distributed machine learning has typically been approached from a data parallel perspective	background	2K_dev_627
where big data are partitioned to multiple workers and an algorithm is executed concurrently over different data subsets under various synchronization schemes to ensure speed-up and/or correctness	background	2K_dev_627
	finding	2K_dev_627
In this paper	mechanism	2K_dev_627
we develop a system for model-parallelism	mechanism	2K_dev_627
STRADS	mechanism	2K_dev_627
that provides a programming abstraction for scheduling parameter updates by discovering and leveraging changing structural properties of ML programs	mechanism	2K_dev_627
STRADS enables a flexible tradeoff between scheduling efficiency and fidelity to intrinsic dependencies within the models	mechanism	2K_dev_627
and improves memory efficiency of distributed ML	mechanism	2K_dev_627
	mechanism	2K_dev_627
We demonstrate the efficacy of model-parallel algorithms implemented on STRADS versus popular implementations for topic modeling	method	2K_dev_627
matrix factorization	method	2K_dev_627
and Lasso	method	2K_dev_627
	method	2K_dev_627
A sibling problem that has received relatively less attention is how to ensure efficient and correct model parallel execution of ML algorithms	purpose	2K_dev_627
where parameters of an ML program are partitioned to different workers and undergone concurrent iterative updates	purpose	2K_dev_627
We argue that model and data parallelisms impose rather different challenges for system design	purpose	2K_dev_627
algorithmic adjustment	purpose	2K_dev_627
and theoretical analysis	purpose	2K_dev_627
Computational cancer phylogenetics seeks to enumerate the temporal sequences of aberrations in tumor evolution	background	2K_dev_628
thereby delineating the evolution of possible tumor progression pathways	background	2K_dev_628
molecular subtypes	background	2K_dev_628
and mechanisms of action	background	2K_dev_628
We previously developed a pipeline for constructing phylogenies describing evolution between major recurring cell types computationally inferred from whole-genome tumor profiles	background	2K_dev_628
	background	2K_dev_628
which confirms its effectiveness for tumor phylogeny inference and suggests avenues for future advances	finding	2K_dev_628
	finding	2K_dev_628
Here	mechanism	2K_dev_628
we present a novel hidden Markov model ( HMM ) scheme through joint segmentation and calling of multisample tumor data Our method classifies sets of genome-wide DNA copy number measurements into a partitioning of samples into normal ( diploid ) or amplified at each probe	mechanism	2K_dev_628
It differs from other similar HMM methods in its design specifically for the needs of tumor phylogenetics	mechanism	2K_dev_628
by seeking to identify robust markers of progression conserved across a set of copy number profiles	mechanism	2K_dev_628
We show an analysis of our method in comparison to other methods on both synthetic and real tumor data	method	2K_dev_628
	method	2K_dev_628
The accuracy and detail of the phylogenies	purpose	2K_dev_628
however	purpose	2K_dev_628
depend on the identification of accurate	purpose	2K_dev_628
high-resolution molecular markers of progression	purpose	2K_dev_628
i	purpose	2K_dev_628
e	purpose	2K_dev_628
	purpose	2K_dev_628
reproducible regions of aberration that robustly differentiate different subtypes and stages of progression	purpose	2K_dev_628
for the problem of inferring such phylogenetically significant markers	purpose	2K_dev_628
	background	2K_dev_629
	finding	2K_dev_629
	mechanism	2K_dev_629
	method	2K_dev_629
	purpose	2K_dev_629
	background	2K_dev_630
	finding	2K_dev_630
We present Air+Touch	mechanism	2K_dev_630
a new class of interactions that interweave touch events with in-air gestures	mechanism	2K_dev_630
We demonstrate how air and touch are highly complementary : touch is used to designate targets and segment in-air gestures	mechanism	2K_dev_630
while in-air gestures add expressivity to touch events	mechanism	2K_dev_630
For example	mechanism	2K_dev_630
a user can draw a circle in the air and tap to trigger a context menu	mechanism	2K_dev_630
do a finger 'high jump ' between two touches to select a region of text	mechanism	2K_dev_630
or drag and in-air 'pigtail ' to copy text to the clipboard we devised a basic taxonomy of Air+Touch interactions	mechanism	2K_dev_630
based on whether the in-air component occurs before	mechanism	2K_dev_630
between or after touches	mechanism	2K_dev_630
Through an observational study	method	2K_dev_630
To illustrate the potential of our approach	method	2K_dev_630
we built four applications that showcase seven exemplar Air+Touch interactions we created	method	2K_dev_630
offering a unified input modality with expressiveness greater than each input modality alone	purpose	2K_dev_630
Recent trends in System-on-a-Chip show that an increasing number of special-purpose processors are being added to improve the efficiency of common operations	background	2K_dev_631
Unfortunately	background	2K_dev_631
the use of these processors may introduce suspension delays incurred by communication	background	2K_dev_631
synchronization and external I/O operations When these processors are used in real-time systems	background	2K_dev_631
conventional schedulability analyses incorporate these delays in the worst-case execution/response time	background	2K_dev_631
hence significantly reducing the schedulable utilization	background	2K_dev_631
	background	2K_dev_631
While RMS is shown to not be optimal	finding	2K_dev_631
it can be used effectively in some special cases that we have identified	finding	2K_dev_631
show that the proposed scheme provides up to 40 times more schedulable utilization than RMS	finding	2K_dev_631
	finding	2K_dev_631
and propose segment-fixed priority scheduling We model the tasks as segments of execution separated by suspensions	mechanism	2K_dev_631
We then derive a utilization bound for the cases as a function of the ratio of the suspension duration to the period of the tasks	mechanism	2K_dev_631
For general cases	mechanism	2K_dev_631
we develop a segment-fixed priority scheduling scheme Our scheme assigns individual segments different priorities and phase offsets that are used for phase enforcement to control the unexpected self-suspending nature	mechanism	2K_dev_631
	mechanism	2K_dev_631
We start from providing response-time analyses for self-suspending tasks under Rate Monotonic Scheduling ( RMS ) With the exact schedulability analysis designed for our scheme	method	2K_dev_631
our experiments	method	2K_dev_631
In this paper	purpose	2K_dev_631
we provide schedulability analyses for self-suspending tasks	purpose	2K_dev_631
	purpose	2K_dev_631
Cloud-sourced virtual appliances ( VAs ) have been touted as powerful solutions for many software maintenance	background	2K_dev_632
mobility	background	2K_dev_632
backward compatibility	background	2K_dev_632
and security challenges	background	2K_dev_632
supports fluid interaction even in challenging network conditions	finding	2K_dev_632
such as 4G LTE	finding	2K_dev_632
	finding	2K_dev_632
to create a VA cloud service More specifically	mechanism	2K_dev_632
we wish to support a YouTube-like streaming service for executable content	mechanism	2K_dev_632
such as games	mechanism	2K_dev_632
interactive books	mechanism	2K_dev_632
research artifacts	mechanism	2K_dev_632
etc	mechanism	2K_dev_632
Users should be able to post	mechanism	2K_dev_632
browse through	mechanism	2K_dev_632
and interact with executable content swiftly and without long interruptions Intuitively	mechanism	2K_dev_632
this seems impossible ; the bandwidths	mechanism	2K_dev_632
latencies	mechanism	2K_dev_632
and costs of last-mile networks would be prohibitive given the sheer sizes of virtual machines ! Yet	mechanism	2K_dev_632
we show that a set of carefully crafted	mechanism	2K_dev_632
novel prefetching and streaming techniques can bring this goal surprisingly close to reality	mechanism	2K_dev_632
We show that vTube	method	2K_dev_632
a VA streaming system that incorporates our techniques	method	2K_dev_632
In this paper	purpose	2K_dev_632
we ask whether it is possible that supports fluid	purpose	2K_dev_632
interactive user experience even over mobile networks	purpose	2K_dev_632
	background	2K_dev_633
improving upon past bounds with convergence rates that depend logarithmically on the data dimension	finding	2K_dev_633
and demonstrating state-of-the-art performance on two real-world tasks	finding	2K_dev_633
	finding	2K_dev_633
This paper considers the sparse Gaussian conditional random field	mechanism	2K_dev_633
a discriminative extension of sparse inverse covariance estimation	mechanism	2K_dev_633
where we use convex methods The model has been proposed by multiple researchers within the past year	mechanism	2K_dev_633
yet previous papers have been substantially limited in their analysis of the method and in the ability to solve large-scale problems In this paper	mechanism	2K_dev_633
we make three contributions : 1 ) we develop a second-order active-set method which is several orders of magnitude faster than previously proposed optimization approaches for this problem	mechanism	2K_dev_633
	mechanism	2K_dev_633
2 ) we analyze the model from a theoretical standpoint	method	2K_dev_633
3 ) we apply the method to large-scale energy forecasting problems	method	2K_dev_633
	method	2K_dev_633
to learn a high-dimensional conditional distribution of outputs given inputs	purpose	2K_dev_633
Previously it has been shown that	background	2K_dev_634
under some conditions on the distribution of votes	background	2K_dev_634
if the number of manipulators is o ( n )	background	2K_dev_634
where n is the number of voters	background	2K_dev_634
then the probability that a random profile is manipulable by the coalition goes to zero as the number of voters goes to infinity	background	2K_dev_634
whereas if the number of manipulators is ( n )	background	2K_dev_634
then the probability that a random profile is manipulable goes to one This result analytically validates recent empirical results	background	2K_dev_634
and suggests that deciding the coalitional manipulation problem may be of limited computational hardness in practice	background	2K_dev_634
	background	2K_dev_634
and we show that as c goes from zero to infinity	finding	2K_dev_634
the limiting probability that a random profile is manipulable goes from zero to one in a smooth fashion	finding	2K_dev_634
i	finding	2K_dev_634
e	finding	2K_dev_634
	finding	2K_dev_634
there is a smooth phase transition between the two regimes	finding	2K_dev_634
	finding	2K_dev_634
Here we consider the critical window	mechanism	2K_dev_634
where a coalition has size cn	mechanism	2K_dev_634
	mechanism	2K_dev_634
	method	2K_dev_634
We study the phase transition of the coalitional manipulation problem for generalized scoring rules	purpose	2K_dev_634
Real-time captioning provides people who are deaf or hard of hearing access to speech in settings such as classrooms and live events	background	2K_dev_635
	background	2K_dev_635
We have shown that the accuracy of Scribe captions approaches that of a professional stenographer	finding	2K_dev_635
while its latency and cost is dramatically lower	finding	2K_dev_635
We introduce Legion Scribe ( Scribe )	mechanism	2K_dev_635
a system that allows 3-5 ordinary people who can hear and type Each person is unable to type at natural speaking rates	mechanism	2K_dev_635
and so is asked only to type part of what they hear Scribe automatically stitches all of the partial captions together to form a complete caption stream	mechanism	2K_dev_635
	method	2K_dev_635
The most reliable approach to provide these captions is to recruit an expert stenographer who is able to type at natural speaking rates	purpose	2K_dev_635
but they charge more than $ 100 USD per hour and must be scheduled in advance	purpose	2K_dev_635
to jointly caption speech in real-time	purpose	2K_dev_635
	purpose	2K_dev_635
Distributed online groups have great potential for generating interdependent and complex products like encyclopedia articles or product design	background	2K_dev_636
These results have implications for small group theory and crowdsourcing research	background	2K_dev_636
	background	2K_dev_636
Our results indicate that	finding	2K_dev_636
contrary to prior work	finding	2K_dev_636
a sequential work structure was more effective than a simultaneous work structure as the size of the group increased	finding	2K_dev_636
suggests that social processes such as territoriality partially accounts for these results	finding	2K_dev_636
mitigated the detrimental effects of the simultaneous work structure	finding	2K_dev_636
	finding	2K_dev_636
	mechanism	2K_dev_636
We conducted an experiment comparing the effectiveness of two coordination strategies ( simultaneous vs	method	2K_dev_636
sequential work ) on a complex creative task as the number of group members increased	method	2K_dev_636
A mediation analysis A follow up experiment giving workers specific roles	method	2K_dev_636
However	purpose	2K_dev_636
coordinating multiple group members to work together effectively while minimizing process losses remains an open challenge	purpose	2K_dev_636
	purpose	2K_dev_636
In a multimillion-node network of who-follows-whom like Twitter	background	2K_dev_637
since a high count of followers leads to higher profits	background	2K_dev_637
users have the incentive to boost their in-degree	background	2K_dev_637
	background	2K_dev_637
Moreover	finding	2K_dev_637
we show it is effective	finding	2K_dev_637
	mechanism	2K_dev_637
we propose CatchSync	mechanism	2K_dev_637
which exploits two tell-tale signs of the suspicious behavior : ( a ) synchronized behavior : the zombie followers have extremely similar following behavior pattern	mechanism	2K_dev_637
because	mechanism	2K_dev_637
say	mechanism	2K_dev_637
they are generated by a script ; and ( b ) abnormal behavior : their behavior pattern is very different from the majority	mechanism	2K_dev_637
Our CatchSync introduces novel measures to quantify both concepts and catches the suspicious behavior	mechanism	2K_dev_637
	mechanism	2K_dev_637
in a real-world social network	method	2K_dev_637
Can we spot the suspicious following behavior	purpose	2K_dev_637
which may indicate zombie followers and suspicious followees ? To answer the above question	purpose	2K_dev_637
Contemporary parallelization strategies employ fine-grained operations and scheduling beyond the classic bulk-synchronous processing paradigm popularized by MapReduce	background	2K_dev_638
or even specialized operators relying on graphical representations of ML programs	background	2K_dev_638
We demonstrate how such a design in light of ML-first principles leads to significant performance improvements versus well-known implementations of several ML programs	finding	2K_dev_638
allowing them to run in much less time and at considerably larger model sizes	finding	2K_dev_638
	finding	2K_dev_638
We propose a general-purpose framework that systematically addresses data- and model-parallel challenges in large-scale ML	mechanism	2K_dev_638
by leveraging several fundamental properties underlying ML programs that make them different from conventional operation-centric programs : error tolerance	mechanism	2K_dev_638
dynamic structure	mechanism	2K_dev_638
and nonuniform convergence ; all stem from the optimization-centric nature shared in ML programs ' mathematical definitions	mechanism	2K_dev_638
and the iterative-convergent behavior of their algorithmic solutions	mechanism	2K_dev_638
These properties present unique opportunities for an integrative system design	mechanism	2K_dev_638
built on bounded-latency network synchronization and dynamic load-balancing scheduling	mechanism	2K_dev_638
which is efficient	mechanism	2K_dev_638
programmable	mechanism	2K_dev_638
and enjoys provable correctness guarantees	mechanism	2K_dev_638
on modestly-sized computer clusters	method	2K_dev_638
	method	2K_dev_638
How can one build a distributed framework that allows efficient deployment of a wide spectrum of modern advanced machine learning ( ML ) programs for industrial-scale problems using Big Models ( 100s of billions of parameters ) on Big Data ( terabytes or petabytes ) - The variety of approaches tends to pull systems and algorithms design in different directions	purpose	2K_dev_638
and it remains difficult to find a universal platform applicable to a wide range of different ML programs at scale	purpose	2K_dev_638
	purpose	2K_dev_638
	background	2K_dev_639
Our method outperforms other well known baselines Finally	finding	2K_dev_639
we also provide a fast	finding	2K_dev_639
parallel approximation of the same	finding	2K_dev_639
Assuming the social network to be an integer-weighted graph ( where the weights can be intuitively defined as the number of common friends	mechanism	2K_dev_639
followers	mechanism	2K_dev_639
documents exchanged	mechanism	2K_dev_639
etc	mechanism	2K_dev_639
)	mechanism	2K_dev_639
we transform the social network to a more efficient representation	mechanism	2K_dev_639
In this new representation	mechanism	2K_dev_639
each user is a bag of her one-hop neighbors	mechanism	2K_dev_639
We propose a mixed-membership model to identify compact communities using this transformation	mechanism	2K_dev_639
Next	mechanism	2K_dev_639
we augment the representation and the model to incorporate user-content information imposing topical consistency in the communities	mechanism	2K_dev_639
In our model a user can belong to multiple communities and a community can participate in multiple topics This allows us to discover community memberships as well as community and user interests	mechanism	2K_dev_639
on two real-world social networks	method	2K_dev_639
	method	2K_dev_639
In this paper	purpose	2K_dev_639
we address the problem of discovering topically meaningful	purpose	2K_dev_639
yet compact ( densely connected ) communities in a social network	purpose	2K_dev_639
	purpose	2K_dev_639
Recently	background	2K_dev_640
data with complex characteristics such as epilepsy electroencephalography ( EEG ) time series has emerged	background	2K_dev_640
Epilepsy EEG data has special characteristics including nonlinearity	background	2K_dev_640
nonnormality	background	2K_dev_640
and nonperiodicity	background	2K_dev_640
	background	2K_dev_640
results show that when compared to previous methods	finding	2K_dev_640
the proposed method can forecast faster and accurately	finding	2K_dev_640
In this paper	mechanism	2K_dev_640
we propose a coercively adjusted autoregression ( CA-AR ) method that forecasts future values from a multivariable epilepsy EEG time series	mechanism	2K_dev_640
We use the technique of random coefficients	mechanism	2K_dev_640
which forcefully adjusts the coefficients with 1 and 1	mechanism	2K_dev_640
The fractal dimension is used to determine the order of the CA-AR model	mechanism	2K_dev_640
We applied the CA-AR method reflecting special characteristics of data to forecast the future value of epilepsy EEG data	mechanism	2K_dev_640
	mechanism	2K_dev_640
Experimental	method	2K_dev_640
Therefore	purpose	2K_dev_640
it is important to find a suitable forecasting method that covers these special characteristics	purpose	2K_dev_640
With the continuous improvement in genotyping and molecular phenotyping technology and the decreasing typing cost	background	2K_dev_641
it is expected that in a few years	background	2K_dev_641
more and more clinical studies of complex diseases will recruit thousands of individuals for pan-omic genetic association analyses	background	2K_dev_641
	background	2K_dev_641
and report some interesting findings	finding	2K_dev_641
	finding	2K_dev_641
We present GenAMap	mechanism	2K_dev_641
an interactive analytics software platform that 1 ) automates the execution of principled machine learning methods that detect genome- and phenome-wide associations among genotypes	mechanism	2K_dev_641
gene expression data	mechanism	2K_dev_641
and clinical or other macroscopic traits	mechanism	2K_dev_641
and 2 ) provides new visualization tools specifically designed to aid in the exploration of association mapping results Algorithmically	mechanism	2K_dev_641
GenAMap is based on a new paradigm for GWAS and PheWAS analysis	mechanism	2K_dev_641
termed structured association mapping	mechanism	2K_dev_641
which leverages various structures in the omic data GenAMap is available from http : //sailing	mechanism	2K_dev_641
cs	mechanism	2K_dev_641
cmu	mechanism	2K_dev_641
edu/genamap	mechanism	2K_dev_641
	mechanism	2K_dev_641
We demonstrate the function of GenAMap via a case study of the Brem and Kruglyak yeast dataset	method	2K_dev_641
and then apply it on a comprehensive eQTL analysis of the NIH heterogeneous stock mice dataset	method	2K_dev_641
Hence	purpose	2K_dev_641
there is a great need for algorithms and software tools that could scale up to the whole omic level	purpose	2K_dev_641
integrate different omic data	purpose	2K_dev_641
leverage rich structure information	purpose	2K_dev_641
and be easily accessible to non-technical users	purpose	2K_dev_641
	purpose	2K_dev_641
	background	2K_dev_642
	finding	2K_dev_642
	mechanism	2K_dev_642
	method	2K_dev_642
	purpose	2K_dev_642
Oral tongue squamous cell carcinoma ( OTSCC ) is associated with poor prognosis	background	2K_dev_643
Whats new ? Oral tongue squamous cell carcinoma ( OTSCC ) is a rare head and neck cancer that typically is asymptomatic in early stages	background	2K_dev_643
	background	2K_dev_643
Unsupervised hierarchical clustering of the FISH data distinguished three clusters related to smoking status Copy number increases of all five markers were found to be correlated to non-smoking habits	finding	2K_dev_643
while smokers in this cohort had low-level copy number gains The patients whose tumors were modeled as progressing by a more diverse distribution of copy number changes across the four genes have poorer prognosis	finding	2K_dev_643
This is consistent with the view that multiple genetic pathways need to become deregulated in order for cancer to progress	finding	2K_dev_643
Analyses of the models showed that the more diverse the changes within the four marker genes	finding	2K_dev_643
the worse the outcome in OTSCC	finding	2K_dev_643
The markers predicted survival independent of smoking behavior and tumor stage	finding	2K_dev_643
Using the phylogenetic modeling software FISHtrees	mechanism	2K_dev_643
we constructed models of tumor progression for each patient based on the four gene probes	mechanism	2K_dev_643
Then	mechanism	2K_dev_643
we derived test statistics on the models that are significant predictors of disease-free and overall survival	mechanism	2K_dev_643
independent of tumor stage and smoking status in multivariate analysis	mechanism	2K_dev_643
Here	mechanism	2K_dev_643
using four fluorescence in situ hybridization ( FISH ) gene probes and the software FISHtrees	mechanism	2K_dev_643
phylogenetic tree models of tumor progression in OTSCC patients were constructed	mechanism	2K_dev_643
we analyzed four gene probes ( TERC	method	2K_dev_643
CCND1	method	2K_dev_643
EGFR and TP53 ) and the centromere probe CEP4 as a marker of chromosomal instability	method	2K_dev_643
using fluorescence in situ hybridization ( FISH ) in single cells from the tumors of sixty-five OTSCC patients ( Stage I	method	2K_dev_643
n=15 ; Stage II	method	2K_dev_643
n=30 ; Stage III	method	2K_dev_643
n=7 ; Stage IV	method	2K_dev_643
n=13 )	method	2K_dev_643
	method	2K_dev_643
To improve prognostication Hence	purpose	2K_dev_643
in order to improve prognosis in OTSCC	purpose	2K_dev_643
predictive biomarkers that are independent of tumor stage must be identified	purpose	2K_dev_643
	purpose	2K_dev_643
and derive some recommendations	background	2K_dev_644
Smartphone users are often unaware of the data collected by apps running on their devices	background	2K_dev_644
	background	2K_dev_644
participants reassessing their permissions	finding	2K_dev_644
and 58 % of them further restricting some of their permissions We discuss how participants interacted both with the permission manager and the privacy nudges	finding	2K_dev_644
analyze the effectiveness of both solutions	finding	2K_dev_644
Our study provides both qualitative and quantitative evidence that these approaches are complementary and can each play a significant role in empowering users to more effectively control their privacy	finding	2K_dev_644
For instance	finding	2K_dev_644
even after a week with access to the permission manager	finding	2K_dev_644
participants benefited from nudges showing them how often some of their sensitive data was being accessed by apps	finding	2K_dev_644
with 95 % of	finding	2K_dev_644
	mechanism	2K_dev_644
that evaluates the benefits of giving users an app permission manager and sending them nudges	method	2K_dev_644
We report on a study intended to raise their awareness of the data collected by their apps	purpose	2K_dev_644
	background	2K_dev_645
We report surprising patterns	finding	2K_dev_645
the most striking of which are : ( a ) the FIZZLE pattern	finding	2K_dev_645
i	finding	2K_dev_645
e	finding	2K_dev_645
	finding	2K_dev_645
excitement about Polly shows a power-law decay over time with ex- ponent of -1	finding	2K_dev_645
2 ; ( b ) the RENDEZVOUS pattern	finding	2K_dev_645
that obeys a power law ( we explain RENDEZVOUS in the text ) ; ( c ) the DISPERSION pattern	finding	2K_dev_645
we find that the more a person uses Polly	finding	2K_dev_645
the fewer friends he will use it with	finding	2K_dev_645
but in a reciprocal fashion	finding	2K_dev_645
Finally	mechanism	2K_dev_645
we also propose a generator of influence networks	mechanism	2K_dev_645
	mechanism	2K_dev_645
using data from the Polly telephone-based application	method	2K_dev_645
a large influence network of 72	method	2K_dev_645
000 people	method	2K_dev_645
with about 173	method	2K_dev_645
000 in- teractions	method	2K_dev_645
spanning 500MB of log data and 200 GB of audio data	method	2K_dev_645
	method	2K_dev_645
When a free	purpose	2K_dev_645
catchy application shows up	purpose	2K_dev_645
how quickly will people notify their friends about it ? Will the enthusiasm drop exponentially with time	purpose	2K_dev_645
or oscillate ? What other patterns emerge ? Here we answer these questions which generate networks that mimic our discovered patterns	purpose	2K_dev_645
	purpose	2K_dev_645
Inadequate information interoperability in facility management ( FM ) activities costs time and money being wasted for searching for the needed information in many different data sources	background	2K_dev_646
An integrated building information model ( BIM )	background	2K_dev_646
depicting as-is conditions	background	2K_dev_646
has a high potential to minimize such wastes	background	2K_dev_646
However	background	2K_dev_646
facility managers still face the challenge of generating as-is building information models for existing facilities	background	2K_dev_646
	background	2K_dev_646
The comparative analysis results reveal several information gaps among different sources	finding	2K_dev_646
The research described in this paper targets by leveraging heterogeneous existing information sources	mechanism	2K_dev_646
such as drawings and operation and maintenance manuals	mechanism	2K_dev_646
	mechanism	2K_dev_646
This approach was investigated through detailed case studies done in two old academic buildings	method	2K_dev_646
Existing information obtained from documents has been compared to Industry Foundation Classes ( IFC )	method	2K_dev_646
COBie and the data generated from a BIM authoring system	method	2K_dev_646
A main problem with current approaches for generating as-is BIMs is that they mainly focus on capturing and providing geometric information	purpose	2K_dev_646
Many other types of information are missing	purpose	2K_dev_646
such as equipment warranty and technical parameters	purpose	2K_dev_646
the generation of accurate and semantically-rich as-is BIMs	purpose	2K_dev_646
	background	2K_dev_647
For correctly specified latent tree graphical models	finding	2K_dev_647
we show that a global optimum of the optimization problem can be obtained via a recursive decomposition algorithm	finding	2K_dev_647
This algorithm recovers previous spectral algorithms for hidden Markov models ( Hsu et al	finding	2K_dev_647
	finding	2K_dev_647
2009 ; Foster et al	finding	2K_dev_647
	finding	2K_dev_647
2012 ) and latent tree graphical models ( Parikh et al	finding	2K_dev_647
	finding	2K_dev_647
2011 ; Song et al	finding	2K_dev_647
	finding	2K_dev_647
2011 ) as special cases	finding	2K_dev_647
elucidating the global objective these algorithms are optimizing	finding	2K_dev_647
this new estimator significantly improves over the state-of-the-art	finding	2K_dev_647
In this new view	mechanism	2K_dev_647
the marginal probability table of the observed variables is treated as a tensor	mechanism	2K_dev_647
and we show that : ( i ) the latent variables induce low rank structures in various matricizations of the tensor ; ( ii ) this collection of low rank matricizations induces a hierarchical low rank decomposition of the tensor	mechanism	2K_dev_647
We further derive an optimization problem for estimating ( alternative ) parameters of a latent tree graphical model	mechanism	2K_dev_647
allowing us to represent the marginal probability table of the observed variables in a compact and robust way	mechanism	2K_dev_647
The optimization problem aims to find the best hierarchical low rank approximation of a tensor in Frobenius norm	mechanism	2K_dev_647
For misspecified latent tree graphical models	mechanism	2K_dev_647
we derive a novel decomposition based on our framework	mechanism	2K_dev_647
and provide approximation guarantee and computational complexity analysis	mechanism	2K_dev_647
In both synthetic and real world data	method	2K_dev_647
	method	2K_dev_647
We approach the problem of estimating the parameters of a latent tree graphical model from a hierarchical tensor decomposition point of view	purpose	2K_dev_647
	purpose	2K_dev_647
Much work in optimal control and inverse control has assumed that the controller has perfect knowledge of plant dynamics	background	2K_dev_648
Due to sensory feedback delay	background	2K_dev_648
the subject uses an internal model to generate an internal prediction of the current plant state	background	2K_dev_648
which may differ from the actual plant state	background	2K_dev_648
We discovered that the subject 's internal model deviated from the true BMI plant dynamics and provided significantly better explanation of the recorded neural control signals than did the true plant dynamics	finding	2K_dev_648
	finding	2K_dev_648
We develop a probabilistic framework and exact EM algorithm	mechanism	2K_dev_648
We applied this framework to demonstrations by a nonhuman primate of brain-machine interface ( BMI ) control	method	2K_dev_648
	method	2K_dev_648
However	purpose	2K_dev_648
if the controller is a human or animal subject	purpose	2K_dev_648
the subject 's internal dynamics model may differ from the true plant dynamics	purpose	2K_dev_648
Here	purpose	2K_dev_648
we consider the problem of learning the subject 's internal model from demonstrations of control and knowledge of task goals	purpose	2K_dev_648
to jointly estimate the internal model	purpose	2K_dev_648
internal state trajectories	purpose	2K_dev_648
and feedback delay	purpose	2K_dev_648
	purpose	2K_dev_648
	background	2K_dev_649
	finding	2K_dev_649
We describe the architecture and prototype implementation of an assistive system based on Google Glass devices It combines the first-person image capture and sensing capabilities of Glass with remote processing to perform real-time scene interpretation	mechanism	2K_dev_649
The system architecture is multi-tiered It offers tight end-to-end latency bounds on compute-intensive operations	mechanism	2K_dev_649
while addressing concerns such as limited battery capacity and limited processing capability of wearable devices The system gracefully degrades services in the face of network failures and unavailability of distant architectural tiers	mechanism	2K_dev_649
	mechanism	2K_dev_649
	method	2K_dev_649
for users in cognitive decline	purpose	2K_dev_649
	purpose	2K_dev_649
Nonparametric mixture models based on the Dirichlet process are an elegant alternative to finite models when the number of underlying components is unknown	background	2K_dev_650
We show that our approach allows scalable inference without the deterioration in estimate quality that accompanies existing methods	finding	2K_dev_650
	finding	2K_dev_650
In this paper	mechanism	2K_dev_650
we describe auxiliary variable representations for the Dirichlet process and the hierarchical Dirichlet process that allow us	mechanism	2K_dev_650
	method	2K_dev_650
	purpose	2K_dev_650
but inference in such models can be slow	purpose	2K_dev_650
Existing attempts to parallelize inference in such models have relied on introducing approximations	purpose	2K_dev_650
which can lead to inaccuracies in the posterior estimate to perform MCMC using the correct equilibrium distribution	purpose	2K_dev_650
in a distributed manner	purpose	2K_dev_650
	purpose	2K_dev_650
Nowadays	background	2K_dev_651
facility management ( FM ) teams are facing challenges to generate accurate and semantically-rich as-is BIMs for existing buildings	background	2K_dev_651
In order to address these challenges	background	2K_dev_651
formalized approaches are required to support conflict resolution	background	2K_dev_651
data extraction and integration	background	2K_dev_651
	background	2K_dev_651
The initial findings from the case study highlighted two main challenges associated with model generation from existing data sources : information extraction and integration Existing information for different components is typically stored in heterogeneous data sources with various formats and quality	finding	2K_dev_651
and hence requires different approaches to extract information	finding	2K_dev_651
The findings also showed that almost 40 % of the component attributes investigated had conflicting values in existing sources	finding	2K_dev_651
	finding	2K_dev_651
	mechanism	2K_dev_651
that aimed at leveraging existing data sources ( e	method	2K_dev_651
g	method	2K_dev_651
	method	2K_dev_651
archived documents and data in FM systems ) to generate accurate and semanticallyrich as-is BIMs	method	2K_dev_651
	method	2K_dev_651
Current model creation approaches	purpose	2K_dev_651
such as model generation based on point cloud data	purpose	2K_dev_651
mainly capture geometric information of a building and lack to provide additional semantic information about components and other project information	purpose	2K_dev_651
This paper provides the results of a detailed case study	purpose	2K_dev_651
Formal verification and validation play a crucial role in making cyber-physical systems ( CPS ) safe	background	2K_dev_652
Formal methods make strong guarantees about the system behavior if accurate models of the system can be obtained	background	2K_dev_652
including models of the controller and of the physical dynamics	background	2K_dev_652
In CPS	background	2K_dev_652
models are essential ; but any model we could possibly build necessarily deviates from the real world	background	2K_dev_652
Overall	finding	2K_dev_652
ModelPlex generates provably correct monitor conditions that	finding	2K_dev_652
are provably guaranteed to imply that the offline safety verification results about the CPS model apply to the present run of the actual CPS implementation	finding	2K_dev_652
This article introduces ModelPlex	mechanism	2K_dev_652
a method ModelPlex provides correctness guarantees for CPS executions at runtime : it combines offline verification of CPS models with runtime validation of system executions for compliance with the model	mechanism	2K_dev_652
ModelPlex ensures in a provably correct way that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model If	mechanism	2K_dev_652
at some point	mechanism	2K_dev_652
the observed behavior no longer complies with the model so that offline verification results no longer apply	mechanism	2K_dev_652
ModelPlex initiates provably safe fallback actions	mechanism	2K_dev_652
assuming the system dynamics deviation is bounded This article	mechanism	2K_dev_652
furthermore	mechanism	2K_dev_652
develops a systematic technique by a correct-by-construction approach	mechanism	2K_dev_652
leading to verifiably correct runtime model validation	mechanism	2K_dev_652
	method	2K_dev_652
if checked to hold at runtime	method	2K_dev_652
If the real system fits to the model	purpose	2K_dev_652
its behavior is guaranteed to satisfy the correctness properties verified with respect to the model	purpose	2K_dev_652
Otherwise	purpose	2K_dev_652
all bets are off	purpose	2K_dev_652
ensuring that verification results about models apply to CPS implementations	purpose	2K_dev_652
to synthesize provably correct monitors automatically from CPS proofs in differential dynamic logic	purpose	2K_dev_652
	background	2K_dev_653
	finding	2K_dev_653
	mechanism	2K_dev_653
	method	2K_dev_653
	purpose	2K_dev_653
Demand response has gained significant attention in recent years as it demonstrates potentials to enhance the power system 's operational flexibility in a cost-effective way	background	2K_dev_654
Industrial loads such as steel manufacturing plants consume large amounts of electric energy	background	2K_dev_654
and their electricity bills account for a remarkable percentage of their total operation cost	background	2K_dev_654
Meanwhile	background	2K_dev_654
lots of industrial loads are very flexible in terms of adjusting their power consumption rate	background	2K_dev_654
e	background	2K_dev_654
g	background	2K_dev_654
through switching the transformer tap position	background	2K_dev_654
	background	2K_dev_654
	finding	2K_dev_654
In this paper	mechanism	2K_dev_654
we focus on the steel plant and optimize its scheduling from both the energy and the spinning reserve markets	mechanism	2K_dev_654
	mechanism	2K_dev_654
	method	2K_dev_654
Hence	purpose	2K_dev_654
industrial loads such as the steel plants have both the motivation and the ability to support power system operation through demand response to maximize its profits	purpose	2K_dev_654
Black-box mutational fuzzing is a simple yet effective technique to find bugs in software	background	2K_dev_655
show that one of our new scheduling algorithms outperforms the multi-armed bandit algorithm in the current version of the CERT Basic Fuzzing Framework ( BFF ) by finding 1	finding	2K_dev_655
5x more unique bugs in the same amount of time	finding	2K_dev_655
	finding	2K_dev_655
We develop an analytic framework using a mathematical model of black-box mutational fuzzing	mechanism	2K_dev_655
and use it to evaluate 26 existing and new randomized online scheduling algorithms	method	2K_dev_655
Our experiments	method	2K_dev_655
Given a set of program-seed pairs	purpose	2K_dev_655
we ask how to schedule the fuzzings of these pairs in order to maximize the number of unique bugs found at any point in time	purpose	2K_dev_655
	purpose	2K_dev_655
Much research on human action recognition has been oriented toward the performance gain on lab-collected datasets	background	2K_dev_656
with promising results	finding	2K_dev_656
	finding	2K_dev_656
The paucity of labeled real-world videos motivates us to `` borrow '' strength from other resources	mechanism	2K_dev_656
Specifically	mechanism	2K_dev_656
considering that many lab datasets are available	mechanism	2K_dev_656
we propose to harness lab datasets given that the lab and real-world datasets are related As their action categories are usually inconsistent	mechanism	2K_dev_656
we design a multi-task learning framework to jointly optimize the classifiers for both sides	mechanism	2K_dev_656
The general Schatten $ $ p $ $ p -norm is exerted on the two classifiers to explore the shared knowledge between them	mechanism	2K_dev_656
In this way	mechanism	2K_dev_656
our framework is able to mine the shared knowledge between two datasets even if the two have different action categories	mechanism	2K_dev_656
which is a major virtue of our method	mechanism	2K_dev_656
The shared knowledge is further used to improve the action recognition in the real-world videos	mechanism	2K_dev_656
	mechanism	2K_dev_656
Extensive experiments are performed on real-world datasets	method	2K_dev_656
Yet real-world videos are more diverse	purpose	2K_dev_656
with more complicated actions and often only a few of them are precisely labeled	purpose	2K_dev_656
Thus	purpose	2K_dev_656
recognizing actions from these videos is a tough mission	purpose	2K_dev_656
to facilitate the action recognition in real-world videos	purpose	2K_dev_656
	background	2K_dev_657
	finding	2K_dev_657
	mechanism	2K_dev_657
	method	2K_dev_657
	purpose	2K_dev_657
The costs are convex	background	2K_dev_658
have Lipschitz continuous gradient ( with constant L )	background	2K_dev_658
and bounded gradient	background	2K_dev_658
	background	2K_dev_658
achieves rates O ( logK/K ) and O ( logk/k )	finding	2K_dev_658
It achieves rates O ( 1/ K 2- ) and O ( 1/k 2 ) ( > 0 arbitrarily small )	finding	2K_dev_658
examples illustrate our findings	finding	2K_dev_658
	finding	2K_dev_658
We propose two fast distributed gradient algorithms based on the centralized Nesterov gradient algorithm and establish their convergence rates in terms of the per-node communications K and the per-node gradient evaluations k	mechanism	2K_dev_658
Our first method	mechanism	2K_dev_658
Distributed Nesterov Gradient	mechanism	2K_dev_658
Our second method	mechanism	2K_dev_658
Distributed Nesterov gradient with Consensus iterations	mechanism	2K_dev_658
assumes at all nodes knowledge of L and ( W ) - the second largest singular value of the N N doubly stochastic weight matrix W	mechanism	2K_dev_658
	mechanism	2K_dev_658
Further	method	2K_dev_658
we give for both methods explicit dependence of the convergence constants on N and W	method	2K_dev_658
Simulation	method	2K_dev_658
We study distributed optimization problems when N nodes minimize the sum of their individual costs subject to a common vector variable	purpose	2K_dev_658
In spite of many favorable characteristics of guided-waves for Nondestructive Evaluation ( NDE ) of pipes	background	2K_dev_659
real-world application of these systems is still quite limited	background	2K_dev_659
	background	2K_dev_659
It is observed that masking effects of flow rate for damage detection can be at least as significant as temperature effects	finding	2K_dev_659
and that such effects become more dominant when flow rate and temperature variations co-occur	finding	2K_dev_659
	mechanism	2K_dev_659
We first provide a review of the studies to date in the field of guided-wave based testing to identify research gaps for enhancing the application of these systems in pipeline NDE To study the identified gaps	method	2K_dev_659
guided-wave data from a fully operational piping system	method	2K_dev_659
with continuously varying flow rate and temperature	method	2K_dev_659
is used Time-shift and amplitude drift effects due to flow rate variations are evaluated along with those of temperature	method	2K_dev_659
	method	2K_dev_659
Beside the complexities derived from multi-modal	purpose	2K_dev_659
dispersive and multi-path characteristics of guided-waves	purpose	2K_dev_659
one of the main challenges in guided-wave based NDE of pipelines is sensitivity of these systems to variations of environmental and operational conditions ( EOC )	purpose	2K_dev_659
This paper investigates the effects of varying EOCs on guilded-wave based NDE of pipelines	purpose	2K_dev_659
	purpose	2K_dev_659
Given a graph with billions of nodes and edges	background	2K_dev_660
how can we find patterns and anomalies ? Are there nodes that participate in too many or too few triangles ? Are there close-knit near-cliques ? These questions are expensive to answer unless we have the first several eigenvalues and eigenvectors of the graph adjacency matrix	background	2K_dev_660
	background	2K_dev_660
We report important discoveries about nearcliques and triangles on several real-world graphs	finding	2K_dev_660
including a snapshot of the Twitter social network ( 56 Gb	finding	2K_dev_660
2 billion edges ) and the YahooWeb data set	finding	2K_dev_660
one of the largest publicly available graphs ( 120 Gb	finding	2K_dev_660
1	finding	2K_dev_660
4 billion nodes	finding	2K_dev_660
6	finding	2K_dev_660
6 billion edges )	finding	2K_dev_660
	finding	2K_dev_660
with the proposed HEIGEN algorithm	mechanism	2K_dev_660
which we carefully design to be accurate	mechanism	2K_dev_660
efficient	mechanism	2K_dev_660
and able to run on the highly scalable MAPREDUCE ( HADOOP ) environment	mechanism	2K_dev_660
This enables HEIGEN to handle matrices more than 1 ; 000 larger than those which can be analyzed by existing algorithms	mechanism	2K_dev_660
	mechanism	2K_dev_660
We implement HEIGEN and run it on the M45 cluster	method	2K_dev_660
one of the top 50 supercomputers in the world	method	2K_dev_660
	method	2K_dev_660
However	purpose	2K_dev_660
eigensolvers suffer from subtle problems ( e	purpose	2K_dev_660
g	purpose	2K_dev_660
	purpose	2K_dev_660
convergence ) for large sparse matrices	purpose	2K_dev_660
let alone for billion-scale ones	purpose	2K_dev_660
We address this problem	purpose	2K_dev_660
	background	2K_dev_661
results show that the logic-in-memory approach has the potential to enable substantial improvements in energy efficiency without sacrificing image quality	finding	2K_dev_661
In this paper we present a local interpolation-based variant of the well-known polar format algorithm used We develop the algorithm	mechanism	2K_dev_661
which off-loads lightweight computation directly into the SRAM and DRAM Our proposed algorithm performs filtering	mechanism	2K_dev_661
an image perspective transformation	mechanism	2K_dev_661
and a local 2D interpolation	mechanism	2K_dev_661
and supports partial and low-resolution reconstruction We implement our customized SAR grid interpolation logic-in-memory hardware in advanced 14 nm silicon technology	mechanism	2K_dev_661
Our high-level design tools allow to instantiate various optimized design choices to fit image processing and hardware needs of application designers	mechanism	2K_dev_661
	mechanism	2K_dev_661
Our simulation	method	2K_dev_661
for synthetic aperture radar ( SAR ) image formation	purpose	2K_dev_661
to match the capabilities of the application-specific logic-in-memory processing paradigm	purpose	2K_dev_661
Hierarchical clustering methods offer an intuitive and powerful way to model a wide variety of data sets	background	2K_dev_662
	background	2K_dev_662
We demonstrate the efficacy of our model and inference algorithm	finding	2K_dev_662
In this paper	mechanism	2K_dev_662
we present a distribution over collections of time-dependent	mechanism	2K_dev_662
infinite-dimensional trees	mechanism	2K_dev_662
and present an efficient and scalable algorithm	mechanism	2K_dev_662
on both synthetic data and real-world document corpora	method	2K_dev_662
However	purpose	2K_dev_662
the assumption of a fixed hierarchy is often overly restrictive when working with data generated over a period of time : We expect both the structure of our hierarchy	purpose	2K_dev_662
and the parameters of the clusters	purpose	2K_dev_662
to evolve with time that can be used to model evolving hierarchies for performing approximate inference in such a model	purpose	2K_dev_662
	purpose	2K_dev_662
In modern crowdsourcing markets	background	2K_dev_663
requesters face the challenge of training and managing large transient workforces	background	2K_dev_663
Requesters can hire peer workers to review others ' work	background	2K_dev_663
but the value may be marginal	background	2K_dev_663
especially if the reviewers lack requisite knowledge	background	2K_dev_663
	background	2K_dev_663
The results show that workers who review others ' work perform better on subsequent tasks than workers who just produce	finding	2K_dev_663
We also find that interactive reviewer teams outperform individual reviewers on all quality measures	finding	2K_dev_663
However	finding	2K_dev_663
aggregating individual reviewers into nominal groups produces better quality assessments than interactive teams	finding	2K_dev_663
except in task domains where discussion helps overcome individual misconceptions	finding	2K_dev_663
	mechanism	2K_dev_663
An online between-subjects experiment compares the trade-offs of reviewing versus producing work using three different organization strategies : working individually	method	2K_dev_663
working as an interactive team	method	2K_dev_663
and aggregating individuals into nominal groups	method	2K_dev_663
Our research explores if and how workers learn and improve their performance in a task domain by serving as peer reviewers	purpose	2K_dev_663
Further	purpose	2K_dev_663
we investigate whether peer reviewing may be more effective in teams where the reviewers can reach consensus through discussion	purpose	2K_dev_663
Understanding where electricity is being used in buildings is an important tool for Cyber-Physical Systems ( CPS ) used in building energy conservation and efficiency	background	2K_dev_664
The system is able to detect appliance state transitions with an accuracy of 95	finding	2K_dev_664
8 % and estimate the overall energy with an accuracy of 98	finding	2K_dev_664
1 %	finding	2K_dev_664
In this paper	mechanism	2K_dev_664
we present an energy measurement system using a wireless sensor network consisting of contactless electromagnetic field ( EMF ) sensors deployed near each appliance	mechanism	2K_dev_664
and a whole-house power meter	mechanism	2K_dev_664
We present the design of a battery-operated EMF sensor	mechanism	2K_dev_664
based on magnetic and electric field fluctuations	mechanism	2K_dev_664
Each detector wirelessly transmits state change events to a circuit-panel energy meter	mechanism	2K_dev_664
in a time-synchronized fashion	mechanism	2K_dev_664
so that the overall power measurements can be used to estimate appliance-level energy usage	mechanism	2K_dev_664
Our EMF sensors are able to detect significant power state changes from a few inches away	mechanism	2K_dev_664
thus making it possible to externally monitor in-wall wiring to devices	mechanism	2K_dev_664
We experimentally evaluate our proposed EMF sensor	method	2K_dev_664
three-phase power meter and communication protocol in a residential building collecting data for over a week	method	2K_dev_664
	method	2K_dev_664
Current approaches for appliance-level energy metering typically require the installation of plug-through power meters	purpose	2K_dev_664
which is often difficult and costly for devices with inaccessible wires or outlets	purpose	2K_dev_664
or appliances that draw large amounts of current	purpose	2K_dev_664
that estimates the energy consumption of individual appliances which can detect appliance state transitions within close proximity	purpose	2K_dev_664
Methods for the analysis of chromatin immunoprecipitation sequencing ( ChIP-seq ) data start by aligning the short reads to a reference genome	background	2K_dev_665
	background	2K_dev_665
indicates that our method outperforms alignment based methods that utilize closely related species	finding	2K_dev_665
	finding	2K_dev_665
Here we develop methods for de novo analysis of ChIP-seq data	mechanism	2K_dev_665
Our methods combine de novo assembly with statistical tests enabling motif discovery without the use of a reference genome	mechanism	2K_dev_665
	mechanism	2K_dev_665
We validate the performance of our method using human and mouse data	method	2K_dev_665
Analysis of fly data	method	2K_dev_665
While often successful	purpose	2K_dev_665
they are not appropriate for cases where a reference genome is not available	purpose	2K_dev_665
	purpose	2K_dev_665
Consumers who are close to one another in a social network often make similar purchase decisions This similarity can result from latent homophily or social influence	background	2K_dev_666
as well as common exogenous factors	background	2K_dev_666
Latent homophily means consumers who are connected to one another are likely to have similar characteristics and product preferences Social influence refers to the ability of one consumer to directly influence another consumer 's decision based upon their communication	background	2K_dev_666
Identification is achieved due to our dynamic	finding	2K_dev_666
panel data structure and the availability of detailed communication data	finding	2K_dev_666
We find strong influence effects and latent homophily effects in both the purchase timing and product choice decisions of consumers	finding	2K_dev_666
This paper was accepted by Sandra Slaughter	finding	2K_dev_666
information systems	finding	2K_dev_666
	mechanism	2K_dev_666
We present an empirical study We simultaneously measure latent homophily and social influence	method	2K_dev_666
while also accounting for exogenous factors	method	2K_dev_666
	method	2K_dev_666
of purchases of caller ring-back tones using data from an Asian mobile network that predicts consumers ' purchase timing and choice decisions	purpose	2K_dev_666
	purpose	2K_dev_666
How can web services that depend on user generated content discern fraudulent input by spammers from legitimate input ? as well as potential extensions to anomaly detection problems in other domains	background	2K_dev_667
	background	2K_dev_667
Finally	finding	2K_dev_667
we demonstrate and discuss the effectiveness of CopyCatch	finding	2K_dev_667
Our method	mechanism	2K_dev_667
which we refer to as CopyCatch	mechanism	2K_dev_667
by analyzing only the social graph between users and Pages and the times at which the edges in the graph ( the Likes ) were created We offer the following contributions : ( 1 ) We give a novel problem formulation	mechanism	2K_dev_667
with a simple concrete definition of suspicious behavior in terms of graph structure and edge constraints ( 2 ) We offer two algorithms - one provably-convergent iterative algorithm and one approximate	mechanism	2K_dev_667
scalable MapReduce implementation 3 ) We show that our method severely limits `` greedy attacks '' and analyze the bounds from the application of the Zarankiewicz problem to our setting CopyCatch is actively in use at Facebook	mechanism	2K_dev_667
searching for attacks on Facebook 's social graph of over a billion users	mechanism	2K_dev_667
many millions of Pages	mechanism	2K_dev_667
and billions of Page Likes	mechanism	2K_dev_667
	mechanism	2K_dev_667
at Facebook and on synthetic data	method	2K_dev_667
	method	2K_dev_667
In this paper we focus on the social network Facebook and the problem of discerning ill-gotten Page Likes	purpose	2K_dev_667
made by spammers hoping to turn a profit	purpose	2K_dev_667
from legitimate Page Likes detects lockstep Page Like patterns on Facebook to find such suspicious lockstep behavior	purpose	2K_dev_667
Iris masks play an important role in iris recognition They indicate which part of the iris texture map is useful and which part is occluded or contaminated by noisy image artifacts such as eyelashes	background	2K_dev_668
eyelids	background	2K_dev_668
eyeglasses frames	background	2K_dev_668
and specular reflections	background	2K_dev_668
The accuracy of the iris mask is extremely important	background	2K_dev_668
The performance of the iris recognition system will decrease dramatically when the iris mask is inaccurate	background	2K_dev_668
even when the best recognition algorithm is used	background	2K_dev_668
	background	2K_dev_668
results show that the masks generated by the proposed algorithm increase the iris recognition rate	finding	2K_dev_668
verifying the effectiveness and importance of our proposed method for iris occlusion estimation	finding	2K_dev_668
	finding	2K_dev_668
In this work	mechanism	2K_dev_668
we propose to use Figueiredo and Jain 's Gaussian Mixture Models ( FJ-GMMs ) We also explored possible features and found that Gabor Filter Bank ( GFB ) provides the most discriminative information for our goal Finally	mechanism	2K_dev_668
we applied Simulated Annealing ( SA ) technique to optimize the parameters of GFB in order to achieve the best recognition rate	mechanism	2K_dev_668
	mechanism	2K_dev_668
Experimental on both ICE2 and UBIRIS dataset	method	2K_dev_668
Traditionally	purpose	2K_dev_668
people used the rule-based algorithms to estimate iris masks from iris images	purpose	2K_dev_668
However	purpose	2K_dev_668
the accuracy of the iris masks generated this way is questionable to model the underlying probabilistic distributions of both valid and invalid regions on iris images	purpose	2K_dev_668
	purpose	2K_dev_668
Given a simple noun such as { \em apple }	background	2K_dev_669
and a question such as `` is it edible ? ``	background	2K_dev_669
what processes take place in the human brain ?	background	2K_dev_669
GeBM produces brain activity patterns that are strikingly similar to the real ones	finding	2K_dev_669
and the inferred functional connectivity is able to provide neuroscientific insights towards a better understanding of the way that neurons interact with each other	finding	2K_dev_669
as well as detect regularities and outliers in multi-subject brain activity measurements	finding	2K_dev_669
	finding	2K_dev_669
In this work we present a simple	mechanism	2K_dev_669
novel good-enough brain model	mechanism	2K_dev_669
or GeBM in short	mechanism	2K_dev_669
and a novel algorithm Sparse-SysId Moreover	mechanism	2K_dev_669
GeBM is able to simulate basic psychological phenomena such as habituation and priming ( whose definition we provide in the main text )	mechanism	2K_dev_669
We evaluate GeBM by using both synthetic and real brain data	method	2K_dev_669
Using the real data	method	2K_dev_669
More specifically	purpose	2K_dev_669
given the stimulus	purpose	2K_dev_669
what are the interactions between ( groups of ) neurons ( also known as functional connectivity ) and how can we automatically infer those interactions	purpose	2K_dev_669
given measurements of the brain activity ? Furthermore	purpose	2K_dev_669
how does this connectivity differ across different human subjects ? which are able to effectively model the dynamics of the neuron interactions and infer the functional connectivity	purpose	2K_dev_669
Given a network with attributed edges	background	2K_dev_670
how can we identify anomalous behavior ? Networks with edge attributes are ubiquitous	background	2K_dev_670
and capture rich information about interactions between nodes	background	2K_dev_670
	background	2K_dev_670
: we show that EdgeCentric successfully spots numerous such anomalies where it achieved 0	finding	2K_dev_670
87 precision over the top 100 results	finding	2K_dev_670
	finding	2K_dev_670
Our work has a number of notable contributions	mechanism	2K_dev_670
including ( a ) formulation : while most other graph-based anomaly detection works use structural graph connectivity or node information	mechanism	2K_dev_670
we focus on the new problem of leveraging edge information	mechanism	2K_dev_670
( b ) methodology : we introduce EdgeCentric	mechanism	2K_dev_670
an intuitive and scalable compression-based approach and ( c ) practicality	mechanism	2K_dev_670
in several large	method	2K_dev_670
edge-attributed real-world graphs	method	2K_dev_670
including the Flipkart e-commerce graph with over 3 million product reviews between 1	method	2K_dev_670
1 million users and 545 thousand products	method	2K_dev_670
	method	2K_dev_670
In this paper	purpose	2K_dev_670
we aim to utilize exactly this information to discern suspicious from typical behavior in an unsupervised fashion	purpose	2K_dev_670
lending well to the traditional scarcity of ground-truth labels in practical anomaly detection scenarios	purpose	2K_dev_670
for detecting edge-attributed graph anomalies	purpose	2K_dev_670
	purpose	2K_dev_670
	background	2K_dev_671
Finally	finding	2K_dev_671
we demonstrate the algorithm 's utility	finding	2K_dev_671
In contrast to previous matrix recovery work	mechanism	2K_dev_671
we drop the assumption of a random sampling of entries in favor of a deterministic sampling of principal submatrices of the matrix	mechanism	2K_dev_671
We develop a set of sufficient conditions for the recovery of a SPSD matrix from a set of its principal submatrices	mechanism	2K_dev_671
present necessity results based on this set of conditions and develop an algorithm that can exactly recover a matrix when these conditions are met	mechanism	2K_dev_671
The proposed algorithm is naturally generalized to the problem of noisy matrix recovery	mechanism	2K_dev_671
and we provide a worst-case bound on reconstruction error for this scenario	mechanism	2K_dev_671
	mechanism	2K_dev_671
on noiseless and noisy simulated datasets	method	2K_dev_671
	method	2K_dev_671
We consider the problem of recovering a symmetric	purpose	2K_dev_671
positive semidefinite ( SPSD ) matrix from a subset of its entries	purpose	2K_dev_671
possibly corrupted by noise	purpose	2K_dev_671
	purpose	2K_dev_671
	background	2K_dev_672
	finding	2K_dev_672
This paper explores a PAC ( probably approximately correct ) learning model in cooperative games	mechanism	2K_dev_672
Specifically	mechanism	2K_dev_672
we are given m random samples of coalitions and their values	mechanism	2K_dev_672
taken from some unknown cooperative game ; We also establish a novel connection between PAC learnability and core stability : for games that are efficiently learnable	mechanism	2K_dev_672
it is possible to find payoff divisions that are likely to be stable using a polynomial number of samples	mechanism	2K_dev_672
We study the PAC learnability of several well-known classes of cooperative games	method	2K_dev_672
such as network flow games	method	2K_dev_672
threshold task games	method	2K_dev_672
and induced subgraph games	method	2K_dev_672
	method	2K_dev_672
can we predict the values of unseen coalitions ?	purpose	2K_dev_672
	background	2K_dev_673
We then demonstrate that our approach can discover complementary views on the brand associations that are hardly obtained from text data	finding	2K_dev_673
show the superior performance of our algorithm for the two tasks over other candidate methods	finding	2K_dev_673
In this paper	mechanism	2K_dev_673
we study an approach by leveraging large-scale online photo collections contributed by the general public	mechanism	2K_dev_673
Brand Associations	mechanism	2K_dev_673
one of central concepts in marketing	mechanism	2K_dev_673
describe customers ' top-of-mind attitudes or feelings toward a brand	mechanism	2K_dev_673
( e	mechanism	2K_dev_673
g	mechanism	2K_dev_673
what comes to mind when you think of Burberry ? ) Traditionally	mechanism	2K_dev_673
brand associations are measured by analyzing the text data from consumers ' responses to the survey or their online conversation logs In this paper	mechanism	2K_dev_673
we go beyond textual media and take advantage of large-scale photos shared on the Web More specifically	mechanism	2K_dev_673
we jointly achieve the following two fundamental tasks in a mutually-rewarding way : ( i ) detecting exemplar images as key visual concepts associated with brands	mechanism	2K_dev_673
and ( ii ) localizing the regions of brand in images	mechanism	2K_dev_673
	mechanism	2K_dev_673
For experiments we collect about five millions of images of 48 brands crawled from five popular online photo sharing sites We also quantitatively	method	2K_dev_673
for discovering brand associations	purpose	2K_dev_673
Abstract : Security-sensitive applications that execute untrusted code often check the codes integrity by comparing its syntax to a known good value or sandbox the code to contain its effects	background	2K_dev_674
We illustrate both new reasoning principles of System M	finding	2K_dev_674
System M is a new program logic System M extends Hoare Type Theory ( HTT ) First	mechanism	2K_dev_674
its type system internalizes logical equality	mechanism	2K_dev_674
facilitating reasoning about applications that check code integrity	mechanism	2K_dev_674
Second	mechanism	2K_dev_674
a confinement rule assigns an effect type to a computation based solely on knowledge of the computations sandbox	mechanism	2K_dev_674
We prove the sound-ness of System M relative to a step-indexed trace-based semantic model	method	2K_dev_674
by verifying the main integrity property of the design of Memoir	method	2K_dev_674
a previously proposed trusted computing system for ensuring state continuity of isolated security-sensitive applications	method	2K_dev_674
for reasoning about such security-sensitive applications	purpose	2K_dev_674
to trace safety properties and	purpose	2K_dev_674
additionally	purpose	2K_dev_674
contains two new reasoning principles	purpose	2K_dev_674
	purpose	2K_dev_674
There has been recent interest in applying Stackelberg games to infrastructure security	background	2K_dev_675
in which a defender must protect targets from attack by an adaptive adversary	background	2K_dev_675
In real-world security settings the adversaries are humans and are thus boundedly rational	background	2K_dev_675
	background	2K_dev_675
	finding	2K_dev_675
We propose a new solution concept	mechanism	2K_dev_675
monotonic maximin We propose a mixed-integer linear program formulation We also consider top-monotonic maximin	mechanism	2K_dev_675
a related solution concept that is more conservative	mechanism	2K_dev_675
and propose a polynomial-time algorithm for top-monotonic maximin	mechanism	2K_dev_675
	mechanism	2K_dev_675
	method	2K_dev_675
Most existing approaches for computing defender strategies against boundedly rational adversaries try to optimize against specific behavioral models of adversaries	purpose	2K_dev_675
and provide no quality guarantee when the estimated model is inaccurate	purpose	2K_dev_675
which provides guarantees against all adversary behavior models satisfying monotonicity	purpose	2K_dev_675
including all in the family of Regular Quantal Response functions for computing monotonic maximin	purpose	2K_dev_675
The development of accurate clinical biomarkers has been challenging in part due to the diversity between patients and diseases	background	2K_dev_676
MSS provides a straightforward approach for modeling highly divergent subclasses of patients	background	2K_dev_676
which may be adaptable for diverse applications	background	2K_dev_676
that yielded similar classification accuracy to several other classification algorithms	finding	2K_dev_676
revealed subclasses of patients based on distinct marker states	finding	2K_dev_676
Here we present a new strategy that accounts for completely distinct patient subclasses	mechanism	2K_dev_676
Marker State Space ( MSS ) defines marker states based on all possible patterns of high and low values among a panel of markers	mechanism	2K_dev_676
Each marker state is defined as either a case state or a control state	mechanism	2K_dev_676
and a sample is classified as case or control based on the state it occupies	mechanism	2K_dev_676
	mechanism	2K_dev_676
MSS was used to define multi-marker panels that were robust in cross validation and training-set/test-set analyses and A three-marker panel for discriminating pancreatic cancer patients from control subjects	method	2K_dev_676
One approach to account for the diversity is to use multiple markers to classify patients	purpose	2K_dev_676
based on the concept that each individual marker contributes information from its respective subclass of patients	purpose	2K_dev_676
for developing biomarker panels	purpose	2K_dev_676
Background Serum albumin is a major pharmacokinetic effector of	background	2K_dev_677
	finding	2K_dev_677
	mechanism	2K_dev_677
the crystal structures of six oncology agents were determined in complex with human serum albumin at resolutions of 2	method	2K_dev_677
8 to 2	method	2K_dev_677
0 A : camptothecin	method	2K_dev_677
9-amino-camptothecin	method	2K_dev_677
etoposide	method	2K_dev_677
teniposide	method	2K_dev_677
bicalutamide and idarubicin	method	2K_dev_677
To gain further insight into albumin binding chemistry	purpose	2K_dev_677
Multimedia data are usually represented by multiple features	background	2K_dev_678
results show that it is beneficial to combine multiple features	finding	2K_dev_678
The performance of the proposed algorithm is remarkable when only a small amount of labeled training data are available	finding	2K_dev_678
	finding	2K_dev_678
In this paper	mechanism	2K_dev_678
we propose a new algorithm	mechanism	2K_dev_678
namely Multi-feature Learning via Hierarchical Regression where two issues are considered	mechanism	2K_dev_678
First	mechanism	2K_dev_678
labeling large amount of training data is labor-intensive	mechanism	2K_dev_678
It is meaningful to effectively leverage unlabeled data to facilitate multimedia semantics understanding	mechanism	2K_dev_678
Second	mechanism	2K_dev_678
given that multimedia data can be represented by multiple features	mechanism	2K_dev_678
it is advantageous to develop an algorithm which combines evidence obtained from different features to infer reliable multimedia semantic concept classifiers	mechanism	2K_dev_678
We design a hierarchical regression model to exploit the information derived from each type of feature	mechanism	2K_dev_678
which is then collaboratively fused to obtain a multimedia semantic concept classifier	mechanism	2K_dev_678
Both label information and data distribution of different features representing multimedia data are considered	mechanism	2K_dev_678
The algorithm can be applied to a wide range of multimedia applications and	mechanism	2K_dev_678
experiments are conducted on video data for video concept annotation and action recognition	method	2K_dev_678
Using Trecvid and CareMedia video datasets	method	2K_dev_678
the experimental	method	2K_dev_678
for multimedia semantics understanding	purpose	2K_dev_678
Matrix-parametrized models	background	2K_dev_679
including multiclass logistic regression and sparse coding	background	2K_dev_679
are used in machine learning ( ML ) applications ranging from computer vision to computational biology	background	2K_dev_679
	background	2K_dev_679
corroborate its efficiency	finding	2K_dev_679
	mechanism	2K_dev_679
we propose a Sufficient Factor Broadcasting ( SFB ) computation model for efficient distributed learning of a large family of matrix-parameterized models	mechanism	2K_dev_679
which share the following property : the parameter update computed on each data sample is a rank-1 matrix	mechanism	2K_dev_679
i	mechanism	2K_dev_679
e	mechanism	2K_dev_679
	mechanism	2K_dev_679
the outer product of two `` sufficient factors '' ( SFs By broadcasting the SFs among worker machines and reconstructing the update matrices locally at each worker	mechanism	2K_dev_679
SFB improves communication efficiency -- - communication costs are linear in the parameter matrix 's dimensions	mechanism	2K_dev_679
rather than quadratic -- - without affecting computational correctness	mechanism	2K_dev_679
We present a theoretical convergence analysis of SFB	method	2K_dev_679
and empirically on four different matrix-parametrized ML models	method	2K_dev_679
	method	2K_dev_679
When these models are applied to large-scale ML problems starting at millions of samples and tens of thousands of classes	purpose	2K_dev_679
their parameter matrix can grow at an unexpected rate	purpose	2K_dev_679
resulting in high parameter synchronization costs that greatly slow down distributed learning	purpose	2K_dev_679
To address this issue	purpose	2K_dev_679
BACKGROUND There is a need of such studies in African Americans	background	2K_dev_680
because they display a higher incidence of aggressive CRC tumors	background	2K_dev_680
This WES study in African American patients with CRC provides insight into the identification of novel somatic mutations in APC Our data suggest an association between specific mutations in the Wnt signaling pathway and an increased risk of CRC	background	2K_dev_680
The analysis of the pathogenicity of these novel variants may shed light on the aggressive nature of CRC in African Americans	background	2K_dev_680
RESULTS We identified somatic mutations in genes that are known targets in CRC such as APC	finding	2K_dev_680
BRAF	finding	2K_dev_680
KRAS	finding	2K_dev_680
and PIK3CA	finding	2K_dev_680
We detected novel alterations in the Wnt pathway gene	finding	2K_dev_680
APC	finding	2K_dev_680
within its exon 15	finding	2K_dev_680
of which mutations are highly associated with CRC CONCLUSIONS	finding	2K_dev_680
	mechanism	2K_dev_680
METHODS We performed whole exome sequencing ( WES ) on DNA from 12 normal/tumor pairs of African American CRC patient tissues	method	2K_dev_680
Data analysis was performed using the software package GATK ( Genome Analysis Tool Kit )	method	2K_dev_680
Normative population databases ( eg	method	2K_dev_680
1000 Genomes SNP database	method	2K_dev_680
dbSNP	method	2K_dev_680
and HapMap ) were used for comparison	method	2K_dev_680
Variants were annotated using analysis of variance and were validated via Sanger sequencing	method	2K_dev_680
The purpose of this study was to identify genome-wide single nucleotide variants and mutations in African American patients with colorectal cancer ( CRC )	purpose	2K_dev_680
Numeric time series data has unique storage requirements and access patterns that can benefit from specialized support	background	2K_dev_681
given its importance in Big Data analyses	background	2K_dev_681
	background	2K_dev_681
	finding	2K_dev_681
and illustrates its potential for satisfying key requirements	finding	2K_dev_681
This paper describes the support needed suggests an architecture	mechanism	2K_dev_681
	method	2K_dev_681
Popular frameworks and databases focus on addressing other needs	purpose	2K_dev_681
making them a suboptimal fit	purpose	2K_dev_681
for numeric time series for efficient time series storage	purpose	2K_dev_681
	background	2K_dev_682
	finding	2K_dev_682
We present a new algorithm that produces in any dimension with guaranteed optimal output size We also provide an approximate Delaunay graph Our algorithm runs in expected time O ( 2 O ( d ) ( n log n + m ) )	mechanism	2K_dev_682
where n is the input size	mechanism	2K_dev_682
m is the output point set size	mechanism	2K_dev_682
and d is the ambient dimension The constants only depend on the desired element quality bounds	mechanism	2K_dev_682
To gain this new efficiency	mechanism	2K_dev_682
the algorithm approximately maintains the Voronoi diagram of the current set of points by storing a superset of the Delaunay neighbors of each point By retaining quality of the Voronoi diagram and avoiding the storage of the full Voronoi diagram	mechanism	2K_dev_682
a simple exponential dependence on d is obtained in the running time Thus	mechanism	2K_dev_682
if one only wants the approximate neighbors structure of a refined Delaunay mesh conforming to a set of input points	mechanism	2K_dev_682
the algorithm will return a size 2 O ( d ) m graph in 2 O ( d ) ( n log n + m ) expected time	mechanism	2K_dev_682
If m is superlinear in n	mechanism	2K_dev_682
then we can produce a hierarchically well-spaced superset of size 2 O ( d ) n in 2 O ( d ) n log n expected time	mechanism	2K_dev_682
	mechanism	2K_dev_682
	method	2K_dev_682
a well-spaced superset of points conforming to a given input set on the output points	purpose	2K_dev_682
Distributions over matrices with exchangeable rows and infinitely many columns are useful in constructing nonparametric latent variable models	background	2K_dev_683
	background	2K_dev_683
and can achieve better performance	finding	2K_dev_683
In this paper	mechanism	2K_dev_683
we propose a class of exchangeable nonparametric priors obtained by restricting the domain of existing models Such models allow us to specify the distribution over the number of features per data point	mechanism	2K_dev_683
	mechanism	2K_dev_683
on data sets where the number of features is not well-modeled by the original distribution	method	2K_dev_683
However	purpose	2K_dev_683
the distribution implied by such models over the number of features exhibited by each data point may be poorly-suited for many modeling tasks	purpose	2K_dev_683
Stochastic Differential Equation SDE models are used to describe the dynamics of complex systems with inherent randomness	background	2K_dev_684
The primary purpose of these models is to study rare but interesting or important behaviours	background	2K_dev_684
such as the formation of a tumour	background	2K_dev_684
	finding	2K_dev_684
we introduce a new algorithm specifically designed Our approach relies on temporal logics for specifying rare behaviours of interest	mechanism	2K_dev_684
and on the ability of bit-vector decision procedures to reason exhaustively about fixed-precision arithmetic	mechanism	2K_dev_684
	mechanism	2K_dev_684
We apply our algorithm to a minimal parameterised model of the cell cycle	method	2K_dev_684
and take Brownian noise into account while investigating the likelihood of irregularities in cell size and time between cell divisions	method	2K_dev_684
	method	2K_dev_684
Stochastic simulations are the most common means for estimating or bounding the probability of rare behaviours	purpose	2K_dev_684
but the cost of simulations increases with the rarity of events To address this problem to quantify the likelihood of rare behaviours in SDE models	purpose	2K_dev_684
	purpose	2K_dev_684
	background	2K_dev_685
our method is several orders of magnitude faster	finding	2K_dev_685
with competitive or improved accuracy for latent space recovery and link prediction	finding	2K_dev_685
	finding	2K_dev_685
We propose a scalable approach With a succinct representation of networks as a bag of triangular motifs	mechanism	2K_dev_685
a parsimonious statistical model	mechanism	2K_dev_685
and an efficient stochastic variational inference algorithm	mechanism	2K_dev_685
we are able to analyze real networks with over a million vertices and hundreds of latent roles on a single machine in a matter of hours	mechanism	2K_dev_685
a setting that is out of reach for many existing methods	mechanism	2K_dev_685
When compared to the state-of-the-art probabilistic approaches	method	2K_dev_685
	method	2K_dev_685
for making inference about latent spaces of large networks	purpose	2K_dev_685
	purpose	2K_dev_685
As renewable generation capacity in the power grid increases	background	2K_dev_686
keeping the balance between the supply and demand becomes difficult	background	2K_dev_686
This threatens the grids stability and security	background	2K_dev_686
Existing power reserve assets and regulation methodologies fail to provide the short-term responses required to keep the load and generation balanced as the amount of renewable generation increases	background	2K_dev_686
	background	2K_dev_686
	finding	2K_dev_686
using a centralized control strategy	mechanism	2K_dev_686
to propose a strategy	mechanism	2K_dev_686
We focus on the challenges associated with simulating a realistic TCL population using the models that are proposed in the literature	method	2K_dev_686
Specifically	method	2K_dev_686
we use data collected from residential refrigeration units operating in 214 different households	method	2K_dev_686
Hence	purpose	2K_dev_686
researchers proposed to increase the information exchange within the power network and to introduce realtime demand control to ensure robustness while accommodating the intermittent nature of these generation resources	purpose	2K_dev_686
Constituting a significant portion of the electrical demand of buildings	purpose	2K_dev_686
thermostatically controlled loads ( TCLs ) are wellsuited to provide real-time demand control	purpose	2K_dev_686
In this paper	purpose	2K_dev_686
we shed light on challenges associated with engaging TCLs to the power grid to select parameters when simulating a TCL population	purpose	2K_dev_686
Fusion of multiple features can boost the performance of large-scale visual classification and detection tasks like TRECVID Multimedia Event Detection ( MED ) competition [ 1 ]	background	2K_dev_687
	background	2K_dev_687
our approach achieves promising improvements on HMDB [ 8 ] action recognition dataset and CCV [ 5 ] video classification dataset show that our approach outperforms the state-of-the-art fusion methods for complex event detection	finding	2K_dev_687
	finding	2K_dev_687
In this paper	mechanism	2K_dev_687
we propose a novel feature fusion approach	mechanism	2K_dev_687
namely Feature Weighting via Optimal Thresholding ( FWOT ) FWOT learns the weights	mechanism	2K_dev_687
thresholding and smoothing parameters in a joint framework to combine the decision values obtained from all the individual features and the early fusion	mechanism	2K_dev_687
To the best of our knowledge	mechanism	2K_dev_687
this is the first work to consider the weight and threshold factors of fusion problem simultaneously	mechanism	2K_dev_687
	mechanism	2K_dev_687
Compared to state-of-the-art fusion algorithms	method	2K_dev_687
In addition	method	2K_dev_687
experiments on two TRECVID MED 2011 collections	method	2K_dev_687
to effectively fuse various features	purpose	2K_dev_687
	purpose	2K_dev_687
Background Aging infrastructure in the US has gained quite a bit of attention in the past decade	background	2K_dev_688
Being one type of a critical infrastructure	background	2K_dev_688
embankment dams in the US require significant investment to upgrade the deteriorated parts	background	2K_dev_688
Due to limited budgets	background	2K_dev_688
understanding the behavior of structures over time through risk assessment is essential to prioritize dams	background	2K_dev_688
During the risk assessment for embankment dams	background	2K_dev_688
engineers utilize current and historical data from the design	background	2K_dev_688
construction	background	2K_dev_688
and operation phases of these structures The challenge is that during risk assessment	background	2K_dev_688
various engineers from different disciplines ( e	background	2K_dev_688
g	background	2K_dev_688
	background	2K_dev_688
geotechnical	background	2K_dev_688
hydraulics ) come together	background	2K_dev_688
and how they would like to visualize the available datasets changes based on the discipline-specific analyses they need to perform	background	2K_dev_688
	background	2K_dev_688
	finding	2K_dev_688
	mechanism	2K_dev_688
	method	2K_dev_688
The objective of this research study is to understand the discipline-specific visualization needs of engineers from US Army Corps of Engineers ( USACE ) who are involved in risk assessment of embankment dams when they deal with large set of data accumulated since the inception of dams	purpose	2K_dev_688
	purpose	2K_dev_688
Developments in neural recording technology are rapidly enabling the recording of populations of neurons in multiple brain areas simultaneously	background	2K_dev_689
as well as the identification of the types of neurons being recorded ( e	background	2K_dev_689
g	background	2K_dev_689
	background	2K_dev_689
excitatory vs	background	2K_dev_689
inhibitory )	background	2K_dev_689
This work provides a foundation for studying how multiple populations of neurons interact and how this interaction supports brain function	background	2K_dev_689
and found that gLARA provides a better description of the recordings than pCCA	finding	2K_dev_689
	finding	2K_dev_689
Rather than attempting to identify direct interactions between neurons ( where the number of interactions grows with the number of neurons squared )	mechanism	2K_dev_689
we propose to extract a smaller number of latent variables from each population Specifically	mechanism	2K_dev_689
we propose extensions to probabilistic canonical correlation analysis ( pCCA )	mechanism	2K_dev_689
and study how these latent variables interact	method	2K_dev_689
We then applied these methods to populations of neurons recorded simultaneously in visual areas V1 and V2	method	2K_dev_689
	method	2K_dev_689
There is a growing need for statistical methods to study the interaction among multiple	purpose	2K_dev_689
labeled populations of neurons to capture the temporal structure of the latent variables	purpose	2K_dev_689
as well as to distinguish within-population dynamics from across-population interactions ( termed Group Latent Auto-Regressive Analysis	purpose	2K_dev_689
gLARA	purpose	2K_dev_689
Our findings have both behavioral and policy implications	background	2K_dev_690
as they highlight how technologies that make individuals feel more in control over the publication of personal information may have the paradoxical and unintended consequence of eliciting their disclosure of more sensitive information	background	2K_dev_690
Our findings suggest	finding	2K_dev_690
paradoxically	finding	2K_dev_690
that more control over the publication of their private information decreases individuals privacy concerns and increases their willingness to publish sensitive information	finding	2K_dev_690
even when the probability that strangers will access and use that information stays the same or	finding	2K_dev_690
in fact	finding	2K_dev_690
increases	finding	2K_dev_690
On the other hand	finding	2K_dev_690
less control over the publication of personal information increases individuals privacy concerns and decreases their willingness to publish sensitive information	finding	2K_dev_690
even when the probability that strangers will access and use information actually decreases	finding	2K_dev_690
	finding	2K_dev_690
	mechanism	2K_dev_690
We designed three experiments in the form of online surveys administered to students at a North-American University	method	2K_dev_690
In all experiments we manipulated the participants control over information publication	method	2K_dev_690
but not their control over the actual access to and usage by others of the published information	method	2K_dev_690
We introduce and test the hypothesis that control over publication of private information may influence individuals privacy concerns and affect their propensity to disclose sensitive information	purpose	2K_dev_690
even when the objective risks associated with such disclosures do not change or worsen	purpose	2K_dev_690
	purpose	2K_dev_690
A large number of facility management tasks relying on sensor measurements require knowledge of the context under which the readings were collected	background	2K_dev_691
However	background	2K_dev_691
this context information ( i	background	2K_dev_691
e	background	2K_dev_691
'spatial metadata ' ) is generally recorded manually	background	2K_dev_691
a process that is error-prone and time consuming considering the number of sensors located in a building	background	2K_dev_691
Therefore	background	2K_dev_691
as other researchers have pointed out	background	2K_dev_691
there is a need to automatically determine the location information	background	2K_dev_691
	background	2K_dev_691
We conclude that a linear correlation ( the normalized covariance matrix ) captures the spatial relationship in most situations although it is significantly sensitive to choosing the appropriate window size	finding	2K_dev_691
	finding	2K_dev_691
	mechanism	2K_dev_691
We conducted analyses on three different test beds where temperature measurements from 10 sensors were collected every minute	method	2K_dev_691
We consider every possible size of data subsets within a year to explore time-windowing effects	method	2K_dev_691
We also examine how different physical distances between sensors affect the results	method	2K_dev_691
	method	2K_dev_691
Inferring the relative locations of sensors with respect to each other is arguably the first step to take and previous work in this area has already shown promising initial results In this paper	purpose	2K_dev_691
we explore whether linear correlation or a statistical dependency measure ( in this case distance correlation ) are better suited to infer spatial relations between a pair of temperature sensors in a commercial building	purpose	2K_dev_691
	purpose	2K_dev_691
Most everyday electrical and electromechanical objects emit small amounts of electromagnetic ( EM ) noise during regular operation	background	2K_dev_692
Our studies show that discrimination between dozens of objects is feasible	background	2K_dev_692
independent of wearer	background	2K_dev_692
time and local environment	background	2K_dev_692
	finding	2K_dev_692
By modifying a small	mechanism	2K_dev_692
low-cost	mechanism	2K_dev_692
software-defined radio	mechanism	2K_dev_692
we can detect and classify these signals in real-time	mechanism	2K_dev_692
enabling robust on-touch object detection	mechanism	2K_dev_692
Unlike prior work	mechanism	2K_dev_692
our approach requires no instrumentation of objects or the environment ; our sensor is self-contained and can be worn unobtrusively on the body	mechanism	2K_dev_692
We call our technique EM-Sense and built a proof-of-concept smartwatch implementation	mechanism	2K_dev_692
	mechanism	2K_dev_692
	method	2K_dev_692
When a user makes physical contact with such an object	purpose	2K_dev_692
this EM signal propagates through the user	purpose	2K_dev_692
owing to the conductivity of the human body	purpose	2K_dev_692
	purpose	2K_dev_692
	background	2K_dev_693
	finding	2K_dev_693
	mechanism	2K_dev_693
	method	2K_dev_693
	purpose	2K_dev_693
	background	2K_dev_694
Given a small amount of labeled training data	finding	2K_dev_694
StarScan learns appropriate penalties for both compact and elongated clusters	finding	2K_dev_694
resulting in improved detection performance	finding	2K_dev_694
We propose StarScan	mechanism	2K_dev_694
a new star-shaped scan statistic StarScan generalizes the traditional	mechanism	2K_dev_694
circular spatial scan statistic by allowing the radius of the cluster around a center location to vary continuously with the angle	mechanism	2K_dev_694
but penalizes the log-likelihood ratio score proportional to the total change in radius	mechanism	2K_dev_694
	mechanism	2K_dev_694
StarScan was compared with circular scan and fast subset scan on simulated respiratory outbreaks and bioterrorist anthrax attacks injected into real-world Emergency Department data	method	2K_dev_694
	method	2K_dev_694
for detecting irregularly-shaped spatial clusters	purpose	2K_dev_694
	background	2K_dev_695
which collected 618 high-quality answers to questions asked over 12 days	finding	2K_dev_695
illustrating the feasibility of the approach	finding	2K_dev_695
	finding	2K_dev_695
we introduce the idea of social microvolunteering	mechanism	2K_dev_695
a type of intermediated friendsourcing in which a person can provide access to their friends as potential workers for microtasks supporting causes that they care about	mechanism	2K_dev_695
We explore this idea by creating Visual Answers	mechanism	2K_dev_695
an exemplar social microvolunteering application for Facebook that posts visual questions from people who are blind	mechanism	2K_dev_695
We present results of a survey of 350 participants on the concept of social microvolunteering	method	2K_dev_695
and a deployment of the Visual Answers application with 91 participants	method	2K_dev_695
	method	2K_dev_695
Crowd-powered systems that help people are difficult to scale and sustain because human labor is expensive and worker pools are difficult to grow To address this problem	purpose	2K_dev_695
	background	2K_dev_696
	finding	2K_dev_696
	mechanism	2K_dev_696
	method	2K_dev_696
	purpose	2K_dev_696
	background	2K_dev_697
We prove that our algorithm generates asymptotically exact samples and demonstrate its ability to parallelize burn-in and sampling in several models	finding	2K_dev_697
In this paper	mechanism	2K_dev_697
we present a parallel Markov chain Monte Carlo ( MCMC ) algorithm in which subsets of data are processed independently	mechanism	2K_dev_697
with very little communication	mechanism	2K_dev_697
First	mechanism	2K_dev_697
we arbitrarily partition data onto multiple machines	mechanism	2K_dev_697
Then	mechanism	2K_dev_697
on each machine	mechanism	2K_dev_697
any classical MCMC method ( e	mechanism	2K_dev_697
g	mechanism	2K_dev_697
	mechanism	2K_dev_697
Gibbs sampling ) may be used to draw samples from a posterior distribution given the data subset	mechanism	2K_dev_697
Finally	mechanism	2K_dev_697
the samples from each machine are combined to form samples from the full posterior	mechanism	2K_dev_697
This embarrassingly parallel algorithm allows each machine to act independently on a subset of the data ( without communication ) until the final combination stage	mechanism	2K_dev_697
	mechanism	2K_dev_697
empirically	method	2K_dev_697
Communication costs	purpose	2K_dev_697
resulting from synchronization requirements during learning	purpose	2K_dev_697
can greatly slow down many parallel machine learning algorithms	purpose	2K_dev_697
	purpose	2K_dev_697
Stochastic gradient optimization is a class of widely used algorithms for training machine learning models	background	2K_dev_698
To optimize an objective	background	2K_dev_698
it uses the noisy gradient computed from the random data samples instead of the true gradient computed from the entire dataset	background	2K_dev_698
	background	2K_dev_698
On both problems	finding	2K_dev_698
our approach shows faster convergence and better performance than the classical approach	finding	2K_dev_698
In this paper	mechanism	2K_dev_698
we develop a general approach of using control variate Data statistics such as low-order moments ( pre-computed or estimated online ) is used to form the control variate	mechanism	2K_dev_698
	mechanism	2K_dev_698
We demonstrate how to construct the control variate for two practical problems using stochastic gradient optimization	method	2K_dev_698
One is convexthe MAP estimation for logistic regression	method	2K_dev_698
and the other is non-convexstochastic variational inference for latent Dirichlet allocation	method	2K_dev_698
	method	2K_dev_698
However	purpose	2K_dev_698
when the variance of the noisy gradient is large	purpose	2K_dev_698
the algorithm might spend much time bouncing around	purpose	2K_dev_698
leading to slower convergence and worse performance for variance reduction in stochastic gradient	purpose	2K_dev_698
	purpose	2K_dev_698
	background	2K_dev_699
and demonstrate that FGSS can successfully detect and characterize relevant patterns in each domain FGSS substantially decreased run time and improved detection power for massive multivariate data sets	finding	2K_dev_699
We propose Fast Generalized Subset Scan ( FGSS )	mechanism	2K_dev_699
a new method We frame the pattern detection problem as a search over subsets of data records and attributes	mechanism	2K_dev_699
maximizing a nonparametric scan statistic over all such subsets We prove that the nonparametric scan statistics possess a novel property that allows for efficient optimization over the exponentially many subsets of the data without an exhaustive search	mechanism	2K_dev_699
enabling FGSS to scale to massive and high-dimensional data sets	mechanism	2K_dev_699
We evaluate the performance of FGSS in three real-world application domains ( customs monitoring	method	2K_dev_699
disease surveillance	method	2K_dev_699
and network intrusion detection )	method	2K_dev_699
As compared to three other recently proposed detection algorithms	method	2K_dev_699
	method	2K_dev_699
for detecting anomalous patterns in general categorical data sets	purpose	2K_dev_699
Paid crowd work offers remarkable opportunities for improving productivity	background	2K_dev_700
social mobility	background	2K_dev_700
and the global economy by engaging a geographically distributed workforce to complete complex tasks on demand and at scale	background	2K_dev_700
	background	2K_dev_700
	finding	2K_dev_700
Drawing on theory from organizational behavior and distributed computing	mechanism	2K_dev_700
as well as direct feedback from workers	mechanism	2K_dev_700
we outline a framework The framework lays out research challenges in twelve major areas : workflow	mechanism	2K_dev_700
task assignment	mechanism	2K_dev_700
hierarchy	mechanism	2K_dev_700
real-time response	mechanism	2K_dev_700
synchronous collaboration	mechanism	2K_dev_700
quality control	mechanism	2K_dev_700
crowds guiding AIs	mechanism	2K_dev_700
AIs guiding crowds	mechanism	2K_dev_700
platforms	mechanism	2K_dev_700
job design	mechanism	2K_dev_700
reputation	mechanism	2K_dev_700
and motivation	mechanism	2K_dev_700
	method	2K_dev_700
But it is also possible that crowd work will fail to achieve its potential	purpose	2K_dev_700
focusing on assembly-line piecework	purpose	2K_dev_700
Can we foresee a future crowd workplace in which we would want our children to participate ? This paper frames the major challenges that stand in the way of this goal	purpose	2K_dev_700
that will enable crowd work that is complex	purpose	2K_dev_700
collaborative	purpose	2K_dev_700
and sustainable	purpose	2K_dev_700
	purpose	2K_dev_700
	background	2K_dev_701
We show that our congestion model is effective in modeling dynamic congestion conditions	finding	2K_dev_701
We also show that our routing algorithm generates significantly faster routes compared to standard baselines	finding	2K_dev_701
and achieves near-optimal performance We also present the results which showcases the efficacy of our approach	finding	2K_dev_701
we first propose a Gaussian Process Dynamic Congestion Model that can effectively characterize both the dynamics and the uncertainty of congestion conditions	mechanism	2K_dev_701
Our model is efficient and thus facilitates real-time adaptive routing in the face of uncertainty	mechanism	2K_dev_701
Using this congestion model	mechanism	2K_dev_701
we develop an efficient algorithm for non-myopic adaptive routing A key property of our approach is the ability to efficiently reason about the long-term value of exploration	mechanism	2K_dev_701
which enables collectively balancing the exploration/exploitation trade-off for entire fleets of vehicles	mechanism	2K_dev_701
We validate our approach based on traffic data from two large Asian cities compared to an omniscient routing algorithm	method	2K_dev_701
from a preliminary field study	method	2K_dev_701
	method	2K_dev_701
We consider the problem of adaptively routing a fleet of cooperative vehicles within a road network in the presence of uncertain and dynamic congestion conditions	purpose	2K_dev_701
To tackle this problem to minimize the collective travel time of all vehicles in the system	purpose	2K_dev_701
	purpose	2K_dev_701
This enables radial interactions in an area many times larger than a mobile device ; for example	background	2K_dev_702
virtual buttons that lie above	background	2K_dev_702
below and to the left and right	background	2K_dev_702
which shows that Toffee can accurately resolve the bearings of touch events ( mean error of 4	finding	2K_dev_702
3 with a laptop prototype )	finding	2K_dev_702
	finding	2K_dev_702
we have developed Toffee	mechanism	2K_dev_702
a sensing approach and onto ad hoc adjacent surfaces	mechanism	2K_dev_702
most notably tabletops This is achieved using a novel application of acoustic time differences of arrival ( TDOA ) correlation	mechanism	2K_dev_702
Previous time-of-arrival based systems have required semi-permanent instrumentation of the surface and were too large for use in mobile devices	mechanism	2K_dev_702
Our approach requires only a hard tabletop and gravity -- the latter acoustically couples mobile devices to surfaces	mechanism	2K_dev_702
	mechanism	2K_dev_702
We conducted an evaluation	method	2K_dev_702
	method	2K_dev_702
The simple fact that human fingers are large and mobile devices are small has led to the perennial issue of limited surface area for touch-based interactive tasks	purpose	2K_dev_702
In response	purpose	2K_dev_702
that extends touch interaction beyond the small confines of a mobile device	purpose	2K_dev_702
	background	2K_dev_703
	finding	2K_dev_703
	mechanism	2K_dev_703
	method	2K_dev_703
	purpose	2K_dev_703
	background	2K_dev_704
that highlight its immediate feasibility and utility	finding	2K_dev_704
We present Lumitrack that uses projected structured patterns and linear optical sensors	mechanism	2K_dev_704
Each sensor unit is capable of recovering 2D location within the projection area	mechanism	2K_dev_704
while multiple sensors can be combined for up to six degree of freedom ( DOF ) tracking	mechanism	2K_dev_704
Our structured light approach is based on special patterns	mechanism	2K_dev_704
called m-sequences	mechanism	2K_dev_704
in which any consecutive sub-sequence of m bits is unique	mechanism	2K_dev_704
Lumitrack can utilize both digital and static projectors	mechanism	2K_dev_704
as well as scalable embedded sensing configurations	mechanism	2K_dev_704
The resulting system enables high-speed	mechanism	2K_dev_704
high precision	mechanism	2K_dev_704
and low-cost motion tracking for a wide range of interactive applications	mechanism	2K_dev_704
	mechanism	2K_dev_704
We detail the hardware	method	2K_dev_704
operation	method	2K_dev_704
and performance characteristics of our approach	method	2K_dev_704
as well as a series of example applications	method	2K_dev_704
	purpose	2K_dev_704
a novel motion tracking technology	purpose	2K_dev_704
There are many security tools and techniques for analyzing software	background	2K_dev_705
but many of them require access to source code	background	2K_dev_705
A decompiler should focus on two properties to be used for security	background	2K_dev_705
First	background	2K_dev_705
it should recover abstractions as much as possible to minimize the complexity that must be handled by the security analysis that follows	background	2K_dev_705
Second	background	2K_dev_705
it should aim to recover these abstractions correctly	background	2K_dev_705
Previous work in control-flow structuring	background	2K_dev_705
an abstraction recovery problem used in decompilers	background	2K_dev_705
does not provide either of these properties	background	2K_dev_705
	background	2K_dev_705
Our evaluation is an order of magnitude larger than previous systematic studies of endto-end decompilers	finding	2K_dev_705
We show that our decompiler outperforms the de facto industry standard decompiler Hex-Rays in correctness by 114 %	finding	2K_dev_705
and recovers 30 more control-flow structure than existing structuring algorithms in the literature	finding	2K_dev_705
We propose leveraging decompilation	mechanism	2K_dev_705
the study of recovering abstractions from compiled code	mechanism	2K_dev_705
We propose a new structuring algorithm in this paper	mechanism	2K_dev_705
We evaluate our decompiler	method	2K_dev_705
Phoenix	method	2K_dev_705
and our new structuring algorithm	method	2K_dev_705
on a set of 107 real world programs from GNU coreutils	method	2K_dev_705
to apply existing source-based tools and techniques to compiled programs	purpose	2K_dev_705
Specifically	purpose	2K_dev_705
existing structuring algorithms are not semantics-preserving	purpose	2K_dev_705
which means that they can not safely be used for decompilation without modification	purpose	2K_dev_705
Existing structural algorithms also miss opportunities for recovering control flow structure	purpose	2K_dev_705
that addresses these problems	purpose	2K_dev_705
Identifying a suspect wearing a mask ( where only the suspect 's periocular region is visible ) is one of the toughest real-world challenges in biometrics that exist	background	2K_dev_706
This is an important problem faced in many law-enforcement applications on almost a daily basis	background	2K_dev_706
	background	2K_dev_706
show that our reconstruction technique	finding	2K_dev_706
based on a modified sparsifying dictionary learning algorithm	finding	2K_dev_706
can effectively reconstruct faces which we show are actually very similar to the original ground-truth faces	finding	2K_dev_706
We show the real-world applicability of method to show that they still match competitively	finding	2K_dev_706
In this paper	mechanism	2K_dev_706
we present a practical method We propose in this paper	mechanism	2K_dev_706
an approach that will reconstruct the entire frontal face using just the periocular region Further	mechanism	2K_dev_706
our method is open set	mechanism	2K_dev_706
thus can reconstruct any face not seen in training	mechanism	2K_dev_706
	mechanism	2K_dev_706
We empirically by benchmarking face verification results using the reconstructed faces compared to the original faces when evaluated under a large-scale face verification protocol such as NIST 's FRGC protocol where over 256 million face matches are made	method	2K_dev_706
to hallucinate the full frontal face given only the periocular region of a face In such real-world situations	purpose	2K_dev_706
we only have access to the periocular region of a person 's face	purpose	2K_dev_706
Unfortunately commercial matchers are unable to process these images successfully	purpose	2K_dev_706
A device just like Harry Potter 's Marauder 's Map	background	2K_dev_707
which pinpoints the location of each person-of-interest at all times	background	2K_dev_707
provides invaluable information for analysis of surveillance videos	background	2K_dev_707
show that our algorithm performs robust localization and tracking of persons-of-interest not only in outdoor scenes	finding	2K_dev_707
but also in a complex indoor real-world nursing home environment	finding	2K_dev_707
We propose a tracking-by-detection approach with nonnegative discretization to tackle this problem	mechanism	2K_dev_707
Given a set of person detection outputs	mechanism	2K_dev_707
our framework takes advantage of all important cues such as color	mechanism	2K_dev_707
person detection	mechanism	2K_dev_707
face recognition and non-background information to perform tracking	mechanism	2K_dev_707
Local learning approaches are used to uncover the manifold structure in the appearance space with spatio-temporal constraints	mechanism	2K_dev_707
Nonnegative discretization is used to enforce the mutual exclusion constraint	mechanism	2K_dev_707
which guarantees a person detection output to only belong to exactly one individual	mechanism	2K_dev_707
	mechanism	2K_dev_707
Experiments	method	2K_dev_707
To make this device real	purpose	2K_dev_707
a system would be required to perform robust person localization and tracking in real world surveillance scenarios	purpose	2K_dev_707
especially for complex indoor environments with many walls causing occlusion and long corridors with sparse surveillance camera coverage	purpose	2K_dev_707
Using this method	background	2K_dev_708
optimal strategies can be designed for control resource allocation to manage risk in a business process	background	2K_dev_708
Our work contributes to the literature on both ex ante risk management-based business process design and ex post risk assessments of existing business processes and control models This research applies not only to the literature on and practice of process design and risk management but also to business decision support systems in general	background	2K_dev_708
	finding	2K_dev_708
We develop a process modeling-based methodology Our method focuses on the topological structure of a process and takes into account its effect on error propagation and risk mitigation using both expected loss and conditional value-at-risk risk measures	mechanism	2K_dev_708
An order-fulfillment process of an online pharmacy is used to illustrate the methodology	method	2K_dev_708
	method	2K_dev_708
This article investigates the economic consequences of data errors in the information flows associated with business processes for managing the risks associated with such data errors	purpose	2K_dev_708
	purpose	2K_dev_708
Design	background	2K_dev_709
construction and operation of building heating	background	2K_dev_709
ventilation and air conditioning ( HVAC ) systems are complicated processes that generally involve several stakeholders	background	2K_dev_709
such as mechanical designers	background	2K_dev_709
control system integrators	background	2K_dev_709
commissioning agents and facilities managers	background	2K_dev_709
It is important for all these stakeholders at various phases of the project to have a thorough understanding of the system components as well as the control strategy according to the design intent of the mechanical designers	background	2K_dev_709
For example	background	2K_dev_709
when assessing the behavior of a HVAC system during operation phase	background	2K_dev_709
it is important for facilities managers to check for the correctness of every components behavior and its control logic against the design specifications	background	2K_dev_709
Challenges such as missing information for controlled parameters as well as textual descriptions that are open to interpretations are common and result in inaccurate interpretation of the system behavior	background	2K_dev_709
This may adversely affect the overall performance of systems and lead to energy inefficiencies	background	2K_dev_709
	background	2K_dev_709
	finding	2K_dev_709
	mechanism	2K_dev_709
	method	2K_dev_709
The control sequences and logic of HVAC systems are primarily conveyed through schematic diagrams and textual descriptions called sequence of operations ( SOOs ) in construction documents ( ASHRAE	purpose	2K_dev_709
2004 )	purpose	2K_dev_709
Several challenges are associated with extracting and interpreting the information contained in these SOOs	purpose	2K_dev_709
Through a detailed analysis of a case-study conducted in relation to the information provided in the SOOs for the air handling unit ( AHU ) in a building	purpose	2K_dev_709
the research described in this paper highlights these challenges	purpose	2K_dev_709
	purpose	2K_dev_709
Stochastic variational inference finds good posterior approximations of probabilistic models with very large data sets	background	2K_dev_710
It optimizes the variational objective with stochastic optimization	background	2K_dev_710
following noisy estimates of the natural gradient Operationally	background	2K_dev_710
stochastic inference iteratively subsamples from the data	background	2K_dev_710
analyzes the subsample	background	2K_dev_710
and updates parameters with a decreasing learning rate	background	2K_dev_710
	background	2K_dev_710
Inference with the adaptive learning rate converges faster and to a better approximation than the best settings of hand-tuned rates	finding	2K_dev_710
by developing an adaptive learning rate for stochastic variational inference	mechanism	2K_dev_710
Our method requires no tuning and is easily implemented with computations already made in the algorithm	mechanism	2K_dev_710
We demonstrate our approach with latent Dirichlet allocation applied to three large text corpora	method	2K_dev_710
However	purpose	2K_dev_710
the algorithm is sensitive to that rate	purpose	2K_dev_710
which usually requires hand-tuning to each application We solve this problem	purpose	2K_dev_710
Confessions are people 's way of coming clean	background	2K_dev_711
sharing unethical acts with others	background	2K_dev_711
Although confessions are traditionally viewed as categorical one either comes clean or not people often confess to only part of their transgression Such partial confessions may seem attractive	background	2K_dev_711
because they offer an opportunity to relieve ones guilt without having to own up to the full consequences of the transgression It seems that although partial confessions seem attractive	background	2K_dev_711
they come at an emotional cost	background	2K_dev_711
we found a high frequency of partial confessions	finding	2K_dev_711
especially among people cheating to the full extent possible	finding	2K_dev_711
People found partial confessions attractive because they ( correctly ) expected partial confessions to be more believable than not confessing People failed	finding	2K_dev_711
however	finding	2K_dev_711
to anticipate the emotional costs associated with partially confessing In fact	finding	2K_dev_711
partial confessions made people feel worse than not confessing or fully confessing	finding	2K_dev_711
a finding corroborated in a laboratory setting as well as in a study assessing peoples everyday confessions	finding	2K_dev_711
Using a novel experimental design	mechanism	2K_dev_711
In this paper	method	2K_dev_711
we explored the occurrence	method	2K_dev_711
antecedents	method	2K_dev_711
consequences	method	2K_dev_711
and everyday prevalence of partial confessions	method	2K_dev_711
	purpose	2K_dev_711
Compared to visual concepts such as actions	background	2K_dev_712
scenes and objects	background	2K_dev_712
complex event is a higher level abstraction of longer video sequences	background	2K_dev_712
For example	background	2K_dev_712
a `` marriage proposal '' event is described by multiple objects ( e	background	2K_dev_712
g	background	2K_dev_712
	background	2K_dev_712
ring	background	2K_dev_712
faces )	background	2K_dev_712
scenes ( e	background	2K_dev_712
g	background	2K_dev_712
	background	2K_dev_712
in a restaurant	background	2K_dev_712
outdoor ) and actions ( e	background	2K_dev_712
g	background	2K_dev_712
	background	2K_dev_712
kneeling down )	background	2K_dev_712
	background	2K_dev_712
demonstrate that our algorithm is able to utilize related exemplars adaptively	finding	2K_dev_712
and the algorithm gains good performance for complex event detection	finding	2K_dev_712
our algorithm automatically evaluates how positive the related exemplars are for the detection of an event and uses them on an exemplar-specific basis	mechanism	2K_dev_712
	mechanism	2K_dev_712
Experiments	method	2K_dev_712
The positive exemplars which exactly convey the precise semantic of an event are hard to obtain	purpose	2K_dev_712
It would be beneficial to utilize the related exemplars for complex event detection	purpose	2K_dev_712
However	purpose	2K_dev_712
the semantic correlations between related exemplars and the target event vary substantially as relatedness assessment is subjective	purpose	2K_dev_712
Two related exemplars can be about completely different events	purpose	2K_dev_712
e	purpose	2K_dev_712
g	purpose	2K_dev_712
	purpose	2K_dev_712
in the TRECVID MED dataset	purpose	2K_dev_712
both bicycle riding and equestrianism are labeled as related to `` attempting a bike trick '' event	purpose	2K_dev_712
To tackle the subjectiveness of human assessment	purpose	2K_dev_712
	purpose	2K_dev_712
Summary : T cells are activated through interaction with antigen-presenting cells ( APCs )	background	2K_dev_713
During activation	background	2K_dev_713
receptors and signalingintermediates accumulate in diverse spatiotemporal distributions	background	2K_dev_713
Thesedistributions control the probability of signaling interactions and thusgovern information ow through the signaling system	background	2K_dev_713
Spatiotemporal-ly resolved system-scale investigation of signaling can extract the regu-latory information thus encoded	background	2K_dev_713
allowing unique insight into thecontrol of T-cell function	background	2K_dev_713
Substantial technical challenges exist	background	2K_dev_713
andthese are briey discussed herein	background	2K_dev_713
	background	2K_dev_713
We suggest that the regulation ofactin dynamics	finding	2K_dev_713
by controlling signaling distributions and membranetopology	finding	2K_dev_713
is an important rheostat of T-cell signaling	finding	2K_dev_713
Keywords	finding	2K_dev_713
Spatiotemporalsignaling distributions are driven by cell biologically distinct structures	mechanism	2K_dev_713
a large protein assembly at the interface center	mechanism	2K_dev_713
a large invagination	mechanism	2K_dev_713
the actin-supported interface periphery as extended by smaller indi-vidual lamella	mechanism	2K_dev_713
and a newly discovered whole-interface actin-drivenlamellum	mechanism	2K_dev_713
The more than 60 elements of T-cell activation studied todate are dynamically distributed between these structures	mechanism	2K_dev_713
generating acomplex organization of the signaling system	mechanism	2K_dev_713
Signal initiation and coresignaling prefer the interface center	mechanism	2K_dev_713
while signal amplication islocalized in the transient lamellum	mechanism	2K_dev_713
Actin dynamics control signalingdistributions through regulation of the underlying structures and drivea highly undulating T-cell/APC interface that imposes substantialconstraints on T-cell organization	mechanism	2K_dev_713
	mechanism	2K_dev_713
	method	2K_dev_713
While much of the work assessingT-cell spatiotemporal organization uses planar APC substitutes	purpose	2K_dev_713
wefocus here on B-cell APCs with often stark differences	purpose	2K_dev_713
	purpose	2K_dev_713
This setting was recently studied in [ 15 ]	background	2K_dev_714
where the \KernelKernel '' estimator was introduced and shown to have a polynomial rate of convergence	background	2K_dev_714
	background	2K_dev_714
	finding	2K_dev_714
To this end	mechanism	2K_dev_714
we propose the Double-Basis estimator	mechanism	2K_dev_714
which looks in two ways : rst	mechanism	2K_dev_714
the Double-Basis estimator is shown to have a computation complexity that is independent of the number of of instances N when evaluating new predictions after training ; secondly	mechanism	2K_dev_714
the Double-Basis estimator is shown to have a fast rate of convergence for a general class of mappings f2F	mechanism	2K_dev_714
We study the problem of distribution to real regression	method	2K_dev_714
where one aims to regress a mapping f that takes in a distribution input covariate P 2 I ( for a non-parametric family of distributionsI ) and outputs a real-valued response Y 0 f ( P ) +	method	2K_dev_714
	method	2K_dev_714
However	purpose	2K_dev_714
evaluating a new prediction with the Kernel-Kernel estimator scales as ( N )	purpose	2K_dev_714
This causes the dicult situation where a large amount of data may be necessary for a low estimation risk	purpose	2K_dev_714
but the computation cost of estimation becomes infeasible when the data-set is too large to alleviate this big data problem	purpose	2K_dev_714
Primary motor-cortex multi-unit activity ( MUA ) and local-field potentials ( LFPs ) have both been suggested as potential control signals for brain-computer interfaces ( BCIs ) aimed at movement restoration	background	2K_dev_715
Some studies report that LFP-based decoding is comparable to spiking-based decoding	background	2K_dev_715
while others offer contradicting evidence	background	2K_dev_715
Our results suggest that a velocity and speed encoding model is most appropriate for both MUA and LFP H	background	2K_dev_715
whereas a speed only encoding model is adequate for LFP L	background	2K_dev_715
	background	2K_dev_715
We find that in addition to previously reported directional tuning	finding	2K_dev_715
MUA also contains prominent speed tuning	finding	2K_dev_715
LFP activity in low-frequency bands ( 15-40Hz	finding	2K_dev_715
LFP L ) is primarily speed tuned	finding	2K_dev_715
and contains more speed information than both high-frequency LFP ( 100-300Hz	finding	2K_dev_715
LFP H ) and MUA	finding	2K_dev_715
LFP H contains more directional information compared to LFP L	finding	2K_dev_715
but less information when compared with MUA	finding	2K_dev_715
	mechanism	2K_dev_715
Here	method	2K_dev_715
we use regression and mutual information analyses	method	2K_dev_715
Differences in experimental paradigms	purpose	2K_dev_715
tuning models and decoding techniques make it hard to directly compare these results	purpose	2K_dev_715
to study how MUA and LFP encode various kinematic parameters during reaching movements	purpose	2K_dev_715
	purpose	2K_dev_715
Stencil computations are an integral component of applications in a number of scientific computing domains Short-vector SIMD instruction sets are ubiquitous on modern processors and can be used to significantly increase the performance of stencil computations	background	2K_dev_716
	background	2K_dev_716
Performance increases are demonstrated for a number of stencils	finding	2K_dev_716
In this paper	mechanism	2K_dev_716
we propose a domain specific language and compiler and automates both locality and short-vector SIMD optimizations	mechanism	2K_dev_716
along with effective utilization of multi-core parallelism Loop transformations are combined with a data layout transformation	mechanism	2K_dev_716
on several modern SIMD architectures	method	2K_dev_716
Traditional approaches to optimizing stencils on these platforms have focused on either short-vector SIMD or data locality optimizations	purpose	2K_dev_716
for stencil computations that allows specification of stencils in a concise manner to enhance data locality and enable load-balanced parallelism to effectively increase the performance of stencil computations	purpose	2K_dev_716
	purpose	2K_dev_716
We discuss how design teams can use our approach to reflect on prototypes or begin user studies within seconds	background	2K_dev_717
and how	background	2K_dev_717
over time	background	2K_dev_717
Apparition prototypes can become fully-implemented versions of the systems they simulate	background	2K_dev_717
	finding	2K_dev_717
In this paper	mechanism	2K_dev_717
we introduce crowdsourcing techniques and tools Our Apparition system uses paid microtask crowds to make even hard-to-automate functions work immediately	mechanism	2K_dev_717
allowing more fluid prototyping of interfaces that contain interactive elements and complex behaviors As users sketch their interface and describe it aloud in natural language	mechanism	2K_dev_717
crowd workers and sketch recognition algorithms translate the input into user interface elements	mechanism	2K_dev_717
add animations	mechanism	2K_dev_717
and provide Wizard-of-Oz functionality	mechanism	2K_dev_717
Powering Apparition is the first self-coordinated	mechanism	2K_dev_717
real-time crowdsourcing infrastructure We anchor this infrastructure on a new	mechanism	2K_dev_717
lightweight write-locking mechanism that workers can use to signal their intentions to each other	mechanism	2K_dev_717
	mechanism	2K_dev_717
	method	2K_dev_717
Prototyping allows designers to quickly iterate and gather feedback	purpose	2K_dev_717
but the time it takes to create even a Wizard-of-Oz prototype reduces the utility of the process for prototyping interactive systems in the time it takes to describe the idea	purpose	2K_dev_717
	purpose	2K_dev_717
	background	2K_dev_718
Our model consistently outperforms competing models	finding	2K_dev_718
	finding	2K_dev_718
We present a probabilistic language model that captures temporal dynamics and conditions on arbitrary non-linguistic context features	mechanism	2K_dev_718
We learn our model in an efficient online fashion that is scalable for large	mechanism	2K_dev_718
streaming data	mechanism	2K_dev_718
	mechanism	2K_dev_718
With five streaming datasets from two different genres economics news articles and social mediawe evaluate our model on the task of sequential language modeling	method	2K_dev_718
These context features serve as important indicators of language changes that are otherwise difficult to capture using text data by itself	purpose	2K_dev_718
Embankment dams	background	2K_dev_719
like most other civil infrastructure systems	background	2K_dev_719
are exposed to harsh and largely unpredictable environments	background	2K_dev_719
However	background	2K_dev_719
unlike bridges	background	2K_dev_719
buildings and other structures	background	2K_dev_719
their design specifications and as-is properties are not generally known in the same level of detail due to	background	2K_dev_719
among other things	background	2K_dev_719
their age and the difficulties associated with assessing their internal structure	background	2K_dev_719
Hence	background	2K_dev_719
making sense of measurements collected from instruments used to monitor their behavior requires sound engineering judgment and analysis	background	2K_dev_719
as well as robust statistical analysis techniques to prevent misinterpretation	background	2K_dev_719
In the United States ( US )	background	2K_dev_719
the current practice of analyzing the structural integrity of embankment dams relies primarily on manual a posteriori analysis of instrument data by engineers	background	2K_dev_719
leaving much room for improvement through the application of automated data analysis techniques	background	2K_dev_719
In our previous work	background	2K_dev_719
we presented the effectiveness of applying statistical anomaly detection techniques such as Principal Component Analysis and Robust Regression Analysis when analyzing piezometer data collected from embankment dams	background	2K_dev_719
	background	2K_dev_719
the detection accuracy came out to be 98	finding	2K_dev_719
5 %	finding	2K_dev_719
a physics-based model of an embankment dam was developed	mechanism	2K_dev_719
	mechanism	2K_dev_719
By varying a hydraulic conductivity of a soil material in the model	method	2K_dev_719
corresponding detection accuracies and sensitivities of the statistical anomaly detection algorithm were evaluated When we applied our proposed anomaly detection on more realistically simulated anomalous data using the numerical model	method	2K_dev_719
In this paper	purpose	2K_dev_719
we present how we could improve our work by testing with simulated anomalies that are indicative of internal erosion problems	purpose	2K_dev_719
In order to closely replicate more realistic anomalous scenarios	purpose	2K_dev_719
It is typically expected that if a mechanism is truthful	background	2K_dev_720
then the agents would	background	2K_dev_720
indeed	background	2K_dev_720
truthfully report their private information	background	2K_dev_720
	background	2K_dev_720
	finding	2K_dev_720
We wish to design truthful mechanisms that are simple	mechanism	2K_dev_720
that is whose Our approach involves three steps : ( i ) specifying the structure of mechanisms	mechanism	2K_dev_720
( ii ) constructing a verification algorithm	mechanism	2K_dev_720
and ( iii ) measuring the quality of verifiably truthful mechanisms	mechanism	2K_dev_720
	mechanism	2K_dev_720
We demonstrate this approach using a case study : approximate mechanism design without money for facility location	method	2K_dev_720
But why would an agent believe that the mechanism is truthful ? truthfulness can be verified efficiently ( in the computational sense )	purpose	2K_dev_720
	purpose	2K_dev_720
	background	2K_dev_721
and present results of a pilot evaluation of our initial system	finding	2K_dev_721
In this paper	mechanism	2K_dev_721
we review previous work on audio and video processing	mechanism	2K_dev_721
and define the task of topic-oriented multimedia summarization ( TOMS ) using natural language generation ( NLG ) : given a set of automatically extracted features from a video	mechanism	2K_dev_721
a TOMS system will automatically generate a paragraph of natural language	mechanism	2K_dev_721
which summarizes the important information in a video belonging to a certain topic	mechanism	2K_dev_721
and for example provides explanations for why a video was matched and retrieved	mechanism	2K_dev_721
Possible features include visual semantic concepts	mechanism	2K_dev_721
objects	mechanism	2K_dev_721
and actions	mechanism	2K_dev_721
environmental sounds	mechanism	2K_dev_721
and transcripts from automatic speech recognition ( ASR )	mechanism	2K_dev_721
We see this as a first step towards systems that will be able to discriminate visually similar	mechanism	2K_dev_721
but semantically different videos	mechanism	2K_dev_721
compare two videos and provide textual output or summarize a large number of videos at once In this paper	mechanism	2K_dev_721
we introduce our approach We extract various visual concept features	mechanism	2K_dev_721
environmental sounds and ASR transcription features from a given video	mechanism	2K_dev_721
and develop a template-based NLG system to produce a textual recounting based on the extracted features	mechanism	2K_dev_721
	mechanism	2K_dev_721
We also propose possible experimental designs for continuously evaluating and improving TOMS systems	method	2K_dev_721
Given the deluge of multimedia content that is becoming available over the Internet	purpose	2K_dev_721
it is increasingly important to be able to effectively examine and organize these large stores of information in ways that go beyond browsing or collaborative filtering of solving the TOMS problem	purpose	2K_dev_721
	purpose	2K_dev_721
From this comparison of Twitter and in-person regrets	background	2K_dev_722
we provide preliminary ideas for tools to help Twitter users avoid and cope with regret	background	2K_dev_722
	background	2K_dev_722
Participants generally reported similar types of regrets in person and on Twitter	finding	2K_dev_722
In particular	finding	2K_dev_722
they often regretted messages that were critical of others However	finding	2K_dev_722
regretted messages that were cathartic/expressive or revealed too much information were reported at a higher rate for Twitter	finding	2K_dev_722
Regretted messages on Twitter also reached broader audiences	finding	2K_dev_722
In addition	finding	2K_dev_722
we found that participants who posted on Twitter became aware of	finding	2K_dev_722
and tried to repair	finding	2K_dev_722
regret more slowly than those reporting in-person regrets	finding	2K_dev_722
	mechanism	2K_dev_722
We present the results of an online survey of 1	method	2K_dev_722
221 Twitter users	method	2K_dev_722
either saying during in-person conversations or posting on Twitter	method	2K_dev_722
comparing messages individuals regretted	purpose	2K_dev_722
Fragments of first-order temporal logic are useful for representing many practical privacy and security policies	background	2K_dev_723
Past work has proposed two strategies for checking event trace ( audit log ) compliance with policies : online monitoring and offline audit	background	2K_dev_723
	background	2K_dev_723
We prove the correctness of our algorithm	finding	2K_dev_723
This paper proposes a new online monitoring algorithm Our key technical insight is a new called the temporal mode check	mechanism	2K_dev_723
which determines subformulas for which such caching is feasible and those for which it is not and	mechanism	2K_dev_723
hence	mechanism	2K_dev_723
guides our algorithm	mechanism	2K_dev_723
	mechanism	2K_dev_723
and evaluate its performance over synthetic traces and realistic policies	method	2K_dev_723
Although online monitoring is space- and time-efficient	purpose	2K_dev_723
existing techniques insist that satisfying instances of all subformulas of the policy be amenable to caching	purpose	2K_dev_723
which limits expressiveness when some subformulas have infinite support	purpose	2K_dev_723
In contrast	purpose	2K_dev_723
offline audit is brute force and can handle more policies but is not as efficient that caches satisfying instances when it can	purpose	2K_dev_723
and falls back to the brute force search when it can not	purpose	2K_dev_723
flow- and time-sensitive static check of variable groundedness	purpose	2K_dev_723
Abstract Host factor protein Cyclophilin A ( CypA ) regulates HIV-1 viral infectivity through direct interactions with the viral capsid	background	2K_dev_724
by an unknown mechanism	background	2K_dev_724
CypA can either promote or inhibit viral infection	background	2K_dev_724
depending on host cell type and HIV-1 capsid ( CA ) protein sequence	background	2K_dev_724
These results suggest that CypA loop dynamics is a determining factor in HIV-1 's escape from CypA dependence	background	2K_dev_724
	background	2K_dev_724
we demonstrate that assembled CA is dynamic	finding	2K_dev_724
particularly in loop regions exhibits unprecedented mobility on the nanosecond to microsecond timescales	finding	2K_dev_724
and the experimental NMR dipolar order parameters are in quantitative agreement with those calculated from MD trajectories Remarkably	finding	2K_dev_724
the CypA loop dynamics of wild-type CA HXB2 assembly is significantly attenuated upon CypA binding	finding	2K_dev_724
and the dynamics profiles of the A92E and G94D CypA escape mutants closely resemble that of wild-type CA assembly in complex with CypA	finding	2K_dev_724
	mechanism	2K_dev_724
Through the analysis of backbone 1H-15N and 1H-13C dipolar tensors and peak intensities from 3D MAS NMR spectra of wild-type and the A92E and G94D CypA escape mutants	method	2K_dev_724
The CypA loop in assembled wild-type CA from two strains	method	2K_dev_724
We have examined the role of conformational dynamics on the nanosecond to millisecond timescale in HIV-1 CA assemblies in the escape from CypA dependence	purpose	2K_dev_724
by magic-angle spinning ( MAS ) NMR and molecular dynamics ( MD )	purpose	2K_dev_724
	purpose	2K_dev_724
	background	2K_dev_725
that guarantees the new algorithm is safe for all possible inputs	finding	2K_dev_725
We then applied QdL to guide the development of a new algorithm	mechanism	2K_dev_725
We applied quantified differential-dynamic logic ( QdL ) We identified problems with the algorithm	method	2K_dev_725
proved that it was in general unsafe	method	2K_dev_725
and described exactly what could go wrong	method	2K_dev_725
Using \KeYmaeraD ( a tool that mechanizes QdL )	method	2K_dev_725
we created a machine-checked proof	method	2K_dev_725
to analyze a control algorithm designed to provide directional force feedback for a surgical robot	purpose	2K_dev_725
that provides safe operation along with directional force feedback	purpose	2K_dev_725
	purpose	2K_dev_725
The rise of socially targeted marketing suggests that decisions made by consumers can be predicted not only from their personal tastes and characteristics	background	2K_dev_726
but also from the decisions of people who are close to them in their networks	background	2K_dev_726
	background	2K_dev_726
	finding	2K_dev_726
we present a hierarchical auto-probit model for individual binary outcomes that uses and extends the machinery of the auto-probit method for binary data	mechanism	2K_dev_726
	mechanism	2K_dev_726
We demonstrate the behavior of the parameters estimated by the multiple network-regime auto-probit model ( m-NAP ) under various sensitivity conditions	method	2K_dev_726
such as the impact of the prior distribution and the nature of the structure of the network	method	2K_dev_726
We also demonstrate several examples of correlated binary data outcomes in networks of interest to information systems	method	2K_dev_726
including the adoption of caller ring-back tones	method	2K_dev_726
whose use is governed by direct connection but explained by additional network topologies	method	2K_dev_726
	method	2K_dev_726
One obstacle to consider is that there may be several different measures for closeness that are appropriate	purpose	2K_dev_726
either through different types of friendships	purpose	2K_dev_726
or different functions of distance on one kind of friendship	purpose	2K_dev_726
where only a subset of these networks may actually be relevant	purpose	2K_dev_726
Another is that these decisions are often binary and more difficult to model with conventional approaches	purpose	2K_dev_726
both conceptually and computationally	purpose	2K_dev_726
To address these issues	purpose	2K_dev_726
	background	2K_dev_727
	finding	2K_dev_727
	mechanism	2K_dev_727
	method	2K_dev_727
	purpose	2K_dev_727
DOI : 10	background	2K_dev_728
2514/1	background	2K_dev_728
I010178 Complex software systems are becoming increasingly prevalent in aerospace applications : in particular	background	2K_dev_728
to accomplish critical tasks	background	2K_dev_728
Ensuring the safety of these systems is crucial	background	2K_dev_728
as they can have subtly different behaviors under slight variations in operating and proposals are given on how to address these issues	background	2K_dev_728
	background	2K_dev_728
The challenges that naturally arise when applying such technology to industrial-scale applications is then detailed	finding	2K_dev_728
	mechanism	2K_dev_728
As an illustration of these techniques	method	2K_dev_728
a novel lateral midair collision-avoidance maneuver is studied in an ideal setting	method	2K_dev_728
without accounting for the uncertainties of the physical reality	method	2K_dev_728
	method	2K_dev_728
conditions	purpose	2K_dev_728
This paper advocates the use of formal verification techniques and in particulartheoremprovingfor hybridsoftware-intensivesystemsasawell-foundedcomplementaryapproachtothe classical aerospace verification and validation techniques	purpose	2K_dev_728
such as testing or simulation	purpose	2K_dev_728
	purpose	2K_dev_728
Existing Bayesian models	background	2K_dev_729
especially nonparametric Bayesian methods	background	2K_dev_729
rely on specially conceived priors to incorporate domain knowledge for discovering improved latent representations	background	2K_dev_729
Such results contribute to push forward the interface between these two important subfields	background	2K_dev_729
which have been largely treated as isolated in the community	background	2K_dev_729
	background	2K_dev_729
which appear to demonstrate the merits inherited from both large-margin learning and Bayesian nonparametrics	finding	2K_dev_729
	finding	2K_dev_729
In this paper	mechanism	2K_dev_729
we present regularized Bayesian inference ( RegBayes )	mechanism	2K_dev_729
a novel computational framework that performs posterior inference with a regularization term on the desired post-data posterior distribution under an information theoretical formulation	mechanism	2K_dev_729
RegBayes is more flexible than the procedure that elicits expert knowledge via priors	mechanism	2K_dev_729
and it covers both directed Bayesian networks and undirected Markov networks	mechanism	2K_dev_729
When the regularization is induced from a linear operator on the posterior distributions	mechanism	2K_dev_729
such as the expectation operator	mechanism	2K_dev_729
we present a general convex-analysis theorem to characterize the solution of RegBayes	mechanism	2K_dev_729
Furthermore	mechanism	2K_dev_729
we present two concrete examples of RegBayes	mechanism	2K_dev_729
infinite latent support vector machines ( iLSVM ) and multi-task infinite latent support vector machines ( MT-iLSVM )	mechanism	2K_dev_729
which explore the large-margin idea in combination with a nonparametric Bayesian model for discovering predictive latent features for classification and multi-task learning	mechanism	2K_dev_729
respectively	mechanism	2K_dev_729
We present efficient inference methods and	mechanism	2K_dev_729
report empirical studies on several benchmark data sets	method	2K_dev_729
	method	2K_dev_729
While priors affect posterior distributions through Bayes ' rule	purpose	2K_dev_729
imposing posterior regularization is arguably more direct and in some cases more natural and general	purpose	2K_dev_729
	purpose	2K_dev_729
Network robustness is an important principle in biology and engineering	background	2K_dev_730
Previous studies of global networks have identified both redundancy and sparseness as topological properties used by robust networks	background	2K_dev_730
Modules internal to the cell that are less exposed to environmental noise are more connected and less robust than external modules	background	2K_dev_730
A similar design principle is used by several other biological networks	background	2K_dev_730
leads to novel algorithms and insights benefiting both fields	finding	2K_dev_730
	finding	2K_dev_730
We propose a simple change to the evolutionary gene duplication model	mechanism	2K_dev_730
We apply these observations to evaluate and design communication networks that are specifically optimized for noisy or malicious environments Combined	method	2K_dev_730
joint analysis of biological and computational networks	method	2K_dev_730
By focusing on molecular subnetworks	purpose	2K_dev_730
or modules	purpose	2K_dev_730
we show that module topology is tightly linked to the level of environmental variability ( noise ) the module expects to encounter	purpose	2K_dev_730
which gives rise to the rich range of module topologies observed within real networks	purpose	2K_dev_730
	purpose	2K_dev_730
The convergence of mobile computing and cloud computing enables new multimedia applications that are both resource-intensive and interaction-intensive	background	2K_dev_731
For these applications	background	2K_dev_731
end-to-end network bandwidth and latency matter greatly when cloud resources are used to augment the computational power and battery life of a mobile device	background	2K_dev_731
	background	2K_dev_731
	finding	2K_dev_731
We then describe an architectural solution that is a seamless extension of today 's cloud computing infrastructure	mechanism	2K_dev_731
	mechanism	2K_dev_731
We first present quantitative evidence	method	2K_dev_731
that this crucial design consideration to meet interactive performance criteria limits data center consolidation	purpose	2K_dev_731
	background	2K_dev_732
Our analysis reveals how the potential speedups over BCFW depend on the minibatch size and how one can provably obtain large problem dependent speedups	finding	2K_dev_732
obtaining significant speedups over competing state-of-the-art ( and synchronous ) methods on structural SVMs	finding	2K_dev_732
We develop mini-batched parallel Frank-Wolfe ( conditional gradient ) methods Our work includes the basic ( batch ) Frank-Wolfe algorithm as well as the recently proposed Block-Coordinate Frank-Wolfe ( BCFW ) method\citep { lacoste2012block } as special cases Our algorithm permits asynchronous updates within the minibatch	mechanism	2K_dev_732
and is robust to stragglers and faulty worker threads	mechanism	2K_dev_732
We present several experiments to indicate empirical behavior of our methods	method	2K_dev_732
for smooth convex optimization subject to block-separable constraints	purpose	2K_dev_732
	background	2K_dev_733
	finding	2K_dev_733
	mechanism	2K_dev_733
	method	2K_dev_733
	purpose	2K_dev_733
How can we tell when accounts are fake or real in a social network ? And how can we tell which accounts belong to liberal	background	2K_dev_734
conservative or centrist users ? Often	background	2K_dev_734
we can answer such questions and label nodes in a network based on the labels of their neighbors and appropriate assumptions of homophily ( `` birds of a feather flock together '' ) or heterophily ( `` opposites attract '' )	background	2K_dev_734
One of the most widely used methods for this kind of inference is Belief Propagation ( BP ) which iteratively propagates the information from a few nodes with explicit labels throughout a network until convergence	background	2K_dev_734
	background	2K_dev_734
show that LinBP and SBP are orders of magnitude faster than standard BP	finding	2K_dev_734
while leading to almost identical node labels	finding	2K_dev_734
This paper introduces Linearized Belief Propagation ( LinBP )	mechanism	2K_dev_734
a linearization of BP via intuitive matrix equations and	mechanism	2K_dev_734
thus	mechanism	2K_dev_734
comes with exact convergence guarantees	mechanism	2K_dev_734
It handles homophily	mechanism	2K_dev_734
heterophily	mechanism	2K_dev_734
and more general cases that arise in multi-class settings	mechanism	2K_dev_734
Plus	mechanism	2K_dev_734
it allows a compact implementation in SQL	mechanism	2K_dev_734
The paper also introduces Single-pass Belief Propagation ( SBP )	mechanism	2K_dev_734
a localized ( or `` myopic '' ) version of LinBP and for which the final class assignments depend only on the nearest labeled neighbors In addition	mechanism	2K_dev_734
SBP allows fast incremental updates in dynamic networks	mechanism	2K_dev_734
Our runtime experiments	method	2K_dev_734
A well-known problem with BP	purpose	2K_dev_734
however	purpose	2K_dev_734
is that there are no known exact guarantees of convergence in graphs with loops that allows a closed-form solution that propagates information across every edge at most once	purpose	2K_dev_734
	background	2K_dev_735
we show that the proposed approach is more successful than other candidate methods for the topic modeling of competition	finding	2K_dev_735
We also demonstrate the generalization power of the proposed method for three prediction tasks	finding	2K_dev_735
We propose a dynamic topic model by jointly leveraging tweets and their associated images	mechanism	2K_dev_735
For a market of interest ( e	mechanism	2K_dev_735
g	mechanism	2K_dev_735
luxury goods )	mechanism	2K_dev_735
we aim at automatically detecting the latent topics ( e	mechanism	2K_dev_735
g	mechanism	2K_dev_735
bags	mechanism	2K_dev_735
clothes	mechanism	2K_dev_735
luxurious ) that are competitively shared by multiple brands ( e	mechanism	2K_dev_735
g	mechanism	2K_dev_735
Burberry	mechanism	2K_dev_735
Prada	mechanism	2K_dev_735
and Chanel )	mechanism	2K_dev_735
and tracking temporal evolution of the brands ' stakes over the shared topics	mechanism	2K_dev_735
One of key applications of our work is social media monitoring that can provide companies with temporal summaries of highly overlapped or discriminative topics with their major competitors We design our model to correctly address three major challenges : multiview representation of text and images	mechanism	2K_dev_735
modeling of competitiveness of multiple brands over shared topics	mechanism	2K_dev_735
and tracking their temporal evolution	mechanism	2K_dev_735
As far as we know	mechanism	2K_dev_735
no previous model can satisfy all the three challenges	mechanism	2K_dev_735
For evaluation	method	2K_dev_735
we analyze about 10 millions of tweets and 8 millions of associated images of the 23 brands in the two categories of luxury and beer	method	2K_dev_735
Through experiments	method	2K_dev_735
quantitatively	method	2K_dev_735
for monitoring temporal evolution of market competition	purpose	2K_dev_735
	background	2K_dev_736
We show that even a very small number of non-adaptive edge queries per vertex results in large gains in expected successful matches	finding	2K_dev_736
In this paper	mechanism	2K_dev_736
we provide edge and set query algorithms that provably achieve some fraction of the omniscient optimal solution	mechanism	2K_dev_736
Our main theoretical result for the stochastic matching ( i	mechanism	2K_dev_736
e	mechanism	2K_dev_736
	mechanism	2K_dev_736
2-set packing ) problem is the design of an adaptive algorithm that queries only a constant number of edges per vertex and achieves a ( 1-e ) fraction of the omniscient optimal solution	mechanism	2K_dev_736
for an arbitrarily small e > 0 Moreover	mechanism	2K_dev_736
this adaptive algorithm performs the queries in only a constant number of rounds	mechanism	2K_dev_736
We complement this result with a non-adaptive ( i	mechanism	2K_dev_736
e	mechanism	2K_dev_736
	mechanism	2K_dev_736
one round of queries ) algorithm that achieves a ( 0	mechanism	2K_dev_736
5 - e ) fraction of the omniscient optimum	mechanism	2K_dev_736
We also extend both our results to stochastic k-set packing by designing an adaptive algorithm that achieves a ( 2/k - e ) fraction of the omniscient optimal solution	mechanism	2K_dev_736
again with only O ( 1 ) queries per element	mechanism	2K_dev_736
This guarantee is close to the best known polynomial-time approximation ratio of 3/k+1 -e for the deterministic k-set packing problem [ Furer 2013	mechanism	2K_dev_736
We empirically explore the application of ( adaptations of ) these algorithms to the kidney exchange problem	method	2K_dev_736
where patients with end-stage renal failure swap willing but incompatible donors on both generated data and on real data from the first 169 match runs of the UNOS nationwide kidney exchange	method	2K_dev_736
The stochastic matching problem deals with finding a maximum matching in a graph whose edges are unknown but can be accessed via queries	purpose	2K_dev_736
This is a special case of stochastic k-set packing	purpose	2K_dev_736
where the problem is to find a maximum packing of sets	purpose	2K_dev_736
each of which exists with some probability	purpose	2K_dev_736
for these two problems	purpose	2K_dev_736
respectively	purpose	2K_dev_736
	purpose	2K_dev_736
	background	2K_dev_737
	finding	2K_dev_737
	mechanism	2K_dev_737
	method	2K_dev_737
	purpose	2K_dev_737
Undirected graphical models are important in a number of modern applications that involve exploring or exploiting dependency structures underlying the data	background	2K_dev_738
For example	background	2K_dev_738
they are often used to explore complex systems where connections between entities are not well understood	background	2K_dev_738
such as in functional brain networks or genetic networks	background	2K_dev_738
demonstrate the effectiveness of the method under various conditions	finding	2K_dev_738
	finding	2K_dev_738
In this paper	mechanism	2K_dev_738
we propose a new principled framework The structure of a graph is inferred through estimation of non-zero partial canonical correlation between nodes	mechanism	2K_dev_738
Under a Gaussian model	mechanism	2K_dev_738
this strategy is equivalent to estimating conditional independencies between random vectors represented by the nodes and it generalizes the classical problem of covariance selection ( Dempster	mechanism	2K_dev_738
1972 )	mechanism	2K_dev_738
We relate the problem of estimating non-zero partial canonical correlations to maximizing a penalized Gaussian likelihood objective and develop a method that efficiently maximizes this objective	mechanism	2K_dev_738
We provide illustrative applications to uncovering gene regulatory networks from gene and protein profiles	mechanism	2K_dev_738
and uncovering brain connectivity graph from positron emission tomography data	mechanism	2K_dev_738
Finally	mechanism	2K_dev_738
we provide sufficient conditions under which the true graphical structure can be recovered correctly	mechanism	2K_dev_738
	mechanism	2K_dev_738
Extensive simulation studies	method	2K_dev_738
Existing methods for estimating structure of undirected graphical models focus on scenarios where each node represents a scalar random variable	purpose	2K_dev_738
such as a binary neural activation state or a continuous mRNA abundance measurement	purpose	2K_dev_738
even though in many real world problems	purpose	2K_dev_738
nodes can represent multivariate variables with much richer meanings	purpose	2K_dev_738
such as whole images	purpose	2K_dev_738
text documents	purpose	2K_dev_738
or multi-view feature vectors	purpose	2K_dev_738
for estimating the structure of undirected graphical models from such multivariate ( or multi-attribute ) nodal data	purpose	2K_dev_738
	purpose	2K_dev_738
Many large-scale machine learning ( ML ) applications use iterative algorithms to converge on parameter values that make the chosen model fit the input data	background	2K_dev_739
show that such exploitation reduces per-iteration time by 33 -- 98 %	finding	2K_dev_739
for three real ML workloads	finding	2K_dev_739
and that these improvements are robust to variation in the patterns over time	finding	2K_dev_739
This paper shows that these repeating patterns can and should be exploited Focusing on the increasingly popular `` parameter server '' approach to sharing model parameters among worker threads	mechanism	2K_dev_739
we describe and demonstrate how the repeating patterns can be exploited Examples include replacing dynamic cache and server structures with static pre-serialized structures	mechanism	2K_dev_739
informing prefetch and partitioning decisions	mechanism	2K_dev_739
and determining which data should be cached at each thread to avoid both contention and slow accesses to memory banks attached to other sockets	mechanism	2K_dev_739
	mechanism	2K_dev_739
Experiments	method	2K_dev_739
Often	purpose	2K_dev_739
this approach results in the same sequence of accesses to parameters repeating each iteration to improve the efficiency of the parallel and distributed ML applications that will be a mainstay in cloud computing environments	purpose	2K_dev_739
Dashboards are increasingly being used in commercial buildings to show building data in an intuitive way to occupants and facility operators	background	2K_dev_740
Such dashboards make relevant parties aware of the impact that they have on a buildings behavior and enable them to understand the dynamics of building systems and current/historical energy use	background	2K_dev_740
and as a result	background	2K_dev_740
support reduction in energy use and improvement of operations of such systems	background	2K_dev_740
	background	2K_dev_740
The findings show that effective building energy dashboards should contain query-based and quick-access based functionalities for showing building energy data through the use of various widgets and user interactions Such dashboards should also enable decomposing data within spatial and temporal dimensions	finding	2K_dev_740
interacting with static and dynamic data sources	finding	2K_dev_740
and providing information about directly measurable energy usage vs	finding	2K_dev_740
resulting energy use indicators	finding	2K_dev_740
	finding	2K_dev_740
This paper gives an overview of an approach for a monitored building that includes highly sensed building automation systems and sensors for energy consumption	mechanism	2K_dev_740
This project is part of the Energy Efficient Buildings Hub in the Philadelphia Navy Yard	mechanism	2K_dev_740
The developed approach incorporates formalization of a taxonomy for building energy dashboards	mechanism	2K_dev_740
identification of visualization aids and requirements through a questionnaire	mechanism	2K_dev_740
	mechanism	2K_dev_740
and a prototype implementation	method	2K_dev_740
	method	2K_dev_740
for designing and implementing an energy dashboard	purpose	2K_dev_740
	background	2K_dev_741
	finding	2K_dev_741
	mechanism	2K_dev_741
	method	2K_dev_741
	purpose	2K_dev_741
Many modern multi-core processors sport a large shared cache with the primary goal of enhancing the statistic performance of computing workloads	background	2K_dev_742
However	background	2K_dev_742
due to resulting cache interference among tasks	background	2K_dev_742
the uncontrolled use of such a shared cache can significantly hamper the predictability and analyzability of multi-core real-time systems	background	2K_dev_742
Software cache partitioning has been considered as an attractive approach to address this issue because it does not require any hardware support beyond that available on many modern processors	background	2K_dev_742
	background	2K_dev_742
results indicate that	finding	2K_dev_742
compared to the traditional approaches	finding	2K_dev_742
our scheme is up to 39 % more memory space efficient and consumes up to 25 % less cache partitions while maintaining cache predictability	finding	2K_dev_742
Our scheme also yields a significant utilization benefit that increases with the number of tasks	finding	2K_dev_742
	finding	2K_dev_742
In this paper	mechanism	2K_dev_742
we propose a practical OS-level cache management scheme Our scheme provides predictable cache performance	mechanism	2K_dev_742
addresses the aforementioned problems of existing software cache partitioning	mechanism	2K_dev_742
and efficiently allocates cache partitions to schedule a given task set	mechanism	2K_dev_742
We have implemented and evaluated our scheme in Linux/RK running on the Intel Core i7 quad-core processor	method	2K_dev_742
Experimental	method	2K_dev_742
However	purpose	2K_dev_742
the state-of-the-art software cache partitioning techniques face two challenges : ( 1 ) the memory co-partitioning problem	purpose	2K_dev_742
which results in page swapping or waste of memory	purpose	2K_dev_742
and ( 2 ) the availability of a limited number of cache partitions	purpose	2K_dev_742
which causes degraded performance	purpose	2K_dev_742
These are major impediments to the practical adoption of software cache partitioning	purpose	2K_dev_742
for multi-core real-time systems	purpose	2K_dev_742
Existing algorithms for trajectory-based clustering usually rely on simplex representation and a single proximity-related distance ( or similarity ) measure Consequently	background	2K_dev_743
additional information markers ( e	background	2K_dev_743
g	background	2K_dev_743
	background	2K_dev_743
social interactions or the semantics of the spatial layout ) are usually ignored	background	2K_dev_743
leading to the inability to fully discover the communities in the trajectory database	background	2K_dev_743
Experimental results demonstrate that TODMIS correctly and efficiently discovers the real grouping behaviors in these diverse settings	finding	2K_dev_743
	finding	2K_dev_743
we propose TODMIS : a general framework for Trajectory cOmmunity Discovery using Multiple Information Sources	mechanism	2K_dev_743
TODMIS combines additional information with raw trajectory data and creates multiple similarity metrics In our proposed approach	mechanism	2K_dev_743
we first develop a novel approach by constructing a Markov Random Walk model from the semantically-labeled trajectory data	mechanism	2K_dev_743
and then measuring similarity at the distribution level In addition	mechanism	2K_dev_743
we also extract and compute pair-wise similarity measures related to three additional markers	mechanism	2K_dev_743
namely trajectory level spatial alignment ( proximity )	mechanism	2K_dev_743
temporal patterns and multi-scale velocity statistics Finally	mechanism	2K_dev_743
after creating a single similarity metric from the weighted combination of these multiple measures	mechanism	2K_dev_743
we apply dense sub-graph detection	mechanism	2K_dev_743
We evaluated TODMIS extensively using traces of ( i ) student movement data in a campus	method	2K_dev_743
( ii ) customer trajectories in a shopping mall	method	2K_dev_743
and ( iii ) city-scale taxi movement data	method	2K_dev_743
This is especially true for human-generated trajectories	purpose	2K_dev_743
where additional fine-grained markers ( e	purpose	2K_dev_743
g	purpose	2K_dev_743
	purpose	2K_dev_743
movement velocity at certain locations	purpose	2K_dev_743
or the sequence of semantic spaces visited ) can help capture latent relationships between cluster members	purpose	2K_dev_743
To address this limitation	purpose	2K_dev_743
for computing semantic level similarity to discover the set of distinct communities	purpose	2K_dev_743
	purpose	2K_dev_743
	background	2K_dev_744
	finding	2K_dev_744
	mechanism	2K_dev_744
	method	2K_dev_744
	purpose	2K_dev_744
Chorus demonstrates a new future in which conversational assistants are made usable in the real world by combining human and machine intelligence	background	2K_dev_745
and may enable a useful new way of interacting with the crowds powering other systems	background	2K_dev_745
demonstrate that Chorus can provide accurate	finding	2K_dev_745
topical responses	finding	2K_dev_745
answering nearly 93 % of user queries appropriately	finding	2K_dev_745
and staying on-topic in over 95 % of responses We also observed that Chorus has advantages over pairing an end user with a single crowd worker and end users completing their own tasks in terms of speed	finding	2K_dev_745
quality	finding	2K_dev_745
and breadth of assistance	finding	2K_dev_745
In this paper	mechanism	2K_dev_745
we introduce Chorus	mechanism	2K_dev_745
a crowd-powered conversational assistant	mechanism	2K_dev_745
When using Chorus	mechanism	2K_dev_745
end users converse continuously with what appears to be a single conversational partner	mechanism	2K_dev_745
Behind the scenes	mechanism	2K_dev_745
Chorus leverages multiple crowd workers to propose and vote on responses	mechanism	2K_dev_745
A shared memory space helps the dynamic crowd workforce maintain consistency	mechanism	2K_dev_745
and a game-theoretic incentive mechanism helps to balance their efforts between proposing and voting	mechanism	2K_dev_745
Studies with 12 end users and 100 crowd workers	method	2K_dev_745
Despite decades of research attempting to establish conversational interaction between humans and computers	purpose	2K_dev_745
the capabilities of automated conversational systems are still limited	purpose	2K_dev_745
	purpose	2K_dev_745
Organizations that collect and use large volumes of personal information often use security audits to protect data subjects from inappropriate uses of this information by authorized insiders	background	2K_dev_746
In face of unknown incentives of employees	background	2K_dev_746
a reasonable audit strategy for the organization is one that minimizes its regret	background	2K_dev_746
We prove a hardness result showing that	finding	2K_dev_746
with imperfect information	finding	2K_dev_746
any k-adaptive regret minimizing algorithm ( with fixed strategies as experts ) must be inefficient unless NP 0 RP even when playing against an oblivious adversary In contrast	finding	2K_dev_746
for bounded-memory games of perfect and imperfect information we present approximate 0-adaptive regret minimization algorithms against an oblivious adversary running in time $ n^ { O\left ( 1\right ) } $	finding	2K_dev_746
we introduce a richer class of games called bounded-memory games	mechanism	2K_dev_746
We introduce the notion of k-adaptive regret	mechanism	2K_dev_746
which compares the reward obtained by playing actions prescribed by the algorithm against a hypothetical k-adaptive adversary with the reward obtained by the best expert in hindsight against the same adversary	mechanism	2K_dev_746
Roughly	mechanism	2K_dev_746
a hypothetical k-adaptive adversary adapts her strategy to the defender 's actions exactly as the real adversary would within each window of karounds	mechanism	2K_dev_746
A k-adaptive adversary is a natural model for temporary adversaries ( e	mechanism	2K_dev_746
g	mechanism	2K_dev_746
	mechanism	2K_dev_746
company employees ) who stay for a certain number of audit cycles and are then replaced by a different person Our definition is parameterized by a set of experts	mechanism	2K_dev_746
which can include both fixed and adaptive defender strategies	mechanism	2K_dev_746
We investigate the inherent complexity of and design algorithms for adaptive regret minimization in bounded-memory games of perfect and imperfect information	mechanism	2K_dev_746
	method	2K_dev_746
While regret minimization has been extensively studied in repeated games	purpose	2K_dev_746
the standard notion of regret for repeated games can not capture the complexity of the interaction between the organization ( defender ) and an adversary	purpose	2K_dev_746
which arises from dependence of rewards and actions on history	purpose	2K_dev_746
To account for this generality	purpose	2K_dev_746
which can provide a more accurate model of the audit process	purpose	2K_dev_746
	purpose	2K_dev_746
but the task of determining which SNPs have functional consequences remains an open challenge	background	2K_dev_747
This brought the effective coverage in the assemblies to eightfold	finding	2K_dev_747
reducing the number and size of gaps in the final assembly over what would be obtained with 5	finding	2K_dev_747
11-fold coverage	finding	2K_dev_747
The two assembly strategies yielded very similar results that largely agree with independent mapping data The assemblies effectively cover the euchromatic regions of the human chromosomes	finding	2K_dev_747
More than 90 % of the genome is in scaffold assemblies of 100	finding	2K_dev_747
000 bp or more	finding	2K_dev_747
and 25 % of the genome is in scaffolds of 10 million bp or larger Analysis of the genome sequence revealed 26	finding	2K_dev_747
588 protein-encoding transcripts for which there was strong corroborating evidence and an additional 12	finding	2K_dev_747
000 computationally derived genes with mouse matches or other weak supporting evidence Although gene-dense clusters are obvious	finding	2K_dev_747
almost half the genes are dispersed in low G+C sequence separated by large tracts of apparently noncoding sequence	finding	2K_dev_747
Only 1	finding	2K_dev_747
1 % of the genome is spanned by exons	finding	2K_dev_747
whereas 24 % is in introns	finding	2K_dev_747
with 75 % of the genome being intergenic DNA	finding	2K_dev_747
Duplications of segmental blocks	finding	2K_dev_747
ranging in size up to chromosomal lengths	finding	2K_dev_747
are abundant throughout the genome and reveal a complex evolutionary history indicates vertebrate expansions of genes associated with neuronal function	finding	2K_dev_747
with tissue-specific developmental regulation	finding	2K_dev_747
and with the hemostasis and immune systems provided locations of 2	finding	2K_dev_747
1 million single-nucleotide polymorphisms ( SNPs ) A random pair of human haploid genomes differed at a rate of 1 bp per 1250 on average	finding	2K_dev_747
but there was marked heterogeneity in the level of polymorphism across the genome	finding	2K_dev_747
Less than 1 % of all SNPs resulted in variation in proteins	finding	2K_dev_747
	finding	2K_dev_747
A 2	mechanism	2K_dev_747
91-billion base pair ( bp ) consensus sequence of the euchromatic portion of the human genome was generated by the whole-genome shotgun sequencing method	mechanism	2K_dev_747
The 14	mechanism	2K_dev_747
8-billion bp DNA sequence was generated over 9 months from 27	mechanism	2K_dev_747
271	mechanism	2K_dev_747
853 high-quality sequence reads ( 5	mechanism	2K_dev_747
11-fold coverage of the genome ) from both ends of plasmid clones made from the DNA of five individuals	mechanism	2K_dev_747
Two assembly strategiesa whole-genome assembly and a regional chromosome assemblywere used	mechanism	2K_dev_747
each combining sequence data from Celera and the publicly funded genome effort	mechanism	2K_dev_747
The public data were shredded into 550-bp segments to create a 2	mechanism	2K_dev_747
9-fold coverage of those genome regions that had been sequenced	mechanism	2K_dev_747
without including biases inherent in the cloning and assembly procedure used by the publicly funded group	mechanism	2K_dev_747
Comparative genomic analysis DNA sequence comparisons between the consensus sequence and publicly funded genome data	method	2K_dev_747
	purpose	2K_dev_747
Developments in health information technology have encouraged the establishment of distributed systems known as Health Information Exchanges ( HIEs ) to enable the sharing of patient records between institutions In many cases	background	2K_dev_748
the parties running these exchanges wish to limit the amount of information they are responsible for holding because of sensitivities about patient information	background	2K_dev_748
Hence	background	2K_dev_748
there is an interest in broker-based HIEs that keep limited information in the exchange repositories	background	2K_dev_748
	finding	2K_dev_748
In this paper	mechanism	2K_dev_748
we consider some of the requirements and present a design in a way that controls the information available in audit logs and regulates their release for investigations Our approach is based on formal rules for audit and the use of Hierarchical Identity-Based Encryption ( HIBE ) to support staged release of data needed in audits and a balance between automated and manual reviews	mechanism	2K_dev_748
	mechanism	2K_dev_748
We test our methodology via an extension of a standard for auditing HIEs called the Audit Trail and Node Authentication Profile ( ATNA ) protocol	method	2K_dev_748
However	purpose	2K_dev_748
it is essential to audit these exchanges carefully due to risks of inappropriate data sharing for auditing broker-based HIEs	purpose	2K_dev_748
	background	2K_dev_749
we show improved performance over scalable Gaussian processes with flexible kernel learning models	finding	2K_dev_749
and stand-alone deep architectures	finding	2K_dev_749
We introduce scalable deep kernels	mechanism	2K_dev_749
which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods	mechanism	2K_dev_749
Specifically	mechanism	2K_dev_749
we transform the inputs of a spectral mixture base kernel with a deep architecture	mechanism	2K_dev_749
using local kernel interpolation	mechanism	2K_dev_749
inducing points	mechanism	2K_dev_749
and structure exploiting ( Kronecker and Toeplitz ) algebra for a scalable kernel representation	mechanism	2K_dev_749
We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process	mechanism	2K_dev_749
Inference and learning cost $ O ( n ) $ for $ n $ training points	mechanism	2K_dev_749
and predictions cost $ O ( 1 ) $ per test point	mechanism	2K_dev_749
On a large and diverse collection of applications	method	2K_dev_749
including a dataset with 2 million examples	method	2K_dev_749
	method	2K_dev_749
These closed-form kernels can be used as drop-in replacements for standard kernels	purpose	2K_dev_749
with benefits in expressive power and scalability	purpose	2K_dev_749
	purpose	2K_dev_749
Significant efforts are being made in the improvement of building automation and control systems in order to optimize the performance of buildings ( e	background	2K_dev_750
g	background	2K_dev_750
reduction of energy consumption )	background	2K_dev_750
As sensor networks in buildings increase	background	2K_dev_750
the complexity of managing them also increases	background	2K_dev_750
For instance	background	2K_dev_750
the generation and maintenance of metadata about sensors	background	2K_dev_750
such as their location within a building	background	2K_dev_750
currently requires significant manual labor	background	2K_dev_750
Being able to understand the relationships between different measurement types and building characteristics is fundamental in achieving an automatic mapping of sensors in buildings	background	2K_dev_750
	background	2K_dev_750
	finding	2K_dev_750
	mechanism	2K_dev_750
The energy contained in the conditioned air delivered to each room is presented as a characteristic feature in order to understand the differences between rooms	method	2K_dev_750
	method	2K_dev_750
The research described in this paper explores the relationship between different HVAC system sensor measurements and physical characteristics of spaces	purpose	2K_dev_750
and its potential application in streamlining the identification of sensor location within a facility	purpose	2K_dev_750
and this paper describes initial observations and results towards this goal	purpose	2K_dev_750
	purpose	2K_dev_750
	background	2K_dev_751
( 2 ) We provide proof of our model 's robustness to spam and anomalous behavior	finding	2K_dev_751
to demonstrate the model 's effectiveness in accurately predicting user 's ratings	finding	2K_dev_751
avoiding prediction skew in the face of injected spam	finding	2K_dev_751
and finding interesting patterns in real world ratings data	finding	2K_dev_751
	finding	2K_dev_751
In this paper we describe a unified Bayesian approach to Collaborative Filtering It models the discrete structure of ratings and is flexible to the often non-Gaussian shape of the distribution	mechanism	2K_dev_751
Additionally	mechanism	2K_dev_751
our method finds a co-clustering of the users and items	mechanism	2K_dev_751
which improves the model 's accuracy and makes the model robust to fraud	mechanism	2K_dev_751
We offer three main contributions : ( 1 ) We provide a novel model and Gibbs sampling algorithm that accurately models the quirks of real world ratings	mechanism	2K_dev_751
such as convex ratings distributions	mechanism	2K_dev_751
	mechanism	2K_dev_751
3 ) We use several real world datasets	method	2K_dev_751
Given a large dataset of users ' ratings of movies	purpose	2K_dev_751
what is the best model to accurately predict which movies a person will like ? And how can we prevent spammers from tricking our algorithms into suggesting a bad movie ? Is it possible to infer structure between movies simultaneously ? that accomplishes all of these goals	purpose	2K_dev_751
	purpose	2K_dev_751
	background	2K_dev_752
	finding	2K_dev_752
	mechanism	2K_dev_752
	method	2K_dev_752
	purpose	2K_dev_752
Standard approaches to stochastic discrete systems require numerical solutions for large optimization problems and quickly become infeasible with larger state spaces	background	2K_dev_753
Generalizations of these techniques to hybrid systems with stochastic effects are even more challenging It is in principle applicable to a variety of stochastic models from other domains	background	2K_dev_753
e	background	2K_dev_753
g	background	2K_dev_753
	background	2K_dev_753
systems biology	background	2K_dev_753
	background	2K_dev_753
While the answer to the verification problem is not guaranteed to be correct	finding	2K_dev_753
we prove that Bayesian SMC can make the probability of giving a wrong answer arbitrarily small We show that our technique enables faster verification than state-of-the-art statistical techniques	finding	2K_dev_753
	finding	2K_dev_753
In particular	mechanism	2K_dev_753
we present a Statistical Model Checking ( SMC ) approach based on Bayesian statistics We show that our approach is feasible for a certain class of hybrid systems with stochastic transitions	mechanism	2K_dev_753
a generalization of Simulink/Stateflow models	mechanism	2K_dev_753
The SMC approach was pioneered by Younes and Simmons in the discrete and non-Bayesian case	mechanism	2K_dev_753
It solves the verification problem by combining randomized sampling of system traces ( which is very efficient for Simulink/Stateflow ) with hypothesis testing ( i	mechanism	2K_dev_753
e	mechanism	2K_dev_753
	mechanism	2K_dev_753
testing against a probability threshold ) or estimation ( i	mechanism	2K_dev_753
e	mechanism	2K_dev_753
	mechanism	2K_dev_753
computing with high probability a value close to the true probability )	mechanism	2K_dev_753
We believe SMC is essential for scaling up to large Stateflow/Simulink models	mechanism	2K_dev_753
The advantage is that answers can usually be obtained much faster than with standard	mechanism	2K_dev_753
exhaustive model checking techniques We emphasize that Bayesian SMC is by no means restricted to Stateflow/Simulink models	mechanism	2K_dev_753
We apply our Bayesian SMC approach to a representative example of stochastic discrete-time hybrid system models in Stateflow/Simulink : a fuel control system featuring hybrid behavior and fault tolerance	method	2K_dev_753
	method	2K_dev_753
We address the problem of model checking stochastic systems	purpose	2K_dev_753
i	purpose	2K_dev_753
e	purpose	2K_dev_753
	purpose	2K_dev_753
checking whether a stochastic system satisfies a certain temporal property with a probability greater ( or smaller ) than a fixed threshold	purpose	2K_dev_753
Existing literature proposes distributed gradient-like methods that are computationally cheap and resilient to link failures	background	2K_dev_754
but have slow convergence rates	background	2K_dev_754
For comparison	background	2K_dev_754
the standard distributed gradient method can not do better than ( 1/k 2/3 ) and ( 1/ K 2/3 )	background	2K_dev_754
on the same class of cost functions ( even for static networks )	background	2K_dev_754
	background	2K_dev_754
We prove their convergence rates Then the modified D-NG achieves rates O ( logk/k ) and O ( logK/ K )	finding	2K_dev_754
and the modified D-NC rates O ( 1/k 2 ) and O ( 1/ K 2- )	finding	2K_dev_754
where > 0 is arbitrarily small illustrate our analytical findings	finding	2K_dev_754
In this paper	mechanism	2K_dev_754
we propose accelerated distributed gradient methods that 1 ) are resilient to link failures ; 2 ) computationally cheap ; and 3 ) improve convergence rates over other gradient methods	mechanism	2K_dev_754
We model the network by a sequence of independent	mechanism	2K_dev_754
identically distributed random matrices { W ( k ) } drawn from the set of symmetric	mechanism	2K_dev_754
stochastic matrices with positive diagonals	mechanism	2K_dev_754
The network is connected on average and the cost functions are convex	mechanism	2K_dev_754
differentiable	mechanism	2K_dev_754
with Lipschitz continuous and bounded gradients	mechanism	2K_dev_754
We design two distributed Nesterov-like gradient methods that modify the D-NG and D-NC methods that we proposed for static networks	mechanism	2K_dev_754
in terms of the expected optimality gap at the cost function	method	2K_dev_754
Let k and K be the number of per-node gradient evaluations and per-node communications	method	2K_dev_754
respectively	method	2K_dev_754
Simulation examples	method	2K_dev_754
We consider distributed optimization in random networks where N nodes cooperatively minimize the sum i=1 N f i ( x ) of their individual convex costs	purpose	2K_dev_754
	purpose	2K_dev_754
	background	2K_dev_755
	finding	2K_dev_755
	mechanism	2K_dev_755
	method	2K_dev_755
	purpose	2K_dev_755
In search advertising	background	2K_dev_756
the search engine needs to select the most profitable advertisements to display	background	2K_dev_756
which can be formulated as an instance of online learning with partial feedback	background	2K_dev_756
also known as the stochastic multi-armed bandit ( MAB ) problem	background	2K_dev_756
	finding	2K_dev_756
We then propose simple bias-correction methods with benefits to both the search engine and the advertisers	mechanism	2K_dev_756
	mechanism	2K_dev_756
	method	2K_dev_756
In this paper	purpose	2K_dev_756
we show that the naive application of MAB algorithms to search advertising for advertisement selection will produce sample selection bias that harms the search engine by decreasing expected revenue and `` estimation of the largest mean '' ( ELM ) bias that harms the advertisers by increasing game-theoretic player-regret	purpose	2K_dev_756
	purpose	2K_dev_756
	background	2K_dev_757
	finding	2K_dev_757
	mechanism	2K_dev_757
	method	2K_dev_757
	purpose	2K_dev_757
Smartwatches promise to bring enhanced convenience to common communication	background	2K_dev_758
creation and information retrieval tasks	background	2K_dev_758
	finding	2K_dev_758
In this work	mechanism	2K_dev_758
we propose a complementary input approach : using the watch face as a multi-degree-of-freedom	mechanism	2K_dev_758
mechanical interface	mechanism	2K_dev_758
We developed a proof of concept smartwatch that supports continuous 2D panning and twist	mechanism	2K_dev_758
as well as binary tilt and click	mechanism	2K_dev_758
	mechanism	2K_dev_758
To illustrate the potential of our approach	method	2K_dev_758
we developed a series of example applications	method	2K_dev_758
many of which are cumbersome -- or even impossible -- on today 's smartwatch devices	method	2K_dev_758
	method	2K_dev_758
Due to their prominent placement on the wrist	purpose	2K_dev_758
they must be small and otherwise unobtrusive	purpose	2K_dev_758
which limits the sophistication of interactions we can perform	purpose	2K_dev_758
This problem is particularly acute if the smartwatch relies on a touchscreen for input	purpose	2K_dev_758
as the display is small and our fingers are relatively large	purpose	2K_dev_758
	purpose	2K_dev_758
Which song will Smith listen to next ? Which restaurant will Alice go to tomorrow ? Which product will John click next	background	2K_dev_759
TribeFlow is more accurate and up to 413x faster than top competitors	finding	2K_dev_759
	finding	2K_dev_759
Mindful of these challenges we propose TribeFlow	mechanism	2K_dev_759
a method designed TribeFlow is a general method that can perform next product recommendation	mechanism	2K_dev_759
next song recommendation	mechanism	2K_dev_759
next location prediction	mechanism	2K_dev_759
and general arbitrary-length user trajectory prediction without domain-specific knowledge	mechanism	2K_dev_759
	mechanism	2K_dev_759
	method	2K_dev_759
These applications have in common the prediction of user trajectories that are in a constant state of flux over a hidden network ( e	purpose	2K_dev_759
g	purpose	2K_dev_759
website links	purpose	2K_dev_759
geographic location )	purpose	2K_dev_759
Moreover	purpose	2K_dev_759
what users are doing now may be unrelated to what they will be doing in an hour from now to cope with the complex challenges of learning personalized predictive models of non-stationary	purpose	2K_dev_759
transient	purpose	2K_dev_759
and time-heterogeneous user trajectories	purpose	2K_dev_759
For instance	background	2K_dev_760
although `` eats '' and `` stares at '' seem unrelated in text	background	2K_dev_760
they share semantics visually	background	2K_dev_760
When people are eating something	background	2K_dev_760
they also tend to stare at the food	background	2K_dev_760
	background	2K_dev_760
We show improvements on three tasks : common-sense assertion classification	finding	2K_dev_760
visual paraphrasing and text-based image retrieval	finding	2K_dev_760
Our code and datasets are available online	finding	2K_dev_760
	finding	2K_dev_760
We propose a model We note that the visual grounding of words depends on semantics	mechanism	2K_dev_760
and not the literal pixels	mechanism	2K_dev_760
We thus use abstract scenes created from clipart to provide the visual grounding	mechanism	2K_dev_760
We find that the embeddings we learn capture fine-grained	mechanism	2K_dev_760
visually grounded notions of semantic relatedness	mechanism	2K_dev_760
over text-only word embeddings ( word2vec )	method	2K_dev_760
to learn visually grounded word embeddings ( vis-w2v ) to capture visual notions of semantic relatedness	purpose	2K_dev_760
While word embeddings trained using text have been extremely successful	purpose	2K_dev_760
they can not uncover notions of semantic relatedness implicit in our visual world	purpose	2K_dev_760
Grounding diverse relations like `` eats '' and `` stares at '' into vision remains challenging	purpose	2K_dev_760
despite recent progress in vision	purpose	2K_dev_760
	purpose	2K_dev_760
Learning about a new area of knowledge is challenging for novices partly because they are not yet aware of which topics are most important	background	2K_dev_761
The first experiment shows that a high context	finding	2K_dev_761
low structure interface helps crowdworkers perform faster	finding	2K_dev_761
higher quality synthesis	finding	2K_dev_761
while the second experiment shows that a tournament-style ( parallelized ) crowd workflow produces faster	finding	2K_dev_761
higher quality	finding	2K_dev_761
more diverse outlines than a linear ( serial/iterative ) workflow	finding	2K_dev_761
we present Crowdlines	mechanism	2K_dev_761
a system that uses crowdsourcing to help people synthesize diverse online information	mechanism	2K_dev_761
Crowdworkers make connections across sources to produce a rich outline that surfaces diverse perspectives within important topics	mechanism	2K_dev_761
	mechanism	2K_dev_761
We evaluate Crowdlines with two experiments	method	2K_dev_761
The Internet contains a wealth of information for learning the underlying structure of a domain	purpose	2K_dev_761
but relevant sources often have diverse structures and emphases	purpose	2K_dev_761
making it hard to discern what is widely considered essential knowledge vs	purpose	2K_dev_761
what is idiosyncratic	purpose	2K_dev_761
Crowdsourcing offers a potential solution because humans are skilled at evaluating high-level structure	purpose	2K_dev_761
but most crowd micro-tasks provide limited context and time	purpose	2K_dev_761
To address these challenges	purpose	2K_dev_761
	purpose	2K_dev_761
Review fraud is a pervasive problem in online commerce	background	2K_dev_762
in which fraudulent sellers write or purchase fake reviews to manipulate perception of their products and services	background	2K_dev_762
	background	2K_dev_762
show that BIRDNEST successfully spots review fraud in large real-world graphs : the 50 most suspicious users of the Flipkart platform flagged by our algorithm were investigated and all identified as fraudulent by domain experts at Flipkart	finding	2K_dev_762
Hence	mechanism	2K_dev_762
in this paper	mechanism	2K_dev_762
we propose an approach which combines these 2 approaches in a principled manner	mechanism	2K_dev_762
allowing successful detection even when one of these signs is not present To combine these 2 approaches	mechanism	2K_dev_762
we formulate our Bayesian Inference for Rating Data ( BIRD ) model	mechanism	2K_dev_762
a flexible Bayesian model of user rating behavior	mechanism	2K_dev_762
Based on our model we formulate a likelihood-based suspiciousness metric	mechanism	2K_dev_762
Normalized Expected Surprise Total ( NEST )	mechanism	2K_dev_762
We propose a linear-time algorithm for performing Bayesian inference using our model and computing the metric	mechanism	2K_dev_762
	mechanism	2K_dev_762
Experiments on real data	method	2K_dev_762
Fake reviews are often detected based on several signs	purpose	2K_dev_762
including 1 ) they occur in short bursts of time ; 2 ) fraudulent user accounts have skewed rating distributions	purpose	2K_dev_762
However	purpose	2K_dev_762
these may both be true in any given dataset	purpose	2K_dev_762
for detecting fraudulent reviews	purpose	2K_dev_762
	background	2K_dev_763
that illustrate the value and immediate feasibility of our approach	finding	2K_dev_763
	finding	2K_dev_763
We describe a novel approach offering two additional	mechanism	2K_dev_763
analog degrees of freedom for interactive functions	mechanism	2K_dev_763
Further	mechanism	2K_dev_763
we show that our approach can be achieved on off-the-shelf consumer touchscreen devices : a smartphone and smartwatch	mechanism	2K_dev_763
	mechanism	2K_dev_763
We validate our technique though a user study on both devices and conclude with several demo applications	method	2K_dev_763
for estimating the pitch and yaw of fingers relative to a touchscreen 's surface	purpose	2K_dev_763
	purpose	2K_dev_763
User identification and differentiation have implications in many application domains	background	2K_dev_764
including security	background	2K_dev_764
personalization	background	2K_dev_764
and co-located multiuser systems	background	2K_dev_764
In response	background	2K_dev_764
dozens of approaches have been developed	background	2K_dev_764
from fingerprint and retinal scans	background	2K_dev_764
to hand gestures and RFID tags	background	2K_dev_764
Our user study demonstrates twenty-participant authentication accuracies of 99	finding	2K_dev_764
6 %	finding	2K_dev_764
For twenty-user identification	finding	2K_dev_764
our software achieved 94	finding	2K_dev_764
0 % accuracy and 98	finding	2K_dev_764
2 % on groups of four	finding	2K_dev_764
simulating family use	finding	2K_dev_764
	finding	2K_dev_764
In this work	mechanism	2K_dev_764
we propose CapAuth	mechanism	2K_dev_764
a technique that uses existing	mechanism	2K_dev_764
low-level touchscreen data	mechanism	2K_dev_764
combined with machine learning classifiers	mechanism	2K_dev_764
	mechanism	2K_dev_764
As a proof-of-concept	method	2K_dev_764
we ran our software on an off-the-shelf Nexus 5 smartphone	method	2K_dev_764
	method	2K_dev_764
to provide real-time authentication and even identification of users	purpose	2K_dev_764
Health information exchanges ( HIEs ) are healthcare information technology efforts designed to foster coordination of patient care across the fragmented U	background	2K_dev_765
S	background	2K_dev_765
healthcare system	background	2K_dev_765
Their purpose is to improve efficiency and quality of care through enhanced sharing of patient data	background	2K_dev_765
Across the United States	background	2K_dev_765
numerous states have enacted laws that provide various forms of incentives for HIEs and address growing privacy concerns associated with the sharing of patient data Our results contribute to the burgeoning literature on health information technology and the debate on the impact of privacy regulation on technology innovation	background	2K_dev_765
In particular	background	2K_dev_765
they show that the impact of privacy regulation on the success of information technology efforts is heterogeneous : both positive and negative effects can arise from regulation	background	2K_dev_765
depending on the specific attributes of privacy laws	background	2K_dev_765
This paper was accepted by Anandhi Bharadwaj	background	2K_dev_765
information systems	background	2K_dev_765
Although we observe that privacy regulation alone can result in a decrease in planning and operational HIEs	finding	2K_dev_765
we also find that	finding	2K_dev_765
when coupled with incentives	finding	2K_dev_765
privacy regulation with requirements for patient consent can actually positively impact the development of HIE efforts Among all states with laws creating HIE incentives	finding	2K_dev_765
only states that combined incentives with consent requirements saw a net increase in operational HIEs ; HIEs in those states also reported decreased levels of privacy concern relative to HIEs in states with other legislative approaches	finding	2K_dev_765
	mechanism	2K_dev_765
focusing on the impact of laws that include requirements for patient consent	method	2K_dev_765
We investigate the impact on the emergence of HIEs of state laws that incentivize HIE efforts and state laws that include different types of privacy requirements for sharing healthcare data	purpose	2K_dev_765
	purpose	2K_dev_765
Natural language dialog is an important and intuitive way for people to access information and services This hybrid systems approach will help make dialog systems both more general and more robust going forward	background	2K_dev_766
	finding	2K_dev_766
This paper introduces Guardian	mechanism	2K_dev_766
a crowdpowered framework that wraps existing Web APIs into immediately usable spoken dialog systems Guardian takes as input the Web API and desired task	mechanism	2K_dev_766
and the crowd determines the parameters necessary to complete it	mechanism	2K_dev_766
how to ask for them	mechanism	2K_dev_766
and interprets the responses from the API	mechanism	2K_dev_766
The system is structured so that	mechanism	2K_dev_766
over time	mechanism	2K_dev_766
it can learn to take over for the crowd	mechanism	2K_dev_766
	mechanism	2K_dev_766
	method	2K_dev_766
However	purpose	2K_dev_766
current dialog systems are limited in scope	purpose	2K_dev_766
brittle to the richness of natural language	purpose	2K_dev_766
and expensive to produce	purpose	2K_dev_766
	purpose	2K_dev_766
Recent research has highlighted the need for upstream planning in healthcare service delivery systems	background	2K_dev_767
patient scheduling	background	2K_dev_767
and resource allocation in the hospital inpatient setting DRGs are a payment scheme employed at patients discharge	background	2K_dev_767
where the DRG and length of stay determine the revenue that the hospital obtains	background	2K_dev_767
The largest improvements were observed at and before admission	finding	2K_dev_767
when information such as procedures and diagnoses is typically incomplete	finding	2K_dev_767
but performance was improved even after a substantial portion of the patients length of stay	finding	2K_dev_767
and under multiple scenarios making different assumptions about the available information	finding	2K_dev_767
Using the improved DRG predictions within our resource allocation model improves contribution margin by 2	finding	2K_dev_767
9 % and the utilization of scarce resources such as operating rooms and beds from 66	finding	2K_dev_767
3 % to 67	finding	2K_dev_767
3 % and from 70	finding	2K_dev_767
7 % to 71	finding	2K_dev_767
7 %	finding	2K_dev_767
respectively	finding	2K_dev_767
This enables 9	finding	2K_dev_767
0 % more nonurgent elective patients to be admitted as compared to the baseline	finding	2K_dev_767
	finding	2K_dev_767
based on machine learning ( ML ) and mixed-integer programming ( MIP )	mechanism	2K_dev_767
We show that early and accurate DRG classification using ML methods	mechanism	2K_dev_767
incorporated into an MIP-based resource allocation model	mechanism	2K_dev_767
can increase the hospitals contribution margin	mechanism	2K_dev_767
the number of admitted patients	mechanism	2K_dev_767
and the utilization of resources such as operating rooms and beds	mechanism	2K_dev_767
We test these methods on hospital data containing more than 16	method	2K_dev_767
000 inpatient records and demonstrate improved DRG classification accuracy as compared to the hospitals current approach	method	2K_dev_767
This study examines the value of upstream planning within hospital-wide resource allocation decisions focusing on prediction of diagnosis-related groups ( DRGs ) and the use of these predictions for allocating scarce hospital resources	purpose	2K_dev_767
	purpose	2K_dev_767
Touchscreens with dynamic electrostatic friction are a com-pelling	background	2K_dev_768
low-latency and solid-state haptic feedback technology	background	2K_dev_768
Work to date has focused on minimum perceptual difference	background	2K_dev_768
texture rendering	background	2K_dev_768
and fingertip-surface models	background	2K_dev_768
	background	2K_dev_768
Our results show that can improve targeting speed by 7	finding	2K_dev_768
5 % compared to conventional flat touchscreens	finding	2K_dev_768
	mechanism	2K_dev_768
electrostatic haptic feedback	method	2K_dev_768
However	purpose	2K_dev_768
no work to date has quantified how electrostatic feedback can be used to improve user performance	purpose	2K_dev_768
in par-ticular targeting	purpose	2K_dev_768
where virtual objects rendered on touchscreens can offer tactile feedback	purpose	2K_dev_768
Background Effective management and treatment of cancer continues to be complicated by the rapid evolution and resulting heterogeneity of tumors	background	2K_dev_769
Phylogenetic study of cell populations in single tumors provides a way to delineate intra-tumoral heterogeneity and identify robust features of evolutionary processes	background	2K_dev_769
	finding	2K_dev_769
Here	mechanism	2K_dev_769
we investigate a strategy	mechanism	2K_dev_769
	method	2K_dev_769
The introduction of single-cell sequencing has shown great promise for advancing single-tumor phylogenetics ; however	purpose	2K_dev_769
the volume and high noise in these data present challenges for inference	purpose	2K_dev_769
especially with regard to chromosome abnormalities that typically dominate tumor evolution to use such data to track differences in tumor cell genomic content during progression	purpose	2K_dev_769
When training large machine learning models with many variables or parameters	background	2K_dev_770
a single machine is often inadequate since the model may be too large to fit in memory	background	2K_dev_770
while training can take a long time even with stochastic updates	background	2K_dev_770
A natural recourse is to turn to distributed cluster computing	background	2K_dev_770
in order to harness additional memory and processors	background	2K_dev_770
	background	2K_dev_770
	finding	2K_dev_770
We develop a framework of primitives	mechanism	2K_dev_770
STRADS	mechanism	2K_dev_770
thus improving their memory efficiency while presenting new opportunities to speed up convergence without compromising inference correctness	mechanism	2K_dev_770
We demonstrate the efficacy of model-parallel algorithms implemented in STRADS versus popular implementations for Topic Modeling	method	2K_dev_770
Matrix Factorization and Lasso	method	2K_dev_770
	method	2K_dev_770
However	purpose	2K_dev_770
naive	purpose	2K_dev_770
unstructured parallelization of ML algorithms can make inefficient use of distributed memory	purpose	2K_dev_770
while failing to obtain proportional convergence speedups or can even result in divergence	purpose	2K_dev_770
for dynamic model-parallelism in order to explore partitioning and update scheduling of model variables in distributed ML algorithms	purpose	2K_dev_770
The ap- proach can	background	2K_dev_771
e	background	2K_dev_771
g	background	2K_dev_771
	background	2K_dev_771
generate nontrivial algebraic invariant equations capturing the airplane behavior during take-off or landing in longitudinal motion	background	2K_dev_771
	background	2K_dev_771
	finding	2K_dev_771
by one polynomial and a finite set of its successive Lie derivatives	mechanism	2K_dev_771
This so-called differential radical characterization re- lies on a sound abstraction of the reachable set of solutions by the smallest variety that contains it	mechanism	2K_dev_771
The characterization leads to a differential radical invariant proof rule that is sound and complete	mechanism	2K_dev_771
which implies that invariance of algebraic equa- tions over real-closed fields is decidable Furthermore	mechanism	2K_dev_771
the problem of generating invariant varieties is shown to be as hard as minimizing the rank of a symbolic matrix	mechanism	2K_dev_771
and is therefore NP-hard	mechanism	2K_dev_771
We investigate symbolic linear algebra tools based on Gaussian elimination	method	2K_dev_771
We prove that any invariant algebraic set of a given polynomial vector field can be algebraically represented to efficiently automate the generation	purpose	2K_dev_771
When companies operate on the graphs with monetary incentives to sell Twitter `` Followers '' and Facebook page `` Likes ''	background	2K_dev_772
the graphs show strange connectivity patterns	background	2K_dev_772
We report strange deviations from typical patterns like smooth degree distributions	finding	2K_dev_772
We find that such deviations are often due to `` lockstep behavior '' that large groups of followers connect to the same groups of followees	finding	2K_dev_772
We discover that ( a ) the lockstep behaviors on the graph shape dense `` block '' in its adjacency matrix and creates `` rays '' in spectral subspaces	finding	2K_dev_772
and ( b ) partially overlapping of the behaviors shape `` staircase '' in its adjacency matrix and creates `` pearls '' in spectral subspaces The results demonstrate the scalability and effectiveness of our proposed algorithm	finding	2K_dev_772
The second contribution is that we provide a fast algorithm	mechanism	2K_dev_772
using the discovery as a guide for practitioners	mechanism	2K_dev_772
	mechanism	2K_dev_772
In this paper	method	2K_dev_772
we study a complete graph from a large Twitter-style social network	method	2K_dev_772
spanning up to 3	method	2K_dev_772
33 billion edges	method	2K_dev_772
Our first contribution is that we study strange patterns on the adjacency matrix and in the spectral subspaces with respect to several flavors of lockstep	method	2K_dev_772
We carry out extensive experiments on both synthetic and real datasets	method	2K_dev_772
as well as public datasets from IMDb and US Patent	method	2K_dev_772
	method	2K_dev_772
Given multimillion-node graphs such as `` who-follows-whom ''	purpose	2K_dev_772
`` patent-cites-patent ''	purpose	2K_dev_772
`` user-likes-page '' and `` actor/director-makes-movie '' networks	purpose	2K_dev_772
how can we find unexpected behaviors ? to detect users who offer the lockstep behaviors in undirected/directed/bipartite graphs	purpose	2K_dev_772
Characterizing the spatial distribution of proteins directly from microscopy images is a difficult problem with numerous applications in cell biology ( e	background	2K_dev_773
g	background	2K_dev_773
identifying motor-related proteins ) and clinical research ( e	background	2K_dev_773
g	background	2K_dev_773
identification of cancer biomarkers ) Such models are expected to be valuable for representing and summarizing each pattern and for constructing systems biology simulations of cell behaviors	background	2K_dev_773
	background	2K_dev_773
We were able to show that these patterns could be distinguished from each other with high accuracy	finding	2K_dev_773
and we were able to assign to one of these subclasses hundreds of proteins whose subcellular localization had not previously been well defined	finding	2K_dev_773
Here we describe the design of a system including quantification of their relationships to microtubules	mechanism	2K_dev_773
We constructed the system using confocal immunofluorescence microscopy images from the Human Protein Atlas project for 11 punctate proteins in three cultured cell lines These proteins have previously been characterized as being primarily located in punctate structures	mechanism	2K_dev_773
but their images had all been annotated by visual examination as being simply vesicular	mechanism	2K_dev_773
In addition to providing these novel annotations	mechanism	2K_dev_773
we built a generative approach to modeling of punctate distributions	mechanism	2K_dev_773
	method	2K_dev_773
that provides automated analysis of punctate protein patterns in microscope images	purpose	2K_dev_773
that captures the essential characteristics of the distinct patterns	purpose	2K_dev_773
	purpose	2K_dev_773
Revenue maximization in combinatorial auctions ( and other multidimensional selling settings ) is one of the most important and elusive problems in mechanism design	background	2K_dev_774
Such priors do not exist in most applications	background	2K_dev_774
Rather	background	2K_dev_774
in many applications ( such as premium display advertising markets )	background	2K_dev_774
there is essentially a point prior	background	2K_dev_774
which may not be accurate	background	2K_dev_774
	background	2K_dev_774
validate the approach and show that our techniques dramatically improve scalability over a leading general-purpose MIP solver	finding	2K_dev_774
In this paper	mechanism	2K_dev_774
we instead study a common revenue-enhancement approach - bundling - in the context of the most commonly studied combinatorial auction mechanism	mechanism	2K_dev_774
the Vickrey-Clarke-Groves ( VCG ) mechanism	mechanism	2K_dev_774
We adopt the point prior model	mechanism	2K_dev_774
and prove robustness to inaccuracy in the prior	mechanism	2K_dev_774
Then	mechanism	2K_dev_774
we present a branch-and-bound framework for finding the optimal bundling	mechanism	2K_dev_774
We introduce several techniques	mechanism	2K_dev_774
Experiments on CATS distributions	method	2K_dev_774
The optimal design is unknown	purpose	2K_dev_774
and is known to include features that are not acceptable in many applications	purpose	2K_dev_774
such as favoring some bidders over others and randomization A second challenge in mechanism design for combinatorial auctions is that the prior distribution on each bidder 's valuation can be doubly exponential	purpose	2K_dev_774
for branching	purpose	2K_dev_774
upper bounding	purpose	2K_dev_774
lower bounding	purpose	2K_dev_774
and lazy bounding	purpose	2K_dev_774
	purpose	2K_dev_774
	background	2K_dev_775
Most noticeably	finding	2K_dev_775
the accuracy of our algorithm reaches 51	finding	2K_dev_775
8 % on the challenging HMDB dataset which outperforms the state-of-the-art of 7	finding	2K_dev_775
3 % relatively	finding	2K_dev_775
	finding	2K_dev_775
We propose a novel content driven pooling that leverages space-time context while being robust toward global space-time transformations	mechanism	2K_dev_775
Being robust to such transformations is of primary importance in unconstrained videos where the action localizations can drastically shift between frames	mechanism	2K_dev_775
Our pooling identifies regions of interest using video structural cues estimated by different saliency functions	mechanism	2K_dev_775
To combine the different structural information	mechanism	2K_dev_775
we introduce an iterative structure learning algorithm	mechanism	2K_dev_775
WSVM ( weighted SVM )	mechanism	2K_dev_775
that determines the optimal saliency layout of an action model through a sparse regularizer	mechanism	2K_dev_775
A new optimization method is proposed to solve the WSVM highly non-smooth objective function	mechanism	2K_dev_775
	mechanism	2K_dev_775
We evaluate our approach on standard action datasets ( KTH	method	2K_dev_775
UCF50 and HMDB )	method	2K_dev_775
	method	2K_dev_775
We address the problem of action recognition in unconstrained videos	purpose	2K_dev_775
	purpose	2K_dev_775
	background	2K_dev_776
we provide very positive results for plurality and very negative results for Borda	finding	2K_dev_776
and place veto in the middle of this spectrum	finding	2K_dev_776
	finding	2K_dev_776
via the notion of the price of anarchy	mechanism	2K_dev_776
using the scores of alternatives as a proxy for their quality and bounding the ratio between the score of the optimal alternative and the score of the winning alternative in Nash equilibrium Specifically	mechanism	2K_dev_776
we are interested in Nash equilibria that are obtained via sequences of rational strategic moves	mechanism	2K_dev_776
Focusing on three common voting rules -- plurality	mechanism	2K_dev_776
veto	mechanism	2K_dev_776
and Borda --	mechanism	2K_dev_776
	method	2K_dev_776
It is well known that strategic behavior in elections is essentially unavoidable ; we therefore ask : how bad can the rational outcome be ? We answer this question	purpose	2K_dev_776
Given a large graph	background	2K_dev_777
like a computer communication network	background	2K_dev_777
which $ k $ nodes should we immunize ( or monitor	background	2K_dev_777
or remove )	background	2K_dev_777
to make it as robust as possible against a computer virus attack ? This problem	background	2K_dev_777
referred to as the node immunization problem	background	2K_dev_777
is the core building block in many high-impact applications	background	2K_dev_777
ranging from public health	background	2K_dev_777
cybersecurity to viral marketing	background	2K_dev_777
A central component in node immunization is to find the best $ k $ bridges of a given graph	background	2K_dev_777
	background	2K_dev_777
( 1 ) the proposed bridging score gives mining results consistent with intuition ; and ( 2 ) the proposed fast solution is up to seven orders of magnitude faster than straightforward alternatives	finding	2K_dev_777
First of all	mechanism	2K_dev_777
we propose a novel bridging score $ \Delta \lambda $	mechanism	2K_dev_777
inspired by immunology	mechanism	2K_dev_777
and we show that its results agree with intuition for several realistic settings	mechanism	2K_dev_777
Since the straightforward way to compute $ \Delta \lambda $ is computationally intractable	mechanism	2K_dev_777
we then focus on the computational issues and propose a surprisingly efficient way ( $ O ( nk^2+m ) $ ) to estimate it	mechanism	2K_dev_777
	mechanism	2K_dev_777
Experimental results on real graphs show that	method	2K_dev_777
In this setting	purpose	2K_dev_777
we typically want to determine the relative importance of a node ( or a set of nodes ) within the graph	purpose	2K_dev_777
for example	purpose	2K_dev_777
how valuable ( as a bridge ) a person or a group of persons is in a social network	purpose	2K_dev_777
To the best of our knowledge	background	2K_dev_778
our work represents the largest study of propagation patterns of executables	background	2K_dev_778
Finally	finding	2K_dev_778
we discover the SharkFin temporal propagation pattern of executable files	finding	2K_dev_778
the GeoSplit pattern in the geographical spread of machines that report executables to Symantec 's servers	finding	2K_dev_778
the Periodic Power Law ( Ppl ) distribution of the life-time of URLs	finding	2K_dev_778
and we show how to efficiently extrapolate crucial properties of the data from a small sample	finding	2K_dev_778
	mechanism	2K_dev_778
by analyzing patterns from 22 million malicious ( and benign ) files	method	2K_dev_778
found on 1	method	2K_dev_778
6 million hosts worldwide during the month of June 2011	method	2K_dev_778
We conduct this study using the WINE database available at Symantec Research Labs Additionally	method	2K_dev_778
we explore the research questions raised by sampling on such large databases of executables ; the importance of studying the implications of sampling is twofold : First	method	2K_dev_778
sampling is a means of reducing the size of the database hence making it more accessible to researchers ; second	method	2K_dev_778
because every such data collection can be perceived as a sample of the real world	method	2K_dev_778
How does malware propagate ? Does it form spikes over time ? Does it resemble the propagation pattern of benign files	purpose	2K_dev_778
such as software patches ? Does it spread uniformly over countries ? How long does it take for a URL that distributes malware to be detected and shut down ? In this work	purpose	2K_dev_778
we answer these questions	purpose	2K_dev_778
	background	2K_dev_779
we discovered that duplicate points create subtle issues	finding	2K_dev_779
that the literature has ignored : if dmax is the multiplicity of the most over-plotted point	finding	2K_dev_779
typical algorithms are quadratic on dmax	finding	2K_dev_779
we show that our methods give either exact results	finding	2K_dev_779
or highly accurate approximate ones	finding	2K_dev_779
	finding	2K_dev_779
We propose several ways we report wall-clock times and our time savings ; and	mechanism	2K_dev_779
After careful analysis	method	2K_dev_779
	method	2K_dev_779
Given a large cloud of multi-dimensional points	purpose	2K_dev_779
and an off-theshelf outlier detection method	purpose	2K_dev_779
why does it take a week to finish ? to eliminate the problem	purpose	2K_dev_779
Counterfactual Regret Minimization ( CFR ) is a leading algorithm for finding a Nash equilibrium in large zero-sum imperfect-information games	background	2K_dev_780
CFR is an iterative algorithm that repeatedly traverses the game tree	background	2K_dev_780
updating regrets at each information set	background	2K_dev_780
	background	2K_dev_780
show an order of magnitude speed improvement	finding	2K_dev_780
and the relative speed improvement increases with the size of the game	finding	2K_dev_780
	finding	2K_dev_780
We introduce to CFR It revisits that sequence at the earliest subsequent CFR iteration where the regret could have become positive	mechanism	2K_dev_780
had that path been explored on every iteration The new algorithm maintains CFR 's convergence guarantees while making iterations significantly fastereven if previously known pruning techniques are used in the comparison	mechanism	2K_dev_780
This improvement carries over to CFR+	mechanism	2K_dev_780
a recent variant of CFR	mechanism	2K_dev_780
	mechanism	2K_dev_780
Experiments	method	2K_dev_780
an improvement that prunes any path of play in the tree	purpose	2K_dev_780
and its descendants	purpose	2K_dev_780
that has negative regret	purpose	2K_dev_780
Influence maximization is a problem of maximizing the aggregate adoption of products	background	2K_dev_781
technologies	background	2K_dev_781
or even beliefs	background	2K_dev_781
Most past algorithms leveraged an assumption of submodularity that captures diminishing returns to scale	background	2K_dev_781
	background	2K_dev_781
prove that this policy is optimal in a very general setting	finding	2K_dev_781
that the proposed `` best-time '' algorithm remains quite effective the `` best-time '' policy becomes suboptimal	finding	2K_dev_781
and is significantly outperformed by our more general heuristic	finding	2K_dev_781
We formulate a dynamic influence maximization problem under increasing returns We propose a simple algorithm in this model which chooses the best time period to use up the entire budget ( called Best-Stage )	mechanism	2K_dev_781
and We also propose a heuristic algorithm for this problem of which Best-Stage decision is a special case	mechanism	2K_dev_781
Additionally	method	2K_dev_781
we experimentally verify even as we relax the assumptions under which optimality can be proved	method	2K_dev_781
However	method	2K_dev_781
we find that when we add a `` learning-by-doing '' effect	method	2K_dev_781
in which the adoption costs decrease not as a function of time	method	2K_dev_781
but as a function of aggregate adoption	method	2K_dev_781
	method	2K_dev_781
While submodularity is natural in many domains	purpose	2K_dev_781
early stages of innovation adoption are often better characterized by convexity	purpose	2K_dev_781
which is evident for renewable technologies	purpose	2K_dev_781
such as rooftop solar to scale over a finite time horizon	purpose	2K_dev_781
in which the decision maker faces a budget constraint	purpose	2K_dev_781
Pareto efficiency is a widely used property in solution concepts for cooperative and non -- cooperative game -- theoretic settings and	background	2K_dev_782
more generally	background	2K_dev_782
in multi -- objective problems	background	2K_dev_782
	background	2K_dev_782
	finding	2K_dev_782
In this paper	mechanism	2K_dev_782
we show that the Pareto curve of a bimatrix game can be found exactly in polynomial time and that it is composed of a polynomial number of pieces	mechanism	2K_dev_782
Furthermore	mechanism	2K_dev_782
each piece is a quadratic function We use this result to provide algorithms	mechanism	2K_dev_782
	method	2K_dev_782
However	purpose	2K_dev_782
finding or even approximating ( when the objective functions are not convex ) the Pareto curve is hard	purpose	2K_dev_782
Most of the literature focuses on computing concise representations to approximate the Pareto curve or on exploiting evolutionary approaches to generate approximately Pareto efficient samples of the curve for game-theoretic solution concepts that incorporate Pareto efficiency	purpose	2K_dev_782
Extensive-form games are a powerful tool for modeling a large range of multiagent scenarios Finally we discuss how our theory applies to several practical problems for which no solution quality bounds could be derived before	background	2K_dev_783
	finding	2K_dev_783
Leveraging recent results on abstraction solution quality	mechanism	2K_dev_783
we develop the first framework For games where the error is Lipschitz-continuous in the distance of a continuous point to its nearest discrete point	mechanism	2K_dev_783
we show that a uniform discretization of the space is optimal	mechanism	2K_dev_783
When the error is monotonically increasing in distance to nearest discrete point	mechanism	2K_dev_783
we develop an integer program for finding the optimal discretization when the error is described by piecewise linear functions	mechanism	2K_dev_783
This result can further be used to approximate optimal solutions to general monotonic error functions	mechanism	2K_dev_783
	mechanism	2K_dev_783
	method	2K_dev_783
However	purpose	2K_dev_783
most solution algorithms require discrete	purpose	2K_dev_783
finite games	purpose	2K_dev_783
In contrast	purpose	2K_dev_783
many real-world domains require modeling with continuous action spaces	purpose	2K_dev_783
This is usually handled by heuristically discretizing the continuous action space without solution quality bounds	purpose	2K_dev_783
In this paper we address this issue	purpose	2K_dev_783
for providing bounds on solution quality for discretization of continuous action spaces in extensive-form games	purpose	2K_dev_783
	purpose	2K_dev_783
Kidney exchange	background	2K_dev_784
where candidates with organ failure trade incompatible but willing donors	background	2K_dev_784
is a life-saving alternative to the deceased donor waitlist	background	2K_dev_784
which has inadequate supply to meet demand We conclude with thoughts regarding the fielding of a nationwide liver or joint liver-kidney exchange from a legal and computational point of view	background	2K_dev_784
	background	2K_dev_784
	finding	2K_dev_784
In this paper	mechanism	2K_dev_784
we begin by proposing the idea of liver exchange	mechanism	2K_dev_784
and show on demographically accurate data that vetted kidney exchange algorithms can be adapted to clear such an exchange at the nationwide level	mechanism	2K_dev_784
We then explore cross-organ donation where kidneys and livers can be bartered for each other	mechanism	2K_dev_784
We show theoretically that this multi-organ exchange provides linearly more transplants than running separate kidney and liver exchanges ; this linear gain is a product of altruistic kidney donors creating chains that thread through the liver pool	mechanism	2K_dev_784
We support this result experimentally on demographically accurate multi-organ exchanges	method	2K_dev_784
While fielded kidney exchanges see huge benefit from altruistic kidney donors ( who give an organ without a paired needy candidate )	purpose	2K_dev_784
a significantly higher medical risk to the donor deters similar altruism with livers	purpose	2K_dev_784
The human brain is widely hypothesized to construct inner beliefs about how the world works	background	2K_dev_785
It is thought that we need this conception to coordinate our movements and anticipate rapid events that go on around us	background	2K_dev_785
A driver	background	2K_dev_785
for example	background	2K_dev_785
needs to predict how the car should behave in response to every turn of the steering wheel and every tap on the brake	background	2K_dev_785
But on icy roads	background	2K_dev_785
these predictions will often not reflect how the car would behave	background	2K_dev_785
Applying the brakes sharply in these conditions could send the car skidding uncontrollably rather than stopping	background	2K_dev_785
The brain constructs such inner beliefs over time through experience and learning Taken together	background	2K_dev_785
this work provides a framework for understanding how the brain transforms sensory information into instructions for movement	background	2K_dev_785
The findings could also help improve the performance of brain-machine interfaces and suggest how we can learn new skills more rapidly and proficiently in everyday life	background	2K_dev_785
The monkeys cursor movements were remarkably precise	finding	2K_dev_785
In fact	finding	2K_dev_785
the experiment showed that the monkeys could internally predict their cursor movements just as a driver predicts how a car will move when turning the steering wheel These findings indicate that the monkeys have likely developed inner beliefs to predict how their neural signals drive the cursor	finding	2K_dev_785
and that these beliefs helped coordinate their performance	finding	2K_dev_785
In addition	finding	2K_dev_785
when the monkeys did make mistakes	finding	2K_dev_785
their neural signals were not entirely wrongin fact they were typically consistent with the monkeys inner beliefs about how the cursor moves	finding	2K_dev_785
A mismatch between these inner beliefs and reality explained most of the monkeys mistakes	finding	2K_dev_785
This experiment uncovered that	finding	2K_dev_785
during the course of learning	finding	2K_dev_785
the monkeys inner beliefs realigned to better match the movements of the new cursor	finding	2K_dev_785
	finding	2K_dev_785
	mechanism	2K_dev_785
by conducting a brain-machine interface experiment	method	2K_dev_785
In this experiment	method	2K_dev_785
neural signals from the brains of two rhesus macaques were recorded using arrays of electrodes and translated into movements of a cursor on a computer screen	method	2K_dev_785
The monkeys were then trained to mentally move the cursor to hit targets on the screen	method	2K_dev_785
next conducted an experiment in which the cursor moved in a way that was substantially different from the monkeys inner beliefs	method	2K_dev_785
In general	purpose	2K_dev_785
a mismatch between ones inner beliefs and reality is thought to cause errors and accidents	purpose	2K_dev_785
Yet this compelling hypothesis has not yet been fully investigated	purpose	2K_dev_785
Golub et al	purpose	2K_dev_785
investigated this hypothesis To study this learning process	purpose	2K_dev_785
Golub et al	purpose	2K_dev_785
A multi-faceted graph defines several facets on a set of nodes	background	2K_dev_786
Each facet is a set of edges that represent the relationships between the nodes in a specific context	background	2K_dev_786
	background	2K_dev_786
where NeSim is shown to be superior to MCL	finding	2K_dev_786
JP and AP	finding	2K_dev_786
the well-established clustering algorithms We also report the success stories of MuFace in finding advertisement click rings	finding	2K_dev_786
	finding	2K_dev_786
We propose NeSim	mechanism	2K_dev_786
a distributed efficient clustering algorithm We also propose optimizations to further improve the scalability	mechanism	2K_dev_786
the efficiency and the clusters quality We employ generalpurpose graph-clustering algorithms in a novel way Due to the qualities of NeSim	mechanism	2K_dev_786
we employ it as a backbone in the distributed MuFace algorithm	mechanism	2K_dev_786
which discovers multi-faceted communities	mechanism	2K_dev_786
	mechanism	2K_dev_786
We evaluate the proposed algorithms on several real and synthetic datasets	method	2K_dev_786
	method	2K_dev_786
Mining multi-faceted graphs have several applications	purpose	2K_dev_786
including finding fraudster rings that launch advertising traffic fraud attacks	purpose	2K_dev_786
tracking IP addresses of botnets over time	purpose	2K_dev_786
analyzing interactions on social networks and co-authorship of scientific papers that does soft clustering on individual facets	purpose	2K_dev_786
to discover communities across facets	purpose	2K_dev_786
The leading approach for solving large imperfect-information games is automated abstraction followed by running an equilibrium-finding algorithm	background	2K_dev_787
	background	2K_dev_787
It won the 2014 Annual Computer Poker Competition	finding	2K_dev_787
beating each opponent with statistical significance	finding	2K_dev_787
We introduce a distributed version of the most commonly used equilibrium-finding algorithm	mechanism	2K_dev_787
counterfactual regret minimization ( CFR )	mechanism	2K_dev_787
The new algorithm begets constraints on the abstraction so as to make the pieces running on different computers disjoint We introduce an algorithm while capitalizing on state-of-the-art abstraction ideas such as imperfect recall and the earth-mover's-distance similarity metric	mechanism	2K_dev_787
Our techniques enabled an equilibrium computation of unprecedented size on a supercomputer with a high inter-blade memory latency	mechanism	2K_dev_787
Prior approaches run slowly on this architecture Our approach also leads to a significant improvement over using the prior best approach on a large shared-memory server with low memory latency	mechanism	2K_dev_787
Finally	mechanism	2K_dev_787
we introduce a family of post-processing techniques that outperform prior ones	mechanism	2K_dev_787
We applied these techniques to generate an agent for two-player no-limit Texas Hold'em	method	2K_dev_787
which enables CFR to scale to dramatically larger abstractions and numbers of cores	purpose	2K_dev_787
for generating such abstractions	purpose	2K_dev_787
How can we succinctly describe a million-node graph with a few simple sentences ? Given a large graph	background	2K_dev_788
how can we find its most `` important '' structures	background	2K_dev_788
so that we can summarize it and easily visualize it ? How can we measure the `` importance '' of a set of discovered subgraphs in a large graph ?	background	2K_dev_788
	finding	2K_dev_788
To this end	mechanism	2K_dev_788
we first mine candidate subgraphs using one or more graph partitioning algorithms Next	mechanism	2K_dev_788
we identify the optimal summarization using the minimum description length MDL principle	mechanism	2K_dev_788
picking only those subgraphs from the candidates that together yield the best lossless compression of the graph-or	mechanism	2K_dev_788
equivalently	mechanism	2K_dev_788
that most succinctly describe its adjacency matrix	mechanism	2K_dev_788
	method	2K_dev_788
Starting with the observation that real graphs often consist of stars	purpose	2K_dev_788
bipartite cores	purpose	2K_dev_788
cliques	purpose	2K_dev_788
and chains	purpose	2K_dev_788
our main idea is to find the most succinct description of a graph in these `` vocabulary '' terms	purpose	2K_dev_788
	purpose	2K_dev_788
	background	2K_dev_789
demonstrates superior performance and reliability compared to a basic decision tree approach We also briefly discuss how the method has assisted in debugging a commercial autonomous ground vehicle system	finding	2K_dev_789
	finding	2K_dev_789
We propose a method Our method models the set of fault-triggering inputs as a Cartesian product and identifies this set by actively querying the system under test	mechanism	2K_dev_789
The active sampling scheme is very efficient in the common case that few fields in the interface are relevant to causing the fault This scheme also solves the problem of efficiently finding sufficient examples to model rare faults	mechanism	2K_dev_789
which is problematic for other learning-based methods	mechanism	2K_dev_789
Compared to other techniques	mechanism	2K_dev_789
ours requires no parameter turning or post-processing in order to produce useful results	mechanism	2K_dev_789
	mechanism	2K_dev_789
We analyze the method qualitatively	method	2K_dev_789
theoretically	method	2K_dev_789
and empirically An experimental evaluation	method	2K_dev_789
for generating interpretable descriptions of inputs that cause faults in high-dimensional software interfaces	purpose	2K_dev_789
Latent Variable Models ( LVMs ) are a large family of machine learning models providing a principled and effective way to extract underlying patterns	background	2K_dev_790
structure and knowledge from observed data	background	2K_dev_790
	background	2K_dev_790
We show that the monotonicity of the lower bound is closely aligned with the MAR to qualify the lower bound as a desirable surrogate of the MAR we demonstrate that MAR can effectively capture long-tail patterns	finding	2K_dev_790
reduce model complexity without sacrificing expressivity and improve interpretability	finding	2K_dev_790
	finding	2K_dev_790
	mechanism	2K_dev_790
we develop a novel regularization technique for LVMs	mechanism	2K_dev_790
which controls the geometry of the latent space during learning to enable the learned latent components of LVMs to be diverse in the sense that they are favored to be mutually different from each other	mechanism	2K_dev_790
to accomplish long-tail coverage	mechanism	2K_dev_790
low redundancy	mechanism	2K_dev_790
and better interpretability We propose a mutual angular regularizer ( MAR ) to encourage the components in LVMs to have larger mutual angles	mechanism	2K_dev_790
The MAR is non-convex and non-smooth	mechanism	2K_dev_790
entailing great challenges for optimization	mechanism	2K_dev_790
To cope with this issue	mechanism	2K_dev_790
we derive a smooth lower bound of the MAR and optimize the lower bound instead	mechanism	2K_dev_790
	mechanism	2K_dev_790
Using neural network ( NN ) as an instance	method	2K_dev_790
we analyze how the MAR affects the generalization performance of NN On two popular latent variable models -- - restricted Boltzmann machine and distance metric learning	method	2K_dev_790
	method	2K_dev_790
Due to the dramatic growth of volume and complexity of data	purpose	2K_dev_790
several new challenges have emerged and can not be effectively addressed by existing LVMs : ( 1 ) How to capture long-tail patterns that carry crucial information when the popularity of patterns is distributed in a power-law fashion ? ( 2 ) How to reduce model complexity and computational cost without compromising the modeling power of LVMs ? ( 3 ) How to improve the interpretability and reduce the redundancy of discovered patterns ? To addresses the three challenges discussed above	purpose	2K_dev_790
	background	2K_dev_791
and exhibits a higher fitting accuracy on all of them	finding	2K_dev_791
	finding	2K_dev_791
We propose a facial alignment algorithm Our approach proceeds from sparse to dense landmarking steps using a set of specific models trained to best account for the shape and texture variation manifested by facial landmarks and facial shapes across pose and various expressions We also propose the use of a novel $ \ell _1 $ -regularized least squares approach that we incorporate into our shape model	mechanism	2K_dev_791
which is an improvement over the shape model used by several prior Active Shape Model ( ASM ) based facial landmark localization algorithms	mechanism	2K_dev_791
	mechanism	2K_dev_791
Our approach is compared against several state-of-the-art methods on many challenging test datasets	method	2K_dev_791
that is able to jointly deal with the presence of facial pose variation	purpose	2K_dev_791
partial occlusion of the face	purpose	2K_dev_791
and varying illumination and expressions	purpose	2K_dev_791
	purpose	2K_dev_791
	background	2K_dev_792
showing good performance for modeling previously unseen molecular configurations we show substantial improvement over the state of the art in molecular energy optimization	finding	2K_dev_792
Motivated by problems such as molecular energy prediction	mechanism	2K_dev_792
we derive an ( improper ) kernel between geometric inputs	mechanism	2K_dev_792
that is able Since many physical simulations based upon geometric data produce derivatives of the output quantity with respect to the input positions	mechanism	2K_dev_792
we derive an approach that incorporates derivative information into our kernel learning	mechanism	2K_dev_792
We further show how to exploit the low rank structure of the resulting kernel matrices to speed up learning	mechanism	2K_dev_792
	mechanism	2K_dev_792
Finally	method	2K_dev_792
we evaluated the method in the context of molecular energy prediction	method	2K_dev_792
Integrating the approach into a Bayesian optimization	method	2K_dev_792
	method	2K_dev_792
to capture the relevant rotational and translation invariances in geometric data	purpose	2K_dev_792
The leading approach for computing strong game-theoretic strategies in large imperfect-information games is to first solve an abstracted version of the game offline	background	2K_dev_793
then perform a table lookup during game play	background	2K_dev_793
	background	2K_dev_793
show that our algorithm leads to significantly stronger performance against the strongest agents from the 2013 AAAI Annual Computer Poker Competition	finding	2K_dev_793
	finding	2K_dev_793
We consider where we solve the portion of the game that we have actually reached in real time to a greater degree of accuracy than in the initial computation	mechanism	2K_dev_793
We call this approach endgame solving	mechanism	2K_dev_793
Theoretically	mechanism	2K_dev_793
we show that endgame solving can produce highly exploitable strategies in some games ; however	mechanism	2K_dev_793
we show that it can guarantee a low exploitability in certain games where the opponent is given sufficient exploitative power within the endgame	mechanism	2K_dev_793
Furthermore	mechanism	2K_dev_793
despite the lack of a general worst-case guarantee	mechanism	2K_dev_793
we describe benefits of endgame solving	mechanism	2K_dev_793
We present an efficient algorithm and present a new variance-reduction technique	mechanism	2K_dev_793
Experiments on no-limit Texas Hold'em	method	2K_dev_793
a modification to this approach for performing endgame solving in large imperfect-information games	purpose	2K_dev_793
for evaluating the performance of an agent that uses endgame solving	purpose	2K_dev_793
	purpose	2K_dev_793
The proliferation of mobile technologies makes it possible for mobile advertisers to go beyond the realtime snapshot of the static location and contextual information about consumers	background	2K_dev_794
This indicates closely targeted mobile ads may constrict consumer focus and significantly reduce the impulsive purchase behavior	background	2K_dev_794
Our finding suggests marketers should carefully design mobile advertising strategy	background	2K_dev_794
depending on different business contexts	background	2K_dev_794
	background	2K_dev_794
We found the new mobile trajectory-based advertising is significantly more effective for focal advertising store compared to several existing baselines	finding	2K_dev_794
It is especially effective in attracting highincome consumers	finding	2K_dev_794
Interestingly	finding	2K_dev_794
it becomes less effective during the weekend	finding	2K_dev_794
	finding	2K_dev_794
In this study	mechanism	2K_dev_794
we propose a novel mobile advertising strategy	mechanism	2K_dev_794
To evaluate the effectiveness of this strategy	method	2K_dev_794
we design a large-scale randomized field experiment in a large shopping mall in Asia based on 83	method	2K_dev_794
370 unique user responses for two weeks in 2014	method	2K_dev_794
	method	2K_dev_794
that leverages full information on consumers offline moving trajectories	purpose	2K_dev_794
	purpose	2K_dev_794
Simultaneously achieving high level of faithfulness and expressiveness is very rare among other methods	background	2K_dev_795
	background	2K_dev_795
The illumination normalized faces using our proposed Pokerface not only exhibit very high fidelity against neutrally illuminated face	finding	2K_dev_795
but also allow for a significant improvement in face verification experiments using even the simplest classifier	finding	2K_dev_795
	finding	2K_dev_795
We propose a new method called the Pokerface The Pokerface is a two-phase approach	mechanism	2K_dev_795
It first aims at maximizing the minimum gap between adjacently-valued pixels while keeping the partial ordering of the pixels in the face image under extreme illumination condition	mechanism	2K_dev_795
an intuitive effort based on order theory to unveil the underlying structure of a dark image	mechanism	2K_dev_795
This optimization can be formulated as a feasibility search problem and can be efficiently solved by linear programming	mechanism	2K_dev_795
It then smooths the intermediate representation by repressing the energy of the gradient map	mechanism	2K_dev_795
The smoothing step is carried out by total variation minimization and sparse approximation	mechanism	2K_dev_795
	mechanism	2K_dev_795
These conclusions are drawn after benchmarking our algorithm against 22 prevailing illumination normalization techniques on both the CMU Multi-PIE database and Extended YaleB database that are widely adopted for face illumination problems	method	2K_dev_795
for extreme face illumination normalization	purpose	2K_dev_795
	purpose	2K_dev_795
Living organisms adapt to challenges through evolution and adaptation	background	2K_dev_796
Potential application classes include therapeutics at the population	background	2K_dev_796
individual	background	2K_dev_796
and molecular levels ( drug design )	background	2K_dev_796
as well as cell repurposing and synthetic biology	background	2K_dev_796
	finding	2K_dev_796
propose the wild idea of computational game theory for ( typically incomplete-information ) multistage games and opponent exploitation techniques	mechanism	2K_dev_796
A sequential contingency plan for steering is constructed computationally for the setting at hand In the biological context	mechanism	2K_dev_796
the opponent ( e	mechanism	2K_dev_796
g	mechanism	2K_dev_796
	mechanism	2K_dev_796
a disease ) has a systematic handicap because it evolves myopically	mechanism	2K_dev_796
This can be exploited by computing trapping strategies that cause the opponent to evolve into states where it can be handled effectively	mechanism	2K_dev_796
	mechanism	2K_dev_796
	method	2K_dev_796
This has proven to be a key difficulty in developing therapies	purpose	2K_dev_796
since the organisms develop resistance	purpose	2K_dev_796
steering evolution/adaptation strategicallyusing	purpose	2K_dev_796
	background	2K_dev_797
and it showed improved retrieval accuracy and efficiency	finding	2K_dev_797
	finding	2K_dev_797
We propose a retrieval method based on a bag-of-visual-words ( BoVW ) to identify discriminative characteristics between different medical images with Pruned Dictionary based on Latent Semantic Topic description We refer to this as the PD-LST retrieval	mechanism	2K_dev_797
Our method has two main components	mechanism	2K_dev_797
First	mechanism	2K_dev_797
we calculate a topic-word significance value for each visual word given a certain latent topic to evaluate how the word is connected to this latent topic	mechanism	2K_dev_797
The latent topics are learnt	mechanism	2K_dev_797
based on the relationship between the images and words	mechanism	2K_dev_797
and are employed to bridge the gap between low-level visual features and high-level semantics	mechanism	2K_dev_797
These latent topics describe the images and words semantically and can thus facilitate more meaningful comparisons between the words	mechanism	2K_dev_797
Second	mechanism	2K_dev_797
we compute an overall-word significance value to evaluate the significance of a visual word within the entire dictionary	mechanism	2K_dev_797
We designed an iterative ranking method to measure overall-word significance by considering the relationship between all latent topics and words	mechanism	2K_dev_797
The words with higher values are considered meaningful with more significant discriminative power in differentiating medical images	mechanism	2K_dev_797
	mechanism	2K_dev_797
We evaluated our method on two public medical imaging datasets	method	2K_dev_797
Content-based medical image retrieval ( CBMIR ) is an active research area for disease diagnosis and treatment but it can be problematic given the small visual variations between anatomical structures	purpose	2K_dev_797
	purpose	2K_dev_797
	background	2K_dev_798
	finding	2K_dev_798
A system and method The system is based on a sensor network and is efficient	mechanism	2K_dev_798
scalable	mechanism	2K_dev_798
and requires only short-range communication	mechanism	2K_dev_798
The system allows for sensor-to-sensor communication as well as the traditional sensor-to-anchor communication	mechanism	2K_dev_798
the present invention pairs each resource with an inexpensive	mechanism	2K_dev_798
low-powered sensor possessing minimal communication and computation capabilities	mechanism	2K_dev_798
The sensors communicate with only nearby resources or anchors and those resources communicate with their nearby resources or anchors until a wireless	mechanism	2K_dev_798
linked network of resources and anchors is formed	mechanism	2K_dev_798
	method	2K_dev_798
for locating	purpose	2K_dev_798
tracking	purpose	2K_dev_798
and monitoring resource in large-scale facilities is disclosed herein to effectively eliminate long-range communications	purpose	2K_dev_798
In order to perform resource localization and tracking	purpose	2K_dev_798
Deep learning ( DL ) has achieved notable successes in many machine learning tasks	background	2K_dev_799
A number of frameworks have been developed to expedite the process of designing and training deep neural networks ( DNNs )	background	2K_dev_799
such as Caffe	background	2K_dev_799
Torch and Theano	background	2K_dev_799
	background	2K_dev_799
show that Poseidon converges to same objectives as a single machine	finding	2K_dev_799
and achieves state-of-art training speedup Poseidon with 8 nodes achieves better speedup and competitive accuracy to recent CPU-based distributed systems such as Adam and Le et al	finding	2K_dev_799
	finding	2K_dev_799
which use 10s to 1000s of nodes	finding	2K_dev_799
we propose Poseidon	mechanism	2K_dev_799
a scalable system architecture for distributed inter-machine communication in existing DL frameworks We integrate Poseidon with Caffe Poseidon features three key contributions that accelerate DNN training on clusters : ( 1 ) a three-level hybrid architecture that allows Poseidon to support both CPU-only and GPU-equipped clusters	mechanism	2K_dev_799
( 2 ) a distributed wait-free backpropagation ( DWBP ) algorithm to improve GPU utilization and to balance communication	mechanism	2K_dev_799
and ( 3 ) a structure-aware communication protocol ( SACP ) to minimize communication overheads	mechanism	2K_dev_799
	mechanism	2K_dev_799
and evaluate its performance at training DNNs for object recognition	method	2K_dev_799
We empirically across multiple models and well-established datasets using a commodity GPU cluster of 8 nodes ( e	method	2K_dev_799
g	method	2K_dev_799
4	method	2K_dev_799
5x speedup on AlexNet	method	2K_dev_799
4x on GoogLeNet	method	2K_dev_799
4x on CIFAR-10 )	method	2K_dev_799
On the much larger ImageNet22K dataset	method	2K_dev_799
Currently they can harness multiple GPUs on a single machine	purpose	2K_dev_799
but are unable to use GPUs that are distributed across multiple machines ; as even average-sized DNNs can take days to train on a single GPU with 100s of GBs to TBs of data	purpose	2K_dev_799
distributed GPUs present a prime opportunity for scaling up DL	purpose	2K_dev_799
However	purpose	2K_dev_799
the limited bandwidth available on commodity Ethernet networks presents a bottleneck to distributed GPU training	purpose	2K_dev_799
and prevents its trivial realization To investigate how to adapt existing frameworks to efficiently support distributed GPUs	purpose	2K_dev_799
	purpose	2K_dev_799
	background	2K_dev_800
We find that there exist conditions under which the intermediary obtains the highest proportion of benefits from targeting and	finding	2K_dev_800
in general	finding	2K_dev_800
the intermediary 's incentives regarding the type of consumer information to be used for targeting are misaligned with the incentives of firms and/or consumers Furthermore	finding	2K_dev_800
consumers ' surplus from targeting is higher when only specific types of personal information are made available during the targeting process	finding	2K_dev_800
	finding	2K_dev_800
We develop a three '' players model that includes firms	mechanism	2K_dev_800
consumers	mechanism	2K_dev_800
and an intermediary `` the ad exchange	mechanism	2K_dev_800
and analyze three scenarios that differ in the type of consumers ' data available during the targeting : a case in which only the horizontal information ( consumers ' brand preferences ) is available ; a case in which only vertical information ( consumers ' purchasing power ) is available ; a case in which both pieces of information are available	method	2K_dev_800
We investigate the welfare implications and the allocative effects of different consumer data '' handling regimes in online targeted advertisin g	purpose	2K_dev_800
	purpose	2K_dev_800
	background	2K_dev_801
results are provided to demonstrate the advantages and properties of the proposed approach based on weighted kernel	finding	2K_dev_801
	finding	2K_dev_801
In contrast with the uniform kernel used in the previous work	mechanism	2K_dev_801
a weighted kernel is proposed	mechanism	2K_dev_801
where weight parameters serve to selectively incorporate sensors information into the fusion centers decision rule based on quality of sensors observations	mechanism	2K_dev_801
Furthermore	mechanism	2K_dev_801
weight parameters also serve as sensor selection parameters with nonzero parameters corresponding to sensors being selected	mechanism	2K_dev_801
By introducing the $ l_1 $ regularization on weight parameters into the risk minimization framework	mechanism	2K_dev_801
sensor selection is jointly performed with decision rules for sensors and the fusion center with the resulting optimal decision rule having only sparse nonzero weight parameters A gradient projection algorithm and a Gauss-Seidel algorithm are developed to solve the risk minimization problem	mechanism	2K_dev_801
which is nonconvex	mechanism	2K_dev_801
and both algorithms are shown to converge to critical points	mechanism	2K_dev_801
Conditions on the sample complexity to guarantee asymptotically small estimation error are characterized based on analysis of Rademacher complexity	mechanism	2K_dev_801
Connection between the probability of error and the risk function is also studied	mechanism	2K_dev_801
	mechanism	2K_dev_801
Numerical	method	2K_dev_801
The kernel-based nonparametric approach proposed by Nguyen	purpose	2K_dev_801
Wainwright	purpose	2K_dev_801
and Jordan is further investigated for decentralized detection	purpose	2K_dev_801
	purpose	2K_dev_801
We ultimately envision this technique being integrated into future smartwatches	background	2K_dev_802
allowing hand gestures and direct touch manipulation to work synergistically to support interactive tasks on small screens	background	2K_dev_802
	background	2K_dev_802
Our wrist location achieved 97 % and 87 % accuracies on these gesture sets respectively	finding	2K_dev_802
while our arm location achieved 93 % and 81 %	finding	2K_dev_802
	finding	2K_dev_802
We present Tomo	mechanism	2K_dev_802
a wearable	mechanism	2K_dev_802
low-cost system using Electrical Impedance Tomography ( EIT ) This is achieved by measuring the cross-sectional impedances between all pairs of eight electrodes resting on a user 's skin	mechanism	2K_dev_802
Our approach is sufficiently compact and low-powered that we integrated the technology into a prototype wrist- and armband	mechanism	2K_dev_802
which can monitor and classify gestures in real-time	mechanism	2K_dev_802
	mechanism	2K_dev_802
We conducted a user study that evaluated two gesture sets	method	2K_dev_802
one focused on gross hand gestures and another using thumb-to-finger pinches	method	2K_dev_802
to recover the interior impedance geometry of a user 's arm	purpose	2K_dev_802
	purpose	2K_dev_802
Next-generation information technologies will process unprecedented amounts of loosely structured data that overwhelm existing computing systems	background	2K_dev_803
1	finding	2K_dev_803
000-fold	finding	2K_dev_803
N3XT by using new logic and memory technologies	mechanism	2K_dev_803
3D integration with fine-grained connectivity	mechanism	2K_dev_803
and new architectures for computation immersed in memory	mechanism	2K_dev_803
	mechanism	2K_dev_803
	method	2K_dev_803
improves the energy efficiency of abundant-data applications	purpose	2K_dev_803
The rise of big data has led to new demands for machine learning ( ML ) systems to learn complex models	background	2K_dev_804
with millions to billions of parameters	background	2K_dev_804
that promise adequate capacity to digest massive datasets and offer powerful predictive analytics ( such as high-dimensional latent features	background	2K_dev_804
intermediate representations	background	2K_dev_804
and decision functions ) thereupon	background	2K_dev_804
we present opportunities for ML researchers and practitioners to further shape and enlarge the area that lies between ML and systems	background	2K_dev_804
	background	2K_dev_804
	finding	2K_dev_804
discuss a series of principles and strategies distilled from our recent efforts on industrial-scale ML solutions	mechanism	2K_dev_804
These principles and strategies span a continuum from application	mechanism	2K_dev_804
to engineering	mechanism	2K_dev_804
and to theoretical research and development of big ML systems and architectures	mechanism	2K_dev_804
with the goal of understanding how to make them efficient	mechanism	2K_dev_804
generally applicable	mechanism	2K_dev_804
and supported with convergence and scaling guarantees	mechanism	2K_dev_804
They concern four key questions that traditionally receive little attention in ML research : By exposing underlying statistical and algorithmic characteristics unique to ML programs but not typically seen in traditional computer programs	mechanism	2K_dev_804
and by dissecting successful cases to reveal how we have harnessed these principles to design and develop both high-performance distributed ML software as well as general-purpose ML frameworks	mechanism	2K_dev_804
	mechanism	2K_dev_804
	method	2K_dev_804
In order to run ML algorithms at such scales	purpose	2K_dev_804
on a distributed cluster with tens to thousands of machines	purpose	2K_dev_804
it is often the case that significant engineering efforts are requiredand one might fairly ask whether such engineering truly falls within the domain of ML research Taking the view that big ML systems can benefit greatly from ML-rooted statistical and algorithmic insightsand that ML researchers should therefore not shy away from such systems designwe How can an ML program be distributed over a cluster ? How can ML computation be bridged with inter-machine communication ? How can such communication be performed ? What should be communicated between machines ?	purpose	2K_dev_804
Semantic search or text-to-video search in video is a novel and challenging problem in information and multimedia retrieval	background	2K_dev_805
We share our observations and lessons in building such a state-of-the-art system	background	2K_dev_805
which may be instrumental in guiding the design of the future system for video search and analysis	background	2K_dev_805
	background	2K_dev_805
The novelty and practicality are demonstrated by where the proposed system achieves the best performance	finding	2K_dev_805
	finding	2K_dev_805
This paper presents a state-of-the-art system for event search without any user-generated metadata or example videos	mechanism	2K_dev_805
known as text-to-video search	mechanism	2K_dev_805
The system relies on substantial video content understanding and allows for searching complex events over a large collection of videos	mechanism	2K_dev_805
The proposed text-to-video search can be used to augment the existing text-to-text search for video	mechanism	2K_dev_805
	mechanism	2K_dev_805
the evaluation in NIST TRECVID 2014	method	2K_dev_805
	method	2K_dev_805
Existing solutions are mainly limited to text-to-text matching	purpose	2K_dev_805
in which the query words are matched against the user-generated metadata	purpose	2K_dev_805
This kind of text-to-text search	purpose	2K_dev_805
though simple	purpose	2K_dev_805
is of limited functionality as it provides no understanding about the video content	purpose	2K_dev_805
	purpose	2K_dev_805
	background	2K_dev_806
We show that the mechanism results in significant gains on data from a national kidney exchange that includes 59 % of all US transplant centers	finding	2K_dev_806
	finding	2K_dev_806
We present a credit-based matching mechanism in particularthat is both strategy proof and efficient	mechanism	2K_dev_806
that is	mechanism	2K_dev_806
it guarantees truthful disclosure of donor-patient pairs from the transplant centers and results in the maximum global matching Furthermore	mechanism	2K_dev_806
the mechanism is individually rational in the sense that	mechanism	2K_dev_806
in the long run	mechanism	2K_dev_806
it guarantees each transplant center more matches than the center could have achieved alone	mechanism	2K_dev_806
The mechanism does not require assumptions about the underlying distribution of compatibility graphsa nuance that has previously produced conflicting results in other aspects of theoretical kidney exchange Our results apply not only to matching via 2-cycles : the matchings can also include cycles of any length and altruist-initiated chains	mechanism	2K_dev_806
which is important at least in kidney exchanges	mechanism	2K_dev_806
The mechanism can also be adjusted to guarantee immediate individual rationality at the expense of economic efficiency	mechanism	2K_dev_806
while preserving strategy proofness via the credits	mechanism	2K_dev_806
This circumvents a well-known impossibility result in static kidney exchange concerning the existence of an individually rational	mechanism	2K_dev_806
strategy-proof	mechanism	2K_dev_806
and maximal mechanism	mechanism	2K_dev_806
	mechanism	2K_dev_806
empirically	method	2K_dev_806
for dynamic barter marketsand kidney exchange	purpose	2K_dev_806
The leading approach for solving large imperfect-information games is automated abstraction followed by running an equilibrium-finding algorithm	background	2K_dev_807
that won the 2014 Annual Computer Poker Competition	finding	2K_dev_807
beating each opponent with statistical significance	finding	2K_dev_807
	finding	2K_dev_807
We introduce a distributed version of the most commonly used equilibrium-finding algorithm	mechanism	2K_dev_807
counterfactual regret minimization ( CFR )	mechanism	2K_dev_807
The new algorithm begets constraints on the abstraction so as to make the pieces running on different computers disjoint We introduce an algorithm while capitalizing on state-of-the-art abstraction ideas such as imperfect recall and earth-mover 's distance	mechanism	2K_dev_807
Our techniques enabled an equilibrium computation of unprecedented size on a supercomputer with a high inter-blade memory latency	mechanism	2K_dev_807
Prior approaches run slowly on this architecture	mechanism	2K_dev_807
Our approach also leads to a significant improvement over using the prior best approach on a large shared-memory server with low memory latency	mechanism	2K_dev_807
Finally	mechanism	2K_dev_807
we introduce a family of post-processing techniques that outperform prior ones	mechanism	2K_dev_807
We applied these techniques to generate an agent for two-player no-limit Texas Hold'em	method	2K_dev_807
called Tartanian7	method	2K_dev_807
	method	2K_dev_807
which enables CFR to scale to dramatically larger abstractions and numbers of cores	purpose	2K_dev_807
for generating such abstractions	purpose	2K_dev_807
	background	2K_dev_808
The results from our studies indicate that the proposed SC-FAC model is reliable and accurately perform prior shape weak object segmentation	finding	2K_dev_808
The average performance of the mouth segmentation using proposed SC-FAC on 1918 images from the MBGC database under different illuminations	finding	2K_dev_808
expressions	finding	2K_dev_808
and complex background reaches to a Precision of 91	finding	2K_dev_808
30 %	finding	2K_dev_808
a Recall of 91	finding	2K_dev_808
32 % and an F-measure of 90	finding	2K_dev_808
62 %	finding	2K_dev_808
In this paper	mechanism	2K_dev_808
we propose a novel joint formulation of feature-based active contour ( FAC ) and prior shape constraints ( CS Our proposed SC-FAC model is able to robustly segment the lips/mouth that belongs to a given mouth shape space while minimizing the energy functional	mechanism	2K_dev_808
The shape space is defined by a 2D Modified Active Shape Model ( MASM ) whereas the active contour model is based on the Chan-Vese functional Our SC-FAC energy functional is able to overcome the drawback of noise while minimizing the fitting forces under the shape constraints HighlightsPropose a novel joint formulation of contour and shape for lips segmentation	mechanism	2K_dev_808
Robustly segment lips under challenging environment and complex background	mechanism	2K_dev_808
The energy functional is composed of 5 terms based on the Chan-Vese functional	mechanism	2K_dev_808
The shape space is defined by a 2D	mechanism	2K_dev_808
Experiments are conducted from the MBGC	mechanism	2K_dev_808
VidTIMIT	mechanism	2K_dev_808
JAFFE	mechanism	2K_dev_808
and LFW databases	mechanism	2K_dev_808
We conducted our experiments on images captured under challenging conditions such as varying illumination	method	2K_dev_808
low contrast	method	2K_dev_808
facial expression	method	2K_dev_808
low resolution	method	2K_dev_808
blurring	method	2K_dev_808
wearing beard/moustache and cosmetic affection from the MBGC	method	2K_dev_808
VidTIMIT	method	2K_dev_808
JAFFE	method	2K_dev_808
and LFW databases	method	2K_dev_808
	method	2K_dev_808
for lips/mouth segmentation in the wild	purpose	2K_dev_808
Bayesian theory has provided a compelling conceptualization for perceptual inference in the brain	background	2K_dev_809
Central to Bayesian inference is the notion of statistical priors	background	2K_dev_809
To understand the neural mechanisms of Bayesian inference	background	2K_dev_809
we need to understand the neural representation of statistical regularities in the natural environment These findings demonstrate that there is a relationship between the functional connectivity observed in the visual cortex and the statistics of natural scenes	background	2K_dev_809
They also suggest that the Boltzmann machine can be a viable model for conceptualizing computations in the visual cortex and	background	2K_dev_809
as such	background	2K_dev_809
can be used to predict neural circuits in the visual cortex from natural scene statistics	background	2K_dev_809
and found that the units in the model exhibited cooperative and competitive interactions	finding	2K_dev_809
forming a disparity association field	finding	2K_dev_809
analogous to the contour association field The cooperative and competitive interactions in the disparity association field are consistent with constraints of computational models for stereo matching	finding	2K_dev_809
and found the results to be consistent with neurophysiological data in terms of the functional connectivity measurements between disparity-tuned neurons in the macaque primary visual cortex	finding	2K_dev_809
	finding	2K_dev_809
a Boltzmann machine model	mechanism	2K_dev_809
We applied In addition	method	2K_dev_809
we simulated neurophysiological experiments on the model	method	2K_dev_809
In this paper	purpose	2K_dev_809
we investigated empirically how statistical regularities in natural 3D scenes are represented in the functional connectivity of disparity-tuned neurons in the primary visual cortex of primates	purpose	2K_dev_809
to learn from 3D natural scenes	purpose	2K_dev_809
	purpose	2K_dev_809
AbstractEngineering analysis to quantify the effects of earthquake forces on the structural strength of components requires determining the damage mode and severity of the components	background	2K_dev_810
	finding	2K_dev_810
This study develops a building-information-modeling ( BIM ) based approach In the proposed approach	mechanism	2K_dev_810
the damage information is represented along with the geometric	mechanism	2K_dev_810
topological	mechanism	2K_dev_810
and structural information	mechanism	2K_dev_810
Transformation and reasoning mechanisms are proposed to utilize the information contained in the BIM	mechanism	2K_dev_810
The approach is validated on a case study building	method	2K_dev_810
which contains 42 damaged piers and spandrels	method	2K_dev_810
	method	2K_dev_810
The analysis requires strength computations and visual damage assessments	purpose	2K_dev_810
which are information intensive	purpose	2K_dev_810
potentially error-prone	purpose	2K_dev_810
and slow	purpose	2K_dev_810
to support the engineering analysis of reinforced concrete structures	purpose	2K_dev_810
to perform strength analysis and visual assessment tasks	purpose	2K_dev_810
	purpose	2K_dev_810
	background	2K_dev_811
show that our approach produces significantly more accurate rankings than alternative approaches	finding	2K_dev_811
We present the first model From this viewpoint	mechanism	2K_dev_811
voting rules are seen as error-correcting codes : their goal is to correct errors in the input rankings and recover a ranking that is close to the ground truth We derive worst-case bounds on the relation between the average accuracy of the input votes	mechanism	2K_dev_811
and the accuracy of the output ranking	mechanism	2K_dev_811
Empirical results from real data	method	2K_dev_811
of optimal voting under adversarial noise	purpose	2K_dev_811
	purpose	2K_dev_811
The use of deductive techniques	background	2K_dev_812
such as theorem provers	background	2K_dev_812
has several advantages in safety verification of hybrid systems	background	2K_dev_812
	finding	2K_dev_812
we present an extension to the deductive verification framework of differential dynamic logic by leveraging forward invariant sets provided by external methods	mechanism	2K_dev_812
such as numerical techniques and designer insights Our key contribution is a new inference rule	mechanism	2K_dev_812
the forward invariant cut rule	mechanism	2K_dev_812
introduced into the proof calculus of KeYmaera	mechanism	2K_dev_812
	mechanism	2K_dev_812
We demonstrate the cut rule in action on an example involving an automotive powertrain control systems	method	2K_dev_812
in which we make use of a simulation-driven numerical technique to compute a local barrier function	method	2K_dev_812
There is often a gap	purpose	2K_dev_812
however	purpose	2K_dev_812
between the type of assistance that a theorem prover requires to make progress on a proof task and the assistance that a system designer is able to provide	purpose	2K_dev_812
To address this deficiency that allows the theorem prover KeYmaera to locally reason about behaviors	purpose	2K_dev_812
Kernel methods are ubiquitous tools in machine learning	background	2K_dev_813
They have proven to be effective in many domains and tasks	background	2K_dev_813
	background	2K_dev_813
Furthermore	finding	2K_dev_813
we show that BaNK outperforms several other scalable approaches for kernel learning	finding	2K_dev_813
In this paper we introduce Bayesian nonparmetric kernel ( BaNK ) learning	mechanism	2K_dev_813
a generic	mechanism	2K_dev_813
data-driven framework We show that this framework can be used for performing both regression and classification tasks and scale to large datasets	mechanism	2K_dev_813
	mechanism	2K_dev_813
on a variety of real world datasets	method	2K_dev_813
Yet	purpose	2K_dev_813
kernel methods often require the user to select a predefined kernel to build an estimator with	purpose	2K_dev_813
However	purpose	2K_dev_813
there is often little reason for the a priori selection of a kernel	purpose	2K_dev_813
Even if a universal approximating kernel is selected	purpose	2K_dev_813
the quality of the finite sample estimator may be greatly effected by the choice of kernel	purpose	2K_dev_813
Furthermore	purpose	2K_dev_813
when directly applying kernel methods	purpose	2K_dev_813
one typically needs to compute a $ N \times N $ Gram matrix of pairwise kernel evaluations to work with a dataset of $ N $ instances	purpose	2K_dev_813
The computation of this Gram matrix precludes the direct application of kernel methods on large datasets for scalable learning of kernels	purpose	2K_dev_813
	purpose	2K_dev_813
When solving extensive-form games with large action spaces	background	2K_dev_814
typically significant abstraction is needed to make the problem manageable from a modeling or computational perspective	background	2K_dev_814
When this occurs	background	2K_dev_814
a procedure is needed to interpret actions of the opponent that fall outside of our abstraction ( by mapping them to actions in our abstraction )	background	2K_dev_814
This is called an action translation mapping	background	2K_dev_814
our mapping performs competitively with the prior mappings	finding	2K_dev_814
We present a new mapping and has significantly lower exploitability than the prior mappings Furthermore	mechanism	2K_dev_814
we observe that the cost of this worst-case performance benefit ( low exploitability ) is not high in practice ; We also observe several paradoxes that can arise when performing action abstraction and translation ; for example	mechanism	2K_dev_814
we show that it is possible to improve performance by including suboptimal actions in our abstraction and excluding optimal actions	mechanism	2K_dev_814
	mechanism	2K_dev_814
against no-limit Texas Hold'em agents submitted to the 2012 Annual Computer Poker Competition	method	2K_dev_814
	method	2K_dev_814
Prior action translation mappings have been based on heuristics without theoretical justification	purpose	2K_dev_814
We show that the prior mappings are highly exploitable and that most of them violate certain natural desiderata	purpose	2K_dev_814
that satisfies these desiderata	purpose	2K_dev_814
Problems of this nature arise in formal verification of continuous and hybrid dynamical systems	background	2K_dev_815
where there is an increasing need for methods to expedite formal proofs	background	2K_dev_815
	background	2K_dev_815
The relationship between increased deductive power and running time performance of the proof rules is far from obvious ; we discuss and illustrate certain classes of problems where this relationship is interesting	finding	2K_dev_815
	mechanism	2K_dev_815
We study the trade-off between proof rule generality and practical performance and evaluate our theoretical observations on a set of benchmarks	method	2K_dev_815
	method	2K_dev_815
This paper studies sound proof rules for checking positive invariance of algebraic and semi-algebraic sets	purpose	2K_dev_815
that is	purpose	2K_dev_815
sets satisfying polynomial equalities and those satisfying finite boolean combinations of polynomial equalities and inequalities	purpose	2K_dev_815
under the flow of polynomial ordinary differential equations	purpose	2K_dev_815
	background	2K_dev_816
	finding	2K_dev_816
	mechanism	2K_dev_816
	method	2K_dev_816
	purpose	2K_dev_816
How can we efficiently decompose a tensor into sparse factors	background	2K_dev_817
when the data do not fit in memory ?	background	2K_dev_817
enabling reproducibility of our work	background	2K_dev_817
	background	2K_dev_817
indicate over 90p sparser outputs and 14 times faster execution	finding	2K_dev_817
with approximation error close to the current state of the art irrespective of computation and memory requirements	finding	2K_dev_817
demonstrating its effectiveness for data-mining practitioners	finding	2K_dev_817
In this work	mechanism	2K_dev_817
we propose P ar C ube	mechanism	2K_dev_817
a new and highly parallelizable method that is well suited to produce sparse approximations In particular	mechanism	2K_dev_817
we are the first to analyze the very large N ell dataset using a sparse tensor decomposition	mechanism	2K_dev_817
demonstrating that P ar C ube enables us to handle effectively and efficiently very large datasets Finally	mechanism	2K_dev_817
we make our highly scalable parallel implementation publicly available	mechanism	2K_dev_817
Experiments with even moderately large data We provide theoretical guarantees for the algorithms correctness and we experimentally validate our claims through extensive experiments	method	2K_dev_817
including four different real world datasets ( E nron	method	2K_dev_817
L bnl	method	2K_dev_817
F acebook and N ell )	method	2K_dev_817
Tensor decompositions have gained a steadily increasing popularity in data-mining applications ; however	purpose	2K_dev_817
the current state-of-art decomposition algorithms operate on main memory and do not scale to truly large datasets	purpose	2K_dev_817
for speeding up tensor decompositions	purpose	2K_dev_817
In the U	background	2K_dev_818
S	background	2K_dev_818
	background	2K_dev_818
the current practice of analyzing the structural integrity of embankment dams relies primarily on manual a posteriori analysis of instrument data by engineers	background	2K_dev_818
leaving much room for improvement through the application of advanced data analysis techniques	background	2K_dev_818
	background	2K_dev_818
In general	finding	2K_dev_818
KL performs better than MPCA and AR	finding	2K_dev_818
and delivers more consistent results throughout the different piezometers and anomaly scenarios	finding	2K_dev_818
Given that KL is a nonparametric technique	finding	2K_dev_818
the authors conclude that the prior assumptions about piezometer data do not always provide the best performance for anomaly prediction	finding	2K_dev_818
	finding	2K_dev_818
	mechanism	2K_dev_818
In this research	method	2K_dev_818
different types of anomaly detection techniques are examined in an effort Moreover	method	2K_dev_818
both the parametric ( Auto Regressive AR and Moving Principal Component Analysis MPCA ) and nonparametric ( Kullback-Leibler Divergence KL ) techniques are applied in order to test if the widely-held assumptions about piezometer data	method	2K_dev_818
i	method	2K_dev_818
e	method	2K_dev_818
	method	2K_dev_818
linearity between piezometer data and pool levels	method	2K_dev_818
as well as normally distributed piezometer data	method	2K_dev_818
are necessary in the anomaly detection task	method	2K_dev_818
to propose which data analytics are appropriate for various anomaly scenarios as well as piezometer locations	purpose	2K_dev_818
	purpose	2K_dev_818
Modeling cell shape variation is critical to our understanding of cell biology The open-source tools provide a powerful basis for future studies of the molecular basis of cell organization	background	2K_dev_819
We find that these are frequently dependent on each other and show that tagged C1QBP reduces the correlation between cell and nuclear shape	finding	2K_dev_819
	finding	2K_dev_819
use this as the motivation for the development of combined cell and nuclear shape space models	mechanism	2K_dev_819
extending nonparametric cell representations to multiple-component three-dimensional cellular shapes and identifying modes of joint shape variation We learn a first-order dynamics model given shapes at a previous time point	mechanism	2K_dev_819
	mechanism	2K_dev_819
Using these methods	method	2K_dev_819
we explore the relationship between cell shape and nuclear shape	method	2K_dev_819
We use this to determine the effects of endogenous protein tags or drugs on the shape dynamics of cell lines and we demonstrate the ability to reconstruct shape spaces using a fraction of computed pairwise distances	method	2K_dev_819
	method	2K_dev_819
Previous work has demonstrated the utility of nonrigid image registration methods for the construction of nonparametric nuclear shape models in which pairwise deformation distances are measured between all shapes and are embedded into a low-dimensional shape space	purpose	2K_dev_819
to predict cell and nuclear shapes	purpose	2K_dev_819
To reduce the computational cost of learning these models	purpose	2K_dev_819
	purpose	2K_dev_819
	background	2K_dev_820
	finding	2K_dev_820
	mechanism	2K_dev_820
	method	2K_dev_820
	purpose	2K_dev_820
Building automation systems are believed to hold the key to significantly reducing the average energy consumption of our residential and commercial building stock	background	2K_dev_821
which in the U	background	2K_dev_821
S	background	2K_dev_821
is responsible for 41 % of the total annual energy use in 2014	background	2K_dev_821
As these systems become more widespread and inexpensive	background	2K_dev_821
the complexity and challenges associated with their installation	background	2K_dev_821
maintenance and upkeep will increase	background	2K_dev_821
One of the primary challenges is the generation and update of the meta-data associated with the sensors and control points distributed throughout the facility Previous research has attempted to reduce the human input required to perform these activities	background	2K_dev_821
by leveraging different signal processing and statistical analysis approaches to infer the sensor types and locations from measurements and/or tags obtained through a BAS	background	2K_dev_821
provide recommendations for future work in this area	background	2K_dev_821
	background	2K_dev_821
show the feasibility of applying data driven approaches in the real world	finding	2K_dev_821
We present the results of our study and	finding	2K_dev_821
In this paper	mechanism	2K_dev_821
we propose a meta-data inference framework	mechanism	2K_dev_821
Furthermore	method	2K_dev_821
we evaluate the framework on two large buildings instrumented with thousands sensors and	method	2K_dev_821
However	purpose	2K_dev_821
because of the relatively small sample size	purpose	2K_dev_821
the feasibility of applying these type approaches on large buildings	purpose	2K_dev_821
as well as their generalizability	purpose	2K_dev_821
remain as unsolved questions to learn from BAS measurement data in a semi-automated way	purpose	2K_dev_821
	purpose	2K_dev_821
	background	2K_dev_822
	finding	2K_dev_822
and show that it converges to a stationary distribution	finding	2K_dev_822
In particular	finding	2K_dev_822
we show that	finding	2K_dev_822
depending on the local dynamical rule	finding	2K_dev_822
different network substructures	finding	2K_dev_822
such as hub or triangle subgraphs	finding	2K_dev_822
are more prone to failure	finding	2K_dev_822
The Dynamic Bond Percolation ( DBP ) process models	mechanism	2K_dev_822
through stochastic local rules	mechanism	2K_dev_822
the dependence of an edge $ ( a	mechanism	2K_dev_822
b ) $ in a network on the states of its neighboring edges Unlike previous models	mechanism	2K_dev_822
DBP does not assume statistical independence between different edges In applications	mechanism	2K_dev_822
this means for example that failures of transmission lines in a power grid are not statistically independent	mechanism	2K_dev_822
or alternatively	mechanism	2K_dev_822
relationships between individuals ( dyads ) can lead to changes in other dyads in a social network	mechanism	2K_dev_822
We consider the time evolution of the probability distribution of the network state	method	2K_dev_822
the collective states of all the edges ( bonds ) We use this distribution to study the emergence of global behaviors like consensus ( i	method	2K_dev_822
e	method	2K_dev_822
	method	2K_dev_822
catastrophic failure or full recovery of the entire grid ) or coexistence ( i	method	2K_dev_822
e	method	2K_dev_822
	method	2K_dev_822
some failed and some operating substructures in the grid	method	2K_dev_822
This paper considers the dynamics of edges in a network	purpose	2K_dev_822
	purpose	2K_dev_822
Image clustering and visual codebook learning are two fundamental problems in computer vision and they are tightly related	background	2K_dev_823
On one hand	background	2K_dev_823
a good codebook can generate effective feature representations which largely affect clustering performance	background	2K_dev_823
On the other hand	background	2K_dev_823
class labels obtained from image clustering can serve as supervised information to guide codebook learning	background	2K_dev_823
demonstrate the effectiveness of two models	finding	2K_dev_823
	finding	2K_dev_823
In this paper	mechanism	2K_dev_823
we propose a Double Layer Gaussian Mixture Model ( DLGMM ) In DLGMM	mechanism	2K_dev_823
two tasks are seamlessly coupled and can mutually promote each other	mechanism	2K_dev_823
Cluster labels and codebook are jointly estimated to achieve the overall best performance	mechanism	2K_dev_823
To incorporate the spatial coherence between neighboring visual patches	mechanism	2K_dev_823
we propose a Spatially Coherent DL-GMM which uses a Markov Random Field to encourage neighboring patches to share the same visual word label	mechanism	2K_dev_823
We use variational inference to approximate the posterior of latent variables and learn model parameters	mechanism	2K_dev_823
	mechanism	2K_dev_823
Experiments on two datasets	method	2K_dev_823
Traditionally	purpose	2K_dev_823
these two processes are conducted separately and their correlation is generally ignored	purpose	2K_dev_823
to simultaneously perform image clustering and codebook learning	purpose	2K_dev_823
While prior research has studied the motivations of individuals to consume content on social media platforms Implications for research and practice are also discussed	background	2K_dev_824
	finding	2K_dev_824
Given that content creation efforts are driven not only by their personal preferences	mechanism	2K_dev_824
but also by the content creation decisions of others in the network neighbors	mechanism	2K_dev_824
we develop a new method with panel data	mechanism	2K_dev_824
We face a novel set of big data challenges	mechanism	2K_dev_824
i	mechanism	2K_dev_824
e	mechanism	2K_dev_824
	mechanism	2K_dev_824
both statistical and quantitative	mechanism	2K_dev_824
in estimating peer influence	mechanism	2K_dev_824
We face computational challenges in that we can not reasonably estimate peer influence over the entire YouTube network	mechanism	2K_dev_824
which has billions of nodes	mechanism	2K_dev_824
We employ graph sampling methods to address this issue	mechanism	2K_dev_824
Identification of social influence in large-scale social networks such as YouTube is difficult due to the interdependence in decisions of users	mechanism	2K_dev_824
correlations between the video 's observable and unobservable characteristics and attributes over time These patterns can not be modeled with existing autocorrelation models	mechanism	2K_dev_824
We design a new method	mechanism	2K_dev_824
the Network Auto-Probit Model with Fixed Effects ( NAFE )	mechanism	2K_dev_824
	mechanism	2K_dev_824
	method	2K_dev_824
limited work exists on how contributors are motivated to create content We examine the role of peer influence in content production on YouTube	purpose	2K_dev_824
where content creators are competing for attention to analyze discrete choice decisions ( such as creating content or not ) in a networked environment to identify peer influence among content creators on YouTube	purpose	2K_dev_824
Despite the enormous medical impact of cancers and intensive study of their biology	background	2K_dev_825
detailed characterization of tumor growth and development remains elusive	background	2K_dev_825
This difficulty occurs in large part because of enormous heterogeneity in the molecular mechanisms of cancer progression	background	2K_dev_825
both tumor-to-tumor and cell-to-cell in single tumors	background	2K_dev_825
Advances in genomic technologies	background	2K_dev_825
especially at the single-cell level	background	2K_dev_825
are improving the situation	background	2K_dev_825
but these approaches are held back by limitations of the biotechnologies for gathering genomic data from heterogeneous cell populations and the computational methods for making sense of those data	background	2K_dev_825
One popular way to gain the advantages of whole-genome methods without the cost of single-cell genomics has been the use of computational deconvolution ( unmixing ) methods to reconstruct clonal heterogeneity from bulk genomic data	background	2K_dev_825
a key step in the process of accurately deconvolving tumor genomic data and inferring clonal heterogeneity from bulk data	background	2K_dev_825
	background	2K_dev_825
We show that this new method substantially improves our ability to resolve discrete tumor subgroups	finding	2K_dev_825
Here	mechanism	2K_dev_825
we present a new method by better identifying subspaces corresponding to tumors produced from mixtures of distinct combinations of clonal subpopulations We develop a nonparametric clustering method based on medoidshift clustering for identifying subgroups of tumors expected to correspond to distinct trajectories of evolutionary progression	mechanism	2K_dev_825
	mechanism	2K_dev_825
on synthetic and real tumor copy-number data	method	2K_dev_825
These methods	purpose	2K_dev_825
too	purpose	2K_dev_825
are limited by the difficulty of inferring genomic profiles of rare or subtly varying clonal subpopulations from bulk data	purpose	2K_dev_825
a problem that can be computationally reduced to that of reconstructing the geometry of point clouds of tumor samples in a genome space	purpose	2K_dev_825
to improve that reconstruction	purpose	2K_dev_825
Over the last decade	background	2K_dev_826
the looming power wall has spurred a flurry of interest in developing heterogeneous systems with hardware accelerators	background	2K_dev_826
	background	2K_dev_826
On average	finding	2K_dev_826
the legacy code using our proposed MEmory Accelerated Library ( MEALib ) improves performance and energy efficiency for individual operations in Intel 's Math Kernel Library ( MKL ) by 38 and 75	finding	2K_dev_826
respectively	finding	2K_dev_826
MEALib attains more than 10 better energy efficiency	finding	2K_dev_826
	finding	2K_dev_826
Our accelerator design approach stems from the observation that many efficient and portable software implementations rely on high performance software libraries with well-established application programming interfaces ( APIs ) We propose the integration of hardware accelerators on 3D-stacked memory The fixed APIs with limited configurability simplify the design of the accelerators	mechanism	2K_dev_826
while ensuring that the accelerators have wide applicability	mechanism	2K_dev_826
With our software support that automatically converts library APIs to accelerator invocations	mechanism	2K_dev_826
an additional advantage of our approach is that library-based legacy code automatically gains the benefit of memory-side accelerators without requiring a reimplementation	mechanism	2K_dev_826
	mechanism	2K_dev_826
For a real-world signal processing application that employs Intel MKL	method	2K_dev_826
	method	2K_dev_826
The questions	purpose	2K_dev_826
then	purpose	2K_dev_826
are what and how accelerators should be designed	purpose	2K_dev_826
and what software support is required	purpose	2K_dev_826
that explicitly targets the memory-bounded operations within high performance libraries	purpose	2K_dev_826
	purpose	2K_dev_826
The study of representations invariant to common transformations of the data is important to learning	background	2K_dev_827
	background	2K_dev_827
to illustrate and validate our methods	finding	2K_dev_827
In this paper	mechanism	2K_dev_827
we study kernels that are invariant to the unitary group while having theoretical guarantees We present a theoretically motivated alternate approach to the invariant kernel SVM Unlike previous approaches to the invariant SVM	mechanism	2K_dev_827
the proposed formulation solves both issues mentioned	mechanism	2K_dev_827
We also present a kernel extension of a recent technique to extract linear unitary-group invariant features addressing both issues and extend some guarantees regarding invariance and stability	mechanism	2K_dev_827
	mechanism	2K_dev_827
We present experiments on the UCI ML datasets	method	2K_dev_827
Most techniques have focused on local approximate invariance implemented within expensive optimization frameworks lacking explicit theoretical guarantees in addressing practical issues such as ( 1 ) unavailability of transformed versions of labelled data and ( 2 ) not observing all transformations	purpose	2K_dev_827
	purpose	2K_dev_827
The assembly of virus capsids proceeds by a complicated cascade of association and dissociation steps	background	2K_dev_828
the great majority of which can not be directly experimentally observed This has made capsid assembly a rich field for computational models	background	2K_dev_828
	background	2K_dev_828
The results show that advances in both the data and the algorithms can improve model inference More informative data sources lead to high-quality fits for all methods	finding	2K_dev_828
but DFO methods show substantial advantages on less informative data sources that better represent current experimental practice	finding	2K_dev_828
Here	mechanism	2K_dev_828
we describe progress on fitting kinetic rate constants defining capsid assembly models to experimental data a model of time-resolved mass spectrometry data	mechanism	2K_dev_828
a technology that can be expected to provide much richer data than previously used static light scattering approaches	mechanism	2K_dev_828
	mechanism	2K_dev_828
We evaluate the merits of data-fitting methods based on derivative-free optimization ( DFO ) relative to gradient-based methods used in prior work	method	2K_dev_828
	method	2K_dev_828
but there are substantial obstacles to model inference for such systems a difficult data-fitting problem because of the high computational cost of simulating assembly trajectories	purpose	2K_dev_828
the stochastic noise inherent to the models	purpose	2K_dev_828
and the limited and noisy data available for fitting We further explore the advantages of alternative data sources through simulation of for monitoring bulk capsid assembly	purpose	2K_dev_828
	background	2K_dev_829
the resulting methods often perform as well or better than existing latent variable models	finding	2K_dev_829
while being substantially easier to train	finding	2K_dev_829
We present a convex approach Our approach builds upon recent advances in multivariate total variation regularization	mechanism	2K_dev_829
and seeks to learn a separate set of parameters for the distribution over the observations at each time point	mechanism	2K_dev_829
but with an additional penalty that encourages the parameters to remain constant over time	mechanism	2K_dev_829
We propose efficient optimization methods	mechanism	2K_dev_829
and a two-stage procedure under such models	mechanism	2K_dev_829
based upon kernel density estimation	mechanism	2K_dev_829
Finally	method	2K_dev_829
we show on a number of real-world segmentation tasks	method	2K_dev_829
	method	2K_dev_829
to probabilistic segmentation and modeling of time series data for solving the resulting ( large ) optimization problems for estimating recurring clusters	purpose	2K_dev_829
This typically arises in the tourism setting where attractions can often be bundled and sold as a package to visitors	background	2K_dev_830
While the problem of predicting future locations given the current and past trajectories is well-established	background	2K_dev_830
	background	2K_dev_830
Our predictions show improved accuracies by at least 20	finding	2K_dev_830
one of which comes from the spatiotemporal analysis domain	finding	2K_dev_830
	finding	2K_dev_830
we take a radical approach by looking at it from an economic point of view	mechanism	2K_dev_830
We view an agent 's past trajectories as revealed preference ( RP ) data	mechanism	2K_dev_830
where the choice of locations is a solution to an optimisation problem according to some unknown utility function and subject to the prevailing prices and budget constraint We approximate the prices and budget constraint as the time costs to finish visiting the chosen locations We leverage on a recent line of work that has established algorithms to efficiently learn from RP data ( i	mechanism	2K_dev_830
e	mechanism	2K_dev_830
	mechanism	2K_dev_830
recover the utility functions ) and make predictions of future purchasing behaviours	mechanism	2K_dev_830
We adopt and adapt those work to our original setting while incorporating techniques from spatiotemporal analysis	mechanism	2K_dev_830
	mechanism	2K_dev_830
We experiment with real-world trajectory data collected from a theme park	method	2K_dev_830
in comparison with the baseline methods	method	2K_dev_830
We propose the problem of predicting a bundle of goods	purpose	2K_dev_830
where the goods considered is a set of spatial locations that an agent wishes to visit	purpose	2K_dev_830
Given a large collection of co-evolving online activities	background	2K_dev_831
such as searches for the keywords `` Xbox ''	background	2K_dev_831
`` PlayStation '' and `` Wii ''	background	2K_dev_831
how can we find patterns and rules ? Are these keywords related ? If so	background	2K_dev_831
are they competing against each other ? Can we forecast the volume of user activity for the coming month ?	background	2K_dev_831
show that ECOWEB is effective	finding	2K_dev_831
in that it can capture long-range dynamics and meaningful patterns such as seasonalities	finding	2K_dev_831
and practical	finding	2K_dev_831
in that it can provide accurate long-range forecasts	finding	2K_dev_831
ECOWEB consistently outperforms existing methods in terms of both accuracy and execution speed	finding	2K_dev_831
We present ECOWEB	mechanism	2K_dev_831
( i	mechanism	2K_dev_831
e	mechanism	2K_dev_831
	mechanism	2K_dev_831
Ecosystem on the Web )	mechanism	2K_dev_831
which is an intuitive model designed as a non-linear dynamical system Our second contribution is a novel	mechanism	2K_dev_831
parameter-free	mechanism	2K_dev_831
and scalable fitting algorithm	mechanism	2K_dev_831
ECOWEB-FIT	mechanism	2K_dev_831
that estimates the parameters of ECOWEB	mechanism	2K_dev_831
Extensive experiments on real data	method	2K_dev_831
We conjecture that online activities compete for user attention in the same way that species in an ecosystem compete for food for mining large-scale co-evolving online activities	purpose	2K_dev_831
Software lineage refers to the evolutionary relationship among a collection of software	background	2K_dev_832
The goal of software lineage inference is to recover the lineage given a set of program binaries	background	2K_dev_832
Software lineage can provide extremely useful information in many security scenarios such as malware triage and software vulnerability tracking	background	2K_dev_832
Our results reveal that partial order mismatches and graph arc edit distance often yield the most meaningful comparisons Even without assuming any prior information about the data sets	finding	2K_dev_832
ILINE proved to be effective in lineage inference -- it achieves a mean accuracy of over 84 % for goodware and over 72 % for malware in our data sets	finding	2K_dev_832
	finding	2K_dev_832
we build ILINE	mechanism	2K_dev_832
a system	mechanism	2K_dev_832
and also IEVAL	mechanism	2K_dev_832
a system	mechanism	2K_dev_832
We evaluated ILINE on two types of lineage -- straight line and directed acyclic graph -- with large-scale real-world programs : 1	method	2K_dev_832
777 goodware spanning over a combined 110 years of development history and 114 malware with known lineage collected by the DARPA Cyber Genome program We used IEVAL to study seven metrics to assess the diverse properties of lineage	method	2K_dev_832
in our experiments	method	2K_dev_832
	method	2K_dev_832
In this paper	purpose	2K_dev_832
we systematically study software lineage inference by exploring four fundamental questions not addressed by prior work	purpose	2K_dev_832
First	purpose	2K_dev_832
how do we automatically infer software lineage from program binaries ? Second	purpose	2K_dev_832
how do we measure the quality of lineage inference algorithms ? Third	purpose	2K_dev_832
how useful are existing approaches to binary similarity analysis for inferring lineage in reality	purpose	2K_dev_832
and how about in an idealized setting ? Fourth	purpose	2K_dev_832
what are the limitations that any software lineage inference algorithm must cope with ? Towards these goals for automatic software lineage inference of program binaries for scientific assessment of lineage quality	purpose	2K_dev_832
	purpose	2K_dev_832
With the rise of online social networks and smartphones that record the user 's location	background	2K_dev_833
a new type of online social network has gained popularity during the last few years	background	2K_dev_833
the so called Location-based Social Networks ( LBSNs )	background	2K_dev_833
In such networks	background	2K_dev_833
users voluntarily share their location with their friends via a check-in	background	2K_dev_833
In exchange they get recommendations tailored to their particular location as well as special deals that businesses offer when users check-in frequently	background	2K_dev_833
LBSNs started as specialized platforms such as Gowalla and Foursquare	background	2K_dev_833
however their immense popularity has led online social networking giants like Facebook to adopt this functionality	background	2K_dev_833
The spatial aspect of LBSNs directly ties the physical with the online world	background	2K_dev_833
creating a very rich ecosystem where users interact with their friends both online as well as declare their physical ( co- ) presence in various locations	background	2K_dev_833
	finding	2K_dev_833
In this work	mechanism	2K_dev_833
we propose to model and analyze LBSNs using Tensors and Tensor Decompositions	mechanism	2K_dev_833
powerful analytical tools that have enjoyed great growth and success in fields like Machine Learning	mechanism	2K_dev_833
Data Mining	mechanism	2K_dev_833
and Signal Processing alike	mechanism	2K_dev_833
In addition to Tensor Decompositions	mechanism	2K_dev_833
we use Signal Processing tools that have been previously used in Direction of Arrival ( DOA ) estimations	mechanism	2K_dev_833
in order	mechanism	2K_dev_833
	method	2K_dev_833
Such a rich environment calls for novel analytic tools that can model the aforementioned types of interactions	purpose	2K_dev_833
By doing so	purpose	2K_dev_833
we identify tightly knit	purpose	2K_dev_833
hidden communities of users and locations which they frequent to study the temporal dynamics of hidden communities in LBSNs	purpose	2K_dev_833
	purpose	2K_dev_833
Prior work has	background	2K_dev_834
among other techniques	background	2K_dev_834
used canonical correlation analysis to project pre-trained vectors in two languages into a common space	background	2K_dev_834
that our method outperforms prior work on multilingual tasks	finding	2K_dev_834
matches the performance of prior work on monolingual tasks	finding	2K_dev_834
and scales linearly with the size of the input data ( and thus the number of languages being embedded )	finding	2K_dev_834
	finding	2K_dev_834
We propose a simple and scalable method that is inspired by the notion that the learned vector representations should be invariant to translation between languages	mechanism	2K_dev_834
We show empirically	method	2K_dev_834
This work focuses on the task of finding latent vector representations of the words in a corpus	purpose	2K_dev_834
In particular	purpose	2K_dev_834
we address the issue of what to do when there are multiple languages in the corpus	purpose	2K_dev_834
	purpose	2K_dev_834
	background	2K_dev_835
	finding	2K_dev_835
	mechanism	2K_dev_835
	method	2K_dev_835
	purpose	2K_dev_835
	background	2K_dev_836
our algorithm performs favorably without the need for careful initialization	finding	2K_dev_836
We propose a spectral approach Our approach is grammarless we directly learn the bracketing structure of a given sentence without using a grammar model The main algorithm is based on lifting the concept of additive tree metrics for structure learning of latent trees in the phylogenetic and machine learning communities to the case where the tree structure varies across examples	mechanism	2K_dev_836
Although finding the minimal latent tree is NP-hard in general	mechanism	2K_dev_836
for the case of projective trees we find that it can be found using bilexical parsing algorithms	mechanism	2K_dev_836
	mechanism	2K_dev_836
Empirically compared to the constituent context model of Klein and Manning ( 2002 )	method	2K_dev_836
for unsupervised constituent parsing that comes with theoretical guarantees on latent structure recovery	purpose	2K_dev_836
	background	2K_dev_837
	finding	2K_dev_837
	mechanism	2K_dev_837
	method	2K_dev_837
	purpose	2K_dev_837
	background	2K_dev_838
show that this often improves running times by an order of magnitude or more vs	finding	2K_dev_838
existing approaches based on conic solvers	finding	2K_dev_838
	finding	2K_dev_838
We present Epsilon	mechanism	2K_dev_838
a system using fast linear and proximal operators	mechanism	2K_dev_838
As with existing convex programming frameworks	mechanism	2K_dev_838
users specify convex optimization problems using a natural grammar for mathematical expressions	mechanism	2K_dev_838
composing functions in a way that is guaranteed to be convex by the rules of disciplined convex programming Given such an input	mechanism	2K_dev_838
the Epsilon compiler transforms the optimization problem into a mathematically equivalent form consisting only of functions with ecient proximal operators|an intermediate representation we refer to as prox-ane form	mechanism	2K_dev_838
By reducing problems to this form	mechanism	2K_dev_838
Epsilon enables solving general convex problems using a large library of fast proximal and linear operators ;	mechanism	2K_dev_838
numerical examples on many popular problems from statistics and machine learning	method	2K_dev_838
for general convex programming	purpose	2K_dev_838
	background	2K_dev_839
it is shown that	finding	2K_dev_839
at every network agent	finding	2K_dev_839
$ \mathcal { CIWNLS } $ leads to consistent parameter estimates the distributed estimator is shown to yield order-optimal convergence rates	finding	2K_dev_839
i	finding	2K_dev_839
e	finding	2K_dev_839
	finding	2K_dev_839
as far as the order of pathwise convergence is concerned	finding	2K_dev_839
the local parameter estimates at each agent are as good as the optimal centralized nonlinear least-squares estimator that requires access to all the observations across all the agents at all times	finding	2K_dev_839
	finding	2K_dev_839
	mechanism	2K_dev_839
where the individual agents observe sequentially over time an independent and identically distributed time-series consisting of a nonlinear function of the true but unknown parameter corrupted by noise A distributed recursive estimator of the consensus+innovations type	mechanism	2K_dev_839
namely $ \mathcal { CIWNLS } $	mechanism	2K_dev_839
is proposed	mechanism	2K_dev_839
in which the agents update their parameter estimates at each observation sampling epoch in a collaborative way by simultaneously processing the latest locally sensed information ( innovations ) and the parameter estimates from other agents ( consensus ) in the local neighborhood conforming to a prespecified interagent communication topology	mechanism	2K_dev_839
Under rather weak conditions on the connectivity of the interagent communication and a global observability criterion Furthermore	method	2K_dev_839
under standard smoothness assumptions on the local observation functions	method	2K_dev_839
To benchmark the performance of the $ \mathcal { CIWNLS } $ estimator with that of the centralized nonlinear least-squares estimator	method	2K_dev_839
the asymptotic normality of the estimate sequence is established	method	2K_dev_839
and the asymptotic covariance of the distributed estimator is evaluated	method	2K_dev_839
This paper focuses on recursive nonlinear least-squares parameter estimation in multiagent networks	purpose	2K_dev_839
Curriculum learning ( CL ) or self-paced learning ( SPL ) represents a recently proposed learning regime inspired by the learning process of humans and animals that gradually proceeds from easy to more complex samples in training	background	2K_dev_840
The two methods share a similar conceptual learning paradigm	background	2K_dev_840
but differ in specific learning schemes	background	2K_dev_840
In CL	background	2K_dev_840
the curriculum is predetermined by prior knowledge	background	2K_dev_840
and remain fixed thereafter	background	2K_dev_840
	background	2K_dev_840
	finding	2K_dev_840
In SPL	mechanism	2K_dev_840
the curriculum is dynamically determined to adjust to the learning pace of the leaner and propose a unified framework named self-paced curriculum leaning ( SPCL )	mechanism	2K_dev_840
SPCL is formulated as a concise optimization problem that takes into account both prior knowledge known before training and the learning progress during training	mechanism	2K_dev_840
	mechanism	2K_dev_840
In comparison to human education	method	2K_dev_840
SPCL is analogous to `` instructor-student-collaborative '' learning mode	method	2K_dev_840
as opposed to `` instructor-driven '' in CL or `` student-driven '' in SPL Empirically	method	2K_dev_840
we show that the advantage of SPCL on two tasks	method	2K_dev_840
	method	2K_dev_840
Therefore	purpose	2K_dev_840
this type of method heavily relies on the quality of prior knowledge while ignoring feedback about the learner	purpose	2K_dev_840
However	purpose	2K_dev_840
SPL is unable to deal with prior knowledge	purpose	2K_dev_840
rendering it prone to overfitting	purpose	2K_dev_840
In this paper	purpose	2K_dev_840
we discover the missing link between CL and SPL	purpose	2K_dev_840
	purpose	2K_dev_840
Image and video classification research has made great progress through the development of handcrafted local features and learning based features	background	2K_dev_841
	background	2K_dev_841
show that by focusing on the structure of CNNs	finding	2K_dev_841
rather than end-to-end training methods	finding	2K_dev_841
we are able to design an efficient and powerful video feature learning algorithm	finding	2K_dev_841
	finding	2K_dev_841
In this paper	mechanism	2K_dev_841
we emphasize their structural similarities and show how such a unified view helps us in designing features that balance efficiency and effectiveness	mechanism	2K_dev_841
We approach this problem by first showing that local handcrafted features and Convolutional Neural Networks ( CNNs ) share the same convolution-pooling network structure	mechanism	2K_dev_841
We then propose a two-stream Convolutional ISA ( ConvISA ) that adopts the convolution-pooling structure of the state-of-the-art handcrafted video feature with greater modeling capacities and a cost-effective training algorithm	mechanism	2K_dev_841
Through custom designed network structures for pixels and optical flow	mechanism	2K_dev_841
our method also reflects distinctive characteristics of these two data sources	mechanism	2K_dev_841
As an example	method	2K_dev_841
we study the problem of designing efficient video feature learning algorithms for action recognition	method	2K_dev_841
Our experimental results on standard action recognition benchmarks	method	2K_dev_841
These two architectures were proposed roughly at the same time and have flourished at overlapping stages of history	purpose	2K_dev_841
However	purpose	2K_dev_841
they are typically viewed as distinct approaches	purpose	2K_dev_841
	purpose	2K_dev_841
Early detection and precise characterization of emerging topics in text streams can be highly useful in applications such as timely and targeted public health interventions and discovering evolving regional business trends	background	2K_dev_842
Many methods have been proposed for detecting emerging events in text streams using topic modeling	background	2K_dev_842
On both tasks	finding	2K_dev_842
we find that Semantic Scan provides significantly better event detection and characterization accuracy than competing approaches	finding	2K_dev_842
while providing up to an order of magnitude speedup	finding	2K_dev_842
In this paper	mechanism	2K_dev_842
we describe Semantic Scan ( SS ) that has been developed specifically Semantic Scan integrates novel contrastive topic modeling with online document assignment and principled likelihood ratio-based spatial scanning to identify emerging events with unexpected patterns of keywords hidden in text streams	mechanism	2K_dev_842
This enables more timely and accurate detection and characterization of anomalous	mechanism	2K_dev_842
spatially localized emerging events Semantic Scan does not require manual intervention or labeled training data	mechanism	2K_dev_842
and is robust to noise in real-world text data since it identifies anomalous text patterns that occur in a cluster of new documents rather than an anomaly in a single new document	mechanism	2K_dev_842
	mechanism	2K_dev_842
We compare Semantic Scan to alternative state-of-the-art methods such as Topics over Time	method	2K_dev_842
Online LDA	method	2K_dev_842
and Labeled LDA on two real-world tasks : ( i ) a disease surveillance task monitoring free-text Emergency Department chief complaints in Allegheny County	method	2K_dev_842
and ( ii ) an emerging business trend detection task based on Yelp reviews	method	2K_dev_842
	method	2K_dev_842
However	purpose	2K_dev_842
these methods have numerous shortcomings that make them unsuitable for rapid detection of locally emerging events on massive text streams	purpose	2K_dev_842
to overcome these shortcomings in detecting new spatially compact events in text streams	purpose	2K_dev_842
Conditional Gaussian graphical models generalize the well-known Gaussian graphical models to conditional distributions to model the output network influenced by conditioning input variables	background	2K_dev_843
	background	2K_dev_843
we show that our methods can solve one million dimensional problems to high accuracy in a little over a day on a single machine	finding	2K_dev_843
In this paper	mechanism	2K_dev_843
we propose a new optimization procedure based on a Newton method leading to drastic improvement in computation time compared to the previous methods We then extend our method to scale to large problems under memory constraints	mechanism	2K_dev_843
using block coordinate descent to limit memory usage while achieving fast convergence	mechanism	2K_dev_843
	mechanism	2K_dev_843
Using synthetic and genomic data	method	2K_dev_843
This paper addresses the problem of scalable optimization for L1-regularized conditional Gaussian graphical models	purpose	2K_dev_843
While highly scalable optimization methods exist for sparse Gaussian graphical model estimation	purpose	2K_dev_843
state-of-the-art methods for conditional Gaussian graphical models are not efficient enough and more importantly	purpose	2K_dev_843
fail due to memory constraints for very large problems that efficiently iterates over two sub-problems	purpose	2K_dev_843
	purpose	2K_dev_843
Unease over data privacy will retard consumer acceptance of IoT deployments	background	2K_dev_844
The primary source of discomfort is a lack of user control over raw data that is streamed directly from sensors to the cloud	background	2K_dev_844
	finding	2K_dev_844
that interposes a locally-controlled software component called a privacy mediator on every raw sensor stream Each mediator is in the same administrative domain as the sensors whose data is being collected	mechanism	2K_dev_844
and dynamically enforces the current privacy policies of the owners of the sensors or mobile users within the domain This solution necessitates a logical point of presence for mediators within the administrative boundaries of each organization	mechanism	2K_dev_844
Such points of presence are provided by cloudlets	mechanism	2K_dev_844
which are small locally-administered data centers at the edge of the Internet that can support code mobility The use of cloudlet-based mediators aligns well with natural personal and organizational boundaries of trust and responsibility	mechanism	2K_dev_844
	mechanism	2K_dev_844
	method	2K_dev_844
This is a direct consequence of the over-centralization of today 's cloud-based IoT hub designs	purpose	2K_dev_844
We propose a solution	purpose	2K_dev_844
	background	2K_dev_845
and demonstrate our method	finding	2K_dev_845
We develop a parallel variational inference ( VI ) procedure we make use of the recently proposed nonparametric VI to facilitate an embarrassingly parallel VI procedure that can be applied to a wider scope of models	mechanism	2K_dev_845
including to nonconjugate models	mechanism	2K_dev_845
We derive our embarrassingly parallel VI algorithm	mechanism	2K_dev_845
	method	2K_dev_845
analyze our method theoretically empirically on a few nonconjugate models	method	2K_dev_845
	method	2K_dev_845
for use in data-distributed settings	purpose	2K_dev_845
where each machine only has access to a subset of data and runs VI independently	purpose	2K_dev_845
without communicating with other machines	purpose	2K_dev_845
This type of `` embarrassingly parallel '' procedure has recently been developed for MCMC inference algorithms ; however	purpose	2K_dev_845
in many cases it is not possible to directly extend this procedure to VI methods without requiring certain restrictive exponential family conditions on the form of the model	purpose	2K_dev_845
Furthermore	purpose	2K_dev_845
most existing ( nonparallel ) VI methods are restricted to use on conditionally conjugate models	purpose	2K_dev_845
which limits their To combat these issues	purpose	2K_dev_845
	purpose	2K_dev_845
Conclusions : A solution meeting the specification of the use case described above could improve human monitoring efficiency with expedited warning of events requiring follow-up	background	2K_dev_846
including otherwise overlooked events with no syndromic indicators	background	2K_dev_846
This approach can remove obstacles to collaboration with efficient	background	2K_dev_846
minimal data-sharing and without costly overhead	background	2K_dev_846
Results : Direct communication between public health problem owners and analytic developers was informative to both groups and constructive for the solution development process	finding	2K_dev_846
The consultancy achieved refinement of the asyndromic detection challenge and of solution requirements	finding	2K_dev_846
Participants summarized and evaluated solution approaches and discussed dissemination and collaboration strategies	finding	2K_dev_846
Materials and Methods : Supported by the Defense Threat Reduction Agency Biosurveillance Ecosystem project	mechanism	2K_dev_846
the International Society for Disease Surveillance formed an advisory group to select tractable use case problems and convene inter-disciplinary consultancies to translate analytic needs into well-defined problems and to promote development of applicable solution methods	mechanism	2K_dev_846
The initial consultancys focus was a problem originated by the North Carolina Department of Health and its NC DETECT surveillance system : Derive a method for detection of patient record clusters worthy of follow-up based on free-text chief complaints and without syndromic classification	mechanism	2K_dev_846
Component tasks are the collection of epidemiologists use case problems	method	2K_dev_846
multidisciplinary consultancies to refine them	method	2K_dev_846
and dissemination of problem requirements and shareable datasets We describe an initial use case and consultancy as a concrete example and challenge to developers	method	2K_dev_846
Introduction : We document a funded effort to bridge the gap between constrained scientific challenges of public health surveillance and methodologies from academia and industry	purpose	2K_dev_846
	purpose	2K_dev_846
	background	2K_dev_847
we show that with significantly lower number of pairwise judgments and feature-engineering effort	finding	2K_dev_847
we can achieve competitive coreference performance	finding	2K_dev_847
	finding	2K_dev_847
In this paper	mechanism	2K_dev_847
we define the problem of coreference resolution in text as one of clustering with pairwise constraints where human experts are asked to provide pairwise constraints ( pairwise judgments of coreferentiality ) Further	mechanism	2K_dev_847
we describe an active learning strategy by asking the most informative questions to human experts at each step of coreference resolution	mechanism	2K_dev_847
	mechanism	2K_dev_847
Positing that these pairwise judgments are easy to obtain from humans given the right context	method	2K_dev_847
We evaluate this hypothesis and our algorithms on both entity and event coreference tasks and on two languages	method	2K_dev_847
	method	2K_dev_847
to guide the clustering process	purpose	2K_dev_847
that minimizes the overall number of such pairwise judgments needed	purpose	2K_dev_847
The Restricted Isometric Property ( R	background	2K_dev_848
I	background	2K_dev_848
P	background	2K_dev_848
) is a very important condition for recovering sparse vectors from high dimensional space	background	2K_dev_848
Traditional methods often rely on R	background	2K_dev_848
I	background	2K_dev_848
P or its relaxed variants	background	2K_dev_848
The proposed algorithm converges geometrically	finding	2K_dev_848
achieves nearly optimal recovery bound O ( s2 log ( d ) ) where s is the sparsity and d is the nominal dimension	finding	2K_dev_848
We prove that when features exhibit cluster structures	mechanism	2K_dev_848
which often happens in real applications	mechanism	2K_dev_848
we are able to recover the sparse vector consistently	mechanism	2K_dev_848
The consistency comes from our proposed density correction algorithm	mechanism	2K_dev_848
which removes the variance of estimated cluster centers using cluster density	mechanism	2K_dev_848
	mechanism	2K_dev_848
In this paper	method	2K_dev_848
we study the sparse recovery problem in which the feature matrix is strictly non-R	method	2K_dev_848
I	method	2K_dev_848
P	method	2K_dev_848
However	purpose	2K_dev_848
in real applications	purpose	2K_dev_848
features are often correlated to each other	purpose	2K_dev_848
which makes these assumptions too strong to be useful	purpose	2K_dev_848
	background	2K_dev_849
We demonstrate that our methods significantly improve the performance of state-of-the-art motion features	finding	2K_dev_849
We propose two well-motivated ranking-based methods First	mechanism	2K_dev_849
as an improvement over the classic power normalization method	mechanism	2K_dev_849
we propose a parameter-free ranking technique called rank normalization ( RaN )	mechanism	2K_dev_849
RaN normalizes each dimension of the video features to address the sparse and bursty distribution problems of Fisher Vectors and VLAD	mechanism	2K_dev_849
Second	mechanism	2K_dev_849
inspired by curriculum learning	mechanism	2K_dev_849
we introduce a training-free re-ranking technique called multi-class iterative re-ranking ( MIR )	mechanism	2K_dev_849
MIR captures relationships among action classes by separating easy and typical videos from difficult ones and re-ranking the prediction scores of classifiers accordingly	mechanism	2K_dev_849
	mechanism	2K_dev_849
on six real-world datasets	method	2K_dev_849
	method	2K_dev_849
to enhance the performance of current state-of-the-art human activity recognition systems	purpose	2K_dev_849
	background	2K_dev_850
	finding	2K_dev_850
	mechanism	2K_dev_850
	method	2K_dev_850
	purpose	2K_dev_850
	background	2K_dev_851
	finding	2K_dev_851
	mechanism	2K_dev_851
	method	2K_dev_851
	purpose	2K_dev_851
Propagation of contagion in networks depends on the graph topology The only known analytical characterization of the equilibrium distribution of this process is for complete networks	background	2K_dev_852
For large networks with arbitrary topology	background	2K_dev_852
it is infeasible to numerically solve for the equilibrium distribution since it requires solving the eigenvalue-eigenvector problem of a matrix that is exponential in N	background	2K_dev_852
the size of the network	background	2K_dev_852
	background	2K_dev_852
We confirm this result	finding	2K_dev_852
on static	mechanism	2K_dev_852
undirected	mechanism	2K_dev_852
finite-size networks	mechanism	2K_dev_852
This is a contact process with nonzero exogenous infection rate ( also known as the { \epsilon } -SIS	mechanism	2K_dev_852
{ \epsilon } susceptible-infected-susceptible	mechanism	2K_dev_852
model [ 1 ] ) We show that	mechanism	2K_dev_852
for a certain range of the network process parameters	mechanism	2K_dev_852
the equilibrium distribution of the extended contact process on arbitrary	mechanism	2K_dev_852
finite-size networks is well approximated by the equilibrium distribution of the scaled SIS process	mechanism	2K_dev_852
which we derived in closed-form in prior work	mechanism	2K_dev_852
We use this approximation to decide	mechanism	2K_dev_852
in polynomial-time	mechanism	2K_dev_852
which agents and network substructures are more susceptible to infection by the extended contact process	mechanism	2K_dev_852
with numerical simulations comparing the equilibrium distribution of the extended contact process with that of a scaled SIS process	method	2K_dev_852
This paper is concerned with studying the time-asymptotic behavior of the extended contact processes	purpose	2K_dev_852
The widespread use of social networks enables the rapid diffusion of information	background	2K_dev_853
e	background	2K_dev_853
g	background	2K_dev_853
	background	2K_dev_853
news	background	2K_dev_853
among users in very large communities	background	2K_dev_853
It is a substantial challenge to be able to observe and understand such diffusion processes	background	2K_dev_853
which may be modeled as networks that are both large and dynamic A key tool in this regard is data summarization	background	2K_dev_853
However	background	2K_dev_853
few existing studies aim to summarize graphs/networks for dynamics	background	2K_dev_853
Dynamic networks raise new challenges not found in static settings	background	2K_dev_853
including time sensitivity and the needs for online interestingness evaluation and summary traceability	background	2K_dev_853
which render existing techniques inapplicable	background	2K_dev_853
The study offers insight into the effectiveness and design properties of OSNet	background	2K_dev_853
	background	2K_dev_853
	finding	2K_dev_853
Based on the concepts of diffusion radius and scope	mechanism	2K_dev_853
we define interestingness measures for dynamic networks	mechanism	2K_dev_853
and we propose OSNet	mechanism	2K_dev_853
an online summarization framework	mechanism	2K_dev_853
We report on extensive experiments with both synthetic and real-life data	method	2K_dev_853
	method	2K_dev_853
We study the topic of dynamic network summarization : how to summarize dynamic networks with millions of nodes by only capturing the few most interesting nodes or edges over time	purpose	2K_dev_853
and we address the problem by finding interestingness-driven diffusion processes	purpose	2K_dev_853
for dynamic networks	purpose	2K_dev_853
Session types provide a means to prescribe the communication behavior between concurrent message-passing processes However	background	2K_dev_854
in a distributed setting	background	2K_dev_854
some processes may be written in languages that do not support static typing of sessions or may be compromised by a malicious intruder	background	2K_dev_854
violating invariants of the session types	background	2K_dev_854
	background	2K_dev_854
We prove that dynamic monitoring does not change system behavior for welltyped processes	finding	2K_dev_854
and that one of an indicated set of possible culprits must have been compromised in case of an alarm	finding	2K_dev_854
	finding	2K_dev_854
We present a system of in the case when the monitor detects an undesirable action and an alarm is raised	mechanism	2K_dev_854
	method	2K_dev_854
In such a setting	purpose	2K_dev_854
dynamically monitoring communication between processes becomes a necessity for identifying undesirable actions	purpose	2K_dev_854
In this paper	purpose	2K_dev_854
we show how to dynamically monitor communication to enforce adherence to session types in a higher-order setting	purpose	2K_dev_854
blame assignment	purpose	2K_dev_854
	background	2K_dev_855
	finding	2K_dev_855
	mechanism	2K_dev_855
	method	2K_dev_855
	purpose	2K_dev_855
	background	2K_dev_856
	finding	2K_dev_856
which has guaranteed convergence and great scalability : close to 6 times faster on instance of ImageNet data set when run with 6 machines	finding	2K_dev_856
shown	finding	2K_dev_856
We propose a distributed approach The proposed scheme is close to optimally scalable in terms of number of machines	mechanism	2K_dev_856
and guaranteed to converge to the same optima as the undistributed setting	mechanism	2K_dev_856
The convergence and scalability of the distributed setting is The convergence analysis provides novel insights into this complex learning scheme	mechanism	2K_dev_856
including : 1 ) layerwise convergence	mechanism	2K_dev_856
and 2 ) convergence of the weights in probability	mechanism	2K_dev_856
	mechanism	2K_dev_856
theoretically empirically empirically across di ? erent datasets ( TIMIT and ImageNet ) and machine learning tasks ( image classi ? cation and phoneme extraction )	method	2K_dev_856
	method	2K_dev_856
to train deep neural networks ( DNNs )	purpose	2K_dev_856
	background	2K_dev_857
results of consistency under orthogonality and appropriate handling of redundant features	finding	2K_dev_857
	finding	2K_dev_857
we demonstrate on synthetic data that the Lass-0 solutions are closer to the true sparse support than L1 regularization models	finding	2K_dev_857
Lass-0 finds more parsimonious solutions that L1 regularization while maintaining similar predictive accuracy	finding	2K_dev_857
using convex relaxation of L1 regularization	mechanism	2K_dev_857
also known as the Lasso	mechanism	2K_dev_857
as an initialization step Our algorithm	mechanism	2K_dev_857
the Lass-0 ( `` Lass-zero '' )	mechanism	2K_dev_857
uses a computationally efficient stepwise search to determine a locally optimal L0 solution given any L1 regularization solution	mechanism	2K_dev_857
We present theoretical Empirically Additionally	method	2K_dev_857
in real-world data	method	2K_dev_857
We compute approximate solutions to L0 regularized linear regression problems	purpose	2K_dev_857
	background	2K_dev_858
	finding	2K_dev_858
	mechanism	2K_dev_858
	method	2K_dev_858
	purpose	2K_dev_858
Overall	background	2K_dev_859
this technique extends the capabilities of 3D printing in a new and interesting way	background	2K_dev_859
without requiring any new hardware	background	2K_dev_859
	background	2K_dev_859
demonstrating the immediate feasibility of our approach using a low cost	finding	2K_dev_859
commodity printer	finding	2K_dev_859
We introduce a technique by exploiting the stringing phenomena inherent in 3D printers using fused deposition modeling Our approach offers a range of design parameters for controlling the properties of single strands and also of hair bundles	mechanism	2K_dev_859
We further detail a list of post-processing techniques for refining the behavior and appearance of printed strands	mechanism	2K_dev_859
	mechanism	2K_dev_859
We provide several examples of output	method	2K_dev_859
	method	2K_dev_859
for furbricating 3D printed hair	purpose	2K_dev_859
fibers and bristles	purpose	2K_dev_859
	purpose	2K_dev_859
One typically proves infeasibility in satisfiability/ constraint satisfaction ( or optimality in integer programming ) by constructing a tree certificate	background	2K_dev_860
	background	2K_dev_860
	finding	2K_dev_860
We explore the power of a simple paradigm	mechanism	2K_dev_860
that of throwing random darts into the assignment space and then This method seems to work well when the number of short certificates of infeasibility is moderate	mechanism	2K_dev_860
suggesting that the overhead of throwing darts is more than paid for by the information gained by these darts	mechanism	2K_dev_860
	mechanism	2K_dev_860
	method	2K_dev_860
However	purpose	2K_dev_860
deciding how to branch in the search tree is hard	purpose	2K_dev_860
and impacts search time drastically	purpose	2K_dev_860
using information gathered by that dart to guide what to do next	purpose	2K_dev_860
	purpose	2K_dev_860
	background	2K_dev_861
	finding	2K_dev_861
	mechanism	2K_dev_861
	method	2K_dev_861
	purpose	2K_dev_861
	background	2K_dev_862
	finding	2K_dev_862
	mechanism	2K_dev_862
	method	2K_dev_862
	purpose	2K_dev_862
Smartwatches are becoming increasingly powerful	background	2K_dev_863
but limited input makes completing complex tasks impractical	background	2K_dev_863
	background	2K_dev_863
and found it was effective at producing reasonable drafts	finding	2K_dev_863
Our WearWrite system introduces a new paradigm not through new hardware or input methods	mechanism	2K_dev_863
but by directing a crowd to work on their behalf from their wearable device WearWrite lets authors give writing instructions and provide bits of expertise and big picture directions from their smartwatch	mechanism	2K_dev_863
while crowd workers actually write the document on more powerful devices	mechanism	2K_dev_863
We used this approach to write three academic papers	method	2K_dev_863
	method	2K_dev_863
for enabling a watch user to contribute to complex tasks	purpose	2K_dev_863
	purpose	2K_dev_863
In applied fields	background	2K_dev_864
practitioners hoping to apply causal structure learning or causal orientation algorithms face an important question : which independence test is appropriate for my data ? In the case of real-valued iid data	background	2K_dev_864
linear dependencies	background	2K_dev_864
and Gaussian error terms	background	2K_dev_864
partial correlation is sufficient	background	2K_dev_864
But once any of these assumptions is modified	background	2K_dev_864
the situation becomes more complex	background	2K_dev_864
We show how properly accounting for spatial and temporal variation can lead to more reasonable causal graphs	finding	2K_dev_864
We also show how highly structured data	finding	2K_dev_864
like images and text	finding	2K_dev_864
can be used in a causal inference framework using a novel structured input/output Gaussian process formulation	finding	2K_dev_864
Inspired by the success of Gaussian process regression for handling non-iid observations in a wide variety of areas and by the usefulness of the Hilbert-Schmidt Independence Criterion ( HSIC )	mechanism	2K_dev_864
a kernel-based independence test	mechanism	2K_dev_864
we propose a simple framework to address all of these issues : first	mechanism	2K_dev_864
use Gaussian process regression to control Second	mechanism	2K_dev_864
use HSIC	mechanism	2K_dev_864
We illustrate this on two classic datasets	method	2K_dev_864
one spatial	method	2K_dev_864
the other temporal	method	2K_dev_864
that are usually treated as iid	method	2K_dev_864
We demonstrate this idea on a dataset of translated sentences	method	2K_dev_864
trying to predict the source language	method	2K_dev_864
Kernel-based tests of independence have gained popularity to deal with nonlinear dependencies in recent years	purpose	2K_dev_864
but testing for conditional independence remains a challenging problem We highlight the important issue of non-iid observations : when data are observed in space	purpose	2K_dev_864
time	purpose	2K_dev_864
or on a network	purpose	2K_dev_864
nearby observations are likely to be similar	purpose	2K_dev_864
This fact biases estimates of dependence between variables	purpose	2K_dev_864
for certain variables and to obtain residuals	purpose	2K_dev_864
to test for independence	purpose	2K_dev_864
	purpose	2K_dev_864
	background	2K_dev_865
	finding	2K_dev_865
	mechanism	2K_dev_865
	method	2K_dev_865
	purpose	2K_dev_865
	background	2K_dev_866
	finding	2K_dev_866
	mechanism	2K_dev_866
	method	2K_dev_866
	purpose	2K_dev_866
	background	2K_dev_867
	finding	2K_dev_867
	mechanism	2K_dev_867
	method	2K_dev_867
	purpose	2K_dev_867
	background	2K_dev_868
	finding	2K_dev_868
An indoor ultrasonic location tracking system that can utilize standard audio speakers The method uses a communication scheme based on linearly increasing frequency modulated chirps in the audio bandwidth just above the human hearing frequency range where mobile devices are still sensitive The method uses gradual frequency and amplitude changes that minimize human perceivable ( psychoacoustic ) artifacts derived from the non-ideal impulse response of audio speakers	mechanism	2K_dev_868
Chirps also benefit from Pulse Compression	mechanism	2K_dev_868
which improves ranging resolution and resilience to both Doppler shifts and multi-path propagation that plague indoor environments	mechanism	2K_dev_868
The method supports the decoding of multiple unique identifier packets simultaneously	mechanism	2K_dev_868
A Time-Difference-of-Arrival pseudo-ranging technique allows for localization without explicit synchronization with the broadcasting infrastructure	mechanism	2K_dev_868
An alternate received signal strength indicator based localization technique allows less accurate localization at the benefit of sparser transmission infrastructure	mechanism	2K_dev_868
	mechanism	2K_dev_868
	method	2K_dev_868
to provide indoor ranging information to modern mobile devices like smartphones and tablets	purpose	2K_dev_868
	purpose	2K_dev_868
Online discussion forums are complex webs of overlapping subcommunities ( macrolevel structure	background	2K_dev_869
across threads ) in which users enact different roles depending on which subcommunity they are participating in within a particular time point ( microlevel structure	background	2K_dev_869
within threads )	background	2K_dev_869
	background	2K_dev_869
we demonstrate that our model can provide useful explanations of microlevel and macrolevel user presentation characteristics in different communities using the topics discovered from posts	finding	2K_dev_869
we show that our model does better than MMSB and LDA in predicting user reply structure within threads that the proposed active sub-network discovery model is stable and recovers the original parameters of the experimental setup with high probability	finding	2K_dev_869
we develop a scalable algorithm based on stochastic variational inference and leverage topic models ( LDA ) along with mixed membership stochastic block ( MMSB ) models	mechanism	2K_dev_869
	mechanism	2K_dev_869
We evaluate our model on three large-scale datasets	method	2K_dev_869
Cancer-ThreadStarter ( 22K users and 14	method	2K_dev_869
4K threads )	method	2K_dev_869
Cancer-NameMention ( 15	method	2K_dev_869
1K users and 12	method	2K_dev_869
4K threads ) and StackOverFlow ( 1	method	2K_dev_869
19 million users and 4	method	2K_dev_869
55 million threads ) Qualitatively	method	2K_dev_869
Quantitatively	method	2K_dev_869
In addition	method	2K_dev_869
we demonstrate via synthetic data experiments	method	2K_dev_869
This sub-network structure is implicit in massive collections of threads	purpose	2K_dev_869
To uncover this structure	purpose	2K_dev_869
	purpose	2K_dev_869
	background	2K_dev_870
	finding	2K_dev_870
	mechanism	2K_dev_870
	method	2K_dev_870
	purpose	2K_dev_870
	background	2K_dev_871
showing that rising 5th and 6th graders can understand the lawfulness of Kodu programs	finding	2K_dev_871
We also discuss some misconceptions students may develop about Kodu	finding	2K_dev_871
their causes	finding	2K_dev_871
and potential remedies	finding	2K_dev_871
	mechanism	2K_dev_871
We present an analysis of assessment data	method	2K_dev_871
This paper introduces reasoning about lawful behavior as an important computational thinking skill and provides examples from a novel introductory programming curriculum using Microsoft 's Kodu Game Lab	purpose	2K_dev_871
	purpose	2K_dev_871
While the version of LegionTools discussed here focuses on Amazon 's Mechanical Turk platform	background	2K_dev_872
it can be easily extended to other platforms as APIs become available	background	2K_dev_872
	background	2K_dev_872
	finding	2K_dev_872
We introduce LegionTools	mechanism	2K_dev_872
a toolkit and interface for managing large	mechanism	2K_dev_872
synchronous crowds of online workers for experiments This poster contributes the design and implementation of a state-of-the-art crowd management tool	mechanism	2K_dev_872
along with a publicly-available	mechanism	2K_dev_872
open-source toolkit that future system builders can use We describe the toolkit itself	mechanism	2K_dev_872
along with the underlying design rationale	mechanism	2K_dev_872
in order to make it clear to the community of system builders at UIST when and how this tool may be beneficial to their project	mechanism	2K_dev_872
We also describe initial deployments of the system in which workers were synchronously recruited to support real-time crowdsourcing systems	method	2K_dev_872
including the largest synchronous recruitment and routing of workers from Mechanical Turk that we are aware of	method	2K_dev_872
to coordinate synchronous crowds of online workers for their systems and studies	purpose	2K_dev_872
	purpose	2K_dev_872
Obtaining per-device energy consumption estimates in Non-Intrusive Load Monitoring ( NILM ) has proven to be a challenging task	background	2K_dev_873
	background	2K_dev_873
We show that reliable energy estimates can be obtained by crowdsourcing the results from using 1	finding	2K_dev_873
456 event detectors applied to the publicly available BLUED dataset	finding	2K_dev_873
	finding	2K_dev_873
We present Power Consumption Clustered Non-Intrusive Load Monitoring ( PCC-NILM )	mechanism	2K_dev_873
a relaxation of the NILM problem The Approximate Power Trace Decomposition Algorithm ( APTDA ) is presented as an unsupervised	mechanism	2K_dev_873
	method	2K_dev_873
that estimates the energy consumed by devices operating in different power ranges	purpose	2K_dev_873
data-driven solution to the PCC-NILM problem	purpose	2K_dev_873
Recently diversity-inducing regularization methods for latent variable models ( LVMs )	background	2K_dev_874
which encourage the components in LVMs to be diverse	background	2K_dev_874
have been studied	background	2K_dev_874
which demonstrates that the MAR can greatly improve the performance of NN and the empirical observations are in accordance with the theoretical analysis	finding	2K_dev_874
We use neural network ( NN ) as a model instance to carry out the study and the analysis shows that increasing the diversity of hidden units in NN would reduce estimation error and increase approximation error	mechanism	2K_dev_874
	mechanism	2K_dev_874
In addition to theoretical analysis	method	2K_dev_874
we also present empirical study	method	2K_dev_874
to address several issues involved in latent variable modeling : ( 1 ) how to capture long-tail patterns underlying data ; ( 2 ) how to reduce model complexity without sacrificing expressivity ; ( 3 ) how to improve the interpretability of learned patterns	purpose	2K_dev_874
While the effectiveness of diversity-inducing regularizers such as the mutual angular regularizer has been demonstrated empirically	purpose	2K_dev_874
a rigorous theoretical analysis of them is still missing	purpose	2K_dev_874
In this paper	purpose	2K_dev_874
we aim to bridge this gap and analyze how the mutual angular regularizer ( MAR ) affects the generalization performance of supervised LVMs	purpose	2K_dev_874
	purpose	2K_dev_874
	background	2K_dev_875
where we identify previously unknown heterogeneous changes in space and time	finding	2K_dev_875
	finding	2K_dev_875
We present a scalable Gaussian process model We use Random Kitchen Sink features to flexibly define a change surface in combination with expressive spectral mixture kernels to capture the complex statistical structure Finally	mechanism	2K_dev_875
through the use of novel methods for additive non-separable kernels	mechanism	2K_dev_875
we can scale the model to large datasets	mechanism	2K_dev_875
We demonstrate the model on numerical and real world data	method	2K_dev_875
including a large spatio-temporal disease dataset	method	2K_dev_875
for identifying and characterizing smooth multidimensional changepoints	purpose	2K_dev_875
and automatically learning changes in expressive covariance structure	purpose	2K_dev_875
	purpose	2K_dev_875
User-generated online reviews can play a significant role in the success of retail products	background	2K_dev_876
hotels	background	2K_dev_876
restaurants	background	2K_dev_876
etc	background	2K_dev_876
	background	2K_dev_876
where FRAUDEAGLE successfully reveals fraud-bots in a large online app review database	finding	2K_dev_876
We propose a fast and effective framework	mechanism	2K_dev_876
FRAUDEAGLE Our method has several advantages : ( 1 ) it exploits the network effect among reviewers and products	mechanism	2K_dev_876
unlike the vast majority of existing methods that focus on review text or behavioral analysis	mechanism	2K_dev_876
( 2 ) it consists of two complementary steps ; scoring users and reviews for fraud detection	mechanism	2K_dev_876
and grouping for visualization and sensemaking	mechanism	2K_dev_876
( 3 ) it operates in a completely unsupervised fashion requiring no labeled data	mechanism	2K_dev_876
while still incorporating side information if available	mechanism	2K_dev_876
and ( 4 ) it is scalable to large datasets as its run time grows linearly with network size	mechanism	2K_dev_876
	mechanism	2K_dev_876
We demonstrate the effectiveness of our framework on syntheticand real datasets ;	method	2K_dev_876
However	purpose	2K_dev_876
review systems are often targeted by opinion spammers who seek to distort the perceived quality of a product by creating fraudulent reviews	purpose	2K_dev_876
for spotting fraudsters and fake reviews in online review datasets	purpose	2K_dev_876
Networked or telematic music performances take many forms	background	2K_dev_877
ranging from small laptop ensembles using local area networks to long-distance musical collaborations using audio and video links	background	2K_dev_877
Two important concerns for any networked performance are :	background	2K_dev_877
which achieved a coordinated performance involving 68 computer musicians	finding	2K_dev_877
each with their own connection to the network	finding	2K_dev_877
are described	finding	2K_dev_877
A recent project	mechanism	2K_dev_877
the Global Net Orchestra	mechanism	2K_dev_877
is described	mechanism	2K_dev_877
the technical aspects of the project	mechanism	2K_dev_877
	method	2K_dev_877
( 1 ) what is the role of communication in the music performance ? In particular	purpose	2K_dev_877
what are the esthetic and pragmatic justifications for performing music at a distance	purpose	2K_dev_877
and ( 2 ) how are the effects of communication latency ameliorated or incorporated into the performance ? In addition to addressing these two concerns	purpose	2K_dev_877
	background	2K_dev_878
	finding	2K_dev_878
In this demo we present Perseus	mechanism	2K_dev_878
a large-scale system by supporting the coupled summarization of graph properties and structures	mechanism	2K_dev_878
guiding attention to outliers	mechanism	2K_dev_878
and allowing the user to interactively explore normal and anomalous node behaviors Specifically	mechanism	2K_dev_878
Perseus provides for the following operations : 1 ) ( e	mechanism	2K_dev_878
g	mechanism	2K_dev_878
	mechanism	2K_dev_878
degree	mechanism	2K_dev_878
PageRank	mechanism	2K_dev_878
real eigenvectors ) by performing scalable	mechanism	2K_dev_878
offline batch processing on Hadoop ; 2 ) ; 3 ) ; 4 )	mechanism	2K_dev_878
by incrementally revealing its neighbors	mechanism	2K_dev_878
In our demonstration	method	2K_dev_878
we invite the audience to interact with Perseus to explore a variety of multi-million-edge social networks including a Wikipedia vote network	method	2K_dev_878
a friendship/foeship network in Slashdot	method	2K_dev_878
and a trust network based on the consumer review website Epinions	method	2K_dev_878
com	method	2K_dev_878
Given a large graph with several millions or billions of nodes and edges	purpose	2K_dev_878
such as a social network	purpose	2K_dev_878
how can we explore it efficiently and find out what is in the data ? that enables the comprehensive analysis of large graphs It automatically extracts graph invariants It interactively visualizes univariate and bivariate distributions for those invariants It summarizes the properties of the nodes that the user selects It efficiently visualizes the induced subgraph of a selected node and its neighbors	purpose	2K_dev_878
The long-term goal of connecting scales in biological simulation can be facilitated by scale-agnostic methods	background	2K_dev_879
show that although WE has important limitations	finding	2K_dev_879
it can achieve performance significantly exceeding standard parallel simulationby orders of magnitude for some observables	finding	2K_dev_879
	finding	2K_dev_879
We demonstrate that the weighted ensemble ( WE ) strategy	mechanism	2K_dev_879
initially developed for molecular simulations The WE approach runs an ensemble of parallel trajectories with assigned weights and uses a statistical resampling strategy of replicating and pruning trajectories to focus computational effort on difficult-to-sample regions	mechanism	2K_dev_879
The method can also generate unbiased estimates of non-equilibrium and equilibrium observables	mechanism	2K_dev_879
sometimes with significantly less aggregate computing time than would be possible using standard parallelization Here	mechanism	2K_dev_879
we use WE to orchestrate particle-based kinetic Monte Carlo simulations	mechanism	2K_dev_879
which include spatial geometry ( e	mechanism	2K_dev_879
g	mechanism	2K_dev_879
	mechanism	2K_dev_879
of organelles	mechanism	2K_dev_879
plasma membrane ) and biochemical interactions among mobile molecular species	mechanism	2K_dev_879
We study a series of models exhibiting spatial	method	2K_dev_879
temporal and biochemical complexity and	method	2K_dev_879
	purpose	2K_dev_879
applies effectively to spatially resolved cell-scale simulations	purpose	2K_dev_879
	purpose	2K_dev_879
Besides the application to password generation	background	2K_dev_880
our proposed Human Usability Model ( HUM ) will have other applications	background	2K_dev_880
	background	2K_dev_880
We show that our password generation methods are humanly computable and	finding	2K_dev_880
to a well-defined extent	finding	2K_dev_880
machine uncrackable	finding	2K_dev_880
Then	mechanism	2K_dev_880
motivated by the special case of password creation	mechanism	2K_dev_880
we propose a collection of well-defined password-generation methods	mechanism	2K_dev_880
For the proof of security	mechanism	2K_dev_880
we posit that password generation methods are public	mechanism	2K_dev_880
but that the humans privately chosen seed is not	mechanism	2K_dev_880
and that the adversary will have observed only a few input-output pairs	mechanism	2K_dev_880
	mechanism	2K_dev_880
	method	2K_dev_880
What can a human compute in his/her head that a powerful adversary can not infer ? To answer this question	purpose	2K_dev_880
we define a model of human computation and a measure of security	purpose	2K_dev_880
	purpose	2K_dev_880
The spatial pyramid and its variants have been very popular feature models due to their success in balancing spatial location encoding and spatial invariance	background	2K_dev_881
results show that	finding	2K_dev_881
despite its simplicity	finding	2K_dev_881
this method achieves comparable or better results than spatio-temporal pyramid	finding	2K_dev_881
This paper introduces the space-time extended descriptor	mechanism	2K_dev_881
a simple but efficient alternative way Instead of only coding motion information and leaving the spatio-temporal location to be represented at the pooling stage	mechanism	2K_dev_881
location information is used as part of the encoding step	mechanism	2K_dev_881
This method is a much more effective and efficient location encoding method as compared to the fixed grid model because it avoids the danger of over committing to artificial boundaries and its dimension is relatively low	mechanism	2K_dev_881
Experimental on several benchmark datasets	method	2K_dev_881
We address the problem of generating video features for action recognition Although it seems straightforward to extend spatial pyramid to the temporal domain ( spatio-temporal pyramid )	purpose	2K_dev_881
the large spatio-temporal diversity of unconstrained videos and the resulting significantly higher dimensional representations make it less appealing to include the spatio-temporal location into the video features	purpose	2K_dev_881
	purpose	2K_dev_881
Suppose you are a teacher	background	2K_dev_882
and have to convey a set of object-property pairs ( 'lions eat meat '	background	2K_dev_882
or 'aspirin is a blood-thinner ' )	background	2K_dev_882
A good teacher will convey a lot of information	background	2K_dev_882
with little effort on the student side	background	2K_dev_882
Specifically	background	2K_dev_882
given a list of objects ( like animals or medical drugs ) and their associated properties	background	2K_dev_882
what is the best and most intuitive way to convey this information to the student	background	2K_dev_882
without the student being overwhelmed ? A related	background	2K_dev_882
harder problem is : how can we assign a numerical score to each lesson plan ( i	background	2K_dev_882
e	background	2K_dev_882
way of conveying information ) ?	background	2K_dev_882
it is effective achieving excellent results on real data	finding	2K_dev_882
both with respect to our proposed metric	finding	2K_dev_882
but also with respect to encoding length	finding	2K_dev_882
demonstrate the effectiveness of HYTRA	finding	2K_dev_882
	finding	2K_dev_882
and we provide a metric for comparing different approaches based on information theory	mechanism	2K_dev_882
We also design a multi-pronged algorithm	mechanism	2K_dev_882
HYTRA	mechanism	2K_dev_882
for this problem	mechanism	2K_dev_882
Our proposed HYTRA is scalable ( near-linear in the dataset size )	mechanism	2K_dev_882
and it is intuitive	mechanism	2K_dev_882
conforming to well-known educational principles	mechanism	2K_dev_882
such as grouping related concepts	mechanism	2K_dev_882
and `` comparing '' and `` contrasting ''	mechanism	2K_dev_882
	mechanism	2K_dev_882
Experiments on real and synthetic datasets	method	2K_dev_882
Here	purpose	2K_dev_882
we give a formal definition of this problem of forming learning units	purpose	2K_dev_882
The engineering analysis for determining the remaining seismic capacity of buildings following earthquakes requires performing structural calculations	background	2K_dev_883
observations of the actual damage	background	2K_dev_883
and applying extensive engineering judgment	background	2K_dev_883
Additionally	background	2K_dev_883
the analysis should often be performed under stringent time requirements	background	2K_dev_883
The results of the study can be used to develop formal representation of damage information in information models and potentially allow better allocation of data collection time in the field	background	2K_dev_883
	background	2K_dev_883
The study showed that the information required to represent the damaged conditions can be grouped under five broad categories and using seventeen damage parameters	finding	2K_dev_883
showed that the damage parameters have varying degrees of importance	finding	2K_dev_883
	finding	2K_dev_883
	mechanism	2K_dev_883
The damage descriptions for seven common damage modes of structural walls were studied by employing the affinity diagramming method	method	2K_dev_883
A sensitivity analysis	method	2K_dev_883
This study identifies the information requirements for representing the damage information and performing the visual damage assessment of structural walls	purpose	2K_dev_883
Differential dynamic logic is a logic for specifying and verifying safety	background	2K_dev_884
liveness	background	2K_dev_884
and other properties about models of cyber-physical systems	background	2K_dev_884
Theorem provers based on differential dynamic logic have been used to verify safety properties for models of self-driving cars and collision avoidance protocols for aircraft	background	2K_dev_884
Examples include : an unambiguous separation between proof checking and proof search	background	2K_dev_884
the ability to extract program traces corresponding to counter-examples	background	2K_dev_884
and synthesis of surely-live deterministic programs from liveness proofs for nondeterministic programs	background	2K_dev_884
	finding	2K_dev_884
This paper presents a differential dynamic logic The resulting logic extends both the syntax and semantics of differential dynamic logic with proof terms -- syntactic representations of logical deductions the logic allows equivalence rewriting deep within formulas and supports both uniform renaming and uniform substitutions	mechanism	2K_dev_884
	method	2K_dev_884
Unfortunately	purpose	2K_dev_884
these theorem provers do not have explicit proof terms	purpose	2K_dev_884
which makes the implementation of a number of important features unnecessarily complicated without soundness-critical and extra-logical extensions to the theorem prover	purpose	2K_dev_884
with such an explicit representation of proofs	purpose	2K_dev_884
To support axiomatic theorem proving	purpose	2K_dev_884
	purpose	2K_dev_884
	background	2K_dev_885
	finding	2K_dev_885
	mechanism	2K_dev_885
	method	2K_dev_885
	purpose	2K_dev_885
	background	2K_dev_886
and observe significant speedups over competing state-of-the-art ( and synchronous ) methods	finding	2K_dev_886
the former on shared memory machines with mini-batching	mechanism	2K_dev_886
and the latter in a delayed update framework	mechanism	2K_dev_886
In both cases	mechanism	2K_dev_886
we perform computations asynchronously whenever possible	mechanism	2K_dev_886
We assume block-separable constraints as in Block-Coordinate Frank-Wolfe ( BCFW ) method ( Lacoste-Julien et al	mechanism	2K_dev_886
	mechanism	2K_dev_886
2013 )	mechanism	2K_dev_886
but our analysis subsumes BCFW and reveals problemdependent quantities that govern the speedups of our methods over BCFW	mechanism	2K_dev_886
A notable feature of our algorithms is that they do not depend on worst-case bounded delays	mechanism	2K_dev_886
but only ( mildly ) on expected delays	mechanism	2K_dev_886
making them robust to stragglers and faulty worker threads	mechanism	2K_dev_886
	mechanism	2K_dev_886
We present experiments on structural SVM and Group Fused Lasso	method	2K_dev_886
	method	2K_dev_886
We study parallel and distributed Frank-Wolfe algorithms ;	purpose	2K_dev_886
	background	2K_dev_887
demonstrate that our approach significantly outperforms the compared baselines	finding	2K_dev_887
	finding	2K_dev_887
In this work	mechanism	2K_dev_887
we introduce Video Question Answering in temporal domain We present an encoder-decoder approach using Recurrent Neural Networks to learn temporal structures of videos and introduce a dual-channel ranking loss to answer multiple-choice questions	mechanism	2K_dev_887
We explore approaches for finer understanding of video content using question form of `` fill-in-the-blank ''	method	2K_dev_887
and managed to collect 109	method	2K_dev_887
895 video clips with duration over 1	method	2K_dev_887
000 hours from TACoS	method	2K_dev_887
MPII-MD	method	2K_dev_887
MEDTest 14 datasets	method	2K_dev_887
while the corresponding 390	method	2K_dev_887
744 questions are generated from annotations Extensive experiments	method	2K_dev_887
to infer the past	purpose	2K_dev_887
describe the present and predict the future	purpose	2K_dev_887
	purpose	2K_dev_887
Mining knowledge from a multimedia database has received increasing attentions recently since huge repositories are made available by the development of the Internet	background	2K_dev_888
	background	2K_dev_888
	finding	2K_dev_888
present a framework where image annotation and image retrieval are considered as the special cases Specifically	mechanism	2K_dev_888
the multimodal data mining problem can be formulated as a structured prediction problem where we learn the mapping from an input to the structured and interdependent output variables	mechanism	2K_dev_888
we propose a new max margin structure learning approach called Enhanced Max Margin Learning ( EMML ) framework	mechanism	2K_dev_888
which is much more efficient with a much faster convergence rate than the existing max margin learning methods	mechanism	2K_dev_888
as verified through empirical evaluations	mechanism	2K_dev_888
Furthermore	mechanism	2K_dev_888
we apply EMML framework that is highly scalable in the sense that the query response time is independent of the database scale The EMML framework allows an efficient multimodal data mining query in a very large scale multimedia database	mechanism	2K_dev_888
and excels many existing multimodal data mining methods in the literature that do not scale up at all	mechanism	2K_dev_888
The performance comparison with a state-of-the-art multimodal data mining method is reported for the real-world image databases	method	2K_dev_888
In this article	purpose	2K_dev_888
we exploit the relations among different modalities in a multimedia database and for general multimodal data mining problem In addition	purpose	2K_dev_888
in order to reduce the demanding computation to develop an effective and efficient solution to the multimodal data mining problem	purpose	2K_dev_888
	background	2K_dev_889
and show its use- fulness for nontrivial temporal properties of hybrid systems solving an open problem formulated in previous work	finding	2K_dev_889
The differential temporal dynamic logic dTL 2 is a logic It combines differential dynamic logic with temporal logic The logic dTL 2 supports some linear time temporal properties of LTL	mechanism	2K_dev_889
It extends differential temporal dynamic logic dTL with nested temporalities	mechanism	2K_dev_889
We take particular care to handle the case of alternating universal dynamic and existential temporal modalities and its dual	mechanism	2K_dev_889
	mechanism	2K_dev_889
We provide a semantics and a proof system for the logic dTL 2	method	2K_dev_889
	method	2K_dev_889
to specify temporal properties of hybrid systems	purpose	2K_dev_889
to reason about the intermediate states reached by a hybrid system	purpose	2K_dev_889
	purpose	2K_dev_889
The interest in distributed control methods for power systems is motivated by the need for scalable solutions to handle the coordination of an increasing number of distributed resources	background	2K_dev_890
	background	2K_dev_890
	finding	2K_dev_890
This paper presents a fully distributed multilevel method Our proposed approach constitutes a distributed iterative mechanism to solve the first order optimality conditions of the DC-OPF problem using the fact that optimality conditions involve local variable couplings The proposed distributed structure requires each bus to update a few local variables and exchange information with neighboring buses Our multilevel distributed approach distributes the computation at several levels	mechanism	2K_dev_890
i	mechanism	2K_dev_890
e	mechanism	2K_dev_890
	mechanism	2K_dev_890
nodes	mechanism	2K_dev_890
subareas and areas	mechanism	2K_dev_890
It allows for synchronous information exchanges	mechanism	2K_dev_890
i	mechanism	2K_dev_890
e	mechanism	2K_dev_890
	mechanism	2K_dev_890
after each iteration	mechanism	2K_dev_890
at the nodal level and asynchronous communication	mechanism	2K_dev_890
i	mechanism	2K_dev_890
e	mechanism	2K_dev_890
	mechanism	2K_dev_890
after multiple iterations	mechanism	2K_dev_890
between subareas and areas	mechanism	2K_dev_890
To define meaningful subareas	mechanism	2K_dev_890
we are using a graph theoretic partitioning method derived from an epidemics model	mechanism	2K_dev_890
	mechanism	2K_dev_890
We compare the performance of the proposed partitioning method over a random partitioning method using the IEEE 118-bus system	method	2K_dev_890
	method	2K_dev_890
to solve the DC Optimal Power Flow problem ( DC-OPF )	purpose	2K_dev_890
	background	2K_dev_891
Preliminary results show that our method allows us to pinpoint locations of co-behavior for traffic in the Manhattan road network	finding	2K_dev_891
	finding	2K_dev_891
We present a spectral analysis of taxi movement based on the graph Fourier transform	mechanism	2K_dev_891
which necessitates the spectral decomposition of a large directed	mechanism	2K_dev_891
sparse matrix Important considerations toward handling this matrix are discussed	mechanism	2K_dev_891
	method	2K_dev_891
We work with the `` NYC Taxi Data Set	purpose	2K_dev_891
'' a historical repository of 750 million rides of taxi medallions over a period of four years ( 20102013 )	purpose	2K_dev_891
This data set provides rich ( batch ) information on the movements in an urban network as its citizens go about their daily life	purpose	2K_dev_891
Plug-meters benefit many grid and building-level energy management applications like automated load control and load scheduling However	background	2K_dev_892
installing and maintaining large and/or long term deployments of such meters requires assignment and updating of the identity ( labels ) of electrical loads connected to them	background	2K_dev_892
	background	2K_dev_892
	finding	2K_dev_892
	mechanism	2K_dev_892
Specifically	method	2K_dev_892
we carry out tests on PLAID	method	2K_dev_892
a publicly available high-frequency dataset of hundreds of residential appliances By examining how the classification accuracy changes with sampling frequency	method	2K_dev_892
we also explore the computational complexity of these techniques	method	2K_dev_892
Although the literature on electricity disaggregation and appliance identification is extensive	purpose	2K_dev_892
there is no consensus on the generalizability of the proposed solutions	purpose	2K_dev_892
especially with respect to the features that are extracted from voltage and current measurements In this paper	purpose	2K_dev_892
we begin to address this problem by comparing the discriminative power of commonly used features	purpose	2K_dev_892
to understand the feasibility and design of a hardware setup that can perform these calculations in near real-time	purpose	2K_dev_892
	purpose	2K_dev_892
Many big data applications collect large numbers of time series A first task in analyzing such data is to find a low- dimensional representation	background	2K_dev_893
a graph	background	2K_dev_893
which faithfully describes relations among the measured processes and through time	background	2K_dev_893
The processes are often affected by a relatively small number of unmeasured trends	background	2K_dev_893
	finding	2K_dev_893
This paper presents a computationally tractable algorithm from the collected data	mechanism	2K_dev_893
	mechanism	2K_dev_893
The algorithm is demonstrated on simulated time series datasets	method	2K_dev_893
for jointly estimating these trends and underlying weighted	purpose	2K_dev_893
directed graph structure	purpose	2K_dev_893
Metering of electricity consumption	background	2K_dev_894
both at the building-level and appliance-level	background	2K_dev_894
provides stakeholders like residents	background	2K_dev_894
facility managers	background	2K_dev_894
building owners	background	2K_dev_894
etc	background	2K_dev_894
with information requisite to engage in energy efficient practices	background	2K_dev_894
	background	2K_dev_894
find that the inferred energy values have an average error of 10	finding	2K_dev_894
9 %	finding	2K_dev_894
	finding	2K_dev_894
In this paper	mechanism	2K_dev_894
we utilize a framework that performs the step of energy estimation for load disaggregation The framework combines data from these contactless sensors and aggregate metering	mechanism	2K_dev_894
in order to virtually meter the electricity consumption of specific appliances The solution requires minimal calibration	mechanism	2K_dev_894
and is easily performed using commercially available sensors	mechanism	2K_dev_894
We test it in a commercial building with 6 appliances that are monitored using magnetic field sensors and	method	2K_dev_894
Currently available solutions for appliance-level energy metering require the installation of plug-through power meters ; this is often difficult and costly for appliances with inaccessible wires/outlets	purpose	2K_dev_894
or for appliances that draw large amounts of current	purpose	2K_dev_894
in order to substitute the need of plug-level sensors with cheap and easily deployable contactless sensors ( e	purpose	2K_dev_894
g	purpose	2K_dev_894
	purpose	2K_dev_894
light	purpose	2K_dev_894
sound	purpose	2K_dev_894
magnetic field sensors )	purpose	2K_dev_894
Previous work has demonstrated the attractiveness of CMOS-PC integration to realize high-performance reconfigurable RF front-end circuits [ 1-2 Four-terminal PC switches with small form factor have been recently shown to possess close-to-ideal properties of an RF switch : a high OFF/ON resistance ratio and extremely high figure-of-merit for RF switches ( FCO 0 1/ ( 2RONCOFF ) ) [ 3-4 ]	background	2K_dev_895
	background	2K_dev_895
	finding	2K_dev_895
This paper presents the first reported in-situ reconfiguration of a narrowband CMOS low noise amplifier ( LNA ) using a GeTe phase-change ( PC ) switch In this work	mechanism	2K_dev_895
we present a robust realization of a reconfigurable 3/5 GHz LNA designed and fabricated in a 0	mechanism	2K_dev_895
13 m CMOS process and flip-chip integrated with a four-terminal PC switch fabricated using an in-house process	mechanism	2K_dev_895
	mechanism	2K_dev_895
	method	2K_dev_895
over two widely separated frequency bands	purpose	2K_dev_895
Devices can be made more intelligent if they have the ability to sense their surroundings and physical configuration	background	2K_dev_896
and demonstrates high accuracy	finding	2K_dev_896
	finding	2K_dev_896
Instead	mechanism	2K_dev_896
we use speakers and microphones already present in a wide variety of devices Our technique sweeps through a range of inaudible frequencies and measures the intensity of reflected sound to deduce information about the immediate environment	mechanism	2K_dev_896
chiefly the materials and geometry of proximate surfaces	mechanism	2K_dev_896
	mechanism	2K_dev_896
We offer several example uses	method	2K_dev_896
two of which we implemented as self-contained demos	method	2K_dev_896
and conclude with an evaluation that quantifies their performance	method	2K_dev_896
However	purpose	2K_dev_896
adding extra	purpose	2K_dev_896
special purpose sensors increases size	purpose	2K_dev_896
price and build complexity	purpose	2K_dev_896
to open new sensing opportunities	purpose	2K_dev_896
People are more creative at solving difficult design problems when they use relevant examples from outside of the problem s domain as inspirations	background	2K_dev_897
Crowd workers drawing inspirations from the distant domains produced more creative solutions to the original problem than did those who sought inspiration on their own	finding	2K_dev_897
or drew inspiration from domains closer to or not sharing structural correspondence with the original problem	finding	2K_dev_897
In this paper	mechanism	2K_dev_897
we demonstrate an approach in which non-experts identify domains that have the potential	mechanism	2K_dev_897
We report an empirical study demonstrating how crowds can generate domains of expertise and that showing people an abstract representation rather than the original problem helps them identify more distant domains	method	2K_dev_897
However	purpose	2K_dev_897
finding such outside-the-box inspirations is difficult	purpose	2K_dev_897
particularly in large idea repositories such as the web	purpose	2K_dev_897
because without guidance people select domains to search based on surface similarity to the problem s domain	purpose	2K_dev_897
to yield useful and non-obvious inspirations for solutions	purpose	2K_dev_897
To study signals on networks	background	2K_dev_898
to detect epidemics	background	2K_dev_898
or to predict blackouts	background	2K_dev_898
we need to understand network topology and its impact on the behavior of network processes	background	2K_dev_898
The high dimensionality of large networks presents significant analytical and computational challenges ; only specific network structures have been studied without approximation	background	2K_dev_898
	background	2K_dev_898
	finding	2K_dev_898
We introduce the network effect ratio	mechanism	2K_dev_898
	method	2K_dev_898
We consider the impact of network topology on the limiting behavior of a dynamical process obeying the stochastic rules of SIS ( susceptible-infected-susceptible ) epidemics using the scaled SIS process which captures the preference of individual agents versus the preference of society ( i	purpose	2K_dev_898
e	purpose	2K_dev_898
	purpose	2K_dev_898
network ) and investigate its effects	purpose	2K_dev_898
3D-stacked integration of DRAM and logic layers using through-silicon via ( TSV ) technology has given rise to a new interpretation of near-data processing ( NDP ) concepts that were proposed decades ago	background	2K_dev_899
However	background	2K_dev_899
processing capability within the stack is limited by stringent power and thermal constraints	background	2K_dev_899
Simple processing mechanisms with intensive memory accesses	background	2K_dev_899
such as data reorganization	background	2K_dev_899
are an effective means of exploiting 3D stacking-based NDP	background	2K_dev_899
Data reorganization handled completely in memory improves the host processor 's memory access performance	background	2K_dev_899
	background	2K_dev_899
	finding	2K_dev_899
This article details data reorganization performed in parallel with host memory accesses	mechanism	2K_dev_899
providing mechanisms	mechanism	2K_dev_899
	method	2K_dev_899
However	purpose	2K_dev_899
in-memory data reorganization performed in parallel with host memory accesses raises issues	purpose	2K_dev_899
including interference	purpose	2K_dev_899
bandwidth allocation	purpose	2K_dev_899
and coherence	purpose	2K_dev_899
Previous work has mainly focused on performing data reorganization while blocking host accesses to address host/NDP interference	purpose	2K_dev_899
flexible bandwidth allocation	purpose	2K_dev_899
and in-memory coherence	purpose	2K_dev_899
	purpose	2K_dev_899
How do people interact with their Facebook wall ? At a high level	background	2K_dev_900
this question captures the essence of our work	background	2K_dev_900
While most prior efforts focus on Twitter	background	2K_dev_900
the much fewer Facebook studies focus on the friendship graph or are limited by the amount of users or the duration of the study	background	2K_dev_900
Our work provides a solid step towards a systematic and quantitative wall-centric profiling of Facebook user activity	background	2K_dev_900
Our key results can be summarized in the following points	finding	2K_dev_900
First	finding	2K_dev_900
we find that many wall activities	finding	2K_dev_900
including number of posts	finding	2K_dev_900
number of likes	finding	2K_dev_900
number of posts of type photo	finding	2K_dev_900
etc	finding	2K_dev_900
	finding	2K_dev_900
can be described by the PowerWall distribution	finding	2K_dev_900
What is more surprising is that most of these distributions have similar slope	finding	2K_dev_900
with a value close to 1 ! Second	finding	2K_dev_900
we show how our patterns and metrics can help us spot surprising behaviors and anomalies	finding	2K_dev_900
For example	finding	2K_dev_900
we find a user posting every two days	finding	2K_dev_900
exactly the same count of posts ; another user posting at midnight	finding	2K_dev_900
with no other activity before or after	finding	2K_dev_900
We propose PowerWall	mechanism	2K_dev_900
a lesser known heavy-tailed distribution	mechanism	2K_dev_900
We conduct an extensive study of roughly 7K users over three years during four month intervals each year	method	2K_dev_900
In this work	purpose	2K_dev_900
we model Facebook user behavior : we analyze the wall activities of users focusing on identifying common patterns and surprising phenomena to fit our data	purpose	2K_dev_900
Biomedical scientists have invested significant effort into making it easy to perform lots of experiments quickly and cheaply	background	2K_dev_901
These high throughput methods are the workhorses of modern systems biology efforts	background	2K_dev_901
However	background	2K_dev_901
we simply can not perform an experiment for every possible combination of different cell type	background	2K_dev_901
genetic mutation and other conditions	background	2K_dev_901
In practice this has led researchers to either exhaustively test a few conditions or targets	background	2K_dev_901
or to try to pick the experiments that best allow a particular problem to be explored	background	2K_dev_901
But which experiments should we pick ? The ones we think we can predict the outcome of accurately	background	2K_dev_901
the ones for which we are uncertain what the results will be	background	2K_dev_901
or a combination of the two ? Humans are not particularly well suited for this task because it requires reasoning about many possible outcomes at the same time	background	2K_dev_901
However	background	2K_dev_901
computers are much better at handling statistics for many experiments	background	2K_dev_901
and machine learning algorithms allow computers to learn how to make predictions and decisions based on the data theyve previously processed The next challenge is to apply these methods to reduce the cost of achieving the goals of large projects	background	2K_dev_901
such as The Cancer Genome Atlas	background	2K_dev_901
showed that the active learning approach outperforms strategies a human might use	finding	2K_dev_901
even when the potential outcomes of individual experiments are not known beforehand	finding	2K_dev_901
	finding	2K_dev_901
Now	mechanism	2K_dev_901
Naik et al	mechanism	2K_dev_901
have performed cell biology experiments in which experiments were chosen by an active learning algorithm and then performed using liquid handling robots and an automated microscope	mechanism	2K_dev_901
The key idea behind the approach is that you learn more from an experiment you cant predict ( or that you predicted incorrectly ) than from just confirming your confident predictions	mechanism	2K_dev_901
The results of the robot-driven experiments	method	2K_dev_901
Previous computer simulations showed that a machine learning approach termed active learning could do a good job of picking a series of experiments to perform in order to efficiently learn a model that predicts the results of experiments that were not done	purpose	2K_dev_901
	purpose	2K_dev_901
In large-scale complex networks	background	2K_dev_902
the underlying nonlinear dynamical system is high-dimensional and performing qualitative analysis of the differential equation becomes prohibitive	background	2K_dev_902
The study of such systems is often deferred to numerical simulations or local analysis about equilibrium points of the system	background	2K_dev_902
	background	2K_dev_902
	finding	2K_dev_902
in a network modeled by the classical logistic ordinary differential equations In this paper	mechanism	2K_dev_902
we extend the work developed in [ 1 ]	mechanism	2K_dev_902
the weaker strain dies out regardless of the initial conditions if its maximum in-flow rate of infection across nodes is smaller than the minimum in-flow rate of the stronger strain	mechanism	2K_dev_902
We bound any solution of the logistic ODE by one- dimensional solutions over certain homogeneous networks	mechanism	2K_dev_902
for which the system is well understood Our global stability approach via bounds readily applies to the discrete-time logistic model counterpart	mechanism	2K_dev_902
	mechanism	2K_dev_902
	method	2K_dev_902
We study the spread of two strains of virus competing for space to formally establish a simple sufficient condition for ( exponentially fast ) survival of the fittest in a bi-layer weighted digraph :	purpose	2K_dev_902
The preferred treatment for kidney failure is a transplant ; however	background	2K_dev_903
demand for donor kidneys far outstrips supply	background	2K_dev_903
Kidney exchange	background	2K_dev_903
an innovation where willing but incompatible patient-donor pairs can exchange organsvia barter cycles and altruist-initiated chainsprovides a life-saving alternative	background	2K_dev_903
Typically	background	2K_dev_903
fielded exchanges act myopically	background	2K_dev_903
considering only the current pool of pairs when planning the cycles and chains	background	2K_dev_903
It results in higher values of the objective it yields better solutions for the efficient objective ( which does not incorporate equity ) than traditional myopic matching that uses the efficiency objective	finding	2K_dev_903
Motivated by our experience running the computational side of a large nationwide kidney exchange	mechanism	2K_dev_903
we present FUTURE-MATCH	mechanism	2K_dev_903
a framework FUTUREMATCH takes as input a high-level objective ( e	mechanism	2K_dev_903
g	mechanism	2K_dev_903
	mechanism	2K_dev_903
`` maximize graft survival of transplants over time '' ) decided on by experts	mechanism	2K_dev_903
then automatically ( i ) learns based on data how to make this objective concrete and ( ii ) learns the `` means '' to accomplish this goala task	mechanism	2K_dev_903
in our experience	mechanism	2K_dev_903
that humans handle poorly It uses data from all live kidney transplants in the US since 1987 to learn the quality of each possible match ; it then learns the potentials of elements of the current input graph offline ( e	mechanism	2K_dev_903
g	mechanism	2K_dev_903
	mechanism	2K_dev_903
potentials of pairs based on features such as donor and patient blood types )	mechanism	2K_dev_903
translates these to weights	mechanism	2K_dev_903
and performs a computationally feasible batch matching that incorporates dynamic	mechanism	2K_dev_903
failure-aware considerations through the weights	mechanism	2K_dev_903
	mechanism	2K_dev_903
We validate FUTUREMATCH on real fielded exchange data Furthermore	method	2K_dev_903
even under economically inefficient objectives that enforce equity	method	2K_dev_903
Yet kidney exchange is inherently dynamic	purpose	2K_dev_903
with participants arriving and departing	purpose	2K_dev_903
Also	purpose	2K_dev_903
many planned exchange transplants do not go to surgery due to various failures	purpose	2K_dev_903
So	purpose	2K_dev_903
it is important to consider the future when matching	purpose	2K_dev_903
for learning to match in a general dynamic model	purpose	2K_dev_903
	purpose	2K_dev_903
Humans rely on eye gaze and hand manipulations extensively in their everyday activities	background	2K_dev_904
Most often	background	2K_dev_904
users gaze at an object to perceive it and then use their hands to manipulate it	background	2K_dev_904
results show that gaze+gesture can outperform systems using gaze or gesture alone	finding	2K_dev_904
and in general	finding	2K_dev_904
approach the performance of `` gold standard '' input systems	finding	2K_dev_904
such as the mouse and trackpad	finding	2K_dev_904
We propose applying a multimodal	mechanism	2K_dev_904
gaze plus free-space gesture approach We show the input methods are highly complementary	mechanism	2K_dev_904
mitigating issues of imprecision and limited expressivity in gaze-alone systems	mechanism	2K_dev_904
and issues of targeting speed in gesture-alone systems	mechanism	2K_dev_904
We extend an existing interaction taxonomy that naturally divides the gaze+gesture interaction space	mechanism	2K_dev_904
which we then populate with a series of example interaction techniques to illustrate the character and utility of each method	mechanism	2K_dev_904
	mechanism	2K_dev_904
We contextualize these interaction techniques in three example scenarios	method	2K_dev_904
In our user study	method	2K_dev_904
we pit our approach against five contemporary approaches ;	method	2K_dev_904
to enable rapid	purpose	2K_dev_904
precise and expressive touch-free interactions	purpose	2K_dev_904
	purpose	2K_dev_904
	background	2K_dev_905
	finding	2K_dev_905
	mechanism	2K_dev_905
	method	2K_dev_905
	purpose	2K_dev_905
There is often a large disparity between the size of a game we wish to solve and the size of the largest instances solvable by the best algorithms ; for example	background	2K_dev_906
a popular variant of poker has about 10165 nodes in its game tree	background	2K_dev_906
while the currently best approximate equilibrium-finding algorithms scale to games with around 1012 nodes	background	2K_dev_906
In order to approximate equilibrium strategies in these games	background	2K_dev_906
the leading approach is to create a sufficiently small strategic approximation of the full game	background	2K_dev_906
called an abstraction	background	2K_dev_906
and to solve that smaller game instead	background	2K_dev_906
The leading abstraction algorithm for imperfect-information games generates abstractions that have imperfect recall and are distribution aware	background	2K_dev_906
using k-means with the earth mover 's distance metric to cluster similar states together	background	2K_dev_906
A distribution-aware abstraction groups states together at a given round if their full distributions over future strength are similar ( as opposed to	background	2K_dev_906
for example	background	2K_dev_906
just the expectation of their strength )	background	2K_dev_906
The leading algorithm considers distributions over future strength at the final round of the game	background	2K_dev_906
show that our algorithm improves performance over the previously best approach	finding	2K_dev_906
	finding	2K_dev_906
We present the first algorithm using earth mover 's distance	mechanism	2K_dev_906
Experiments on no-limit Texas Hold'em	method	2K_dev_906
However	purpose	2K_dev_906
one might benefit by considering the trajectory of distributions over strength in all future rounds	purpose	2K_dev_906
not just the final round	purpose	2K_dev_906
An abstraction algorithm that takes all future rounds into account is called potential aware	purpose	2K_dev_906
for computing potential-aware imperfect-recall abstractions	purpose	2K_dev_906
Non-technical loss ( NTL ) represents a major challenge when providing reliable electrical service in developing countries	background	2K_dev_907
where it often accounts for 11-15 % of total generation capacity [ 1 ]	background	2K_dev_907
NTL is caused by a variety of factors such as theft	background	2K_dev_907
unmetered homes	background	2K_dev_907
and inability to pay which at volume can lead to system instability	background	2K_dev_907
grid failure	background	2K_dev_907
and major financial losses for providers	background	2K_dev_907
	background	2K_dev_907
We show that the model can be used to determine uncertainty bounds that can help in separating NTL from total losses	finding	2K_dev_907
Our approach models the primary sources of state uncertainty including line losses	mechanism	2K_dev_907
transformer losses	mechanism	2K_dev_907
meter calibration error	mechanism	2K_dev_907
packet loss	mechanism	2K_dev_907
and sample synchronization error	mechanism	2K_dev_907
	mechanism	2K_dev_907
We conduct an extensive data-driven simulation on 72 days of wireless meter data from a 430-home microgrid deployed in Les Anglais	method	2K_dev_907
Haiti	method	2K_dev_907
In this paper	purpose	2K_dev_907
we investigate error sources and techniques for separating NTL from total losses in microgrids	purpose	2K_dev_907
	purpose	2K_dev_907
For the important task of binocular depth perception from complex natural-image stimuli	background	2K_dev_908
the neurophysiological basis for disambiguating multiple matches between the eyes across similar features has remained a long-standing problem	background	2K_dev_908
Recurrent interactions among binocular disparity-tuned neurons in the primary visual cortex ( V1 ) could play a role in stereoscopic computationsbyalteringresponsesto favorthemost likelydepthinterpretation fora givenimagepair	background	2K_dev_908
Psychophysicalresearch has shown that binocular disparity stimuli displayed in 1 region of the visualfield can be extrapolated into neighboring regions that contain ambiguous depth information	background	2K_dev_908
by cooperative algorithms play an important role in solving the stereo correspondence problem	background	2K_dev_908
and found that unambiguous binocular disparity stimuli displayed in the surrounding visualfields of disparity-selective V1 neurons indeed modified their responses when either bistable stereoscopic or uniform featureless stimuli were presented within their receptivefield centers	finding	2K_dev_908
The delayed timing of the response behavior compared with the timing of classical surround suppression and multiple control experiments suggests that these modulations are carried out by slower disparity-specific recurrentconnectionsamongV1neurons	finding	2K_dev_908
Theseresultsprovideexplicitevidencethatthespatialinteractionsthatarepredicted	finding	2K_dev_908
	mechanism	2K_dev_908
	method	2K_dev_908
We tested whether neurons in macaque V1 interact in a similar manner	purpose	2K_dev_908
Regret matching is a widely-used algorithm for learning how to	background	2K_dev_909
	finding	2K_dev_909
We prove how this can be done by carefully discounting the prior regrets	mechanism	2K_dev_909
This provides	mechanism	2K_dev_909
to our knowledge	mechanism	2K_dev_909
the first principled warm-starting method It also extends to warm-starting the widely-adopted counterfactual regret minimization ( CFR ) algorithm We then study optimizing a parameter vector for a player in a two-player zero-sum game ( e	mechanism	2K_dev_909
g	mechanism	2K_dev_909
	mechanism	2K_dev_909
optimizing bet sizes to use in poker )	mechanism	2K_dev_909
We propose a custom gradient descent algorithm that provably finds a locally optimal parameter vector while leveraging our warm-start theory to significantly save regret-matching iterations at each step	mechanism	2K_dev_909
It optimizes the parameter vector while simultaneously finding an equilibrium This amounts to the first action abstraction algorithm ( algorithm for selecting a small number of discrete actions to use from a continuum of actions -- a key preprocessing step for solving large games using current equilibrium-finding algorithms ) with convergence guarantees for extensive-form games	mechanism	2K_dev_909
we show this experimentally as well We present experiments in no-limit Leduc Hold'em and nolimit Texas Hold'em to optimize bet sizing	method	2K_dev_909
	method	2K_dev_909
We begin by proving that regrets on actions in one setting ( game ) can be transferred to warm start the regrets for solving a different setting with same structure but different payoffs that can be written as a function of parameters	purpose	2K_dev_909
for no-regret learning	purpose	2K_dev_909
for large incomplete-information games	purpose	2K_dev_909
For many reasons one might consider mechanisms	background	2K_dev_910
or social choice functions	background	2K_dev_910
that only have access to the ordinal rankings of alternatives by the individual agents rather than their utility functions	background	2K_dev_910
sample complexity results for the class of scoring functions	finding	2K_dev_910
	finding	2K_dev_910
under three different models	mechanism	2K_dev_910
In our worst-case model	mechanism	2K_dev_910
no assumptions are made about the underlying distribution and we analyze the worst-case distortion-or degree to which the selected alternative does not maximize social welfare-of optimal ( randomized ) social choice functions	mechanism	2K_dev_910
In our average-case model	mechanism	2K_dev_910
we derive optimal functions under neutral ( or impartial culture ) probabilistic models Finally	mechanism	2K_dev_910
a very general learning-theoretic model allows for the computation of optimal social choice functions ( i	mechanism	2K_dev_910
e	mechanism	2K_dev_910
	mechanism	2K_dev_910
ones that maximize expected social welfare ) under arbitrary	mechanism	2K_dev_910
sampleable distributions In the latter case	mechanism	2K_dev_910
we provide both algorithms and	mechanism	2K_dev_910
and further validate the approach empirically	method	2K_dev_910
We adopt a utilitarian perspective on social choice	purpose	2K_dev_910
assuming that agents have ( possibly latent ) utility functions over some space of alternatives	purpose	2K_dev_910
In this context	purpose	2K_dev_910
one possible objective for a social choice function is the maximization of ( expected ) social welfare relative to the information contained in these rankings We study such optimal social choice functions and underscore the important role played by scoring functions	purpose	2K_dev_910
	background	2K_dev_911
shows that our framework outperforms several strong baselines	finding	2K_dev_911
We provide a solution using instructional materials	mechanism	2K_dev_911
We posit that there is a hidden structure that explains the correctness of an answer given the question and instructional materials and present a unified max-margin framework that learns to find these hidden structures ( given a corpus of question-answer pairs and instructional materials )	mechanism	2K_dev_911
and uses what it learns to answer novel elementary science questions	mechanism	2K_dev_911
Our evaluation	method	2K_dev_911
for elementary science test	purpose	2K_dev_911
In Massively Open Online Courses ( MOOCs ) TA resources are limited ; most MOOCs use peer assessments to grade assignments	background	2K_dev_912
Students have to divide up their time between working on their own homework and grading others	background	2K_dev_912
If there is no risk of being caught and penalized	background	2K_dev_912
students have no reason to spend any time grading others	background	2K_dev_912
Course staff want to incentivize students to balance their time between course work and peer grading	background	2K_dev_912
	background	2K_dev_912
	finding	2K_dev_912
We present the first model	mechanism	2K_dev_912
modeling the student 's choice of effort in response to a grader 's audit levels as a Stackelberg game with multiple followers We demonstrate that computing the equilibrium for this game is computationally hard	mechanism	2K_dev_912
We then provide a PTAS in order to compute an approximate solution to the problem of allocating audit levels	mechanism	2K_dev_912
However	mechanism	2K_dev_912
we show that this allocation does not necessarily maximize social welfare ; in fact	mechanism	2K_dev_912
there exist settings where course auditor utility is arbitrarily far from optimal under an approximately optimal allocation To circumvent this issue	mechanism	2K_dev_912
we present a natural condition that guarantees that approximately optimal TA allocations guarantee approximately optimal welfare for the course auditors	mechanism	2K_dev_912
	method	2K_dev_912
They may do so by auditing students	purpose	2K_dev_912
ensuring that they perform grading correctly	purpose	2K_dev_912
One would not want students to invest too much time on peer grading	purpose	2K_dev_912
as this would result in poor course performance of strategic auditing in peer grading	purpose	2K_dev_912
For decades researchers have struggled with the problem of envy-free cake cutting : how to divide a divisible good between multiple agents so that each agent likes his own allocation best	background	2K_dev_913
	finding	2K_dev_913
Our main result is an envy-free cake cutting protocol for agents with piecewise linear valuations	mechanism	2K_dev_913
which requires a number of operations that is polynomial in natural parameters of the given instance	mechanism	2K_dev_913
	mechanism	2K_dev_913
	method	2K_dev_913
Although an envy-free cake cutting protocol was ultimately devised	purpose	2K_dev_913
it is unbounded	purpose	2K_dev_913
in the sense that the number of operations can be arbitrarily large	purpose	2K_dev_913
depending on the preferences of the agents	purpose	2K_dev_913
We ask whether bounded protocols exist when the agents ' preferences are restricted	purpose	2K_dev_913
	purpose	2K_dev_913
Achieving high performance for compute bounded numerical kernels typically requires an expert to hand select an appropriate set of Single-instruction multiple-data ( SIMD ) instructions	background	2K_dev_914
then statically scheduling them in order to hide their latency while avoiding register spilling in the process	background	2K_dev_914
Unfortunately	background	2K_dev_914
this level of control over the code forces the expert to trade programming abstraction for performance which is why many performance critical kernels are written in assembly language	background	2K_dev_914
An alternative is to either resort to auto-vectorization ( see Figure 1 ) or to use intrinsic functions	background	2K_dev_914
both features offered by compilers However	background	2K_dev_914
in both scenarios the expert loses control over which instructions are selected	background	2K_dev_914
which optimizations are applied to the code and moreover how the instructions are scheduled for a target architecture	background	2K_dev_914
	finding	2K_dev_914
In this paper through the use of custom macro intrinsics that provide the programmer control over the instruction selection	mechanism	2K_dev_914
and scheduling	mechanism	2K_dev_914
while leveraging the compiler to manage the registers This provides the best of both assembly and vector intrinsics programming so that a programmer can obtain high performance implementations within the C programming language	mechanism	2K_dev_914
	method	2K_dev_914
Ideally	purpose	2K_dev_914
the expert would need assembly-like control over their SIMD instructions beyond what intrinsics provide while maintaining a C-level abstraction for the non-performance critical parts we bridge the gap between performance and abstraction for SIMD instructions	purpose	2K_dev_914
	background	2K_dev_915
The resulting axiomatization of differential dynamic logic is proved to be sound and relatively complete	finding	2K_dev_915
	finding	2K_dev_915
This article introduces a relatively complete proof calculus ( dL ) that is entirely based on uniform substitution	mechanism	2K_dev_915
a proof rule that substitutes a formula for a predicate symbol everywhere Uniform substitutions make it possible to use axioms instead of axiom schemata	mechanism	2K_dev_915
thereby substantially simplifying implementations Instead of subtle schema variables and soundness-critical side conditions on the occurrence patterns of logical variables to restrict infinitely many axiom schema instances to sound ones	mechanism	2K_dev_915
the resulting calculus adopts only a finite number of ordinary dLformulas as axioms	mechanism	2K_dev_915
which uniform substitutions instantiate soundly	mechanism	2K_dev_915
The static semantics of differential dynamic logic and the soundness-critical restrictions it imposes on proof steps is captured exclusively in uniform substitutions and variable renamings as opposed to being spread in delicate ways across the prover implementation In addition to sound uniform substitutions	mechanism	2K_dev_915
this article introduces differential forms for differential dynamic logic that make it possible to internalize differential invariants	mechanism	2K_dev_915
differential substitutions	mechanism	2K_dev_915
and derivatives as first-class axioms to reason about differential equations axiomatically	mechanism	2K_dev_915
	method	2K_dev_915
for differential dynamic logic	purpose	2K_dev_915
Complex event detection is a retrieval task with the goal of finding videos of a particular event in a large-scale unconstrained internet video archive	background	2K_dev_916
given example videos and text descriptions	background	2K_dev_916
demonstrate the efficacy of our proposed method	finding	2K_dev_916
	finding	2K_dev_916
In this paper	mechanism	2K_dev_916
we propose two novel strategies based on both the events-kit text descriptions and the concepts high-level feature descriptions	mechanism	2K_dev_916
Moreover	mechanism	2K_dev_916
we introduce a novel event oriented dictionary representation based on the selected semantic concepts Towards this goal	mechanism	2K_dev_916
we leverage training samples of selected concepts from the Semantic Indexing ( SIN ) dataset with a pool of 346 concepts	mechanism	2K_dev_916
into a novel supervised multitask dictionary learning framework	mechanism	2K_dev_916
Extensive experimental results on TRECVID Multimedia Event Detection ( MED ) dataset	method	2K_dev_916
Nowadays	purpose	2K_dev_916
different multimodal fusion schemes of low-level and high-level features are extensively investigated and evaluated for the complex event detection task	purpose	2K_dev_916
However	purpose	2K_dev_916
how to effectively select the high-level semantic meaningful concepts from a large pool to assist complex event detection is rarely studied in the literature to automatically select semantic meaningful concepts for the event detection task	purpose	2K_dev_916
CPS security	background	2K_dev_917
though well studied	background	2K_dev_917
suffers from fragmentation	background	2K_dev_917
we demonstrate an ability to investigate and extend existing results through the proposed information flow analyses	finding	2K_dev_917
This paper considers the development of information flow analyses Here	mechanism	2K_dev_917
we use information flow analysis	mechanism	2K_dev_917
a well established set of methods developed in software security	mechanism	2K_dev_917
Specifically	mechanism	2K_dev_917
we propose the Kullback Liebler ( KL ) divergence as a causal measure of information flow	mechanism	2K_dev_917
which quantifies the effect of adversarial inputs on sensor outputs	mechanism	2K_dev_917
We show that the proposed measure characterizes the resilience of control systems to specific attack strategies by relating the KL divergence to optimal detection	mechanism	2K_dev_917
We then relate information flows to stealthy attack scenarios where an adversary can bypass detection	mechanism	2K_dev_917
Finally	method	2K_dev_917
this article examines active detection mechanisms where a defender intelligently manipulates control inputs or the system itself to elicit information flows from an attacker 's malicious behavior	method	2K_dev_917
In all previous cases	method	2K_dev_917
to support resilient design and active detection of adversaries in cyber physical systems ( CPS	purpose	2K_dev_917
In this paper	purpose	2K_dev_917
we consider control systems as an abstraction of CPS to obtain a unified framework that captures and extends results in control system security	purpose	2K_dev_917
	purpose	2K_dev_917
	background	2K_dev_918
	finding	2K_dev_918
	mechanism	2K_dev_918
	method	2K_dev_918
	purpose	2K_dev_918
	background	2K_dev_919
	finding	2K_dev_919
	mechanism	2K_dev_919
	method	2K_dev_919
	purpose	2K_dev_919
The system and method of the present invention enables high-speed	background	2K_dev_920
high precision	background	2K_dev_920
and low-cost motion tracking for a wide range of applications	background	2K_dev_920
	finding	2K_dev_920
According to embodiments of the present invention are a system and method that use projected structured patterns of light and linear optical sensors Sensors are capable of recovering two-dimensional location within the projection area	mechanism	2K_dev_920
while several sensors can be combined for up to six degrees of freedom tracking	mechanism	2K_dev_920
The structure patterns are based on m-sequences	mechanism	2K_dev_920
in which any consecutive subsequence of m bits is unique	mechanism	2K_dev_920
Both digital and static light sources can be used	mechanism	2K_dev_920
	mechanism	2K_dev_920
	method	2K_dev_920
for motion tracking	purpose	2K_dev_920
	purpose	2K_dev_920
	background	2K_dev_921
	finding	2K_dev_921
	mechanism	2K_dev_921
	method	2K_dev_921
	purpose	2K_dev_921
	background	2K_dev_922
	finding	2K_dev_922
	mechanism	2K_dev_922
	method	2K_dev_922
	purpose	2K_dev_922
	background	2K_dev_923
With a few highly intuitive rules	finding	2K_dev_923
we obtain substantial improvements and achieve state-of-the-art or comparable results to previous best-performing systems	finding	2K_dev_923
	finding	2K_dev_923
We propose a general framework Specifically	mechanism	2K_dev_923
we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks	mechanism	2K_dev_923
We deploy the framework on a CNN for sentiment analysis	method	2K_dev_923
and an RNN for named entity recognition	method	2K_dev_923
Combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce uninterpretability of the neural models	purpose	2K_dev_923
capable of enhancing various types of neural networks ( e	purpose	2K_dev_923
g	purpose	2K_dev_923
	purpose	2K_dev_923
CNNs and RNNs ) with declarative first-order logic rules	purpose	2K_dev_923
	purpose	2K_dev_923
	background	2K_dev_924
we show that an AlN barrier decreases the switch parasitic capacitance with minimal increases in the switching power	finding	2K_dev_924
results in switches with an improvement in cutoff frequency	finding	2K_dev_924
$ f_ { \mathrm { CO } } $ from 5	finding	2K_dev_924
3 to 8 THz	finding	2K_dev_924
a $ C_ { \mathrm { \scriptscriptstyle OFF } } $ improvement from 15 to 10 fF	finding	2K_dev_924
while maintaining the $ R_ { \mathrm { \scriptscriptstyle ON } } $ at 2 $ \Omega $ This improvement was accompanied by normalized minimum power to amorphize increases of only 14 % ( from 1	finding	2K_dev_924
5 to 1	finding	2K_dev_924
7 W ) for a 100-ns heater pulse	finding	2K_dev_924
	finding	2K_dev_924
We demonstrate four-terminal GeTe-based RF switches with These devices incorporate an AlN-based dielectric separating high-conductivity W micro-heaters from the RF signal path	mechanism	2K_dev_924
Decoupling these design variables	mechanism	2K_dev_924
with the high thermal conductivity of the AlN	mechanism	2K_dev_924
makes it possible to increase the electrical separation with a thicker AlN film for lower parasitic capacitance with minimal decrease in desirable thermal coupling Increasing the AlN thickness from 105 to 170 nm	mechanism	2K_dev_924
With dc	method	2K_dev_924
pulsed	method	2K_dev_924
and RF testing	method	2K_dev_924
	method	2K_dev_924
independent thermal actuation ( switching )	purpose	2K_dev_924
	purpose	2K_dev_924
The LD results ans wer a fundamental question on how to quantify the rate at which the distributed scheme approaches the centralized performance as the inter-sensor communication rate increases	background	2K_dev_925
	finding	2K_dev_925
it is shown that the network achieves weak consensus	finding	2K_dev_925
i	finding	2K_dev_925
e	finding	2K_dev_925
	finding	2K_dev_925
the conditional estimation error covariance at a randomly selected sensor converges weakly ( in distribution ) to a unique invariant measure	finding	2K_dev_925
Further	finding	2K_dev_925
it is proved that as ! 1 this invariant measure satisfies the Large Deviation ( LD ) upper and lower bounds	finding	2K_dev_925
implying that this measure converges exponentially fast ( in probability ) to the Dirac measureP	finding	2K_dev_925
where Pis the stable error covariance of the centralized ( Kalman ) filtering setup	finding	2K_dev_925
	finding	2K_dev_925
in distributed Kalman filtering for poten tially unstable and large linear dynamic systems A gossip network protocol termed Modified Gossip Interactive Kalman Filteri ng ( M-GIKF ) is proposed	mechanism	2K_dev_925
where sensors exchange their filtered states ( estimates and error covariances ) and propagate their observations via inter-sensor communications of rate ; is defined as the averaged number of inter-sensor message passa ges per signal evolution epoch The filtered states are interpre ted as stochastic particles swapped through local interaction	mechanism	2K_dev_925
The paper shows that the conditional estimation error covariance sequence at each sensor under M-GIKF evolves as a random Riccati equa- tion ( RRE ) with Markov modulated switching	mechanism	2K_dev_925
By formulating the RRE as a random dynamical system	method	2K_dev_925
This paper studies the convergence of the estimation error process and the characterization of the corresponding invariant measure	purpose	2K_dev_925
How can we analyze large-scale real-world data with various attributes ? Many real-world data ( e	background	2K_dev_926
g	background	2K_dev_926
	background	2K_dev_926
network traffic logs	background	2K_dev_926
web data	background	2K_dev_926
social networks	background	2K_dev_926
knowledge bases	background	2K_dev_926
and sensor streams ) with multiple attributes are represented as multi-dimensional arrays	background	2K_dev_926
called tensors	background	2K_dev_926
For analyzing a tensor	background	2K_dev_926
tensor decompositions are widely used in many data mining applications : detecting malicious attackers in network traffic logs ( with source IP	background	2K_dev_926
destination IP	background	2K_dev_926
port-number	background	2K_dev_926
timestamp )	background	2K_dev_926
finding telemarketers in a phone call history ( with sender	background	2K_dev_926
receiver	background	2K_dev_926
date )	background	2K_dev_926
and identifying interesting concepts in a knowledge base ( with subject	background	2K_dev_926
object	background	2K_dev_926
relation )	background	2K_dev_926
	background	2K_dev_926
and discover hidden concepts	finding	2K_dev_926
	finding	2K_dev_926
In this paper	mechanism	2K_dev_926
we propose HaTen2	mechanism	2K_dev_926
a distributed method that runs on the MapReduce framework	mechanism	2K_dev_926
Our careful design and implementation of HaTen2 dramatically reduce the size of intermediate data and the number of jobs leading to achieve high scalability compared with the state-of-the-art method	mechanism	2K_dev_926
	mechanism	2K_dev_926
Thanks to HaTen2	method	2K_dev_926
we analyze big real-world sparse tensors that can not be handled by the current state of the art	method	2K_dev_926
	method	2K_dev_926
However	purpose	2K_dev_926
current tensor decomposition methods do not scale to large and sparse real-world tensors with millions of rows and columns and `fibers for large-scale tensor decompositions	purpose	2K_dev_926
Mental simulation is an important skill for program understanding and prediction of program behavior Finally	background	2K_dev_927
we present recommendations for question prompt design to foster better student simulation of program execution	background	2K_dev_927
	background	2K_dev_927
Analysis of student responses suggest that this type of question can be used to identify misconceptions and misinterpretation of instructions	finding	2K_dev_927
	finding	2K_dev_927
This poster presents the iterative design and refinement process using a novel introductory computational thinking curriculum for Microsoft 's Kodu Game Lab	mechanism	2K_dev_927
We present an analysis of question prompts and student responses from data collected from three rising 3rd - 6th graders where the curriculum was implemented	method	2K_dev_927
	method	2K_dev_927
Assessing students ' ability to mentally simulate program execution can be challenging in graphical programming environments and on paper-based assessments	purpose	2K_dev_927
for assessing students ability to mentally simulate and predict code behavior	purpose	2K_dev_927
Several important families of graphs are nearly balanced	background	2K_dev_928
in particular	background	2K_dev_928
Eulerian graphs ( with 0 1 ) and residual graphs of ( 1+ ) -approximate undirected maximum flows ( with 0 O ( 1/ ) )	background	2K_dev_928
	background	2K_dev_928
We show that	finding	2K_dev_928
using our approximate maximum flow algorithm	finding	2K_dev_928
we can efficiently determine whether a given directed graph is -balanced	finding	2K_dev_928
	finding	2K_dev_928
We introduce the notion of balance for directed graphs : aweighted directed graph is -balanced if for every cut S V	mechanism	2K_dev_928
the total weight of edges going from S to V S is within factor of the total weight of edges going from V S to S	mechanism	2K_dev_928
We first revisit oblivious routings in directed graphs	mechanism	2K_dev_928
Our main algorithmic result is an oblivious routing scheme for single-source instances that achieve an O ( log 3 n / loglog n ) competitive ratio	mechanism	2K_dev_928
In the process	mechanism	2K_dev_928
we make several technical contributions which may be of independent interest	mechanism	2K_dev_928
In particular	mechanism	2K_dev_928
we give an efficient algorithm We also define and construct low-stretch arborescences	mechanism	2K_dev_928
a generalization of low-stretch spanning trees to directed graphs	mechanism	2K_dev_928
On the negative side	mechanism	2K_dev_928
we present new lower bounds for oblivious routing problems on directed graphs We show that the competitive ratio of oblivious routing algorithms for directed graphs is ( n ) in general ; this result improves upon the long-standing best known lower bound of ( n ) by Hajiaghayi et al	mechanism	2K_dev_928
We also show that our restriction to single-source instances is necessary by showing an ( n ) lower bound for multiple-source oblivious routing in Eulerian graphs	mechanism	2K_dev_928
We also study the maximum flow problem in balanced directed graphs with arbitrary capacities We develop an efficient algorithm that finds an ( 1+ ) -approximate maximum flows in -balanced graphs in time O ( m 2 / 2 )	mechanism	2K_dev_928
	mechanism	2K_dev_928
Additionally	method	2K_dev_928
we give an application to the directed sparsest cut problem	method	2K_dev_928
We use the notion of balance to give a more fine-grained understanding of several well-studied routing questions that are considerably harder in directed graphs for computing low-radius decompositions of directed graphs parameterized by balance	purpose	2K_dev_928
	purpose	2K_dev_928
Virtual machine ( VM ) migration demands distinct properties under resource oversubscription and workload surges	background	2K_dev_929
We show that our implementation	finding	2K_dev_929
	finding	2K_dev_929
resolves VM contention up to several times faster than live migration	finding	2K_dev_929
	finding	2K_dev_929
We present enlightened post-copy	mechanism	2K_dev_929
a new mechanism that evicts the target VM with fast execution transfer and short total duration This design contrasts with common live migration	mechanism	2K_dev_929
which uses the down time of the migrated VM as its primary metric ; it instead focuses on recovering the aggregate performance of the VMs being affected	mechanism	2K_dev_929
In enlightened post-copy	mechanism	2K_dev_929
the guest OS identifies memory state that is expected to encompass the VM 's working set The hypervisor accordingly transfers its state	mechanism	2K_dev_929
mitigating the performance impact on the migrated VM resulting from post-copy transfer	mechanism	2K_dev_929
	mechanism	2K_dev_929
with modest instrumentation in guest Linux	method	2K_dev_929
for VMs under contention	purpose	2K_dev_929
The context of consumer search is often unobserved and the prediction of it can be nontrivial	background	2K_dev_930
Consumers arrive at search engines with diverse interests	background	2K_dev_930
and their search context may vary even when they are searching using the same keyword Our study has the potential to help advertisers design keyword portfolios and bidding strategy by extracting contextual ambiguity and other semantic characteristics of keywords based on large-scale analytics from unstructured data	background	2K_dev_930
It can also help search engines improve the quality of displayed ads in response to a consumer search query	background	2K_dev_930
We find that consumer click behavior varies significantly across keywords	finding	2K_dev_930
and such variation can be partially explained by keyword category and the contextual ambiguity of keywords	finding	2K_dev_930
Specifically	finding	2K_dev_930
higher contextual ambiguity is associated with higher CTR on top-positioned ads	finding	2K_dev_930
but also a faster decay in CTR with screen position	finding	2K_dev_930
Therefore	finding	2K_dev_930
the overall effect of contextual ambiguity on CTR varies across positions	finding	2K_dev_930
	finding	2K_dev_930
In our study	mechanism	2K_dev_930
we propose based on probabilistic topic models from machine learning and computational linguistics using a hierarchical Bayesian approach that allows for topic-specific effects and nonlinear position effects	mechanism	2K_dev_930
and jointly models click-through rate ( CTR ) and ad position ( rank )	mechanism	2K_dev_930
	mechanism	2K_dev_930
We validate our study using a novel data set from a major search engine that contains information on consumer click activities for 2	method	2K_dev_930
625 distinct keywords across multiple product categories from 10	method	2K_dev_930
000 impressions	method	2K_dev_930
In this paper	purpose	2K_dev_930
we explore how the contextual ambiguity of a search can affect a keyword 's performance an automatic way of examining keyword contextual ambiguity We examine the effect of contextual ambiguity on keyword performance	purpose	2K_dev_930
Pipes carrying pressurized fluids are an important part of the civil infrastructure	background	2K_dev_931
and structural health monitoring ( SHM ) could ensure structural integrity by predicting and preventing structural failures Guided wave ultrasonics is a good candidate for use in pipe SHM because guided waves can propagate long distances and are sensitive to structural damage such as cracks and corrosion losses	background	2K_dev_931
	finding	2K_dev_931
We introduce a damage detector based on singular value decomposition ( SVD )	mechanism	2K_dev_931
caused by a mass scatterer that simulates subtle damage	mechanism	2K_dev_931
under realistic environmental variations	mechanism	2K_dev_931
We show the effectiveness and robustness of this method on experimental data collected on a pipe segment under realistic environmental and operational variations over a time period of several months	method	2K_dev_931
However	purpose	2K_dev_931
the multi-modal and dispersive characteristics of guided waves make it difficult to interpret their arrival records	purpose	2K_dev_931
Moreover	purpose	2K_dev_931
guided waves are also sensitive to environmental and operational variations	purpose	2K_dev_931
limiting the effectiveness of ultrasonic methods to detect pipe damage in a real environment	purpose	2K_dev_931
that can identify a change of interest	purpose	2K_dev_931
	background	2K_dev_932
	finding	2K_dev_932
	mechanism	2K_dev_932
	method	2K_dev_932
	purpose	2K_dev_932
Multimedia event detection has been one of the major endeavors in video event analysis	background	2K_dev_933
A variety of approaches have been proposed recently to tackle this problem	background	2K_dev_933
Among others	background	2K_dev_933
using semantic representation has been accredited for its promising performance and desirable ability for human-understandable reasoning	background	2K_dev_933
To generate semantic representation	background	2K_dev_933
we usually utilize several external image/video archives and apply the concept detectors trained on them to the event videos	background	2K_dev_933
Due to the intrinsic difference of these archives	background	2K_dev_933
the resulted representation is presumable to have different predicting capabilities for a certain event	background	2K_dev_933
	background	2K_dev_933
with encouraging results that validate the efficacy of our proposed approach	finding	2K_dev_933
Motivated by these two shortcomings	mechanism	2K_dev_933
we propose a bi-level semantic representation analyzing method	mechanism	2K_dev_933
Regarding source-level	mechanism	2K_dev_933
our method learns weights of semantic representation attained from different multimedia archives	mechanism	2K_dev_933
Meanwhile	mechanism	2K_dev_933
it restrains the negative influence of noisy or irrelevant concepts in the overall concept-level	mechanism	2K_dev_933
In addition	mechanism	2K_dev_933
we particularly focus on efficient multimedia event detection with few positive examples	mechanism	2K_dev_933
which is highly appreciated in the real-world scenario	mechanism	2K_dev_933
	mechanism	2K_dev_933
We perform extensive experiments on the challenging TRECVID MED 2013 and 2014 datasets	method	2K_dev_933
Notwithstanding	purpose	2K_dev_933
not much work is available for assessing the efficacy of semantic representation from the source-level	purpose	2K_dev_933
On the other hand	purpose	2K_dev_933
it is plausible to perceive that some concepts are noisy for detecting a specific event	purpose	2K_dev_933
	background	2K_dev_934
	finding	2K_dev_934
	mechanism	2K_dev_934
	method	2K_dev_934
	purpose	2K_dev_934
In multi-core systems	background	2K_dev_935
main memory is a major shared resource among processor cores A task running on one core can be delayed by other tasks running simultaneously on other cores due to interference in the shared main memory system	background	2K_dev_935
We find that memory interference can be significantly reduced by ( i ) partitioning DRAM banks	finding	2K_dev_935
and ( ii ) co-locating memory-intensive tasks on the same processing core Experimental results show that the predictions made by our approach are close to the measured worst-case interference under workloads with both high and low memory contention In addition	finding	2K_dev_935
our memory interference-aware task allocation algorithm provides a significant improvement in task schedulability over previous work	finding	2K_dev_935
with as much as 96 % more tasksets being schedulable	finding	2K_dev_935
	finding	2K_dev_935
In this paper	mechanism	2K_dev_935
we present techniques on a multi-core platform that uses a commercial-off-the-shelf ( COTS ) DRAM system	mechanism	2K_dev_935
We explicitly model the major resources in the DRAM system	mechanism	2K_dev_935
including banks	mechanism	2K_dev_935
buses	mechanism	2K_dev_935
and the memory controller Based on these observations	mechanism	2K_dev_935
we develop a memory interference-aware task allocation algorithm	mechanism	2K_dev_935
By considering their timing characteristics	method	2K_dev_935
we analyze the worst-case memory interference delay imposed on a task by other tasks running in parallel We evaluate our approach on a COTS-based multi-core platform running Linux/RK	method	2K_dev_935
Such memory interference delay can be large and highly variable	purpose	2K_dev_935
thereby posing a significant challenge for the design of predictable real-time systems	purpose	2K_dev_935
to reduce this interference and provide an upper bound on the worst-case interference for reducing memory interference	purpose	2K_dev_935
Sustainable building system design techniques aim to find an optimal balance between occupant comfort and the energy performance of HVAC systems	background	2K_dev_936
Design and implementation of effective heating ventilating and air conditioning ( HVAC ) controls is the key to achieve these optimal design conditions	background	2K_dev_936
Any anomalies in the functioning of a system component or a control system would result in occupant discomfort and/or energy wastage	background	2K_dev_936
While occupant discomfort can be directly sensed by occupants	background	2K_dev_936
measurement of waste in energy use would require additional sensing and analysis infrastructure One way of identifying such a waste is to compare asdesigned system requirements with the actual performance of the systems The findings in this paper substantiate the need to formally define the sequence of operations and also point to the need to verify the implemented controls in a given project to detect any deviations from the actual design intent	background	2K_dev_936
	background	2K_dev_936
Any deviation in the sensor data as compared to the expected operation pattern of the design intent indicated incorrect operation of the system with incorrectly implemented controls	finding	2K_dev_936
	finding	2K_dev_936
	mechanism	2K_dev_936
One year sensor data for the AHU parameters was analyzed to assess the correctness of the implementation of the design intent	method	2K_dev_936
The design intent was interpreted from the sequence of operations ( SOOs ) and confirmed with a commissioning engineer	method	2K_dev_936
who worked on the project	method	2K_dev_936
The design intent was then graphically represented as a pattern that the sensor data corresponding to the controls is expected to follow if it follows the design intent	method	2K_dev_936
	method	2K_dev_936
This paper presents an analysis of an air handling unit ( AHU ) in a five story office building and provides the comparison results of design requirements against the sensor data corresponding to the AHU parameters	purpose	2K_dev_936
	purpose	2K_dev_936
Elucidating assembly pathways of complex macromolecular structures	background	2K_dev_937
such as virus capsids	background	2K_dev_937
is an important problem for understanding the many cellular processes dependent on self-assembly but also challenging given limited experimental technologies for observing such systems	background	2K_dev_937
We have previously addressed this problem through simulation-based data fitting	background	2K_dev_937
learning rate parameters of coarse-grained stochastic simulation models to match light scattering data from bulk assembly of purified coat protein in vitro providing an unprecedented view of the fine-scale reaction pathways that might have produced those data	background	2K_dev_937
These simulation results help us understand how RNA viral coat and genome may interact in assembly to promote rapid growth while avoiding kinetic traps expected from much prior theory	background	2K_dev_937
bringing us a step closer to the goal of understanding how viral assembly in the cell may differ from our current conception based largely on in vitro models	background	2K_dev_937
	background	2K_dev_937
We find a surprising complexity and synergy of interaction effects	finding	2K_dev_937
Energetic effects that gain or lower free energy tend to disrupt successful assembly relative to the in vitro model individually	finding	2K_dev_937
while the full combination of positive and negative effects collectively promotes greatly accelerated assembly without loss of yield	finding	2K_dev_937
Furthermore	finding	2K_dev_937
it accomplishes this change in kinetics while substantially altering the ensemble of assembly pathways open to the system	finding	2K_dev_937
using analytical models of various contributions of RNA folding to assembly	mechanism	2K_dev_937
	method	2K_dev_937
A key question raised by such models	purpose	2K_dev_937
though	purpose	2K_dev_937
is how well they might reflect assembly under more natural cellular conditions where factors such as local concentration changes	purpose	2K_dev_937
non-specific crowding	purpose	2K_dev_937
and often the influence of nucleic acid during assembly become relevant In the present study	purpose	2K_dev_937
we examine the latter issue	purpose	2K_dev_937
how would influence overall pathways and kinetics	purpose	2K_dev_937
primarily with reference to cowpea chlorotic mottle virus ( CCMV )	purpose	2K_dev_937
	purpose	2K_dev_937
	background	2K_dev_938
	finding	2K_dev_938
	mechanism	2K_dev_938
	method	2K_dev_938
	purpose	2K_dev_938
	background	2K_dev_939
	finding	2K_dev_939
	mechanism	2K_dev_939
	method	2K_dev_939
	purpose	2K_dev_939
Machine learning ( ML ) algorithms are commonly applied to big data	background	2K_dev_940
using distributed systems that partition the data across machines and allow each machine to read and update all ML model parameters -- - a strategy known as data parallelism	background	2K_dev_940
An alternative and complimentary strategy	background	2K_dev_940
model parallelism	background	2K_dev_940
partitions the model parameters for non-shared parallel access and updates	background	2K_dev_940
and may periodically repartition the parameters to facilitate communication	background	2K_dev_940
we show that SchMP programs running on STRADS outperform non-model-parallel ML implementations : for example	finding	2K_dev_940
SchMP LDA and SchMP Lasso respectively achieve 10x and 5x faster convergence than recent	finding	2K_dev_940
well-established baselines	finding	2K_dev_940
	finding	2K_dev_940
We propose scheduled model parallelism ( SchMP )	mechanism	2K_dev_940
a programming approach by efficiently scheduling parameter updates	mechanism	2K_dev_940
taking into account parameter dependencies and uneven convergence	mechanism	2K_dev_940
To support SchMP at scale	mechanism	2K_dev_940
we develop a distributed framework STRADS which optimizes the throughput of SchMP programs	mechanism	2K_dev_940
and benchmark four common ML applications written as SchMP programs : LDA topic modeling	mechanism	2K_dev_940
matrix factorization	mechanism	2K_dev_940
sparse least-squares ( Lasso ) regression and sparse logistic regression By improving ML progress per iteration through SchMP programming whilst improving iteration throughput through STRADS	mechanism	2K_dev_940
	method	2K_dev_940
Model parallelism is motivated by two challenges that data-parallelism does not usually address : ( 1 ) parameters may be dependent	purpose	2K_dev_940
thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure ; ( 2 ) model parameters converge at different rates	purpose	2K_dev_940
thus a small subset of parameters can bottleneck ML algorithm completion	purpose	2K_dev_940
that improves ML algorithm convergence speed	purpose	2K_dev_940
Sequential games of perfect information can be solved by backward induction	background	2K_dev_941
where solutions to endgames are propagated up the game tree	background	2K_dev_941
	background	2K_dev_941
show that our approach leads to significant performance improvements in practice	finding	2K_dev_941
	finding	2K_dev_941
Nonetheless	mechanism	2K_dev_941
we show that endgame solving can have significant benefits in imperfectinformation games with large state and action spaces : computation of exact ( rather than approximate ) equilibrium strategies	mechanism	2K_dev_941
computation of relevant equilibrium refinements	mechanism	2K_dev_941
significantly finer-grained action and information abstraction	mechanism	2K_dev_941
new information abstraction algorithms that take into account the relevant distribution of players types entering the endgame	mechanism	2K_dev_941
being able to select the coarseness of the action abstraction dynamically	mechanism	2K_dev_941
additional abstraction techniques for speeding up endgame solving	mechanism	2K_dev_941
a solution to the off-tree problem	mechanism	2K_dev_941
and using different degrees of probability thresholding in modeling versus playing	mechanism	2K_dev_941
We discuss each of these topics in detail	mechanism	2K_dev_941
and introduce techniques that enable one even when the number of states and actions in the game is large	mechanism	2K_dev_941
Our experiments on two-player no-limit Texas Holdem poker	method	2K_dev_941
However	purpose	2K_dev_941
this does not work in imperfect-information games because different endgames can contain states that belong to the same information set and can not be treated independently	purpose	2K_dev_941
In fact	purpose	2K_dev_941
we show that this approach can fail even in a simple game with a unique equilibrium and a single endgame	purpose	2K_dev_941
to conduct endgame solving in a scalable way	purpose	2K_dev_941
	background	2K_dev_942
	finding	2K_dev_942
	mechanism	2K_dev_942
	method	2K_dev_942
	purpose	2K_dev_942
Privacy decision making has been examined from various perspectives	background	2K_dev_943
A dominant normative perspective has focused on rational processes by which consumers with stable preferences for privacy weigh the expected benefits of privacy choices against their potential costs More recently	background	2K_dev_943
an alternate behavioral perspective has leveraged theories from behavioral decision research to construe privacy decision making as a process in which cognitive heuristics and biases predictably occur Our results suggest a way to integrate diverse streams of IS literature on privacy decision making : consumers may both over-estimate their response to normative factors and under-estimate their response to behavioral factors in hypothetical choice contexts relative to actual choice contexts	background	2K_dev_943
We find that both relative and objective risks can	finding	2K_dev_943
in fact	finding	2K_dev_943
impact consumer privacy decisions	finding	2K_dev_943
However	finding	2K_dev_943
and surprisingly	finding	2K_dev_943
the impact of objective changes in risk diminishes between hypothetical and actual choice settings	finding	2K_dev_943
Vice versa	finding	2K_dev_943
the impact of relative risk is more pronounced going from hypothetical to actual choice settings	finding	2K_dev_943
	finding	2K_dev_943
	mechanism	2K_dev_943
In a series of experiments by evaluating the impact of changes in objective risk of disclosure and the impact of changes in relative perceptions of risk of disclosure on both hypothetical and actual consumer privacy choices	method	2K_dev_943
	method	2K_dev_943
we compare the predictive power of these two perspectives	purpose	2K_dev_943
Communication and coordination play a major role in the ability of bacterial cells to adapt to ever changing environments and conditions	background	2K_dev_944
prove that the method we propose leads to convergence even when using a dynamically changing interaction network	finding	2K_dev_944
illustrate the ability of the method to explain and further predict several aspects of bacterial swarm food search	finding	2K_dev_944
Here we develop a new distributed gradient descent method This method can also be used for computational tasks when agents are facing similarly restricted conditions We formalize the communication and computation assumptions re- quired for successful coordination and The proposed method improves upon prior models suggested for bacterial foraging despite making fewer assumptions	mechanism	2K_dev_944
Simulation studies and analysis of experimental data	method	2K_dev_944
Recent work has shown that such coordination underlies several aspects of bacterial responses including their ability to develop antibiotic resistance	purpose	2K_dev_944
that helps explain how bacterial cells collectively search for food in harsh environments using extremely limited communication and com- putational complexity	purpose	2K_dev_944
ABSTRACT Clad steel refers to a thick carbon steel structural plate bonded to a corrosion resistant alloy ( CRA ) plate	background	2K_dev_945
such as stainless steel or titanium	background	2K_dev_945
and is widely used in industry to construct pressure vessels	background	2K_dev_945
The CRA resists the chemically aggressive environment on the interior	background	2K_dev_945
but can not prevent the development of corrosion losses and cracks that limit the continued safe operation of such vessels	background	2K_dev_945
In previous resear ch	background	2K_dev_945
sponsored by industry to detect and localize damage in pressurized piping systems under operational and environmental changes	background	2K_dev_945
we investigated a number of data-driven signal processing methods to extract damage information from ultrasonic guided wave pitch-catch records ; we also discuss observations of plate-like mode properties implied by these results	background	2K_dev_945
We discuss conditions under which localization is achieved by relatively simple first-arrival methods	finding	2K_dev_945
and other conditions for which data-driven methods are needed	finding	2K_dev_945
We now apply those methods to relatively large clad steel plate specimens	mechanism	2K_dev_945
	mechanism	2K_dev_945
We study a sparse array of wafer-type ultrasonic transducers adhered to the carbon steel surface	method	2K_dev_945
attempting to localize mass scatterers grease-coupled to the stainless steel surface	method	2K_dev_945
	method	2K_dev_945
At present there are no practical methods to detect such defects from the exposed outer surface of the thick carbon steel plate	purpose	2K_dev_945
often necessitating removing such vessels from service and inspecting them visually from the interior	purpose	2K_dev_945
Many commercial products and academic research activities are embracing behavior analysis as a technique for improving detection of attacks of many sortsfrom retweet boosting	background	2K_dev_946
hashtag hijacking to link advertising	background	2K_dev_946
Traditional approaches focus on detecting dense blocks in the adjacency matrix of graph data	background	2K_dev_946
and recently	background	2K_dev_946
the tensors of multimodal data	background	2K_dev_946
where it improves the F1 score over previous techniques by 68percent and finds suspicious behavioral patterns in social datasets spanning 0	finding	2K_dev_946
3 billion posts	finding	2K_dev_946
	finding	2K_dev_946
In this paper	mechanism	2K_dev_946
we first give a list of axioms that any metric of suspiciousness should satisfy ; we propose an intuitive	mechanism	2K_dev_946
principled metric that satisfies the axioms	mechanism	2K_dev_946
and is fast to compute ; moreover	mechanism	2K_dev_946
we propose CrossSpot	mechanism	2K_dev_946
an algorithm typically indicating fraud or some other noteworthy deviation from the usual	mechanism	2K_dev_946
and sort them in the order of importance ( suspiciousness )	mechanism	2K_dev_946
Finally	method	2K_dev_946
we apply CrossSpot to the real data	method	2K_dev_946
	method	2K_dev_946
No method gives a principled way to score the suspiciousness of dense blocks with different numbers of modes and rank them to draw human attention accordingly	purpose	2K_dev_946
to spot dense blocks that are worth inspecting	purpose	2K_dev_946
	purpose	2K_dev_946
A traditional goal of neural recording with extracellular electrodes is to isolate action potential waveforms of an individual neuron	background	2K_dev_947
Recently	background	2K_dev_947
in braincomputer interfaces ( BCIs )	background	2K_dev_947
it has been recognized that threshold crossing events of the voltage waveform also convey rich information	background	2K_dev_947
To date	background	2K_dev_947
the threshold for detecting threshold crossings has been selected to preserve single-neuron isolation	background	2K_dev_947
Significance	background	2K_dev_947
How neural signals are processed impacts the information that can be extracted from them	background	2K_dev_947
Both the type and quality of information contained in threshold crossings depend on the threshold setting	background	2K_dev_947
There is more information available in these signals than is typically extracted	background	2K_dev_947
Adjusting the detection threshold to the parameter of interest in a BCI context should improve our ability to decode motor intent	background	2K_dev_947
and thus enhance BCI control	background	2K_dev_947
Further	background	2K_dev_947
by sweeping the detection threshold	background	2K_dev_947
one can gain insights into the topographic organization of the nearby neural tissue	background	2K_dev_947
	background	2K_dev_947
Main Results	finding	2K_dev_947
The optimal threshold depends on the desired information	finding	2K_dev_947
In M1	finding	2K_dev_947
velocity is optimally encoded at higher thresholds than speed ; in both cases the optimal thresholds are lower than are typically used in BCI applications	finding	2K_dev_947
In V1	finding	2K_dev_947
information about the orientation of a visual stimulus is optimally encoded at higher thresholds than is visual contrast	finding	2K_dev_947
	finding	2K_dev_947
Here we introduce a procedure We apply this procedure in two distinct contexts : the encoding of kinematic parameters from neural activity in primary motor cortex ( M1 )	mechanism	2K_dev_947
and visual stimulus parameters from neural activity in primary visual cortex ( V1 Approach We record extracellularly from multi-electrode arrays implanted in M1 or V1 in monkeys	mechanism	2K_dev_947
Then	mechanism	2K_dev_947
we systematically sweep the voltage detection threshold and quantify the information conveyed by the corresponding threshold crossings A conceptual model explains these results as a consequence of cortical topography	mechanism	2K_dev_947
	method	2K_dev_947
Objective However	purpose	2K_dev_947
the optimal threshold for single-neuron identification is not necessarily the optimal threshold for information extraction to determine the best threshold for extracting information from extracellular recordings	purpose	2K_dev_947
	purpose	2K_dev_947
	background	2K_dev_948
We show that CSMA method can achieve good results and is very efficient in the inpainting problem as compared to [ 1 ]	finding	2K_dev_948
[ 2 ] Our method also achieves higher face recognition rates	finding	2K_dev_948
This paper proposes a novel approach named Compressed Submanifold Multifactor Analysis ( CSMA ) Our approach can deal with the problem of missing values and outliers via SVD-L1 The Random Projection method is used to obtain the fast low-rank approximation of a given multifactor dataset	mechanism	2K_dev_948
In addition	mechanism	2K_dev_948
it is able to preserve the geometry of the original data Our CSMA method can be used efficiently for multiple purposes	mechanism	2K_dev_948
e	mechanism	2K_dev_948
g	mechanism	2K_dev_948
	mechanism	2K_dev_948
noise and outlier removal	mechanism	2K_dev_948
estimation of missing values	mechanism	2K_dev_948
biometric applications	mechanism	2K_dev_948
	mechanism	2K_dev_948
compared to LRTC	method	2K_dev_948
SPMA MPCA and some other methods	method	2K_dev_948
i	method	2K_dev_948
e	method	2K_dev_948
	method	2K_dev_948
PCA	method	2K_dev_948
LDA and LPP	method	2K_dev_948
on three challenging face databases	method	2K_dev_948
i	method	2K_dev_948
e	method	2K_dev_948
	method	2K_dev_948
CMU-MPIE	method	2K_dev_948
CMU-PIE and Extended YALE-B	method	2K_dev_948
Although widely used	purpose	2K_dev_948
Multilinear PCA ( MPCA )	purpose	2K_dev_948
one of the leading multilinear analysis methods	purpose	2K_dev_948
still suffers from four major drawbacks	purpose	2K_dev_948
First	purpose	2K_dev_948
it is very sensitive to outliers and noise	purpose	2K_dev_948
Second	purpose	2K_dev_948
it is unable to cope with missing values	purpose	2K_dev_948
Third	purpose	2K_dev_948
it is computationally expensive since MPCA deals with large multi-dimensional datasets	purpose	2K_dev_948
Finally	purpose	2K_dev_948
it is unable to maintain the local geometrical structures due to the averaging process	purpose	2K_dev_948
to solve the four problems mentioned above	purpose	2K_dev_948
	purpose	2K_dev_948
Consumer privacy decision making is often layered : different interrelated decisions determine	background	2K_dev_949
together	background	2K_dev_949
a final privacy outcome and its associated benefits and costs Layered privacy choices are particularly common online	background	2K_dev_949
where consumers are frequently tasked with multiple	background	2K_dev_949
sequential choices ( such as first selecting a services privacy settings	background	2K_dev_949
and then engaging in privacy-sensitive behaviors ) that will ultimately impact their privacy trade-offs Implications for privacy decision research as well as policy makers are discussed	background	2K_dev_949
We find that various manipulations of decision frames	finding	2K_dev_949
common to privacy contexts	finding	2K_dev_949
can significantly alter individual choice of privacy protective options	finding	2K_dev_949
Further	finding	2K_dev_949
and importantly	finding	2K_dev_949
we find that participants subsequent disclosure behavior stays constant despite the shifts in chosen privacy protections induced by choice framing	finding	2K_dev_949
	finding	2K_dev_949
	mechanism	2K_dev_949
Specifically	method	2K_dev_949
in a series of experiments	method	2K_dev_949
we investigate the impact of framing on participants initial privacy choices	method	2K_dev_949
and whether participants subsequent behaviors take account of	method	2K_dev_949
and neutralize	method	2K_dev_949
that impact	method	2K_dev_949
The layered nature of online privacy choices has important implications for models of privacy decision making and for consumers assumption of privacy risks	purpose	2K_dev_949
In this manuscript	purpose	2K_dev_949
we investigate how changes in the architecture of privacy choices affect an initial layer of privacy choice	purpose	2K_dev_949
and how that effect percolates through subsequent layers of privacy choices	purpose	2K_dev_949
Motivation : As cancer researchers have come to appreciate the importance of intratumor heterogeneity	background	2K_dev_950
much attention has focused on the challenges of accurately profiling heterogeneity in individual patients Experimental technologies for directly profiling genomes of single cells are rapidly improving	background	2K_dev_950
but they are still impractical for large-scale sampling	background	2K_dev_950
Bulk genomic assays remain the standard for population-scale studies	background	2K_dev_950
but conflate the influences of mixtures of genetically distinct tumor	background	2K_dev_950
stromal	background	2K_dev_950
and infiltrating immune cells	background	2K_dev_950
Many computational approaches have been developed to deconvolute these mixed samples and reconstruct the genomics of genetically homogeneous clonal subpopulations	background	2K_dev_950
All such methods	background	2K_dev_950
however	background	2K_dev_950
are limited to reconstructing only coarse approximations to a few major subpopulations	background	2K_dev_950
In prior work	background	2K_dev_950
we showed that one can improve deconvolution of genomic data by leveraging substructure in cellular mixtures through a strategy called simplicial complex inference	background	2K_dev_950
	background	2K_dev_950
Results We show that these improvements lead to more accurate inference of cell populations and mixture proportions We further demonstrate their effectiveness in identifying mixture substructure Availability : Source code is available at this http URL	finding	2K_dev_950
by introducing enhancements to automate learning of substructured genomic mixtures	mechanism	2K_dev_950
with specific emphasis on genome-wide copy number variation ( CNV ) data	mechanism	2K_dev_950
We introduce methods for dimensionality estimation fuzzy clustering and automated model inference methods for other key model parameters	mechanism	2K_dev_950
in simulated scenarios	method	2K_dev_950
in real tumor CNV data	method	2K_dev_950
	method	2K_dev_950
This strategy	purpose	2K_dev_950
however	purpose	2K_dev_950
is also limited by the difficulty of inferring mixture structure from sparse	purpose	2K_dev_950
noisy assays	purpose	2K_dev_950
We improve on past work to better decompose mixture model substructure to better identify substructure in sparse	purpose	2K_dev_950
noisy data ;	purpose	2K_dev_950
The pervasiveness of mobile technologies today have facilitated the creation of massive crowdsourced and geotagged data from individual users in real time and at different locations in the city	background	2K_dev_951
Such ubiquitous user-generated data allow us to infer various patterns of human behavior	background	2K_dev_951
which help us understand the interactions between humans and cities	background	2K_dev_951
Our study demonstrates the potential of how to best make use of the large volumes and diverse sources of crowdsourced and geotagged user-generated data to create matrices to predict local economic demand in a manner that is fast	background	2K_dev_951
cheap	background	2K_dev_951
accurate	background	2K_dev_951
and meaningful	background	2K_dev_951
Our results suggest that foot traffic can increase local popularity and business performance	finding	2K_dev_951
while mobility and traffic from automobiles may hurt local businesses	finding	2K_dev_951
especially the well-established chains and high-end restaurants We also find that on average one more street closure nearby leads to a 4	finding	2K_dev_951
7 % decrease in the probability of a restaurant being fully booked during the dinner peak	finding	2K_dev_951
	finding	2K_dev_951
Our study is instantiated on a unique dataset of restaurant bookings from OpenTable for 3	mechanism	2K_dev_951
187 restaurants in New York City from November 2013 to March 2014	mechanism	2K_dev_951
	mechanism	2K_dev_951
Specifically	method	2K_dev_951
we extract multiple traffic and human mobility features from publicly available data sources using NLP and geo-mapping techniques	method	2K_dev_951
and examine the effects of both static and dynamic features on economic outcome of local businesses	method	2K_dev_951
	method	2K_dev_951
In this study	purpose	2K_dev_951
we focus on understanding users economic behavior in the city by examining the economic value from crowdsourced and geotaggged data	purpose	2K_dev_951
	purpose	2K_dev_951
How much has a network changed since yesterday ? How different is the wiring of Bobs brain ( a left-handed male ) and Alices brain ( a right-handed female )	background	2K_dev_952
and how is it different ? Graph similarity with given node correspondence	background	2K_dev_952
i	background	2K_dev_952
e	background	2K_dev_952
	background	2K_dev_952
the detection of changes in the connectivity of graphs	background	2K_dev_952
arises in numerous settings	background	2K_dev_952
showcase the advantages of our method over existing similarity measures	finding	2K_dev_952
	finding	2K_dev_952
We propose D elta C on	mechanism	2K_dev_952
a principled	mechanism	2K_dev_952
intuitive	mechanism	2K_dev_952
and scalable algorithm ( e	mechanism	2K_dev_952
g	mechanism	2K_dev_952
	mechanism	2K_dev_952
employees of a company	mechanism	2K_dev_952
customers of a mobile carrier In conjunction	mechanism	2K_dev_952
we propose D elta C on -A ttr	mechanism	2K_dev_952
a related approach	mechanism	2K_dev_952
and evaluate when state-of-the-art methods fail to detect crucial connectivity changes in graphs	method	2K_dev_952
Experiments on various synthetic and real graphs Finally	method	2K_dev_952
we employ D elta C on and D elta C on -A ttr on real applications : ( a ) we classify people to groups of high and low creativity based on their brain connectivity graphs	method	2K_dev_952
( b ) do temporal anomaly detection in the who-emails-whom Enron graph and find the top culprits for the changes in the temporal corporate email graph	method	2K_dev_952
and ( c ) recover pairs of test-retest large brain scans ( 17M edges	method	2K_dev_952
up to 90M edges ) for 21 subjects	method	2K_dev_952
	method	2K_dev_952
In this work	purpose	2K_dev_952
we formally state the axioms and desired properties of the graph similarity functions	purpose	2K_dev_952
that assesses the similarity between two graphs on the same nodes that enables attribution of change or dissimilarity to responsible nodes and edges	purpose	2K_dev_952
	purpose	2K_dev_952
Effective enforcement of laws and policies requires expending resources to prevent and detect offenders	background	2K_dev_953
as well as appropriate punishment schemes to deter violators	background	2K_dev_953
In particular	background	2K_dev_953
enforcement of privacy laws and policies in modern organizations that hold large volumes of personal information ( e	background	2K_dev_953
g	background	2K_dev_953
	background	2K_dev_953
hospitals	background	2K_dev_953
banks ) relies heavily on internal audit mechanisms	background	2K_dev_953
	finding	2K_dev_953
We present an audit game model that is a natural generalization of a standard security game model Computing the Stackelberg equilibrium for this game is challenging because it involves solving an optimization problem with non-convex quadratic constraints We present an additive FPTAS that efficiently computes the solution	mechanism	2K_dev_953
	method	2K_dev_953
We study economic considerations in the design of these mechanisms	purpose	2K_dev_953
focusing in particular on effective resource allocation and appropriate punishment schemes	purpose	2K_dev_953
for resource allocation with an additional punishment parameter	purpose	2K_dev_953
	purpose	2K_dev_953
Admixture-introduced linkage disequilibrium ( LD ) has recently been introduced into the inference of the histories of complex admixtures	background	2K_dev_954
Our method is a considerable improvement over other current methods and further facilitates the inference of the histories of complex population admixtures	background	2K_dev_954
	background	2K_dev_954
and it was shown to be more accurate than MALDER	finding	2K_dev_954
a state-of-the-art method that was recently developed for similar purposes	finding	2K_dev_954
under various admixture models	finding	2K_dev_954
Interestingly	finding	2K_dev_954
we were able to identify more than one admixture events in several populations	finding	2K_dev_954
which have yet to be reported	finding	2K_dev_954
For example	finding	2K_dev_954
two major admixture events were identified in the Xinjiang Uyghur	finding	2K_dev_954
occurring around 27 ? ? ? 30 generations ago and 182 ? ? ? 195 generations ago	finding	2K_dev_954
respectively	finding	2K_dev_954
In an African population ( MKK )	finding	2K_dev_954
three recent major admixtures occurring 13 ? ? ? 16	finding	2K_dev_954
50 ? ? ? 67	finding	2K_dev_954
and 107 ? ? ? 139 generations ago were detected	finding	2K_dev_954
We first illustrated the dynamic changes of LD in admixed populations and mathematically formulated the LD under a generalized admixture model with finite population size	mechanism	2K_dev_954
We next developed a new method	mechanism	2K_dev_954
MALDmef	mechanism	2K_dev_954
by fitting LD with multiple exponential functions for inferring and dating multiple-wave admixtures MALDmef takes into account the effects of source populations which substantially affect modeling LD in admixed population	mechanism	2K_dev_954
which renders it capable of efficiently detecting and dating multiple-wave admixture events	mechanism	2K_dev_954
	mechanism	2K_dev_954
The performance of MALDmef was evaluated by simulation We further applied MALDmef to analyzing genome-wide data from the Human Genome Diversity Project ( HGDP ) and the HapMap Project	method	2K_dev_954
	method	2K_dev_954
However	purpose	2K_dev_954
the influence of ancestral source populations on the LD pattern in admixed populations is not properly taken into consideration by currently available methods	purpose	2K_dev_954
which affects the estimation of several gene flow parameters from empirical data	purpose	2K_dev_954
	purpose	2K_dev_954
Large-scale deep learning requires huge computational resources to train a multi-layer neural network	background	2K_dev_955
Recent systems propose using 100s to 1000s of machines to train networks with tens of layers and billions of connections	background	2K_dev_955
We show that GeePS enables a state-of-the-art single-node GPU implementation to scale well	finding	2K_dev_955
such as to 13 times the number of training images processed per second on 16 machines ( relative to the original optimized single-node code ) Moreover	finding	2K_dev_955
GeePS achieves a higher training throughput with just four GPU machines than that a state-of-the-art CPU-only system achieves with 108 machines	finding	2K_dev_955
	finding	2K_dev_955
This paper describes a new parameter server	mechanism	2K_dev_955
called GeePS	mechanism	2K_dev_955
that supports scalable deep learning across GPUs distributed among multiple machines	mechanism	2K_dev_955
overcoming these obstacles	mechanism	2K_dev_955
	mechanism	2K_dev_955
	method	2K_dev_955
While the computation involved can be done more efficiently on GPUs than on more traditional CPU cores	purpose	2K_dev_955
training such networks on a single GPU is too slow and training on distributed GPUs can be inefficient	purpose	2K_dev_955
due to data movement overheads	purpose	2K_dev_955
GPU stalls	purpose	2K_dev_955
and limited GPU memory	purpose	2K_dev_955
	purpose	2K_dev_955
Often	background	2K_dev_956
Big Data applications collect a large number of time series	background	2K_dev_956
for example	background	2K_dev_956
the financial data of companies quoted in a stock exchange	background	2K_dev_956
the health care data of all patients that visit the emergency room of a hospital	background	2K_dev_956
or the temperature sequences continuously measured by weather stations across the US	background	2K_dev_956
A first task in the analytics of these data is to derive a low dimensional representation	background	2K_dev_956
a graph or discrete manifold	background	2K_dev_956
that describes well the interrelations among the time series and their intrarelations across time	background	2K_dev_956
	background	2K_dev_956
The adjacency matrices estimated with the new method are close to the true graph in the simulated data and consistent with prior physical knowledge in the real dataset tested	finding	2K_dev_956
	finding	2K_dev_956
This paper presents a computationally tractable algorithm This graph is directed and weighted	mechanism	2K_dev_956
possibly representing causal relations	mechanism	2K_dev_956
not just reciprocal correlations as in many existing approaches in the literature	mechanism	2K_dev_956
A detailed convergence analysis is carried out	mechanism	2K_dev_956
The algorithm is demonstrated on random graph and real network time series datasets	method	2K_dev_956
and its performance is compared to that of related methods	method	2K_dev_956
	method	2K_dev_956
for estimating this graph structure from the available data	purpose	2K_dev_956
Given a large collection of time-evolving activities	background	2K_dev_957
such as Google search queries	background	2K_dev_957
which consist of d keywords/activities for m locations of duration n	background	2K_dev_957
how can we analyze temporal patterns and relationships among all these activities and find location-specific trends ? How do we go about capturing non-linear evolutions of local activities and forecasting future patterns ? For example	background	2K_dev_957
assume that we have the online search volume for multiple keywords	background	2K_dev_957
e	background	2K_dev_957
g	background	2K_dev_957
	background	2K_dev_957
`` Nokia/Nexus/Kindle '' or `` CNN/BBC '' for 236 countries/territories	background	2K_dev_957
from 2004 to 2015	background	2K_dev_957
	background	2K_dev_957
demonstrate that COMPCUBE consistently outperforms the best state-of- the-art methods in terms of both accuracy and execution speed	finding	2K_dev_957
	finding	2K_dev_957
We present COMPCUBE	mechanism	2K_dev_957
a unifying non-linear model	mechanism	2K_dev_957
which provides a compact and powerful representation of co-evolving activities ; and also a novel fitting algorithm	mechanism	2K_dev_957
COMPCUBE-FIT	mechanism	2K_dev_957
which is parameter-free and scalable Our method captures the following important patterns : ( B ) asic trends	mechanism	2K_dev_957
i	mechanism	2K_dev_957
e	mechanism	2K_dev_957
	mechanism	2K_dev_957
non-linear dynamics of co-evolving activities	mechanism	2K_dev_957
signs of ( C ) ompetition and latent interaction	mechanism	2K_dev_957
e	mechanism	2K_dev_957
g	mechanism	2K_dev_957
	mechanism	2K_dev_957
Nokia vs	mechanism	2K_dev_957
Nexus	mechanism	2K_dev_957
( S ) easonality	mechanism	2K_dev_957
e	mechanism	2K_dev_957
g	mechanism	2K_dev_957
	mechanism	2K_dev_957
a Christmas spike for iPod in the U	mechanism	2K_dev_957
S	mechanism	2K_dev_957
and Europe	mechanism	2K_dev_957
and ( D ) eltas	mechanism	2K_dev_957
e	mechanism	2K_dev_957
g	mechanism	2K_dev_957
	mechanism	2K_dev_957
unrepeated local events such as the U	mechanism	2K_dev_957
S	mechanism	2K_dev_957
election in 2008 Thanks to its concise but effective summarization	mechanism	2K_dev_957
COMPCUBE can also forecast long-range future activities	mechanism	2K_dev_957
	mechanism	2K_dev_957
Extensive experiments on real datasets	method	2K_dev_957
Our goal is to analyze a large collection of multi-evolving activities	purpose	2K_dev_957
and specifically	purpose	2K_dev_957
to answer the following questions : ( a ) Is there any sign of interaction/competition between two different keywords If so	purpose	2K_dev_957
who competes with whom ? ( b ) In which country is the competition strong ? ( c ) Are there any seasonal/annual activities ? ( d ) How can we automatically detect important world-wide ( or local ) events ?	purpose	2K_dev_957
	background	2K_dev_958
	finding	2K_dev_958
	mechanism	2K_dev_958
	method	2K_dev_958
	purpose	2K_dev_958
Given a large collection of co-evolving online activities	background	2K_dev_959
such as searches for the keywords `` Xbox ''	background	2K_dev_959
`` PlayStation '' and `` Wii ''	background	2K_dev_959
how can we find patterns and rules ? Are these keywords related ? If so	background	2K_dev_959
are they competing against each other ?	background	2K_dev_959
show that EcoWeb is effective	finding	2K_dev_959
in that it can capture long-range dynamics and meaningful patterns such as seasonalities	finding	2K_dev_959
and practical	finding	2K_dev_959
in that it can provide accurate long-range forecasts	finding	2K_dev_959
EcoWeb consistently outperforms existing methods in terms of both accuracy and execution speed	finding	2K_dev_959
We present EcoWeb	mechanism	2K_dev_959
( i	mechanism	2K_dev_959
e	mechanism	2K_dev_959
	mechanism	2K_dev_959
Ecosystem on the Web )	mechanism	2K_dev_959
which is an intuitive model designed as a non-linear dynamical system Our second contribution is a novel	mechanism	2K_dev_959
parameter-free	mechanism	2K_dev_959
and scalable fitting algorithm	mechanism	2K_dev_959
EcoWeb-Fit	mechanism	2K_dev_959
that estimates the parameters of EcoWeb	mechanism	2K_dev_959
	mechanism	2K_dev_959
Extensive experiments on real data	method	2K_dev_959
Can we forecast the volume of user activity for the coming month ? We conjecture that online activities compete for user attention in the same way that species in an ecosystem compete for food for mining large-scale co-evolving online activities	purpose	2K_dev_959
	purpose	2K_dev_959
	background	2K_dev_960
	finding	2K_dev_960
	mechanism	2K_dev_960
	method	2K_dev_960
	purpose	2K_dev_960
T cells must receive signals through the T cell receptor ( TCR ) and the costimulatory receptor CD28 to become fully activated	background	2K_dev_961
This combination of imaging and computational analysis could be applied to other systems to determine the spatiotemporal dynamics of signaling molecules	background	2K_dev_961
	background	2K_dev_961
The regulatory proteins WAVE2 and cofilin were efficiently recruited to the immunological synapse only when both TCR and CD28 signaled Constitutive activation of either protein in TCR-stimulated T cells enabled normal actin reorganization even when CD28 signaling was blocked	finding	2K_dev_961
Roybal et al	mechanism	2K_dev_961
imaged actin and fluorescently tagged actin regulatory proteins in T cells activated through the TCR in the absence or presence of CD28 signaling	mechanism	2K_dev_961
Computational image processing to normalize differences in cell shape enabled tracking of the fluorescent proteins	mechanism	2K_dev_961
	mechanism	2K_dev_961
	method	2K_dev_961
Critical to this process is the reorganization of plasma membrane actin at the immunological synapse	purpose	2K_dev_961
the interface between a T cell and an antigen-presenting cell	purpose	2K_dev_961
	background	2K_dev_962
results show that the proposed data-driven approach works well in a smart grid setting with increasing uncertainties and it produces an online state estimate excelling current industrial approach	finding	2K_dev_962
we propose a data-driven state estimation approach based on recent targeted investment on sensors	mechanism	2K_dev_962
data storage	mechanism	2K_dev_962
and computing devices	mechanism	2K_dev_962
An architecture is proposed to use power system physics and pattern to systematically clean historical data and conduct supervised learning	mechanism	2K_dev_962
where historical similar measurements and their states are used to learn the relationship between the current measurement and the state	mechanism	2K_dev_962
In order to deal with nonlinearity	mechanism	2K_dev_962
kernel trick is used to produce linear mapping in a carefully selected higher dimensional space To speed up the data-driven approach for online services	mechanism	2K_dev_962
we analyze power system data set and discover its clustering property due to the periodic pattern of power systems	mechanism	2K_dev_962
This leads to significant dimension reduction and the idea of preorganizing data points in a tree structure for inquiry	mechanism	2K_dev_962
leading to 1000 times speedup	mechanism	2K_dev_962
	mechanism	2K_dev_962
Numerical	method	2K_dev_962
A grand challenge for state estimation in newly built smart grid lies in how to deal with the increasing uncertainties	purpose	2K_dev_962
To solve the problem	purpose	2K_dev_962
	purpose	2K_dev_962
Multi-person tracking plays a critical role in the analysis of surveillance video thus potentially opening the door to automatic summarization of the vast amount of surveillance video generated every day	background	2K_dev_963
and we were able to localize a person 53	finding	2K_dev_963
2 % of the time with 69	finding	2K_dev_963
8 % precision	finding	2K_dev_963
Results showed that we were able to generate a reasonable visual diary ( i	finding	2K_dev_963
e	finding	2K_dev_963
a summary of what a person did ) for different people	finding	2K_dev_963
Therefore	mechanism	2K_dev_963
we propose a multi-person tracking algorithm for very long-term ( e	mechanism	2K_dev_963
g	mechanism	2K_dev_963
month-long ) multi-camera surveillance scenarios	mechanism	2K_dev_963
Long-term tracking is challenging because 1 ) the apparel/appearance of the same person will vary greatly over multiple days and 2 ) a person will leave and re-enter the scene numerous times	mechanism	2K_dev_963
To tackle these challenges	mechanism	2K_dev_963
we leverage face recognition information	mechanism	2K_dev_963
which is robust to apparel change	mechanism	2K_dev_963
to automatically reinitialize our tracker over multiple days of recordings	mechanism	2K_dev_963
Unfortunately	mechanism	2K_dev_963
recognized faces are unavailable oftentimes Therefore	mechanism	2K_dev_963
our tracker propagates identity information to frames without recognized faces by uncovering the appearance and spatial manifold formed by person detections	mechanism	2K_dev_963
	mechanism	2K_dev_963
We tested our algorithm on a 23-day 15-camera data set ( 4	method	2K_dev_963
935 hours total )	method	2K_dev_963
We further performed video summarization experiments based on our tracking output	method	2K_dev_963
on 116	method	2K_dev_963
25 hours of video	method	2K_dev_963
However	purpose	2K_dev_963
most existing work focus on shorter-term ( e	purpose	2K_dev_963
g	purpose	2K_dev_963
minute-long or hour-long ) video sequences	purpose	2K_dev_963
Cyber-physical systems ( CPS ) are heterogeneous	background	2K_dev_964
be- cause they tightly couple computation	background	2K_dev_964
communication	background	2K_dev_964
and control along with physical dynamics	background	2K_dev_964
which are traditionally considered separately	background	2K_dev_964
Without a comprehensive modeling formalism	background	2K_dev_964
model- based development of CPS involves using a multitude of models in a variety of formalisms that capture various aspects of the system design	background	2K_dev_964
such as software design	background	2K_dev_964
networking design	background	2K_dev_964
physical mod- els	background	2K_dev_964
and protocol design	background	2K_dev_964
	finding	2K_dev_964
In this paper	mechanism	2K_dev_964
we propose a multi-view architecture framework that treats models as views of the under- lying system structure and uses structural and semantic mappings Index TermsControl design	mechanism	2K_dev_964
control engineering	mechanism	2K_dev_964
formal veri- fication	mechanism	2K_dev_964
software architecture	mechanism	2K_dev_964
Throughout the paper	method	2K_dev_964
the theoretical concepts are illustrated using two examples : a quad- rotor and an automotive intersection collision avoidance system	method	2K_dev_964
Without a rigorous unifying framework	purpose	2K_dev_964
system integration and integration of the analysis results for vari- ous models remains ad hoc to ensure consistency and enable system-level verification in a hierarchical and compositional manner	purpose	2K_dev_964
	background	2K_dev_965
	finding	2K_dev_965
In this paper	mechanism	2K_dev_965
we introduce InstructableCrowd	mechanism	2K_dev_965
a system We create a framework which enables users to converse with the crowd using their phone and describe a problem which they might have	mechanism	2K_dev_965
We create an interface for a crowd worker to both chat with the user and compose a rule with an `` IF '' part connected to the user 's phone sensors ( e	mechanism	2K_dev_965
g	mechanism	2K_dev_965
incoming emails	mechanism	2K_dev_965
GPS location	mechanism	2K_dev_965
meeting calendar	mechanism	2K_dev_965
weather information etc	mechanism	2K_dev_965
)	mechanism	2K_dev_965
and a `` THEN '' part connected to user 's phone effectors ( e	mechanism	2K_dev_965
g	mechanism	2K_dev_965
sending an email	mechanism	2K_dev_965
creating an alarm	mechanism	2K_dev_965
posting a tweet	mechanism	2K_dev_965
etc	mechanism	2K_dev_965
)	mechanism	2K_dev_965
The system then sends the rules created by the crowd to the user 's phone in order to help the user solve his problem	mechanism	2K_dev_965
	mechanism	2K_dev_965
	method	2K_dev_965
that allows end-users to instruct the crowd to create trigger-action ( `` if	purpose	2K_dev_965
then '' ) rules based on their needs	purpose	2K_dev_965
	purpose	2K_dev_965
The maximum Nash welfare ( MNW ) solution -- - which selects an allocation that maximizes the product of utilities -- - is known to provide outstanding fairness guarantees when allocating divisible goods	background	2K_dev_966
These results lead us to believe that MNW is the ultimate solution for allocating indivisible goods	background	2K_dev_966
and underlie its deployment on a popular fair division website	background	2K_dev_966
	background	2K_dev_966
demonstrate that it scales well	finding	2K_dev_966
And while it seems to lose its luster when applied to indivisible goods	mechanism	2K_dev_966
we show that	mechanism	2K_dev_966
in fact	mechanism	2K_dev_966
the MNW solution is unexpectedly	mechanism	2K_dev_966
strikingly fair even in that setting	mechanism	2K_dev_966
We also establish that the MNW solution provides a good approximation to another popular ( yet possibly infeasible ) fairness property	mechanism	2K_dev_966
the maximin share guarantee	mechanism	2K_dev_966
in theory and -- - even more so -- - in practice	mechanism	2K_dev_966
While finding the MNW solution is computationally hard	mechanism	2K_dev_966
we develop a nontrivial implementation	mechanism	2K_dev_966
and	mechanism	2K_dev_966
on real data	method	2K_dev_966
In particular	purpose	2K_dev_966
we prove that it selects allocations that are envy free up to one good -- - a compelling notion that is quite elusive when coupled with economic efficiency	purpose	2K_dev_966
	purpose	2K_dev_966
	background	2K_dev_967
	finding	2K_dev_967
	mechanism	2K_dev_967
	method	2K_dev_967
	purpose	2K_dev_967
The safety of mobile robots in dynamic environments is predicated on making sure that they do not collide with obstacles	background	2K_dev_968
Our verification results are generic in the sense that they are not limited to the particul ar choices of one specific control algorithm but identify conditions that make them simultaneously apply to a broad class of control algorithms	background	2K_dev_968
	background	2K_dev_968
we prove that provably safe motion is flexible enough to let the r obot still navigate waypoints and pass intersections Moreover	finding	2K_dev_968
we formally prove that safety can still be guaranteed despite s ensor uncertainty and actuator perturbation	finding	2K_dev_968
and when control choices for more aggressive maneuvers are introduced	finding	2K_dev_968
and formally verify a series of increasingly powerful safety properties of controllers ( i ) static safety	mechanism	2K_dev_968
which ensures that no collisions can happen with stationary obstacles	mechanism	2K_dev_968
( ii ) passive safety	mechanism	2K_dev_968
which ensures that no collisions can happen with stationary or moving obstacles while the robot moves	mechanism	2K_dev_968
( iii ) the stronger passive friendly safety in which the robot further maintains sufficient maneuvering distance for obstacles to avoid collision as well	mechanism	2K_dev_968
and ( iv ) passive orientation safety	mechanism	2K_dev_968
which allows for imperfect sensor coverage of the robot	mechanism	2K_dev_968
i	mechanism	2K_dev_968
e	mechanism	2K_dev_968
	mechanism	2K_dev_968
the robot is aw are that not everything in its environment will be visible	mechanism	2K_dev_968
We complement these provably correct safety properties with liveness properties : We use hybrid system models and theorem proving techniques	mechanism	2K_dev_968
	method	2K_dev_968
In support of such safety arguments	purpose	2K_dev_968
we analyze fo r avoiding both stationary and moving obstacles that describe and formally verify the robots discrete control decisions along with it s continuous	purpose	2K_dev_968
physical motion	purpose	2K_dev_968
	purpose	2K_dev_968
	background	2K_dev_969
	finding	2K_dev_969
	mechanism	2K_dev_969
	method	2K_dev_969
	purpose	2K_dev_969
Given a bipartite graph of users and the products that they review	background	2K_dev_970
or followers and followees	background	2K_dev_970
how can we detect fake reviews or follows ? Existing fraud detection methods ( spectral	background	2K_dev_970
etc	background	2K_dev_970
) try to identify dense subgraphs of nodes that are sparsely connected to the remaining graph	background	2K_dev_970
Fraudsters can evade these methods using camouflage	background	2K_dev_970
by adding reviews or follows with honest targets so that they look `` normal ''	background	2K_dev_970
Even worse	background	2K_dev_970
some fraudsters use hijacked accounts from honest users	background	2K_dev_970
and then the camouflage is indeed organic	background	2K_dev_970
	background	2K_dev_970
( c ) is effective in real-world data	finding	2K_dev_970
show that FRAUDAR outperforms the top competitor in accuracy of detecting both camouflaged and non-camouflaged fraud	finding	2K_dev_970
FRAUDAR successfully detected a subgraph of more than 4000 detected accounts	finding	2K_dev_970
of which a majority had tweets showing that they used follower-buying services	finding	2K_dev_970
	finding	2K_dev_970
We propose FRAUDAR	mechanism	2K_dev_970
an algorithm that ( a ) is camouflage-resistant	mechanism	2K_dev_970
( b ) provides upper bounds on the effectiveness of fraudsters	mechanism	2K_dev_970
and	mechanism	2K_dev_970
Experimental results under various attacks Additionally	method	2K_dev_970
in real-world experiments with a Twitter follower-followee graph of 1	method	2K_dev_970
47 billion edges	method	2K_dev_970
	method	2K_dev_970
Our focus is to spot fraudsters in the presence of camouflage or hijacked accounts	purpose	2K_dev_970
	background	2K_dev_971
	finding	2K_dev_971
	mechanism	2K_dev_971
	method	2K_dev_971
	purpose	2K_dev_971
	background	2K_dev_972
	finding	2K_dev_972
	mechanism	2K_dev_972
	method	2K_dev_972
	purpose	2K_dev_972
The underlying motivating application is epidemics like computer virus spreading	background	2K_dev_973
for example	background	2K_dev_973
in wide campus local networks	background	2K_dev_973
	background	2K_dev_973
	finding	2K_dev_973
We consider multiple classes of viruses	mechanism	2K_dev_973
each type bearing their own statistical characterization -- exogenous contamination	mechanism	2K_dev_973
contagious propagation	mechanism	2K_dev_973
and healing	mechanism	2K_dev_973
The network state ( distribution of nodes infected by each class in the network ) is a jump Markov process	mechanism	2K_dev_973
not necessarily reversible	mechanism	2K_dev_973
making it a challenge to obtain its invariant distribution	mechanism	2K_dev_973
By suitable renormalization	mechanism	2K_dev_973
in the limit of a large network ( number of nodes )	mechanism	2K_dev_973
we describe the macroscopic or emergent behavior of the network by the solution of a set of deterministic nonlinear differential equations These nonlinear differential equations are obtained by mean field analysis of the microscopic random dynamics	mechanism	2K_dev_973
We study the qualitative behavior of the nonlinear differential equations describing the mean field dynamics	method	2K_dev_973
Abstract : We study the emergence of global behavior in large scale networks	purpose	2K_dev_973
	purpose	2K_dev_973
The ubiquitous deployment of mobile and sensor technologies has led to both the capacity to observe human behavior in physical ( offline ) settings as well as to record it	background	2K_dev_974
Finally	background	2K_dev_974
our study has important welfare implications in that efficient information sharing leads to an income increase among all drivers	background	2K_dev_974
instead of a redistribution of income between different types of drivers Our work allows us not only to explain driver decision making behavior using these detailed behavioral traces	background	2K_dev_974
but also to prescribe information sharing strategy for the firm in order to improve the overall market efficiency	background	2K_dev_974
We find strong heterogeneity in individual learning behavior and driving decisions	finding	2K_dev_974
which is significantly associated with individual economic outcomes	finding	2K_dev_974
Drivers with higher incomes benefit significantly from their ability to learn from not only demand information directly observable in the local market	finding	2K_dev_974
but also aggregate information on demand flows across markets	finding	2K_dev_974
Interestingly	finding	2K_dev_974
our policy simulations indicate information that is noisy at the individual level becomes valuable after being aggregated across various spatial and temporal dimensions Moreover	finding	2K_dev_974
the value of information does not increase monotonically with the scale and frequency of information sharing	finding	2K_dev_974
	finding	2K_dev_974
This capacity to use data where occupancy of the taxi is known is a distinctive feature of our data set and sets this work apart from prior work which has attempted to study driver behavior We conduct our study using a heterogeneous Bayesian learning model	mechanism	2K_dev_974
	mechanism	2K_dev_974
In this paper	method	2K_dev_974
we study decision making behavior of 11	method	2K_dev_974
196 taxi drivers in a large Asian city using a rich data set consisting of 10	method	2K_dev_974
6 million fine-grained GPS trip records These records include detailed taxi GPS trajectories	method	2K_dev_974
taxi occupancy data ( i	method	2K_dev_974
e	method	2K_dev_974
	method	2K_dev_974
whether a taxi was occupied with a passenger or was vacant ) and taxi drivers daily incomes The specific decision we focus on pertains to actions drivers take to find new passengers after they have dropped off their current passengers	method	2K_dev_974
In particular	method	2K_dev_974
we study the role of information derivable from the GPS trace data ( e	method	2K_dev_974
g	method	2K_dev_974
	method	2K_dev_974
where passengers are dropped off	method	2K_dev_974
where passengers are picked up	method	2K_dev_974
longitudinal taxicab travel history with fine-grained time stamps ) observable by or made available to drivers in enabling them to learn the distribution of demand for their services over space and time	method	2K_dev_974
	method	2K_dev_974
This provides researchers with a new lens to study and better understand the individual decision processes that were previously unobserved	purpose	2K_dev_974
	purpose	2K_dev_974
	background	2K_dev_975
	finding	2K_dev_975
	mechanism	2K_dev_975
	method	2K_dev_975
	purpose	2K_dev_975
	background	2K_dev_976
show that AD3 compares favorably with the state-of-the-art	finding	2K_dev_976
	finding	2K_dev_976
We present AD3	mechanism	2K_dev_976
a new algorithm	mechanism	2K_dev_976
based on the alternating directions method of multipliers	mechanism	2K_dev_976
Like other dual decomposition algorithms	mechanism	2K_dev_976
AD3 has a modular architecture	mechanism	2K_dev_976
where local subproblems are solved independently	mechanism	2K_dev_976
and their solutions are gathered to compute a global update	mechanism	2K_dev_976
The key characteristic of AD3 is that each local subproblem has a quadratic regularizer	mechanism	2K_dev_976
leading to faster convergence	mechanism	2K_dev_976
both theoretically and in practice	mechanism	2K_dev_976
We provide closed-form solutions for these AD3 subproblems for binary pairwise factors and factors imposing first-order logic constraints	mechanism	2K_dev_976
For arbitrary factors ( large or combinatorial )	mechanism	2K_dev_976
we introduce an active set method which requires only an oracle for computing a local MAP configuration	mechanism	2K_dev_976
making AD3 applicable to a wide range of problems	mechanism	2K_dev_976
	mechanism	2K_dev_976
Experiments on synthetic and real-world problems	method	2K_dev_976
for approximate maximum a posteriori ( MAP ) inference on factor graphs	purpose	2K_dev_976
	background	2K_dev_977
	finding	2K_dev_977
We describe a system called Olive that freezes and precisely reproduces the environment necessary It uses virtual machine ( VM ) technology	mechanism	2K_dev_977
complete with all its software dependencies	mechanism	2K_dev_977
This legacy world can be completely closed-source : there is no requirement for availability of source code	mechanism	2K_dev_977
nor a requirement for recompilation or relinking	mechanism	2K_dev_977
The entire VM is streamed over the Internet from a web server	mechanism	2K_dev_977
much as video is streamed today	mechanism	2K_dev_977
	mechanism	2K_dev_977
	method	2K_dev_977
to execute software long after its creation to encapsulate legacy software	purpose	2K_dev_977
	background	2K_dev_978
; and we observe power law growth for both nodes and links	finding	2K_dev_978
a fact that completely breaks the sigmoid models ( like SI	finding	2K_dev_978
and Bass )	finding	2K_dev_978
where NETTIDE gives good fitting accuracy	finding	2K_dev_978
and	finding	2K_dev_978
more importantly	finding	2K_dev_978
applied on the WeChat data	finding	2K_dev_978
our NETTIDE forecasted more than 730 days into the future	finding	2K_dev_978
with 3 % error	finding	2K_dev_978
	finding	2K_dev_978
In its place	mechanism	2K_dev_978
we propose NETTIDE	mechanism	2K_dev_978
along with differential equations for the growth of the count of nodes	mechanism	2K_dev_978
as well as links	mechanism	2K_dev_978
Our model accurately fits the growth patterns of real graphs ; it is general	mechanism	2K_dev_978
encompassing as special cases all the known	mechanism	2K_dev_978
traditional models ( including Bass	mechanism	2K_dev_978
SI	mechanism	2K_dev_978
log-logistic growth ) ; while still remaining parsimonious	mechanism	2K_dev_978
requiring only a handful of parameters Moreover	mechanism	2K_dev_978
our NETTIDE for link growth is the first one of its kind	mechanism	2K_dev_978
accurately fitting real data	mechanism	2K_dev_978
and naturally leading to the densification phenomenon	mechanism	2K_dev_978
	mechanism	2K_dev_978
We examine the growth of several real networks	method	2K_dev_978
including one of the world 's largest online social network	method	2K_dev_978
`` WeChat ''	method	2K_dev_978
with 300 million nodes and 4	method	2K_dev_978
75 billion links by 2013 We validate our model with four real	method	2K_dev_978
time-evolving social networks	method	2K_dev_978
	method	2K_dev_978
What is the growth pattern of social networks	purpose	2K_dev_978
like Facebook and WeChat ? Does it truly exhibit exponential early growth	purpose	2K_dev_978
as predicted by textbook models like the Bass model	purpose	2K_dev_978
SI	purpose	2K_dev_978
or the Branching Process ? How about the count of links	purpose	2K_dev_978
over time	purpose	2K_dev_978
for which there are few published models ?	purpose	2K_dev_978
	background	2K_dev_979
	finding	2K_dev_979
	mechanism	2K_dev_979
	method	2K_dev_979
	purpose	2K_dev_979
	background	2K_dev_980
	finding	2K_dev_980
	mechanism	2K_dev_980
	method	2K_dev_980
	purpose	2K_dev_980
	background	2K_dev_981
We surprisingly find that the evolution patterns of real social groups goes far beyond the classic dynamic models like SI and SIR For example	finding	2K_dev_981
we observe both diffusion and non-diffusion mechanism in the group joining process	finding	2K_dev_981
and power-law decay in group quitting process	finding	2K_dev_981
rather than exponential decay as expected in SIR model	finding	2K_dev_981
	finding	2K_dev_981
Therefore we propose a new model comeNgo	mechanism	2K_dev_981
a concise yet flexible dynamic model Our model has the following advantages : ( a ) unification power : it generalizes earlier theoretical models and different joining and quitting mechanisms we find from observation	mechanism	2K_dev_981
( b ) succinctness and interpretability : it contains only six parameters with clear physical meanings	mechanism	2K_dev_981
( c ) accuracy : it can capture various kinds of group evolution patterns preciously and the goodness of fit increase by 58 % over baseline	mechanism	2K_dev_981
( d ) usefulness : it can be used in multiple application scenarios such as forecasting and pattern discovery	mechanism	2K_dev_981
In this paper	method	2K_dev_981
we examine temporal evolution patterns of more than 100 thousands social groups with more than 10 million users	method	2K_dev_981
	method	2K_dev_981
How do social groups	purpose	2K_dev_981
such as Facebook groups and Wechat groups	purpose	2K_dev_981
dynamically evolve over time ? How do people join the social groups	purpose	2K_dev_981
uniformly or with burst ? What is the pattern of people quitting from groups ? Is there a simple universal model to depict the come-and-go patterns of various groups ? for group evolution	purpose	2K_dev_981
	purpose	2K_dev_981
System management includes the selection of maintenance actions depending on the available observations : when a system is made up by components known to be similar	background	2K_dev_982
data collected on one is also relevant for the management of others	background	2K_dev_982
This is typically the case of wind farms	background	2K_dev_982
which are made up by similar turbines	background	2K_dev_982
Optimal management of wind farms is an important task due to high cost of turbines operation and maintenance : in this context	background	2K_dev_982
we recently proposed a method for planning and learning at system-level	background	2K_dev_982
called PLUS	background	2K_dev_982
built upon the Partially Observable Markov Decision Process ( POMDP ) framework	background	2K_dev_982
which treats transition and emission probabilities as random variables	background	2K_dev_982
and is therefore suitable for including model uncertainty	background	2K_dev_982
and discuss its potential and computational complexity	finding	2K_dev_982
The proposed approach	mechanism	2K_dev_982
called Multiple Uncertain POMDP ( MU-POMDP )	mechanism	2K_dev_982
models the components as POMDPs	mechanism	2K_dev_982
and assumes the corresponding parameters as dependent random variables Through this framework	mechanism	2K_dev_982
we can calibrate specific degradation and emission models for each component while	mechanism	2K_dev_982
at the same time	mechanism	2K_dev_982
process observations at system-level	mechanism	2K_dev_982
	mechanism	2K_dev_982
We compare the performance of the proposed MU-POMDP with PLUS	method	2K_dev_982
	method	2K_dev_982
PLUS models the components as independent or identical	purpose	2K_dev_982
In this paper	purpose	2K_dev_982
we extend that formulation	purpose	2K_dev_982
allowing for a weaker similarity among components	purpose	2K_dev_982
Representing and summarizing human behaviors with rich contexts facilitates behavioral sciences and user-oriented services Traditional behavioral modeling represents a behavior as a tuple in which each element is one contextual factor of one type	background	2K_dev_983
and the tensor-based summaries look for high-order dense blocks by clustering the values ( including timestamps ) in each dimension	background	2K_dev_983
	background	2K_dev_983
CatchTartan outperforms the baselines on both the accuracy and speed	finding	2K_dev_983
	finding	2K_dev_983
providing comprehensive summaries for the events	finding	2K_dev_983
human life and scientific development	finding	2K_dev_983
In this paper	mechanism	2K_dev_983
as a two-level matrix ( temporal-behaviors by dimensional-values ) and propose a novel representation called Tartan that includes a set of dimensions	mechanism	2K_dev_983
the values in each dimension	mechanism	2K_dev_983
a list of consecutive time slices and the behaviors in each slice	mechanism	2K_dev_983
We further develop a propagation method CatchTartan it determines the meaningfulness of updating every element in the Tartan by minimizing the encoding cost in a compression manner	mechanism	2K_dev_983
We apply CatchTartan to four Twitter datasets up to 10 million tweets and the DBLP data	method	2K_dev_983
However	purpose	2K_dev_983
the human behaviors are multicontextual and dynamic : ( 1 ) each behavior takes place within multiple contexts in a few dimensions	purpose	2K_dev_983
which requires the representation to enable non-value and set-values for each dimension ; ( 2 ) many behavior collections	purpose	2K_dev_983
such as tweets or papers	purpose	2K_dev_983
evolve over time we represent the behavioral data for behavioral summary to catch the dynamic multicontextual patterns from the temporal multidimensional data in a principled and scalable way	purpose	2K_dev_983
	background	2K_dev_984
We prove that the mean-squared error of the estimator asymptotically converges if the degree of instability of the field dynamics is within a prespecified threshold defined as tracking capacity of the estimator The tracking capacity is a function of the local observation models and the agent communication network yielding distributed estimates with minimized mean-squared error	finding	2K_dev_984
we show that the distributed estimator with optimal gains converges faster and with approximately 3dB better mean-squared error performance than previous distributed estimators	finding	2K_dev_984
	finding	2K_dev_984
We develop a Kalman filter type consensus + innovations distributed linear estimator of the dynamic field termed as Consensus+Innovations Kalman Filter We design the optimal consensus and innovation gain matrices	mechanism	2K_dev_984
The field is observed by a sparsely connected network of agents/sensors collaborating among themselves We analyze the convergence properties of this distributed estimator Through numerical evaluations	method	2K_dev_984
	method	2K_dev_984
In this paper	purpose	2K_dev_984
we address the distributed filtering and prediction of time-varying random fields represented by linear time-invariant ( LTI ) dynamical systems	purpose	2K_dev_984
In this report	background	2K_dev_985
we describe CMU-SMUs participation in the Video Hyperlinking task of TRECVID 2015	background	2K_dev_985
	background	2K_dev_985
results show that ( 1 ) the context does not generally improve results	finding	2K_dev_985
( 2 ) the search performance mainly rely on textual features	finding	2K_dev_985
and the combination of audio and visual feature can not provide improvements ; ( 3 ) due to the lack of training examples	finding	2K_dev_985
machine learning techniques can not provide contributions	finding	2K_dev_985
	finding	2K_dev_985
We treat video hyperlinking as ad-hoc retrieval scenario and use a variety of retrieval methods	mechanism	2K_dev_985
Different combination strategies are used to combine those features	mechanism	2K_dev_985
Besides	mechanism	2K_dev_985
we also attempt to categorize the queries and use different search strategies for different categories	mechanism	2K_dev_985
	mechanism	2K_dev_985
Experiments	method	2K_dev_985
Our experiments mainly focus on the study of different features on the performance of video hyperlinking	purpose	2K_dev_985
including subtitle	purpose	2K_dev_985
metadata	purpose	2K_dev_985
audio and visual features	purpose	2K_dev_985
as well as the consideration of surrounding context	purpose	2K_dev_985
	purpose	2K_dev_985
The physical constraints of smartwatches limit the range and complexity of tasks that can be completed	background	2K_dev_986
WearWrite represents a new approach to getting work done from wearables using the crowd	background	2K_dev_986
	finding	2K_dev_986
we validate that it is possible to manage the crowd writing process from a watch	finding	2K_dev_986
This paper presents WearWrite	mechanism	2K_dev_986
a system that enables by leveraging a crowd to help translate their ideas into text	mechanism	2K_dev_986
WearWrite users dictate tasks	mechanism	2K_dev_986
respond to questions	mechanism	2K_dev_986
and receive notifications of major edits on their watch	mechanism	2K_dev_986
Using a dynamic task queue	mechanism	2K_dev_986
the crowd receives tasks issued by the watch user and generic tasks from the system Watch users captured new ideas as they came to mind and managed a crowd during spare moments while going about their daily routine	mechanism	2K_dev_986
	mechanism	2K_dev_986
In a week-long study with seven smartwatch users supported by approximately 29 crowd workers each	method	2K_dev_986
Despite interface improvements on smartwatches	purpose	2K_dev_986
the promise of enabling productive work remains largely unrealized users to write documents from their smartwatches	purpose	2K_dev_986
	background	2K_dev_987
We show that on these problems the proposed method performs very well	finding	2K_dev_987
solving the problems faster than state-of-the-art methods and to higher accuracy	finding	2K_dev_987
We present a new algorithmic approach This model has found many applications in multiple change point detection	mechanism	2K_dev_987
signal compression	mechanism	2K_dev_987
and total variation denoising	mechanism	2K_dev_987
though existing algorithms typically using first-order or alternating minimization schemes	mechanism	2K_dev_987
In this paper we instead develop a specialized projected Newton method	mechanism	2K_dev_987
combined with a primal active set approach	mechanism	2K_dev_987
which we show to be substantially faster that existing methods	mechanism	2K_dev_987
Furthermore	mechanism	2K_dev_987
we present two applications that use this algorithm as a fast subroutine for a more complex outer loop : segmenting linear regression models for time series data	mechanism	2K_dev_987
and color image denoising	mechanism	2K_dev_987
	method	2K_dev_987
to the group fused lasso	purpose	2K_dev_987
a convex model that approximates a multi-dimensional signal via an approximately piecewise-constant signal	purpose	2K_dev_987
Crowdsourced clustering approaches present a promising way to harness deep semantic knowledge for clustering complex information	background	2K_dev_988
	background	2K_dev_988
	finding	2K_dev_988
We introduce Alloy	mechanism	2K_dev_988
a hybrid approach that combines the richness of human judgments with the power of machine algorithms	mechanism	2K_dev_988
Alloy supports greater global context through a new `` sample and search '' crowd pattern which changes the crowd 's task from classifying a fixed subset of items to actively sampling and querying the entire dataset It also improves efficiency through a two phase process in which crowds provide examples to help a machine cluster the head of the distribution	mechanism	2K_dev_988
then classify low-confidence examples in the tail To accomplish this	mechanism	2K_dev_988
Alloy introduces a modular `` cast and gather '' approach which leverages a machine learning backbone to stitch together different types of judgment tasks	mechanism	2K_dev_988
	mechanism	2K_dev_988
	method	2K_dev_988
However	purpose	2K_dev_988
existing approaches have difficulties supporting the global context needed for workers to generate meaningful categories	purpose	2K_dev_988
and are costly because all items require human judgments	purpose	2K_dev_988
	purpose	2K_dev_988
As our approach is compact	background	2K_dev_989
non-invasive	background	2K_dev_989
low-cost and low-powered	background	2K_dev_989
we envision the technology being integrated into future smartwatches	background	2K_dev_989
supporting rich touch interactions beyond the confines of the small touchscreen	background	2K_dev_989
Our approach can segment touch events at 99 % accuracy	finding	2K_dev_989
and resolve the 2D location of touches with a mean error of 7	finding	2K_dev_989
6mm	finding	2K_dev_989
	finding	2K_dev_989
SkinTrack is a wearable system It consists of a ring	mechanism	2K_dev_989
which emits a continuous high frequency AC signal	mechanism	2K_dev_989
and a sensing wristband with multiple electrodes	mechanism	2K_dev_989
Due to the phase delay inherent in a high-frequency AC signal propagating through the body	mechanism	2K_dev_989
a phase difference can be observed between pairs of electrodes	mechanism	2K_dev_989
SkinTrack measures these phase differences to compute a 2D finger touch coordinate	mechanism	2K_dev_989
	mechanism	2K_dev_989
	method	2K_dev_989
that enables continuous touch tracking on the skin	purpose	2K_dev_989
Strong Nash equilibrium ( SNE ) is an appealing solution concept when rational agents can form coalitions	background	2K_dev_990
A strategy profile is an SNE if no coalition of agents can benefit by deviating	background	2K_dev_990
validate the overall approach and show that the new conditions significantly reduce search tree size compared to using NE conditions alone	finding	2K_dev_990
	finding	2K_dev_990
We present the first general-purpose algorithms An SNE must simultaneously be a Nash equilibrium ( NE ) and the optimal solution of multiple non-convex optimization problems	mechanism	2K_dev_990
This makes even the derivation of necessary and sufficient mathematical equilibrium constraints difficult	mechanism	2K_dev_990
We show that forcing an SNE to be resilient only to pure-strategy deviations by coalitions	mechanism	2K_dev_990
unlike for NEs	mechanism	2K_dev_990
is only a necessary condition here	mechanism	2K_dev_990
Second	mechanism	2K_dev_990
we show that the application of Karush-Kuhn-Tucker conditions leads to another set of necessary conditions that are not sufficient	mechanism	2K_dev_990
Third	mechanism	2K_dev_990
we show that forcing the Pareto efficiency of an SNE for each coalition with respect to coalition correlated strategies is sufficient but not necessary We then develop a tree search algorithm for SNE finding At each node	mechanism	2K_dev_990
it calls an oracle to suggest a candidate SNE and then verifies the candidate	mechanism	2K_dev_990
We show that our new necessary conditions can be leveraged to make the oracle more powerful	mechanism	2K_dev_990
	mechanism	2K_dev_990
Experiments	method	2K_dev_990
for SNE finding in games with more than two agents	purpose	2K_dev_990
	purpose	2K_dev_990
How can we predict Smith 's main hobby if we know the main hobby of Smith 's friends ? Can we measure the confidence in our predic- tion if we are given the main hobby of only a few of Smith 's friends ?	background	2K_dev_991
results demonstrate that our algorithm outperforms other algorithms on graphs with less smoothness and low label density	finding	2K_dev_991
	finding	2K_dev_991
Providing a confidence level for the classification prob- lem is important because most nodes in real world networks tend to have few neighbors	mechanism	2K_dev_991
and thus	mechanism	2K_dev_991
a small amount of evidence	mechanism	2K_dev_991
Our contributions are three-fold : ( a ) novel algorithm ; we propose a semi-supervised learning algorithm that converges fast	mechanism	2K_dev_991
and provides the confidence estimate	mechanism	2K_dev_991
( b ) theoretical analysis ; we show the solid theoretical foundation of our algo- rithm and the connections to label propagation and Bayesian inference ( c ) empirical analysis ; we perform extensive experiments on three dif- ferent real networks Specifically	method	2K_dev_991
the experimental	method	2K_dev_991
In this paper	purpose	2K_dev_991
we focus on how to estimate the confidence on the node classi- fication problem	purpose	2K_dev_991
	purpose	2K_dev_991
Given their large energy footprints and the availability of building energy management systems	background	2K_dev_992
airports are uniquely positioned to take advantage of demand response ( DR ) programs	background	2K_dev_992
Therefore	background	2K_dev_992
further studies should be carried out to conclude the potential of flight schedules in improving accuracies of energy prediction baselines	background	2K_dev_992
test results reveals that a model	finding	2K_dev_992
which has trained over specific seasonal data with only time-of-week and temperature as inputs	finding	2K_dev_992
has the best prediction performance The number of passengers of departure flight schedules is shown to have a positive relationship to the load	finding	2K_dev_992
but does not improve the model accuracy significantly	finding	2K_dev_992
However	finding	2K_dev_992
since this study is done for the spring season	finding	2K_dev_992
when heating	finding	2K_dev_992
ventilating	finding	2K_dev_992
and air conditioning ( HVAC ) systems run the least	finding	2K_dev_992
the results may not represent other seasons with high cooling or heating demand	finding	2K_dev_992
	finding	2K_dev_992
Specifically	mechanism	2K_dev_992
the authors propose piece-wise linear regression models	mechanism	2K_dev_992
For the given period of April and May	method	2K_dev_992
	method	2K_dev_992
Although a baselinethe estimation of what the load would have been without load reductionis essential to assess the performance of DR strategies	purpose	2K_dev_992
there has been very little published research on developing baselines for airports	purpose	2K_dev_992
Therefore	purpose	2K_dev_992
the research described in this paper aims to develop baseline models specially intended for airport facilities	purpose	2K_dev_992
for predicting electricity demand using time-of-week	purpose	2K_dev_992
temperature	purpose	2K_dev_992
and flight schedule information	purpose	2K_dev_992
	purpose	2K_dev_992
The fair division of indivisible goods has long been an important topic in economics and	background	2K_dev_993
more recently	background	2K_dev_993
computer science	background	2K_dev_993
	background	2K_dev_993
we show that even when the number of goods is larger than the number of agents by a linear fraction	finding	2K_dev_993
envy-free allocations are unlikely to exist	finding	2K_dev_993
We then show that when the number of goods is larger by a logarithmic factor	finding	2K_dev_993
such allocations exist with high probability show that the asymptotic behavior of the theory holds even when the number of goods and agents is quite small	finding	2K_dev_993
We demonstrate that there is a sharp phase transition from nonexistence to existence of envy-free allocations	finding	2K_dev_993
and that on average the computational problem is hardest at that transition	finding	2K_dev_993
We investigate the existence of envyfree allocations of indivisible goods	mechanism	2K_dev_993
	mechanism	2K_dev_993
Under additive valuations	method	2K_dev_993
We support these results experimentally and	method	2K_dev_993
that is	purpose	2K_dev_993
allocations where each player values her own allocated set of goods at least as highly as any other player 's allocated set of goods	purpose	2K_dev_993
	background	2K_dev_994
	finding	2K_dev_994
	mechanism	2K_dev_994
	method	2K_dev_994
	purpose	2K_dev_994
	background	2K_dev_995
	finding	2K_dev_995
	mechanism	2K_dev_995
	method	2K_dev_995
	purpose	2K_dev_995
Non-Technical Loss ( NTL ) represents a major challenge when providing reliable electrical service in developing countries	background	2K_dev_996
where it often accounts for 11-15 % of total generation capacity [ 1 ]	background	2K_dev_996
NTL is caused by a variety of factors such as theft	background	2K_dev_996
unmetered homes	background	2K_dev_996
and inability to pay	background	2K_dev_996
which at volume can lead to system instability	background	2K_dev_996
grid failure	background	2K_dev_996
and major financial losses for providers	background	2K_dev_996
Both classes of approaches can provide a confidence interval based on the amount of detected NTL	finding	2K_dev_996
We see that both are quite effective	finding	2K_dev_996
but that the data-driven class is significantly easier to implement	finding	2K_dev_996
In this paper	mechanism	2K_dev_996
we investigate error sources and techniques The model-driven class considers the primary sources of state uncertainty including line losses	mechanism	2K_dev_996
meter consumption	mechanism	2K_dev_996
meter calibration error	mechanism	2K_dev_996
packet loss	mechanism	2K_dev_996
and sample synchronization error	mechanism	2K_dev_996
In the data-driven class	mechanism	2K_dev_996
we use two approaches that learn grid state based on training data The first approach uses a regression technique on an NTL-free period of grid operation to capture the relationship between state error and total consumption The second approach uses an SVM trained on synthetic NTL data	mechanism	2K_dev_996
	mechanism	2K_dev_996
We adopt and compare two classes of approaches for detecting NTL : ( 1 ) model- driven and ( 2 ) data- driven	method	2K_dev_996
We experimentally evaluate and compare the approaches on wireless meter data collected from a 525-home microgrid deployed in Les Anglais	method	2K_dev_996
Haiti	method	2K_dev_996
In both cases	method	2K_dev_996
we are able to experimentally evaluate to what degree we can reliably separate NTL from total losses	method	2K_dev_996
for separating NTL from total losses in microgrids	purpose	2K_dev_996
	purpose	2K_dev_996
Kidney exchanges are organized markets where patients swap willing but incompatible donors	background	2K_dev_997
In the last decade	background	2K_dev_997
kidney exchanges grew from small and regional to large and national -- -and soon	background	2K_dev_997
international	background	2K_dev_997
This growth results in more lives saved	background	2K_dev_997
but exacerbates the empirical hardness of the $ \mathcal { NP } $ -complete problem of optimally matching patients to donors	background	2K_dev_997
	background	2K_dev_997
show that	finding	2K_dev_997
indeed	finding	2K_dev_997
small numbers of attributes suffice	finding	2K_dev_997
In this paper	mechanism	2K_dev_997
we observe that if the kidney exchange compatibility graph can be encoded by a constant number of patient and donor attributes	mechanism	2K_dev_997
We give necessary and sufficient conditions for losslessly shrinking the representation of an arbitrary compatibility graph	mechanism	2K_dev_997
Then	mechanism	2K_dev_997
using real compatibility graphs from the UNOS nationwide kidney exchange	mechanism	2K_dev_997
we show how many attributes are needed to encode real compatibility graphs	mechanism	2K_dev_997
	mechanism	2K_dev_997
The experiments	method	2K_dev_997
State-of-the-art matching engines use integer programming techniques to clear fielded kidney exchanges	purpose	2K_dev_997
but these methods must be tailored to specific models and objective functions	purpose	2K_dev_997
and may fail to scale to larger exchanges the clearing problem is solvable in polynomial time	purpose	2K_dev_997
	purpose	2K_dev_997
Friendsourcing consists of broadcasting questions and help requests to friends on social networking sites	background	2K_dev_998
Results indicate that large extrinsic rewards increase friends ' response rates without reducing the relationship strength between friends	finding	2K_dev_998
Additionally	finding	2K_dev_998
the extrinsic rewards allow requesters to explain away the failure of friendsourcing requests and thus preserve their perceptions of relationship ties with friends	finding	2K_dev_998
	finding	2K_dev_998
	mechanism	2K_dev_998
we conducted an experiment on a new friendsourcing platform - Mobilyzr	method	2K_dev_998
	method	2K_dev_998
Despite its potential value	purpose	2K_dev_998
friendsourcing requests often fall on deaf ears	purpose	2K_dev_998
One way to improve response rates and motivate friends to undertake more effortful tasks may be to offer extrinsic rewards	purpose	2K_dev_998
such as money or a gift	purpose	2K_dev_998
for responding to friendsourcing requests	purpose	2K_dev_998
However	purpose	2K_dev_998
past research suggests that these extrinsic rewards can have unintended consequences	purpose	2K_dev_998
including undermining intrinsic motivations and undercutting the relationship between people	purpose	2K_dev_998
To explore the effects of extrinsic reward on friends ' response rate and perceived relationship	purpose	2K_dev_998
	purpose	2K_dev_998
	background	2K_dev_999
	finding	2K_dev_999
	mechanism	2K_dev_999
	method	2K_dev_999
	purpose	2K_dev_999
Crowdsourcing offers a powerful new paradigm for online work	background	2K_dev_1000
We also contribute a set of design patterns that may be informative for other systems aimed at supporting big picture thinking in small pieces	background	2K_dev_1000
	background	2K_dev_1000
	finding	2K_dev_1000
In this paper	mechanism	2K_dev_1000
we explore the idea that a computational system can scaffold an emerging interdependent	mechanism	2K_dev_1000
big picture view entirely through the small contributions of individuals	mechanism	2K_dev_1000
each of whom sees only a part of the whole	mechanism	2K_dev_1000
	mechanism	2K_dev_1000
To investigate the viability	method	2K_dev_1000
strengths	method	2K_dev_1000
and weaknesses of this approach we instantiate the idea in a prototype system for accomplishing distributed information synthesis and evaluate its output across a variety of topics	method	2K_dev_1000
	method	2K_dev_1000
However	purpose	2K_dev_1000
real world tasks are often interdependent	purpose	2K_dev_1000
requiring a big picture view of the difference pieces involved Existing crowdsourcing approaches that support such tasks -- ranging from Wikipedia to flash teams -- are bottlenecked by relying on a small number of individuals to maintain the big picture	purpose	2K_dev_1000
	purpose	2K_dev_1000
	background	2K_dev_1001
Our main theoretical result is that any graph specifying synergistic and antagonistic pairs can arise even from a restricted class of cooperative games	finding	2K_dev_1001
	finding	2K_dev_1001
We think of a pair of agents as synergistic ( resp	mechanism	2K_dev_1001
	mechanism	2K_dev_1001
antagonistic ) if the Shapley value of one agent when the other agent participates in a joint effort is higher ( resp	mechanism	2K_dev_1001
lower ) than when the other agent does not participate We also study the computational complexity of determining whether a given pair of agents is synergistic	mechanism	2K_dev_1001
Finally	method	2K_dev_1001
we use the concepts developed in the paper to uncover the structure of synergies in two real-world organizations	method	2K_dev_1001
the European Union and the International Monetary Fund	method	2K_dev_1001
	method	2K_dev_1001
We investigate synergy	purpose	2K_dev_1001
or lack thereof	purpose	2K_dev_1001
between agents in co-operative games	purpose	2K_dev_1001
building on the popular notion of Shapley value	purpose	2K_dev_1001
	purpose	2K_dev_1001
How do users behave if they can tag each other in social networks ? Twitter lists can be regarded as the tagging process ; a user ( i	background	2K_dev_1002
e	background	2K_dev_1002
	background	2K_dev_1002
tagger ) creates a list with a name ( i	background	2K_dev_1002
e	background	2K_dev_1002
	background	2K_dev_1002
tag ) and adds other users ( i	background	2K_dev_1002
e	background	2K_dev_1002
	background	2K_dev_1002
tagged users ) into the list	background	2K_dev_1002
This tagging network is by nature different from the resource tagging networks ( e	background	2K_dev_1002
g	background	2K_dev_1002
	background	2K_dev_1002
Flickr and Delicious ) because users on this network can tag each other	background	2K_dev_1002
This study sheds light on the underlying characteristics of the interactive tagging network	background	2K_dev_1002
which is relevant to the social scientists and the system designers of the tagging systems	background	2K_dev_1002
we found the pervasive patterns across the different tagging networks	finding	2K_dev_1002
and the interactive patterns within the interactive tagging network	finding	2K_dev_1002
	mechanism	2K_dev_1002
By quantitatively studying million-scale networks	method	2K_dev_1002
In this paper	purpose	2K_dev_1002
we answer this question by studying the interactive tagging network constructed by Twitter lists	purpose	2K_dev_1002
We address the following research questions : ( RQ1 ) What is the common patterns and the difference between the interactive tagging network and the resource tagging networks ? ( RQ2 ) Do users tag each other on the interactive tagging network ? And if so	purpose	2K_dev_1002
to what extent ? ( RQ3 ) What is the difference between the two types of relationships on Twitter : who-tags-whom and who-follows-whom ?	purpose	2K_dev_1002
Social media is an increasingly important part of modern life We propose changes that Twitter and other social platforms should make to promote fuller access to users with visual impairments	background	2K_dev_1003
Our findings illuminate the importance of the ability to use social media for people who are blind	finding	2K_dev_1003
while also highlighting the many challenges such media currently present this user base	finding	2K_dev_1003
including difficulty in creating profiles	finding	2K_dev_1003
in awareness of available features and settings	finding	2K_dev_1003
in controlling revelations of one 's disability status	finding	2K_dev_1003
and in dealing with the increasing pervasiveness of image-based content	finding	2K_dev_1003
	finding	2K_dev_1003
	mechanism	2K_dev_1003
via a combination of surveys of blind Twitter users	method	2K_dev_1003
large-scale analysis of tweets from and Twitter profiles of blind and sighted users	method	2K_dev_1003
and analysis of tweets containing embedded imagery	method	2K_dev_1003
	method	2K_dev_1003
We investigate the use of and usability of Twitter by blind users	purpose	2K_dev_1003
While Twitter has traditionally been thought of as the most accessible social media platform for blind users	purpose	2K_dev_1003
Twitter 's increasing integration of image content and users ' diverse uses for images have presented emergent accessibility challenges	purpose	2K_dev_1003
	purpose	2K_dev_1003
	background	2K_dev_1004
	finding	2K_dev_1004
	mechanism	2K_dev_1004
	method	2K_dev_1004
	purpose	2K_dev_1004
	background	2K_dev_1005
verify the superiority of the proposed approach	finding	2K_dev_1005
	finding	2K_dev_1005
We first pre-train a number of concept classifiers using data from other sources	mechanism	2K_dev_1005
Then we evaluate the semantic correlation of each concept w	mechanism	2K_dev_1005
r	mechanism	2K_dev_1005
t	mechanism	2K_dev_1005
the event of interest	mechanism	2K_dev_1005
After further refinement to take prediction inaccuracy and discriminative power into account	mechanism	2K_dev_1005
we apply the discovered concept classifiers on all test videos and obtain multiple score vectors	mechanism	2K_dev_1005
These distinct score vectors are converted into pairwise comparison matrices and the nuclear norm rank aggregation framework is adopted to seek consensus	mechanism	2K_dev_1005
we propose an efficient	mechanism	2K_dev_1005
highly scalable algorithm that is an order of magnitude faster than existing alternatives	mechanism	2K_dev_1005
	mechanism	2K_dev_1005
Experiments on recent TRECVID datasets	method	2K_dev_1005
We focus on detecting complex events in unconstrained Internet videos	purpose	2K_dev_1005
While most existing works rely on the abundance of labeled training data	purpose	2K_dev_1005
we consider a more difficult zero-shot setting where no training data is supplied	purpose	2K_dev_1005
To address the challenging optimization formulation	purpose	2K_dev_1005
	purpose	2K_dev_1005
	background	2K_dev_1006
	finding	2K_dev_1006
We introduce disciplined convex stochastic programming ( DCSP )	mechanism	2K_dev_1006
a modeling framework	mechanism	2K_dev_1006
by allowing modelers to naturally express a wide variety of convex stochastic programs in a manner that reflects their underlying mathematical representation DCSP allows modelers to express expectations of arbitrary expressions	mechanism	2K_dev_1006
partial optimizations	mechanism	2K_dev_1006
and chance constraints across a wide variety of convex optimization problem families ( e	mechanism	2K_dev_1006
g	mechanism	2K_dev_1006
	mechanism	2K_dev_1006
linear	mechanism	2K_dev_1006
quadratic	mechanism	2K_dev_1006
second order cone	mechanism	2K_dev_1006
and semidefinite programs	mechanism	2K_dev_1006
We illustrate DCSP 's expressivity through a number of sample implementations of problems drawn from the operations research	method	2K_dev_1006
finance	method	2K_dev_1006
and machine learning literatures	method	2K_dev_1006
that can significantly lower the barrier for modelers to specify and solve convex stochastic optimization problems	purpose	2K_dev_1006
Nudging behaviors through user interface design is a practice that is well-studied in HCI research	background	2K_dev_1007
Corporations often use this knowledge to modify online interfaces to influence user information disclosure	background	2K_dev_1007
We show that ( 1 ) a set of images	finding	2K_dev_1007
biased toward more revealing figures	finding	2K_dev_1007
change subjects ' personal views of appropriate information to share ; ( 2 ) that shifts in perceptions significantly increases the probability that a subject divulges personal information ; and ( 3 ) that these shift also increases the probability that the subject advises others to do so	finding	2K_dev_1007
Our main contribution is a key mechanism by which norm-shaping designs can change beliefs and subsequent disclosure behaviors	finding	2K_dev_1007
	mechanism	2K_dev_1007
In this paper	method	2K_dev_1007
we experimentally test empirically identifying	method	2K_dev_1007
the impact of a norm-shaping design patterns on information divulging behavior	purpose	2K_dev_1007
	purpose	2K_dev_1007
	background	2K_dev_1008
	finding	2K_dev_1008
A class of models using directed	mechanism	2K_dev_1008
weighted graphs is introduced	mechanism	2K_dev_1008
A computationally tractable algorithm from observed time series data is presented The performance guarantees of this algorithm for prediction are outlined under several assumptions on the properties of the dynamics of the system of agents and on the true values of the parameters	mechanism	2K_dev_1008
These guarantees are tested empirically through simulation studies using several random graph models	method	2K_dev_1008
	method	2K_dev_1008
for describing sets of time series generated by interacting agents for estimating the graph adjacency matrix of this model	purpose	2K_dev_1008
Finding densely connected subgraphs	background	2K_dev_1009
also called communities	background	2K_dev_1009
in networks are of interest for many applications In previous work	background	2K_dev_1009
we showed an optimization method for efficiently finding subgraphs denser than the overall network [ 1 ]	background	2K_dev_1009
This result is derived from our studies of network processes	background	2K_dev_1009
dynamical processes that model interactions between individual agents in networks ( i	background	2K_dev_1009
e	background	2K_dev_1009
	background	2K_dev_1009
spread of infection or cascading failures )	background	2K_dev_1009
	background	2K_dev_1009
	finding	2K_dev_1009
that these subgraphs in the sense that there are no other subgraphs in the network isomorphic to these subgraphs	mechanism	2K_dev_1009
	mechanism	2K_dev_1009
	method	2K_dev_1009
In this paper	purpose	2K_dev_1009
we prove are also unique	purpose	2K_dev_1009
This is one of the oldest non-trivial problems in computational geometry yet despite a long history of research the previous fastest running times for computing a ( 1+ ) -approximate geometric median were O ( d n 4/3 8/3 ) by Chin et	background	2K_dev_1010
al	background	2K_dev_1010
O ( d exp 4 log 1 ) by Badoiu et	background	2K_dev_1010
al	background	2K_dev_1010
O ( nd + poly ( d	background	2K_dev_1010
1 ) ) by Feldman and Langberg	background	2K_dev_1010
and the polynomial running time of O ( ( nd ) O ( 1 ) log1/ ) by Parrilo and Sturmfels and Xue and Ye	background	2K_dev_1010
	background	2K_dev_1010
	finding	2K_dev_1010
In this paper we provide faster algorithms While our O ( d 2 ) is a fairly straightforward application of stochastic subgradient descent	mechanism	2K_dev_1010
our O ( nd log 3 n / ) time algorithm is a novel long step interior point method	mechanism	2K_dev_1010
We start with a simple O ( ( nd ) O ( 1 ) log1/ ) time interior point method and show how to improve it	mechanism	2K_dev_1010
ultimately building an algorithm that is quite non-standard from the perspective of interior point literature	mechanism	2K_dev_1010
Our result is one of few cases of outperforming standard interior point theory	mechanism	2K_dev_1010
Furthermore	mechanism	2K_dev_1010
it is the only case we know of where interior point methods yield a nearly linear time algorithm for a canonical optimization problem that traditionally requires superlinear time	mechanism	2K_dev_1010
	method	2K_dev_1010
for solving the geometric median problem given n points in d compute a point that minimizes the sum of Euclidean distances to the points In this paper we show how to compute such an approximate geometric median in time O ( nd log 3 n / ) and O ( d 2 )	purpose	2K_dev_1010
	purpose	2K_dev_1010
Computer security problems often occur when there are disconnects between users understanding of their role in computer security and what is expected of them	background	2K_dev_1011
that inform future directions for better design and research into security interventions	background	2K_dev_1011
Our findings emphasize the need for better understanding of how users computers get infected	background	2K_dev_1011
so that we can more effectively design user-centered mitigations	background	2K_dev_1011
	background	2K_dev_1011
produced engagement as the overarching theme	finding	2K_dev_1011
whereby participants with greater engagement in computer security and maintenance did not necessarily have more secure computer states Thus	finding	2K_dev_1011
user engagement alone may not be predictive of computer security	finding	2K_dev_1011
We identify several other themes	finding	2K_dev_1011
We built and deployed the Security Behavior Observatory ( SBO ) from participants home computers	mechanism	2K_dev_1011
	mechanism	2K_dev_1011
Combining SBO data with user interviews	method	2K_dev_1011
this paper presents a qualitative study comparing users attitudes	method	2K_dev_1011
behaviors	method	2K_dev_1011
and understanding of computer security to the actual states of their computers Qualitative inductive thematic analysis of the interviews	method	2K_dev_1011
To help users make good security decisions more easily	purpose	2K_dev_1011
we need insights into the challenges they face in their daily computer usage to collect data on user behavior and machine configurations	purpose	2K_dev_1011
	background	2K_dev_1012
	finding	2K_dev_1012
	mechanism	2K_dev_1012
	method	2K_dev_1012
	purpose	2K_dev_1012
The environment of a living cell is vastly different from that of an in vitro reaction system	background	2K_dev_1013
an issue that presents great challenges to the use of in vitro models	background	2K_dev_1013
or computer simulations based on them	background	2K_dev_1013
for understanding biochemistry in vivo	background	2K_dev_1013
Virus capsids make an excellent model system for such questions because they typically have few distinct components	background	2K_dev_1013
making them amenable to in vitro and modeling studies	background	2K_dev_1013
yet their assembly can involve complex networks of possible reactions that can not be resolved in detail by any current experimental technology	background	2K_dev_1013
We previously fit kinetic simulation parameters to bulk in vitro assembly data to yield a close match between simulated and real data	background	2K_dev_1013
and then used the simulations to study features of assembly that can not be monitored experimentally The work demonstrates how computer simulations can help us understand how assembly might differ between the in vitro and in vivo environments and what features of the cellular environment account for these differences	background	2K_dev_1013
	background	2K_dev_1013
exhibit surprising behavioral complexity	finding	2K_dev_1013
with distinct effects often acting synergistically to drive efficient assembly and alter pathways relative to the in vitro model	finding	2K_dev_1013
	finding	2K_dev_1013
We bypass that limitation by applying analytical models of nucleic acid effects to adjust kinetic rate parameters learned from in vitro data to see how these adjustments	mechanism	2K_dev_1013
singly or in combination	mechanism	2K_dev_1013
might affect fine-scale assembly progress	mechanism	2K_dev_1013
The resulting simulations	method	2K_dev_1013
The present work seeks to project how assembly in these simulations fit to in vitro data would be altered by computationally adding features of the cellular environment to the system	purpose	2K_dev_1013
specifically the presence of nucleic acid about which many capsids assemble The major challenge of such work is computational : simulating fine-scale assembly pathways on the scale and in the parameter domains of real viruses is far too computationally costly to allow for explicit models of nucleic acid interaction	purpose	2K_dev_1013
	background	2K_dev_1014
Our main result is that biased games satisfying certain mild conditions always admit an equilibrium	finding	2K_dev_1014
	finding	2K_dev_1014
We present that we call biased games	mechanism	2K_dev_1014
In these games	mechanism	2K_dev_1014
a player 's utility is influenced by the distance between his mixed strategy and a given base strategy	mechanism	2K_dev_1014
We argue that biased games capture important aspects of the interaction between software agents We also tackle the computation of equilibria in biased games	mechanism	2K_dev_1014
	method	2K_dev_1014
a novel extension of normal form games	purpose	2K_dev_1014
A kidney exchange is an organized barter market where patients in need of a kidney swap willing but incompatible donors	background	2K_dev_1015
Determining an optimal set of exchanges is theoretically and empirically hard Traditionally	background	2K_dev_1015
exchanges took place in cycles	background	2K_dev_1015
with each participating patient-donor pair both giving and receiving a kidney	background	2K_dev_1015
The recent introduction of chains	background	2K_dev_1015
where a donor without a paired patient triggers a sequence of donations without requiring a kidney in return	background	2K_dev_1015
increased the efficacy of fielded kidney exchanges -- -while also dramatically raising the empirical computational hardness of clearing the market in practice Finally	background	2K_dev_1015
we note that our position-indexed chain-edge formulation can be modified in a straightforward way to take post-match edge failure into account	background	2K_dev_1015
under the restriction that edges have equal probabilities of failure	background	2K_dev_1015
Post-match edge failure is a primary source of inefficiency in presently-fielded kidney exchanges	background	2K_dev_1015
we show that our new models are competitive with all existing solvers -- -in many cases outperforming all other solvers by orders of magnitude	finding	2K_dev_1015
In this paper	mechanism	2K_dev_1015
we address the tractable clearing of kidney exchanges with short cycles and chains that are long but bounded	mechanism	2K_dev_1015
This corresponds to the practice at most modern fielded kidney exchanges	mechanism	2K_dev_1015
We introduce three new integer programming formulations	mechanism	2K_dev_1015
two of which are compact Furthermore	mechanism	2K_dev_1015
one of these models has a linear programming relaxation that is exactly as tight as the previous tightest formulation ( which was not compact ) for instances in which each donor has a paired patient	mechanism	2K_dev_1015
We show how to implement such failure-aware matching in our model	mechanism	2K_dev_1015
and also extend the state-of-the-art general branch-and-price-based non-compact formulation for the failure-aware problem to run its pricing problem in polynomial time	mechanism	2K_dev_1015
	mechanism	2K_dev_1015
On real data from the UNOS nationwide exchange in the United States and the NLDKSS nationwide exchange in the United Kingdom	method	2K_dev_1015
as well as on generated realistic large-scale data	method	2K_dev_1015
	method	2K_dev_1015
While chains can be quite long	purpose	2K_dev_1015
unbounded-length chains are not desirable : planned donations can fail before transplant for a variety of reasons	purpose	2K_dev_1015
and the failure of a single donation causes the rest of that chain to fail	purpose	2K_dev_1015
so parallel shorter chains are better in practice	purpose	2K_dev_1015
Kidney exchange is a barter market where patients trade willing but medically incompatible donors	background	2K_dev_1016
These trades occur via cycles	background	2K_dev_1016
where each patient-donor pair both gives and receives a kidney	background	2K_dev_1016
and via chains	background	2K_dev_1016
which begin with an altruistic donor who does not require a kidney in return For logistical reasons	background	2K_dev_1016
the maximum length of a cycle is typically limited to a small constant	background	2K_dev_1016
while chains can be much longer	background	2K_dev_1016
Given a compatibility graph of patient-donor pairs	background	2K_dev_1016
altruists	background	2K_dev_1016
and feasible potential transplants between them	background	2K_dev_1016
finding even a maximum-cardinality set of vertex-disjoint cycles and chains is NP-hard	background	2K_dev_1016
There has been much work on developing provably optimal solvers that are efficient in practice	background	2K_dev_1016
One of the leading techniques has been branch and price	background	2K_dev_1016
where column generation is used to incrementally bring cycles and chains into the optimization model on an as-needed basis	background	2K_dev_1016
This shows incorrectness of two leading branch-and-price solvers that suggested polynomial-time chain pricing algorithms	background	2K_dev_1016
	background	2K_dev_1016
	finding	2K_dev_1016
In particular	mechanism	2K_dev_1016
only positive-price columns need to be brought into the model	mechanism	2K_dev_1016
	mechanism	2K_dev_1016
	method	2K_dev_1016
We prove that finding a positive-price chain is NP-complete	purpose	2K_dev_1016
	purpose	2K_dev_1016
An increasingly prevalent technique for improving response time in queueing systems is the use of redundancy	background	2K_dev_1017
In a system with redundant requests	background	2K_dev_1017
each job that arrives to the system is copied and dispatched to multiple servers	background	2K_dev_1017
As soon as the first copy completes service	background	2K_dev_1017
the job is considered complete	background	2K_dev_1017
and all remaining copies are deleted	background	2K_dev_1017
	background	2K_dev_1017
We also find asymptotically exact expressions for the distribution of response time as the number of servers approaches infinity	finding	2K_dev_1017
We propose a theoretical model of redundancy	mechanism	2K_dev_1017
the Redundancy-d system	mechanism	2K_dev_1017
in which each job sends redundant copies to d servers chosen uniformly at random	mechanism	2K_dev_1017
We derive the first exact expressions for mean response time in Redundancy-d systems with any finite number of servers	mechanism	2K_dev_1017
	mechanism	2K_dev_1017
	method	2K_dev_1017
A great deal of empirical work has demonstrated that redundancy can significantly reduce response time in systems ranging from Google 's BigTable service to kidney transplant waitlists	purpose	2K_dev_1017
	purpose	2K_dev_1017
Complex networks have been shown to exhibit universal properties	background	2K_dev_1018
with one of the most consistent patterns being the scale-free degree distribution	background	2K_dev_1018
	background	2K_dev_1018
and we show the pervasiveness of the power-hop	finding	2K_dev_1018
	finding	2K_dev_1018
by identifying another power-law pattern that describes the relationship between the fractions of node pairs C ( r ) within r hops and the hop count r	mechanism	2K_dev_1018
This scale-free distribution is pervasive and describes a large variety of networks	mechanism	2K_dev_1018
ranging from social and urban to technological and biological networks In particular	mechanism	2K_dev_1018
inspired by the definition of the fractal correlation dimension D2 on a point-set	mechanism	2K_dev_1018
we consider the hop-count r to be the underlying distance metric between two vertices of the network	mechanism	2K_dev_1018
and we examine the scaling of C ( r ) with r	mechanism	2K_dev_1018
We find that this relationship follows a power-law in real networks within the range 2 r d	mechanism	2K_dev_1018
where d is the effective diameter of the network	mechanism	2K_dev_1018
that is	mechanism	2K_dev_1018
the 90-th percentile distance We term this relationship as power-hop and the corresponding power-law exponent as power-hop exponent h	mechanism	2K_dev_1018
	mechanism	2K_dev_1018
We provide theoretical justification for this pattern under successful existing network models	method	2K_dev_1018
while we analyze a large set of real and synthetic network datasets	method	2K_dev_1018
but are there regularities obeyed by the r-hop neighborhood in real networks ? We answer this question	purpose	2K_dev_1018
Modernsmartphoneplatformshavemillionsofapps	background	2K_dev_1019
manyofwhich request permissions to access private data and resources	background	2K_dev_1019
like user accounts or location	background	2K_dev_1019
Prior research has shown that users are often unaware of	background	2K_dev_1019
if not uncomfortable with	background	2K_dev_1019
many of their permission settings	background	2K_dev_1019
Prior work also suggests that it is theoretically possible to predict many of the privacy settings a user would want by asking the user a small number of questions	background	2K_dev_1019
We discuss the implications of our results for mobile permission management and the design of personalized privacy assistant solutions	background	2K_dev_1019
	background	2K_dev_1019
The results of our study are encouraging	finding	2K_dev_1019
We find that 78	finding	2K_dev_1019
7 % of the recommendations made by the PPA were adopted by users	finding	2K_dev_1019
Following initial recommendations on permission settings	finding	2K_dev_1019
participants were motivated to further review and modify their settings with daily privacy nudges	finding	2K_dev_1019
Despite showing substantial engagement with these nudges	finding	2K_dev_1019
participants only changed 5	finding	2K_dev_1019
1 % of the settings previously adopted based on the PPAs recommendations	finding	2K_dev_1019
The PPA and its recommendations were perceived as useful and usable	finding	2K_dev_1019
	finding	2K_dev_1019
in which we implemented and evaluated a Personalized Privacy Assistant ( PPA )	mechanism	2K_dev_1019
We report on a field study ( n=72 ) with participants using their own Android devices	method	2K_dev_1019
While these smartphone platforms provide varying degrees of control over these permissions	purpose	2K_dev_1019
the sheer number of decisions that users are expected to manage has been shown to be unrealistically high	purpose	2K_dev_1019
However	purpose	2K_dev_1019
this approach has neither been operationalized nor evaluated with actual users before	purpose	2K_dev_1019
	purpose	2K_dev_1019
The rise of Internet-scale networks	background	2K_dev_1020
such as web graphs and social media with hundreds of millions to billions of nodes	background	2K_dev_1020
presents new scientific opportunities	background	2K_dev_1020
such as overlapping community detection to discover the structure of the Internet	background	2K_dev_1020
or to analyze trends in online social behavior	background	2K_dev_1020
	background	2K_dev_1020
we demonstrate overlapping community detection on real networks with up to 100 million nodes and 1000 communities on 5 machines in under 40 hours	finding	2K_dev_1020
our method is several orders of magnitude faster	finding	2K_dev_1020
with competitive or improved accuracy at overlapping community detection	finding	2K_dev_1020
We propose a scalable approach By applying a succinct representation of networks as a bag of triangular motifs	mechanism	2K_dev_1020
developing a parsimonious statistical model	mechanism	2K_dev_1020
deriving an efficient stochastic variational inference algorithm	mechanism	2K_dev_1020
	mechanism	2K_dev_1020
and implementing it as a distributed cluster program via the Petuum parameter server system	method	2K_dev_1020
Compared to other state-of-the-art probabilistic network approaches	method	2K_dev_1020
	method	2K_dev_1020
However	purpose	2K_dev_1020
many existing probabilistic network models are difficult or impossible to deploy at these massive scales for modeling and inferring latent spaces in Internet-scale networks	purpose	2K_dev_1020
with an eye towards overlapping community detection as a key application	purpose	2K_dev_1020
	purpose	2K_dev_1020
Different propagation characteristics of the wave modes	background	2K_dev_1021
their distinctive sensitivities to different types and ranges of EOCs	background	2K_dev_1021
and to different damage scenarios	background	2K_dev_1021
make the interpretation of diffuse-field guided-wave signals a challenging task	background	2K_dev_1021
	background	2K_dev_1021
We show that such a subset is less affected by EOCs compared to the complete time-traces of the signals	finding	2K_dev_1021
Moreover	finding	2K_dev_1021
it is shown that the effects of damage on the energy of this subset suppress those of EOCs	finding	2K_dev_1021
	finding	2K_dev_1021
This paper proposes an unsupervised feature-extraction method for online damage detection of pipelines under varying EOCs	mechanism	2K_dev_1021
A set of signals from the undamaged state of a pipe are used as reference records	mechanism	2K_dev_1021
The reference dataset is used to extract the aforementioned sparse representation	mechanism	2K_dev_1021
During the monitoring stage	mechanism	2K_dev_1021
the sparse subset	mechanism	2K_dev_1021
representing the undamaged pipe	mechanism	2K_dev_1021
will not accurately reconstruct the energy of a signal from a damaged pipe In other words	mechanism	2K_dev_1021
such a sparse representation of guided-waves is sensitive to occurrence of damage	mechanism	2K_dev_1021
Therefore	mechanism	2K_dev_1021
the energy estimation errors are used as damage-sensitive features for damage detection purposes	mechanism	2K_dev_1021
A diverse set of experimental analyses are conducted to verify the hypotheses of the proposed feature-extraction approach	method	2K_dev_1021
and to validate the detection performance of the damage-sensitive features	method	2K_dev_1021
The empirical validation of the proposed method includes ( 1 ) detecting a structural abnormality in an aluminum pipe	method	2K_dev_1021
under varying temperature at different ranges	method	2K_dev_1021
( 2 ) detecting multiple small damages of different types	method	2K_dev_1021
at different locations	method	2K_dev_1021
in a steel pipe	method	2K_dev_1021
under varying temperature	method	2K_dev_1021
( 3 ) detecting a structural abnormality in an operating hot-water piping system	method	2K_dev_1021
under multiple varying EOCs	method	2K_dev_1021
such as temperature	method	2K_dev_1021
water flow rate	method	2K_dev_1021
and inner pressure ; and ( 4 ) detecting a structural abnormality as the ratio of the damaged pipe 's signals in the reference dataset increases	method	2K_dev_1021
	method	2K_dev_1021
This work addresses the main challenges in real-world application of guided-waves for damage detection of pipelines	purpose	2K_dev_1021
namely their complex nature and sensitivity to environmental and operational conditions ( EOCs ) The objective is to simplify diffuse-field guided-wave signals to a sparse subset of the arrivals that contains the majority of the energy carried by the signal	purpose	2K_dev_1021
While Bayesian methods are praised for their ability to incorporate useful prior knowledge	background	2K_dev_1022
in practice	background	2K_dev_1022
priors that allow for computationally convenient or tractable inference are more commonly used	background	2K_dev_1022
	background	2K_dev_1022
We prove that our method can generate asymptotically exact samples	finding	2K_dev_1022
and demonstrate it	finding	2K_dev_1022
We present a procedure : given an inferred false posterior and true prior	mechanism	2K_dev_1022
our algorithm generates samples from the true posterior	mechanism	2K_dev_1022
This transformation procedure	mechanism	2K_dev_1022
which we call `` prior swapping '' works for arbitrary priors	mechanism	2K_dev_1022
Notably	mechanism	2K_dev_1022
its cost is independent of data size	mechanism	2K_dev_1022
It therefore allows us	mechanism	2K_dev_1022
in some cases	mechanism	2K_dev_1022
to apply significantly less-costly inference procedures to more-sophisticated models than previously possible	mechanism	2K_dev_1022
It also lets us quickly perform any additional inferences	mechanism	2K_dev_1022
such as with updated priors or for many different hyperparameter settings	mechanism	2K_dev_1022
without touching the data	mechanism	2K_dev_1022
	mechanism	2K_dev_1022
empirically on a number of models and priors	method	2K_dev_1022
	method	2K_dev_1022
In this paper	purpose	2K_dev_1022
we investigate the following question : for a given model	purpose	2K_dev_1022
is it possible to use any convenient prior to infer a false posterior	purpose	2K_dev_1022
and afterwards	purpose	2K_dev_1022
given some true prior of interest	purpose	2K_dev_1022
quickly transform this result into the true posterior ? to carry out this task	purpose	2K_dev_1022
	background	2K_dev_1023
results that capture	finding	2K_dev_1023
e	finding	2K_dev_1023
g	finding	2K_dev_1023
	finding	2K_dev_1023
the conspicuous phenomenon of emergence and downfall of leaders in social networks	finding	2K_dev_1023
We propose a family of models by reinforcement and penalization of their connections according to certain local laws of interaction	mechanism	2K_dev_1023
The family of stochastic dynamical systems	mechanism	2K_dev_1023
on the edges of a graph	mechanism	2K_dev_1023
exhibits \emph { good } convergence properties	mechanism	2K_dev_1023
in particular	mechanism	2K_dev_1023
we prove a strong-stability result : a subset of binary matrices or graphs -- characterized by certain compatibility properties -- is a global almost sure attractor of the family of stochastic dynamical systems	mechanism	2K_dev_1023
To illustrate finer properties of the corresponding strong attractor	method	2K_dev_1023
we present some simulation	method	2K_dev_1023
to study the evolution of ties in a network of interacting agents	purpose	2K_dev_1023
	background	2K_dev_1024
	finding	2K_dev_1024
	mechanism	2K_dev_1024
	method	2K_dev_1024
	purpose	2K_dev_1024
An age-old problem in the design of server farms is the choice of the task assignment policy	background	2K_dev_1025
This is the algorithm that determines how to assign incoming jobs to servers	background	2K_dev_1025
Popular policies include Round-Robin assignment	background	2K_dev_1025
Join-the-Shortest-Queue	background	2K_dev_1025
Join-Queue-with-Least-Work	background	2K_dev_1025
and so on	background	2K_dev_1025
We show that when server-side variability dominates runtime	finding	2K_dev_1025
replication of jobs can be very beneficial	finding	2K_dev_1025
	finding	2K_dev_1025
We introduce the Replication-d algorithm	mechanism	2K_dev_1025
where the job is considered `` done '' as soon as the first replica completes	mechanism	2K_dev_1025
We provide an exact closed-form analysis of Replication-d	mechanism	2K_dev_1025
We next introduce a much more general model	mechanism	2K_dev_1025
one which takes both the inherent job size distribution and the server-side variability into account	mechanism	2K_dev_1025
This is a departure from traditional queueing models which only allow for one `` size '' distribution We propose and analyze a new	mechanism	2K_dev_1025
Replicate-Idle-Queue ( RIQ )	mechanism	2K_dev_1025
which is designed to perform well given these dual sources of variability	mechanism	2K_dev_1025
	mechanism	2K_dev_1025
	method	2K_dev_1025
While much research has studied assignment policies	purpose	2K_dev_1025
little has taken into account server-side variability -- the fact that the server we choose might be temporarily and unpredictably slow that replicates each arrival to d servers chosen at random task assignment policy	purpose	2K_dev_1025
Recent advances in Unmanned Aerial Vehicles ( UAVs ) have enabled a myriad of new applications in many different domains from personal entertainment to process and infrastructure online monitoring in large industrial sites	background	2K_dev_1026
among other	background	2K_dev_1026
	background	2K_dev_1026
We show that this platform is non-omnidirectional in the flight plane and that UAV-to-UAV communication ceases around 75m transmitting payloads up to 200m ( over 802	finding	2K_dev_1026
11g @ 54MBps )	finding	2K_dev_1026
Our work focuses on how one can use several small UAVs collaboratively We demonstrate how a TDMA overlay using 802	mechanism	2K_dev_1026
11 radios on low-cost commercial-off-the-shelf ( COTS ) UAVs can be used to enable high channel utilization in multi-hop networks	mechanism	2K_dev_1026
by avoiding mutual interference This paper presents an extensive network characterisation and modelling of the quality of the UAV-to-UAV link	mechanism	2K_dev_1026
in terms of packet delivery ratio as a function of distance	mechanism	2K_dev_1026
packet size and orientation	mechanism	2K_dev_1026
Then	mechanism	2K_dev_1026
we solve the mathematical problem of finding the optimal link length and number of hops that maximize the end-to-end throughput	mechanism	2K_dev_1026
as we extend the network	mechanism	2K_dev_1026
We validate our mathematical model with extensive experimental campaigns	method	2K_dev_1026
to provide extended reach to an online video monitoring system	purpose	2K_dev_1026
	purpose	2K_dev_1026
More than 10 % of the population has dyslexia	background	2K_dev_1027
and most are diagnosed only after they fail in school	background	2K_dev_1027
Currently	background	2K_dev_1027
we are working with schools to put our approach into practice at scale to reduce school failure as a primary way dyslexia is diagnosed	background	2K_dev_1027
	background	2K_dev_1027
revealed differences in how people with dyslexia read and write	finding	2K_dev_1027
with 83 % accuracy in a held-out test set with 100 participants	finding	2K_dev_1027
	finding	2K_dev_1027
detection via machine learning models by watching how people interact with a linguistic web-based game : Dytective The design of Dytective is based on ( i ) the empirical linguistic analysis of the errors that people with dyslexia make	mechanism	2K_dev_1027
( ii ) principles of language acquisition	mechanism	2K_dev_1027
and ( iii ) specific linguistic skills related to dyslexia We trained a machine learning model that was able to predict dyslexia	mechanism	2K_dev_1027
Experiments with 243 children and adults ( 95 with diagnosed dyslexia )	method	2K_dev_1027
This work seeks to change this through scalable early that predict reading and writing difficulties	purpose	2K_dev_1027
	background	2K_dev_1028
Results led to accurate reconstruction of several known regulatory and signaling pathways and to novel mechanistic insights highlighting the usefulness of temporal models	finding	2K_dev_1028
	finding	2K_dev_1028
We present TimePath	mechanism	2K_dev_1028
a new method that integrates time series and static datasets TimePath uses an Integer Programming formulation to select a subset of pathways that	mechanism	2K_dev_1028
together	mechanism	2K_dev_1028
explain the observed dynamic responses	mechanism	2K_dev_1028
Applying TimePath to study human response to HIV-1 We experimentally validated several of TimePaths predictions	method	2K_dev_1028
Motivation : Most methods for reconstructing response networks from high throughput data generate static models which can not distinguish between early and late response stages	purpose	2K_dev_1028
to reconstruct dynamic models of host response to stimulus	purpose	2K_dev_1028
	purpose	2K_dev_1028
	background	2K_dev_1029
results extend the reach of a recent theory of invariance to discriminative and kernelized features based on unitary kernels and outperform previous work in almost all cases on off-angle face matching while we are on par with the previous state-of-the-art on the LFW unsupervised and image-restricted protocols	finding	2K_dev_1029
without any low-level image descriptors other than raw-pixels	finding	2K_dev_1029
We propose an explicitly discriminative and 'simple ' approach	mechanism	2K_dev_1029
the approach works well As a special case	mechanism	2K_dev_1029
a single common framework can be used for face recognition and vice-versa for pose estimation We show that our main proposed method ( DIKF ) can perform well under very challenging large-scale semisynthetic face matching and pose estimation protocols with unaligned faces using no landmarking whatsoever	mechanism	2K_dev_1029
In practice Our theoretical We additionally benchmark on CMU MPIE	method	2K_dev_1029
to generate invariance to nuisance transformations modeled as unitary to handle non-unitary transformations as well	purpose	2K_dev_1029
to generate subject-specific pose-invariant features	purpose	2K_dev_1029
Large graphs are prevalent in many applications and enable a variety of information dissemination processes	background	2K_dev_1030
e	background	2K_dev_1030
g	background	2K_dev_1030
	background	2K_dev_1030
meme	background	2K_dev_1030
virus	background	2K_dev_1030
and influence propagation	background	2K_dev_1030
How can we optimize the underlying graph structure to affect the outcome of such dissemination processes in a desired way ( e	background	2K_dev_1030
g	background	2K_dev_1030
	background	2K_dev_1030
stop a virus propagation	background	2K_dev_1030
facilitate the propagation of a piece of good idea	background	2K_dev_1030
etc ) ? Existing research suggests that the leading eigenvalue of the underlying graph is the key metric in determining the so-called epidemic threshold for a variety of dissemination models	background	2K_dev_1030
	background	2K_dev_1030
In addition	finding	2K_dev_1030
we reveal the intrinsic relationship between edge deletion and node deletion problems	finding	2K_dev_1030
results validate the effectiveness and efficiency of the proposed algorithms	finding	2K_dev_1030
We propose effective	mechanism	2K_dev_1030
scalable algorithms	mechanism	2K_dev_1030
Experimental	method	2K_dev_1030
In this paper	purpose	2K_dev_1030
we study the problem of how to optimally place a set of edges ( e	purpose	2K_dev_1030
g	purpose	2K_dev_1030
	purpose	2K_dev_1030
edge deletion and edge addition ) to optimize the leading eigenvalue of the underlying graph	purpose	2K_dev_1030
so that we can guide the dissemination process in a desired way for edge deletion and edge addition	purpose	2K_dev_1030
respectively	purpose	2K_dev_1030
	purpose	2K_dev_1030
Robust face detection in the wild is one of the ultimate components to support various facial related problems	background	2K_dev_1031
i	background	2K_dev_1031
e	background	2K_dev_1031
unconstrained face recognition	background	2K_dev_1031
facial periocular recognition	background	2K_dev_1031
facial landmarking and pose estimation	background	2K_dev_1031
facial expression recognition	background	2K_dev_1031
3D facial model construction	background	2K_dev_1031
etc	background	2K_dev_1031
results show that our proposed approach trained on WIDER FACE Dataset outperforms strong baselines on WIDER FACE Dataset by a large margin	finding	2K_dev_1031
and consistently achieves competitive results on FDDB against the recent state-of-the-art face detection methods	finding	2K_dev_1031
	finding	2K_dev_1031
In this paper	mechanism	2K_dev_1031
we present a face detection approach named Contextual Multi-Scale Region-based Convolution Neural Network ( CMS-RCNN ) Similar to the region-based CNNs	mechanism	2K_dev_1031
our proposed network consists of the region proposal component and the region-of-interest ( RoI ) detection component	mechanism	2K_dev_1031
However	mechanism	2K_dev_1031
far apart of that network	mechanism	2K_dev_1031
there are two main contributions in our proposed network that play a significant role to achieve the state-of-the-art performance in face detection Firstly	mechanism	2K_dev_1031
the multi-scale information is grouped both in region proposal and RoI detection to deal with tiny face regions	mechanism	2K_dev_1031
Secondly	mechanism	2K_dev_1031
our proposed network allows explicit body contextual reasoning in the network inspired from the intuition of human vision system	mechanism	2K_dev_1031
	mechanism	2K_dev_1031
The proposed approach is benchmarked on two recent challenging face detection databases	method	2K_dev_1031
i	method	2K_dev_1031
e	method	2K_dev_1031
the WIDER FACE Dataset which contains high degree of variability	method	2K_dev_1031
as well as the Face Detection Dataset and Benchmark ( FDDB ) The experimental	method	2K_dev_1031
Although the face detection problem has been intensely studied for decades with various commercial applications	purpose	2K_dev_1031
it still meets problems in some real-world scenarios due to numerous challenges	purpose	2K_dev_1031
e	purpose	2K_dev_1031
g	purpose	2K_dev_1031
heavy facial occlusions	purpose	2K_dev_1031
extremely low resolutions	purpose	2K_dev_1031
strong illumination	purpose	2K_dev_1031
exceptionally pose variations	purpose	2K_dev_1031
image or video compression artifacts	purpose	2K_dev_1031
etc to robustly solve the problems mentioned above	purpose	2K_dev_1031
	purpose	2K_dev_1031
Recently fair division theory has emerged as a promising approach for allocation of multiple computational resources among agents While in reality agents are not all present in the system simultaneously	background	2K_dev_1032
previous work has studied static settings where all relevant information is known upfront	background	2K_dev_1032
We believe that our work informs the design of superior multiagent systems	background	2K_dev_1032
and at the same time expands the scope of fair division theory by initiating the study of dynamic and fair resource allocation mechanisms	background	2K_dev_1032
	background	2K_dev_1032
	finding	2K_dev_1032
On the conceptual level	mechanism	2K_dev_1032
we develop a dynamic model of fair division	mechanism	2K_dev_1032
and propose desirable axiomatic properties On the technical level	mechanism	2K_dev_1032
we construct two novel mechanisms that provably satisfy some of these properties	mechanism	2K_dev_1032
	mechanism	2K_dev_1032
and analyze their performance using real data	method	2K_dev_1032
	method	2K_dev_1032
Our goal is to better understand the dynamic setting for dynamic resource allocation mechanisms	purpose	2K_dev_1032
	purpose	2K_dev_1032
	background	2K_dev_1033
	finding	2K_dev_1033
	mechanism	2K_dev_1033
	method	2K_dev_1033
	purpose	2K_dev_1033
	background	2K_dev_1034
Our main result is a characterization of worst-case optimal truthful estimators	finding	2K_dev_1034
which provably outperform the median	finding	2K_dev_1034
for possibly asymmetric distributions with bounded support	finding	2K_dev_1034
taking a game-theoretic viewpoint In our setting	mechanism	2K_dev_1034
samples are supplied by strategic agents	mechanism	2K_dev_1034
who wish to pull the estimate as close as possible to their own value In this setting	mechanism	2K_dev_1034
the sample mean gives rise to manipulation opportunities	mechanism	2K_dev_1034
whereas the sample median does not We show that when the underlying distribution is symmetric	mechanism	2K_dev_1034
there are truthful estimators that dominate the median	mechanism	2K_dev_1034
	mechanism	2K_dev_1034
	method	2K_dev_1034
We revisit the classic problem of estimating the population mean of an unknown single-dimensional distribution from samples Our key question is whether the sample median is the best ( in terms of mean squared error ) truthful estimator of the population mean	purpose	2K_dev_1034
	background	2K_dev_1035
	finding	2K_dev_1035
and show it often achieves order of magnitude speedups over existing general-purpose optimization solvers	finding	2K_dev_1035
This paper develops an approach a common general-purpose modeling framework	mechanism	2K_dev_1035
Specifically we develop an algorithm based upon fast epigraph projections	mechanism	2K_dev_1035
projections onto the epigraph of a convex function	mechanism	2K_dev_1035
an approach closely linked to proximal operator methods	mechanism	2K_dev_1035
We show that by using these operators	mechanism	2K_dev_1035
we can solve any disciplined convex program without transforming the problem to a standard cone form	mechanism	2K_dev_1035
as is done by current DCP libraries We then develop a large library of efficient epigraph projection operators	mechanism	2K_dev_1035
mirroring and extending work on fast proximal algorithms	mechanism	2K_dev_1035
for many common convex functions	mechanism	2K_dev_1035
Finally	method	2K_dev_1035
we evaluate the performance of the algorithm	method	2K_dev_1035
for efficiently solving general convex optimization problems specified as disciplined convex programs ( DCP )	purpose	2K_dev_1035
Malware authors have been using websites to distribute their products as a way to evade spam filters and classic anti-virus engines	background	2K_dev_1036
which could be of interest to studies on website profiling	background	2K_dev_1036
Our study is a first step towards modeling web-based malware propagation as a network-wide phenomenon and enabling researchers to develop realistic assumptions and models	background	2K_dev_1036
	background	2K_dev_1036
First	finding	2K_dev_1036
we find that legitimate but compromised websites constitute 33	finding	2K_dev_1036
1 % of the malicious websites in our dataset	finding	2K_dev_1036
with an accuracy of 95	finding	2K_dev_1036
3 % Second	finding	2K_dev_1036
we find that malicious URLs can be surprisingly long-lived	finding	2K_dev_1036
with 10 % of malicious sites staying active for three months or more Third	finding	2K_dev_1036
we observe that a significant number of URLs exhibit the same temporal pattern that suggests a flush-crowd behavior	finding	2K_dev_1036
inflicting most of their damage during the first few days of appearance	finding	2K_dev_1036
Finally	finding	2K_dev_1036
the distribution of the visits to malicious sites per user is skewed	finding	2K_dev_1036
with 1	finding	2K_dev_1036
4 % of users visiting more than 10 malicious sites in 8 months	finding	2K_dev_1036
we develop a classifier	mechanism	2K_dev_1036
We conduct an extensive study and follow a website-centric and user-centric point of view We collect data from four online databases	method	2K_dev_1036
including Symantec 's WINE Project	method	2K_dev_1036
for a total of more than 600K malicious URLs and over 500K users	method	2K_dev_1036
Yet there has been relatively little work in modeling the behaviors and temporal properties of websites	purpose	2K_dev_1036
as most research focuses on detecting whether a website distributes malware	purpose	2K_dev_1036
In this paper we ask : How does web-based malware spread ? In order to conduct this study	purpose	2K_dev_1036
to distinguish between compromised vs	purpose	2K_dev_1036
malicious websites	purpose	2K_dev_1036
The design of revenue-maximizing combinatorial auctions	background	2K_dev_1037
i	background	2K_dev_1037
e	background	2K_dev_1037
multi item auctions over bundles of goods	background	2K_dev_1037
is one of the most fundamental problems in computational economics	background	2K_dev_1037
unsolved even for two bidders and two items for sale	background	2K_dev_1037
In the traditional economic models	background	2K_dev_1037
it is assumed that the bidders ' valuations are drawn from an underlying distribution and that the auction designer has perfect knowledge of this distribution Despite this strong and oftentimes unrealistic assumption	background	2K_dev_1037
it is remarkable that the revenue-maximizing combinatorial auction remains unknown The most scalable automated mechanism design algorithms take as input samples from the bidders ' valuation distribution and then search for a high-revenue auction in a rich auction class	background	2K_dev_1037
	background	2K_dev_1037
	finding	2K_dev_1037
In this work	mechanism	2K_dev_1037
we provide the first sample complexity analysis In particular	mechanism	2K_dev_1037
we provide tight sample complexity bounds on the number of samples needed to guarantee that the empirical revenue of the designed mechanism on the samples is close to its expected revenue on the underlying	mechanism	2K_dev_1037
unknown distribution over bidder valuations	mechanism	2K_dev_1037
for each of the auction classes in the hierarchy In addition to helping set automated mechanism design on firm foundations	mechanism	2K_dev_1037
our results also push the boundaries of learning theory	mechanism	2K_dev_1037
In particular	mechanism	2K_dev_1037
the hypothesis functions used in our contexts are defined through multi stage combinatorial optimization procedures	mechanism	2K_dev_1037
rather than simple decision boundaries	mechanism	2K_dev_1037
as are common in machine learning	mechanism	2K_dev_1037
	mechanism	2K_dev_1037
	method	2K_dev_1037
In recent years	purpose	2K_dev_1037
automated mechanism design has emerged as one of the most practical and promising approaches to designing high-revenue combinatorial auctions for the standard hierarchy of deterministic combinatorial auction classes used in automated mechanism design	purpose	2K_dev_1037
	purpose	2K_dev_1037
Online content have become an important medium to disseminate information and express opinions	background	2K_dev_1038
This paper is an extended abstract of the 2012 ACM SIGKDD best doctoral dissertation award of Ahmed [ 2011 ]	background	2K_dev_1038
	background	2K_dev_1038
	finding	2K_dev_1038
and provide algorithms that create a structured representation of the otherwise unstructured content	mechanism	2K_dev_1038
We leverage the expressiveness of latent probabilistic models ( e	mechanism	2K_dev_1038
g	mechanism	2K_dev_1038
	mechanism	2K_dev_1038
topic models ) and non-parametric Bayes techniques ( e	mechanism	2K_dev_1038
g	mechanism	2K_dev_1038
	mechanism	2K_dev_1038
Dirichlet processes )	mechanism	2K_dev_1038
and give online and distributed inference algorithms that scale to terabyte datasets and adapt the inferred representation with the arrival of new documents	mechanism	2K_dev_1038
	method	2K_dev_1038
With their proliferation	purpose	2K_dev_1038
users are faced with the problem of missing the big picture in a sea of irrelevant and/or diverse content	purpose	2K_dev_1038
In this paper	purpose	2K_dev_1038
we addresses the problem of information organization of online document collections	purpose	2K_dev_1038
	purpose	2K_dev_1038
It remains a challenge to detect associations between genotypes and phenotypes because of insufficient sample sizes and complex underlying mechanisms involved in associations	background	2K_dev_1039
Availability and implementation : Software is available at http : //www	background	2K_dev_1039
sailing	background	2K_dev_1039
cs	background	2K_dev_1039
cmu	background	2K_dev_1039
edu/	background	2K_dev_1039
Contact : ude	background	2K_dev_1039
umc	background	2K_dev_1039
sc @ gnixpe	background	2K_dev_1039
Results we show that NETAM finds significantly more phenotype-associated SNPs than traditional genotypephenotype association analysis under false positive control	finding	2K_dev_1039
taking advantage of gene expression data and identified 477 significant path associations	finding	2K_dev_1039
among which we analyzed paths related to beta-amyloid	finding	2K_dev_1039
estrogen	finding	2K_dev_1039
and nicotine pathways	finding	2K_dev_1039
In this article	mechanism	2K_dev_1039
we propose a novel method	mechanism	2K_dev_1039
NETAM	mechanism	2K_dev_1039
We take a network-driven approach : NETAM first constructs an association network	mechanism	2K_dev_1039
where nodes represent SNPs	mechanism	2K_dev_1039
gene traits or phenotypes	mechanism	2K_dev_1039
and edges represent the strength of association between two nodes	mechanism	2K_dev_1039
NETAM assigns a score to each path from an SNP to a phenotype	mechanism	2K_dev_1039
and then identifies significant paths based on the scores	mechanism	2K_dev_1039
In our simulation study	method	2K_dev_1039
Furthermore	method	2K_dev_1039
we applied NETAM on late-onset Alzheimers disease data We also provide hypothetical biological pathways to explain our findings	method	2K_dev_1039
Motivation Fortunately	purpose	2K_dev_1039
it is becoming more feasible to obtain gene expression data in addition to genotypes and phenotypes	purpose	2K_dev_1039
giving us new opportunities to detect true genotypephenotype associations while unveiling their association mechanisms	purpose	2K_dev_1039
that accurately detects associations between SNPs and phenotypes	purpose	2K_dev_1039
as well as gene traits involved in such associations	purpose	2K_dev_1039
	purpose	2K_dev_1039
	background	2K_dev_1040
that demonstrate the flexibility and effectiveness of the MQGM in modeling hetereoskedastic non-Gaussian data	finding	2K_dev_1040
	finding	2K_dev_1040
We introduce the Multiple Quantile Graphical Model ( MQGM )	mechanism	2K_dev_1040
which extends the neighborhood selection approach of Meinshausen and Buhlmann The latter is defined by the basic subproblem of modeling the conditional mean of one variable as a sparse function of all others	mechanism	2K_dev_1040
Our approach models a set of conditional quantiles of one variable as a sparse function of all others	mechanism	2K_dev_1040
and hence offers a much richer	mechanism	2K_dev_1040
more expressive class of conditional distribution estimates We establish that	mechanism	2K_dev_1040
under suitable regularity conditions	mechanism	2K_dev_1040
the MQGM identifies the exact conditional independencies with probability tending to one as the problem size grows	mechanism	2K_dev_1040
even outside of the usual homoskedastic Gaussian data model	mechanism	2K_dev_1040
We develop an efficient algorithm using the alternating direction method of multipliers	mechanism	2K_dev_1040
We also describe a strategy	mechanism	2K_dev_1040
Lastly	method	2K_dev_1040
we present detailed experiments	method	2K_dev_1040
for learning sparse graphical models	purpose	2K_dev_1040
for fitting the MQGM for sampling from the joint distribution that underlies the MQGM estimate	purpose	2K_dev_1040
	purpose	2K_dev_1040
	background	2K_dev_1041
For each user	finding	2K_dev_1041
we discover and explain a surprising	finding	2K_dev_1041
bi-modal pattern of the inter-arrival time ( IAT ) of landed queries ( queries with user click-through ) we then notice the correlations among its parameters at the group level	finding	2K_dev_1041
	finding	2K_dev_1041
In this paper	mechanism	2K_dev_1041
we present a novel	mechanism	2K_dev_1041
user-and group-level framework	mechanism	2K_dev_1041
M3A : Model	mechanism	2K_dev_1041
MetaModel and Anomaly detection Specifically	mechanism	2K_dev_1041
the model Camel-Log is proposed Thus	mechanism	2K_dev_1041
we further propose the metamodel Meta-Click	mechanism	2K_dev_1041
Combining Camel-Log and Meta-Click	mechanism	2K_dev_1041
the proposed M3A has the following strong points : ( 1 ) the accurate modeling of marginal IAT distribution	mechanism	2K_dev_1041
( 2 ) quantitative interpretations	mechanism	2K_dev_1041
and ( 3 ) anomaly detection	mechanism	2K_dev_1041
	mechanism	2K_dev_1041
We studied what is probably the largest	method	2K_dev_1041
publicly available	method	2K_dev_1041
query log that contains more than 30 million queries from 0	method	2K_dev_1041
6 million users	method	2K_dev_1041
	method	2K_dev_1041
'Alice ' is submitting one web search per five minutes	purpose	2K_dev_1041
for three hours in a row - is it normal ? How to detect abnormal search behaviors	purpose	2K_dev_1041
among Alice and other users ? Is there any distinct pattern in Alice 's ( or other users ' ) search behavior ? to describe such an IAT distribution to capture and explain the two-dimensional	purpose	2K_dev_1041
heavy-tail distribution of the parameters	purpose	2K_dev_1041
	purpose	2K_dev_1041
	background	2K_dev_1042
	finding	2K_dev_1042
	mechanism	2K_dev_1042
	method	2K_dev_1042
	purpose	2K_dev_1042
The large number of user-generated videos uploaded on to the Internet everyday has led to many commercial video search engines	background	2K_dev_1043
which mainly rely on text metadata for search	background	2K_dev_1043
	background	2K_dev_1043
where our system outperformed other submissions in both text queries and video example queries	finding	2K_dev_1043
thus demonstrating the effectiveness of our proposed approaches	finding	2K_dev_1043
We present novel strategies in these topics and under different query inputs	mechanism	2K_dev_1043
including pure textual queries and query by video examples	mechanism	2K_dev_1043
	mechanism	2K_dev_1043
Our proposed strategies have been incorporated into our submission for the TRECVID 2014 Multimedia Event Detection evaluation	method	2K_dev_1043
	method	2K_dev_1043
However	purpose	2K_dev_1043
metadata is often lacking for user-generated videos	purpose	2K_dev_1043
thus these videos are unsearchable by current search engines	purpose	2K_dev_1043
Therefore	purpose	2K_dev_1043
content-based video retrieval ( CBVR ) tackles this metadata-scarcity problem by directly analyzing the visual and audio streams of each video	purpose	2K_dev_1043
CBVR encompasses multiple research topics	purpose	2K_dev_1043
including low-level feature design	purpose	2K_dev_1043
feature fusion	purpose	2K_dev_1043
semantic detector training and video search/reranking	purpose	2K_dev_1043
to enhance CBVR in both accuracy speed	purpose	2K_dev_1043
Recent computer systems research has proposed using redundant requests to reduce latency	background	2K_dev_1044
The idea is to run a request on multiple servers and wait for the first completion ( discarding all remaining copies of the request	background	2K_dev_1044
We find some surprising results First	finding	2K_dev_1044
the response time of a fully redundant class follows a simple exponential distribution and that of the non-redundant class follows a generalized hyperexponential	finding	2K_dev_1044
Second	finding	2K_dev_1044
fully redundant classes are `` immune '' to any pain caused by other classes becoming redundant We find that	finding	2K_dev_1044
in many cases	finding	2K_dev_1044
redundancy outperforms JSQ and Opt-Split with respect to overall response time	finding	2K_dev_1044
making it an attractive solution	finding	2K_dev_1044
	finding	2K_dev_1044
This paper presents the first exact analysis of systems with redundancy We allow for any number of classes of redundant requests	mechanism	2K_dev_1044
any number of classes of non-redundant requests	mechanism	2K_dev_1044
any degree of redundancy	mechanism	2K_dev_1044
and any number of heterogeneous servers	mechanism	2K_dev_1044
In all cases we derive the limiting distribution of the state of the system	mechanism	2K_dev_1044
In small ( two or three server ) systems	mechanism	2K_dev_1044
we derive simple forms for the distribution of response time of both the redundant classes and non-redundant classes	mechanism	2K_dev_1044
and we quantify the `` gain '' to redundant classes and `` pain '' to non-redundant classes caused by redundancy	mechanism	2K_dev_1044
	mechanism	2K_dev_1044
We also compare redundancy with other approaches for reducing latency	method	2K_dev_1044
such as optimal probabilistic splitting of a class among servers ( Opt-Split ) and join-the-shortest-queue ( JSQ ) routing of a class	method	2K_dev_1044
However	purpose	2K_dev_1044
there is no exact analysis of systems with redundancy	purpose	2K_dev_1044
Work in human-computer interaction has generally assumed either a single user or a group of users working together in a shared virtual space Recent crowd-powered systems use a different model in which a dynamic group of individuals ( the crowd ) collectively form a single actor that responds to real-time performance tasks	background	2K_dev_1045
e	background	2K_dev_1045
g	background	2K_dev_1045
	background	2K_dev_1045
controlling an on-screen character	background	2K_dev_1045
driving a robot	background	2K_dev_1045
or operating an existing desktop interface	background	2K_dev_1045
Nowhere is the focus on the individual performer more finely resolved than in the study of the human psychomotor system	background	2K_dev_1045
a mainstay topic in psychology that	background	2K_dev_1045
largely owing to Fitts law	background	2K_dev_1045
also has a legacy in HCI	background	2K_dev_1045
This work contributes to the beginning of a predictive science for the general crowd actor model	background	2K_dev_1045
	finding	2K_dev_1045
In this paper	mechanism	2K_dev_1045
we introduce the idea of the crowd actor as a way by modeling the crowd as a individual motor system performing pointing tasks	mechanism	2K_dev_1045
	mechanism	2K_dev_1045
We combined the input of 200 participants in a controlled offline experiment to demonstrate the inherent trade-offs between speed and errors based on personality	method	2K_dev_1045
the number of constituent individuals	method	2K_dev_1045
and the mechanism used to distribute work across the group	method	2K_dev_1045
Finally	method	2K_dev_1045
10 workers participated in a synchronous experiment to explore how the crowd actor responds in a real online setting	method	2K_dev_1045
to model coordination strategies and resulting collective performance	purpose	2K_dev_1045
and discuss how the crowd actor is influenced not only by the domain on which it is asked to operate but also by the personality endowed to it by algorithms used to combine the inputs of constituent participants	purpose	2K_dev_1045
Therefore	purpose	2K_dev_1045
we explored our notion of a crowd actor	purpose	2K_dev_1045
	background	2K_dev_1046
show that not only is our proposed tracker effective	finding	2K_dev_1046
but also the solution path enables automatic pinpointing of potential tracking failures	finding	2K_dev_1046
which can be readily utilized in an active learning framework to improve identity-aware multi-object tracking	finding	2K_dev_1046
	finding	2K_dev_1046
We propose an identity-aware multi-object tracker based on the solution path algorithm	mechanism	2K_dev_1046
Our tracker not only produces based on cues such as recognition	mechanism	2K_dev_1046
but also has the ability The tracker is formulated as a quadratic optimization problem with l0 norm constraints	mechanism	2K_dev_1046
which we propose to solve with the solution path algorithm	mechanism	2K_dev_1046
The algorithm successively solves the same optimization problem but under different lp norm constraints	mechanism	2K_dev_1046
where p gradually decreases from 1 to 0	mechanism	2K_dev_1046
Inspired by the success of the solution path algorithm in various machine learning tasks	mechanism	2K_dev_1046
this strategy is expected to converge to a better local minimum than directly minimizing the hardly solvable l0 norm or the roughly approximated l1 norm constraints	mechanism	2K_dev_1046
Furthermore	mechanism	2K_dev_1046
the acquired solution path complies with the `` decision making process '' of the tracker	mechanism	2K_dev_1046
which provides more insight to locating potential tracking errors	mechanism	2K_dev_1046
	mechanism	2K_dev_1046
Experiments	method	2K_dev_1046
identity-coherent trajectories to pinpoint potential tracking errors	purpose	2K_dev_1046
	background	2K_dev_1047
With the progressively trained CNN models	finding	2K_dev_1047
we have achieved better gender classification results on the large-scale PCSO mugshot database with 400K images under occlusion and low-resolution settings	finding	2K_dev_1047
compared to the one undergone traditional training	finding	2K_dev_1047
Inspired by the trainable attention model via deep architecture	mechanism	2K_dev_1047
and the fact that the periocular region is proven to be the most salient region for gender classification purposes	mechanism	2K_dev_1047
we are able to design a progressive convolutional neural network training paradigm The network benefits from this attention shift and becomes more robust towards occlusions and low-resolution degradations	mechanism	2K_dev_1047
In addition	mechanism	2K_dev_1047
our progressively trained network is sufficiently generalized so that it can be robust to occlusions of arbitrary types and at arbitrary locations	mechanism	2K_dev_1047
as well as low resolution	mechanism	2K_dev_1047
	method	2K_dev_1047
In this work	purpose	2K_dev_1047
we have undertaken the task of occlusion and low-resolution robust facial gender classification to enforce the attention shift during the learning process	purpose	2K_dev_1047
The hope is to enable the network to attend to particular high-profile regions ( e	purpose	2K_dev_1047
g	purpose	2K_dev_1047
the periocular region ) without the need to change the network architecture itself	purpose	2K_dev_1047
	purpose	2K_dev_1047
	background	2K_dev_1048
	finding	2K_dev_1048
	mechanism	2K_dev_1048
	method	2K_dev_1048
	purpose	2K_dev_1048
	background	2K_dev_1049
	finding	2K_dev_1049
	mechanism	2K_dev_1049
	method	2K_dev_1049
	purpose	2K_dev_1049
	background	2K_dev_1050
	finding	2K_dev_1050
	mechanism	2K_dev_1050
	method	2K_dev_1050
	purpose	2K_dev_1050
Advances in fluorescence in situ hybridization ( FISH ) make it feasible to detect multiple copy-number changes in hundreds of cells of solid tumors	background	2K_dev_1051
Studies using FISH	background	2K_dev_1051
sequencing	background	2K_dev_1051
and other technologies have revealed substantial intra-tumor heterogeneity The evolution of subclones in tumors may be modeled by phylogenies	background	2K_dev_1051
Tumors often harbor aneuploid or polyploid cell populations	background	2K_dev_1051
Tests on simulated data show improved accuracy of the ploidy-based approach relative to prior ploidyless methods Tests on real data further demonstrate novel insights these methods offer into tumor progression processes	finding	2K_dev_1051
Trees for DCIS samples are significantly less complex than trees for paired IDC samples Consensus graphs show substantial divergence among most paired samples from both sets	finding	2K_dev_1051
Low consensus between DCIS and IDC trees may help explain the difficulty in finding biomarkers that predict which DCIS cases are at most risk to progress to IDC	finding	2K_dev_1051
The FISHtrees software is available at ftp : //ftp	finding	2K_dev_1051
ncbi	finding	2K_dev_1051
nih	finding	2K_dev_1051
gov/pub/FISHtrees	finding	2K_dev_1051
We present FISHtrees 3	mechanism	2K_dev_1051
0	mechanism	2K_dev_1051
which implements a ploidy-based tree building method based on mixed integer linear programming ( MILP ) The ploidy-based modeling in FISHtrees includes a new formulation of the problem of merging trees for changes of a single gene into trees modeling changes in multiple genes and the ploidy	mechanism	2K_dev_1051
When multiple samples are collected from each patient	mechanism	2K_dev_1051
varying over time or tumor regions	mechanism	2K_dev_1051
it is useful to evaluate similarities in tumor progression among the samples	mechanism	2K_dev_1051
Therefore	mechanism	2K_dev_1051
we further implemented in FISHtrees 3	mechanism	2K_dev_1051
0 a new method to build consensus graphs for multiple samples	mechanism	2K_dev_1051
	mechanism	2K_dev_1051
We validate FISHtrees 3	method	2K_dev_1051
0 on a simulated data and on FISH data from paired cases of cervical primary and metastatic tumors and on paired breast ductal carcinoma in situ ( DCIS ) and invasive ductal carcinoma ( IDC )	method	2K_dev_1051
	method	2K_dev_1051
Using a FISH probe to estimate changes in ploidy can guide the creation of trees that model changes in ploidy and individual gene copy-number variations	purpose	2K_dev_1051
In learning latent variable models ( LVMs )	background	2K_dev_1052
it is important to effectively capture infrequent patterns and shrink model size without sacrificing modeling power	background	2K_dev_1052
Various studies have been done to `` diversify '' a LVM	background	2K_dev_1052
which aim to learn a diverse set of latent components in LVMs	background	2K_dev_1052
and experimental results demonstrate the effectiveness and efficiency of our methods	finding	2K_dev_1052
	finding	2K_dev_1052
We propose two approaches that have complementary advantages	mechanism	2K_dev_1052
One is to define diversity-promoting mutual angular priors which assign larger density to components with larger mutual angles based on Bayesian network and von Mises-Fisher distribution and use these priors to affect the posterior via Bayes rule	mechanism	2K_dev_1052
We develop two efficient approximate posterior inference algorithms based on variational inference and Markov chain Monte Carlo sampling	mechanism	2K_dev_1052
The other approach is to impose diversity-promoting regularization directly over the post-data distribution of components	mechanism	2K_dev_1052
	mechanism	2K_dev_1052
These two methods are applied to the Bayesian mixture of experts model to encourage the `` experts '' to be diverse	method	2K_dev_1052
Most existing studies fall into a frequentist-style regularization framework	purpose	2K_dev_1052
where the components are learned via point estimation	purpose	2K_dev_1052
In this paper	purpose	2K_dev_1052
we investigate how to `` diversify '' LVMs in the paradigm of Bayesian learning	purpose	2K_dev_1052
which has advantages complementary to point estimation	purpose	2K_dev_1052
such as alleviating overfitting via model averaging and quantifying uncertainty	purpose	2K_dev_1052
	background	2K_dev_1053
where our system outperforms previous approaches by a large gap	finding	2K_dev_1053
	finding	2K_dev_1053
Instead	mechanism	2K_dev_1053
we propose a probabilistic model by jointly leveraging text and images	mechanism	2K_dev_1053
To avoid hand-crafted feature engineering	mechanism	2K_dev_1053
we design end-to-end features based on distributed representations of images and words The model is discriminatively trained given a small set of existing ontologies and is capable of building full taxonomies from scratch for a collection of unseen conceptual label items with associated images	mechanism	2K_dev_1053
We evaluate our model and features on the WordNet hierarchies	method	2K_dev_1053
	method	2K_dev_1053
We study the problem of automatically building hypernym taxonomies from textual and visual data	purpose	2K_dev_1053
Previous works in taxonomy induction generally ignore the increasingly prominent visual data	purpose	2K_dev_1053
which encode important perceptual semantics	purpose	2K_dev_1053
for taxonomy induction	purpose	2K_dev_1053
	background	2K_dev_1054
	finding	2K_dev_1054
	mechanism	2K_dev_1054
	method	2K_dev_1054
	purpose	2K_dev_1054
Besides appearance information	background	2K_dev_1055
the video contains temporal evolution	background	2K_dev_1055
which represents an important and useful source of information about its content	background	2K_dev_1055
Many video representation approaches are based on the motion information within the video	background	2K_dev_1055
The common approach to extract the motion information is to compute the optical flow from the vertical and the horizontal temporal evolution of two consecutive frames	background	2K_dev_1055
	background	2K_dev_1055
Our HMG pipeline with several additional speed-ups is able to achieve real-time video processing and outperforms several well-known descriptors including descriptors based on the costly optical flow	finding	2K_dev_1055
	finding	2K_dev_1055
In this work we propose a very efficient approach Our method is based on a simple temporal and spatial derivation	mechanism	2K_dev_1055
which captures the changes between two consecutive frames	mechanism	2K_dev_1055
	mechanism	2K_dev_1055
The proposed descriptor	method	2K_dev_1055
Histograms of Motion Gradients ( HMG )	method	2K_dev_1055
is validated on the UCF50 human action recognition dataset	method	2K_dev_1055
	method	2K_dev_1055
However	purpose	2K_dev_1055
the computation of optical flow is very demanding in terms of computational cost	purpose	2K_dev_1055
in many cases being the most significant processing step within the overall pipeline of the target video analysis application	purpose	2K_dev_1055
to capture the motion information within the video	purpose	2K_dev_1055
	purpose	2K_dev_1055
The applications of laser scanning technology are rapidly expanding in the civil engineering domain	background	2K_dev_1056
LiDAR technology is now commonly used in the surveying and monitoring of large infrastructures In particular	background	2K_dev_1056
tunnels have become key transport infrastructures	background	2K_dev_1056
subjected to maintenance processes that allow quality checks for tunnel modifications or tunnel clearance and profile checks	background	2K_dev_1056
demonstrating that tunnel management activities can definitely benefit from using mobile LiDAR by minimizing survey time and increasing productivity in dangerous environments	background	2K_dev_1056
	background	2K_dev_1056
An accuracy of 100 % in detection of cross sections is achieved	finding	2K_dev_1056
Only one of the cross sections shows a relative error in vertical clearance measurement higher than 1 %	finding	2K_dev_1056
The results demonstrated the effectiveness of the developed approach for computing vertical clearances and	finding	2K_dev_1056
The research described in this paper targets developing an approach based on ground based mobile LiDAR data	mechanism	2K_dev_1056
The steps of this approach include extraction of cross sections orthogonal to the vehicle trajectory and road markings based on radiometric information	mechanism	2K_dev_1056
and conversion of cross section to a two-dimensional profile to estimate the vertical clearance	mechanism	2K_dev_1056
	mechanism	2K_dev_1056
The validation of the developed approach is done using real-life case study	method	2K_dev_1056
a road tunnel in southern Galicia	method	2K_dev_1056
Spain	method	2K_dev_1056
	method	2K_dev_1056
to semi-automatically retrieve the tunnel vertical clearance	purpose	2K_dev_1056
Complex event detection on unconstrained Internet videos has seen much progress in recent years	background	2K_dev_1057
and achieve state-of-the-art performances	finding	2K_dev_1057
	finding	2K_dev_1057
In this paper	mechanism	2K_dev_1057
we present a state-of-the-art event search system without any example videos	mechanism	2K_dev_1057
Relying on the key observation that events ( e	mechanism	2K_dev_1057
g	mechanism	2K_dev_1057
dog show ) are usually compositions of multiple mid-level concepts ( e	mechanism	2K_dev_1057
g	mechanism	2K_dev_1057
`` dog	mechanism	2K_dev_1057
'' `` theater	mechanism	2K_dev_1057
'' and `` dog jumping '' )	mechanism	2K_dev_1057
we first train a skip-gram model to measure the relevance of each concept with the event of interest The relevant concept classifiers then cast votes on the test videos but their reliability	mechanism	2K_dev_1057
due to lack of labeled training videos	mechanism	2K_dev_1057
has been largely unaddressed We propose to combine the concept classifiers based on a principled estimate of their accuracy on the unlabeled test videos A novel warping technique is proposed to improve the performance and an efficient highly-scalable algorithm is provided to quickly solve the resulting optimization	mechanism	2K_dev_1057
We conduct extensive experiments on the latest TRECVID MEDTest 2014	method	2K_dev_1057
MEDTest 2013 and CCV datasets	method	2K_dev_1057
	method	2K_dev_1057
However	purpose	2K_dev_1057
state-of-the-art performance degrades dramatically when the number of positive training exemplars falls short	purpose	2K_dev_1057
Since label acquisition is costly	purpose	2K_dev_1057
laborious	purpose	2K_dev_1057
and time-consuming	purpose	2K_dev_1057
there is a real need to consider the much more challenging semantic event search problem	purpose	2K_dev_1057
where no example video is given	purpose	2K_dev_1057
	purpose	2K_dev_1057
Kidney exchange	background	2K_dev_1058
where candidates with organ failure trade incompatible but willing donors	background	2K_dev_1058
is a lifesaving alternative to the deceased donor waitlist	background	2K_dev_1058
which has inadequate supply to meet demand While fielded kidney exchanges see huge benefit from altruistic kidney donors ( who give an organ without a paired needy candidate )	background	2K_dev_1058
a significantly higher medical risk to the donor deters similar altruism with livers	background	2K_dev_1058
We conclude with thoughts regarding the fielding of a nationwide liver or joint liverkidney exchange from a legal and computational point of view	background	2K_dev_1058
	background	2K_dev_1058
	finding	2K_dev_1058
In this paper	mechanism	2K_dev_1058
we begin by proposing the idea of liver exchange	mechanism	2K_dev_1058
and show on demographically accurate data that We then explore crossorgan donation where kidneys and livers can be bartered for each other	mechanism	2K_dev_1058
We show theoretically that this multiorgan exchange provides linearly more transplants than running separate kidney and liver exchanges ; this linear gain is a product of altruistic kidney donors creating chains that thread through the liver pool	mechanism	2K_dev_1058
	mechanism	2K_dev_1058
We support this result experimentally on demographically accurate multi-organ exchanges	method	2K_dev_1058
vetted kidney exchange algorithms can be adapted to clear such an exchange at the nationwide level	purpose	2K_dev_1058
	purpose	2K_dev_1058
Suspicious graph patterns show up in many applications	background	2K_dev_1059
from Twitter users who buy fake followers	background	2K_dev_1059
manipulating the social network	background	2K_dev_1059
to botnet members performing distributed denial of service attacks	background	2K_dev_1059
disturbing the network traffic graph	background	2K_dev_1059
C atch S ync consistently outperforms existing competitors	finding	2K_dev_1059
both in detection accuracy by 36p on Twitter and 20p on Tencent Weibo	finding	2K_dev_1059
as well as in speed	finding	2K_dev_1059
We propose a fast and effective method	mechanism	2K_dev_1059
C atch S ync	mechanism	2K_dev_1059
which exploits two of the tell-tale signs left in graphs by fraudsters : ( a ) synchronized behavior : suspicious nodes have extremely similar behavior patterns because they are often required to perform some task together ( such as follow the same user ) ; and ( b ) rare behavior : their connectivity patterns are very different from the majority We introduce novel measures and we propose a parameter-free algorithm that works on the resulting synchronicity-normality plots	mechanism	2K_dev_1059
Thanks to careful design	mechanism	2K_dev_1059
C atch S ync has the following desirable properties : ( a ) it is scalable to large datasets	mechanism	2K_dev_1059
being linear in the graph size ; ( b ) it is parameter free ; and ( c ) it is side-information-oblivious : it can operate using only the topology	mechanism	2K_dev_1059
without needing labeled data	mechanism	2K_dev_1059
nor timing information	mechanism	2K_dev_1059
and the like	mechanism	2K_dev_1059
	mechanism	2K_dev_1059
while still capable of using side information if available	mechanism	2K_dev_1059
	mechanism	2K_dev_1059
We applied C atch S ync on three large	method	2K_dev_1059
real datasets	method	2K_dev_1059
1-billion-edge Twitter social graph	method	2K_dev_1059
3-billion-edge	method	2K_dev_1059
and 12-billion-edge Tencent Weibo social graphs	method	2K_dev_1059
and several synthetic ones ;	method	2K_dev_1059
Given a directed graph of millions of nodes	purpose	2K_dev_1059
how can we automatically spot anomalous	purpose	2K_dev_1059
suspicious nodes judging only from their connectivity patterns ? to quantify both concepts ( synchronicity and normality )	purpose	2K_dev_1059
Action recognition ( AR ) is one of the most important tasks in video analysis and computer vision	background	2K_dev_1060
Recently a large number of related methods have been proposed	background	2K_dev_1060
leaving a reasonable space for further exploring the insights underlying such type of infrared AR problem and accordingly designing proper techniques to further promote the performance on this specifically constructed InfAR dataset	background	2K_dev_1060
	background	2K_dev_1060
Our results reveal : ( 1 ) In all	finding	2K_dev_1060
dense trajectory feature can achieve the best performance while the appearance features	finding	2K_dev_1060
e	finding	2K_dev_1060
g	finding	2K_dev_1060
	finding	2K_dev_1060
HOG	finding	2K_dev_1060
have relatively poorer performance ; ( 2 ) the encoding method of vector of locally aggregated descriptors is evidently better than that of the widely-used Fisher Vector ; ( 3 ) the late fusion facilitates a better performance than early fusion ; ( 4 ) action videos captured in winter is more discriminable than in summer ; ( 5 ) compared to appearance information	finding	2K_dev_1060
the motion information is more essential for infrared action recognition and utilizing this information through deep CNN can improve greatly the performance	finding	2K_dev_1060
The best performance achieved on our dataset is 76	finding	2K_dev_1060
66 % ( Average Precision )	finding	2K_dev_1060
	finding	2K_dev_1060
Specifically	mechanism	2K_dev_1060
we construct a new Infrared Action Recognition ( InfAR ) dataset captured at different times	mechanism	2K_dev_1060
including in summer and winter	mechanism	2K_dev_1060
and explore how discriminable actions in our InfAR dataset are with the state-of-the-art pipelines based on low-level features and deep convolutional neural network ( CNN )	mechanism	2K_dev_1060
respectively	mechanism	2K_dev_1060
	mechanism	2K_dev_1060
	method	2K_dev_1060
While most of these methods are investigated on AR datasets collected from the visible spectrum	purpose	2K_dev_1060
the AR problem under infrared scenarios still has not attracted much attention	purpose	2K_dev_1060
There is even few public infrared datasets available for supporting the fundamental evaluation requirements of this research To this issue	purpose	2K_dev_1060
this work aims to emphasize the importance of the infrared AR problem in applications and arouse researchers ' attention on this task	purpose	2K_dev_1060
Suppose you are a teacher	background	2K_dev_1061
and have to convey a set of object-property pairs 'lions eat meat '	background	2K_dev_1061
A good teacher will convey a lot of information	background	2K_dev_1061
with little effort on the student side	background	2K_dev_1061
What is the best and most intuitive way to convey this information to the student	background	2K_dev_1061
without the student being overwhelmed ?	background	2K_dev_1061
it is effective	finding	2K_dev_1061
achieving excellent results on real data	finding	2K_dev_1061
both with respect to our proposed metric	finding	2K_dev_1061
but also with respect to encoding length demonstrate the effectiveness of groupNteach	finding	2K_dev_1061
	finding	2K_dev_1061
we provide a metric based on information theory	mechanism	2K_dev_1061
We also design an algorithm	mechanism	2K_dev_1061
groupNteach Our proposed groupNteach is scalable near-linear in the dataset size ; and it is intuitive	mechanism	2K_dev_1061
conforming to well-known educational principles	mechanism	2K_dev_1061
	mechanism	2K_dev_1061
Experiments on real and synthetic datasets	method	2K_dev_1061
A related	purpose	2K_dev_1061
harder problem is : how can we assign a numerical score to each lesson plan i	purpose	2K_dev_1061
e	purpose	2K_dev_1061
	purpose	2K_dev_1061
way of conveying information ? Here	purpose	2K_dev_1061
we give a formal definition of this problem of forming learning units and for comparing different approaches for this problem	purpose	2K_dev_1061
	purpose	2K_dev_1061
It is common that users are interested in finding video segments	background	2K_dev_1062
which contain further information about the video contents in a segment of interest	background	2K_dev_1062
	background	2K_dev_1062
Results show that ( 1 ) text features play a crucial role in search performance	finding	2K_dev_1062
and the combination of audio and visual features can not provide improvements ; ( 2 ) the consideration of contexts can not obtain better results ; and ( 3 ) due to the lack of training examples	finding	2K_dev_1062
machine learning techniques can not improve the performance	finding	2K_dev_1062
	finding	2K_dev_1062
	mechanism	2K_dev_1062
In this study	method	2K_dev_1062
we explore the effectiveness of various video features on the performance of video hyperlinking	method	2K_dev_1062
including subtitle	method	2K_dev_1062
metadata	method	2K_dev_1062
content features ( i	method	2K_dev_1062
e	method	2K_dev_1062
	method	2K_dev_1062
audio and visual )	method	2K_dev_1062
surrounding context	method	2K_dev_1062
as well as the combinations of those features	method	2K_dev_1062
Besides	method	2K_dev_1062
we also test different search strategies over different types of queries	method	2K_dev_1062
which are categorized according to their video contents	method	2K_dev_1062
Comprehensive experimental studies have been conducted on the dataset of TRECVID 2015 video hyperlinking task	method	2K_dev_1062
To facilitate users to find and browse related video contents	purpose	2K_dev_1062
video hyperlinking aims at constructing links among video segments with relevant information in a large video collection	purpose	2K_dev_1062
	purpose	2K_dev_1062
Clustering is the task of grouping a set of objects so that objects in the same cluster are more similar to each other than to those in other clusters	background	2K_dev_1063
The crucial step in most clustering algorithms is to find an appropriate similarity metric	background	2K_dev_1063
which is both challenging and problem-dependent	background	2K_dev_1063
confirm several orders of magnitude speedup while still achieving state-of-the-art performance	finding	2K_dev_1063
	finding	2K_dev_1063
In this paper	mechanism	2K_dev_1063
we propose a new structured Mahalanobis Distance Metric Learning method We formulate our problem as an instance of large margin structured prediction and prove that it can be solved very efficiently in closed-form	mechanism	2K_dev_1063
The complexity of our method is ( in most cases ) linear in the size of the training dataset We further reveal a striking similarity between our approach and multivariate linear regression	mechanism	2K_dev_1063
	mechanism	2K_dev_1063
Experiments on both synthetic and real datasets	method	2K_dev_1063
Supervised clustering approaches	purpose	2K_dev_1063
which can exploit labeled clustered training data that share a common metric with the test set	purpose	2K_dev_1063
have thus been proposed	purpose	2K_dev_1063
Unfortunately	purpose	2K_dev_1063
current metric learning approaches for supervised clustering do not scale to large or even medium-sized datasets	purpose	2K_dev_1063
for supervised clustering	purpose	2K_dev_1063
	purpose	2K_dev_1063
	background	2K_dev_1064
	finding	2K_dev_1064
	mechanism	2K_dev_1064
	method	2K_dev_1064
	purpose	2K_dev_1064
	background	2K_dev_1065
	finding	2K_dev_1065
	mechanism	2K_dev_1065
	method	2K_dev_1065
	purpose	2K_dev_1065
Matrix sketching is aimed at finding close approximations of a matrix by factors of much smaller dimensions	background	2K_dev_1066
which has important applications in optimization and machine learning	background	2K_dev_1066
Given a matrix A of size m by n	background	2K_dev_1066
state-of-the-art randomized algorithms take O ( m * n ) time and space to obtain its low-rank decomposition	background	2K_dev_1066
	background	2K_dev_1066
fully demonstrate the potential of our methods in large scale matrix sketching and related areas	finding	2K_dev_1066
In this paper	mechanism	2K_dev_1066
we propose the cascaded bilateral sampling ( CABS ) framework We start from demonstrating how the approximation quality of bilateral matrix sketching depends on the encoding powers of sampling	mechanism	2K_dev_1066
In particular	mechanism	2K_dev_1066
the sampled rows and columns should correspond to the code-vectors in the ground truth decompositions Motivated by this analysis	mechanism	2K_dev_1066
we propose to first generate a pilot-sketch using simple random sampling	mechanism	2K_dev_1066
and then pursue more advanced	mechanism	2K_dev_1066
`` follow-up '' sampling on the pilot-sketch factors seeking maximal encoding powers In this cascading process	mechanism	2K_dev_1066
the rise of approximation quality is shown to be lower-bounded by the improvement of encoding powers in the follow-up sampling step	mechanism	2K_dev_1066
thus theoretically guarantees the algorithmic boosting property	mechanism	2K_dev_1066
Computationally	mechanism	2K_dev_1066
our framework only takes linear time and space	mechanism	2K_dev_1066
and at the same time its performance rivals the quality of state-of-the-art algorithms consuming a quadratic amount of resources	mechanism	2K_dev_1066
Empirical evaluations on benchmark data	method	2K_dev_1066
Although quite useful	purpose	2K_dev_1066
the need to store or manipulate the entire matrix makes it a computational bottleneck for truly large and dense inputs	purpose	2K_dev_1066
Can we sketch an m-by-n matrix in O ( m + n ) cost by accessing only a small fraction of its rows and columns	purpose	2K_dev_1066
without knowing anything about the remaining data ? to solve this problem	purpose	2K_dev_1066
	purpose	2K_dev_1066
	background	2K_dev_1067
	finding	2K_dev_1067
The system is equipped with its own controller and attack detector	mechanism	2K_dev_1067
and the goal of the attacker is to move the system to a target state while altering the system 's actuator input and sensor output to avoid detection	mechanism	2K_dev_1067
We formulate a cost function that reflects the attacker 's goals	mechanism	2K_dev_1067
and	mechanism	2K_dev_1067
using dynamic programming	mechanism	2K_dev_1067
we show that the optimal attack strategy reduces to a linear feedback of the attacker 's state estimate By changing the parameters of the cost function	mechanism	2K_dev_1067
we show how an attacker can design optimal attacks to balance the control objective and the detection avoidance objective	mechanism	2K_dev_1067
	mechanism	2K_dev_1067
Finally	method	2K_dev_1067
we provide a numerical illustration based on a remotely-controlled helicopter under attack	method	2K_dev_1067
	method	2K_dev_1067
This paper studies attackers with control objectives against cyber-physical systems ( CPS )	purpose	2K_dev_1067
At least 10 % of the global population has dyslexia	background	2K_dev_1068
In the United States and Spain	background	2K_dev_1068
dyslexia is associated with a large percentage of school drop out Our results suggest that Dytective is able to differentiate school age children with and without dyslexia in both English and Spanish speakers	background	2K_dev_1068
We found children with and without dyslexia differed significantly in their performance on the game	finding	2K_dev_1068
we designed a browser-based game	mechanism	2K_dev_1068
Dytective	mechanism	2K_dev_1068
to detect risk of dyslexia across the English and Spanish languages Dytective consists of linguistic tasks informed by analysis of common errors made by persons with dyslexia	mechanism	2K_dev_1068
To evaluate Dytective	method	2K_dev_1068
we conducted a user study with 60 English and Spanish speaking children between 7 and 12 years old	method	2K_dev_1068
Current methods to detect risk of dyslexia are language specific	purpose	2K_dev_1068
expensive	purpose	2K_dev_1068
or do not scale well because they require a professional or extensive equipment	purpose	2K_dev_1068
A central challenge to detecting dyslexia is handling its differing manifestations across languages	purpose	2K_dev_1068
To address this	purpose	2K_dev_1068
	purpose	2K_dev_1068
	background	2K_dev_1069
	finding	2K_dev_1069
	mechanism	2K_dev_1069
	method	2K_dev_1069
	purpose	2K_dev_1069
Acute hypotensive episodes ( AHEs ) are serious clinical events in intensive care units ( ICUs )	background	2K_dev_1070
and require immediate treatment to prevent patient injury	background	2K_dev_1070
	background	2K_dev_1070
HeartCast was found to outperform other state-of-the-art methods found in the literature with a 13	finding	2K_dev_1070
7 % improvement in classification accuracy	finding	2K_dev_1070
We propose HeartCast	mechanism	2K_dev_1070
a model that extracts essential features from such data HeartCast combines a non-linear support vector machine with best-feature extraction via analysis of the baseline threshold	mechanism	2K_dev_1070
quartile parameters	mechanism	2K_dev_1070
and window size of the physiological signals	mechanism	2K_dev_1070
Our approach has the following benefits : ( a ) it extracts the most relevant features ; ( b ) it provides the best results for identification of an AHE event ; ( c ) it is fast and scales with linear complexity over the length of the window ; and ( d ) it can manage missing values and noise/outliers by using a best-feature extraction method	mechanism	2K_dev_1070
	mechanism	2K_dev_1070
We performed experiments on data continuously captured from physiological time series of ICU patients ( roughly 3 GB of processed data )	method	2K_dev_1070
	method	2K_dev_1070
Reducing the risks associated with an AHE requires effective and efficient mining of data generated from multiple physiological time series	purpose	2K_dev_1070
to effectively predict AHE	purpose	2K_dev_1070
	purpose	2K_dev_1070
Summary An important experimental design question for high-throughput time series studies is the number of replicates required for accurate reconstruction of the profiles	background	2K_dev_1071
Due to budget and sample availability constraints	background	2K_dev_1071
more replicates imply fewer time points and vice versa These results provide theoretical support to the large number of high-throughput time series experiments that do not use replicates	background	2K_dev_1071
we observe that	finding	2K_dev_1071
under reasonable noise levels	finding	2K_dev_1071
autocorrelations in the time series data allow dense sampling to better determine the correct levels of non-sampled points when compared to replicate sampling	finding	2K_dev_1071
by developing a theoretical framework that focuses on a restricted yet expressive set of possible curves over a wide range of noise levels and by analyzing real expression data	mechanism	2K_dev_1071
A Java implementation of our framework can be used	mechanism	2K_dev_1071
For both the theoretical analysis and experimental data	method	2K_dev_1071
We analyze the performance of dense and replicate sampling to determine the best replicate strategy given the expected noise	purpose	2K_dev_1071
	background	2K_dev_1072
results show that our method archives better performance than Faster R-CNN on both hands on wheel detection and cell-phone usage detection while remaining at similar testing cost our approach obtains higher accuracy	finding	2K_dev_1072
is less time consuming and is independent to landmarking	finding	2K_dev_1072
The groundtruth database will be publicly available	finding	2K_dev_1072
In this paper	mechanism	2K_dev_1072
we present an advanced deep learning based approach we propose Multiple Scale Faster-RCNN ( MSFRCNN ) approach that uses a standard Region Proposal Network ( RPN ) generation and incorporates feature maps from shallower convolution feature maps	mechanism	2K_dev_1072
i	mechanism	2K_dev_1072
e	mechanism	2K_dev_1072
conv3 and conv4	mechanism	2K_dev_1072
for ROI pooling	mechanism	2K_dev_1072
In our driver distraction detection framework	mechanism	2K_dev_1072
we first make use of the proposed MS-FRCNN to detect individual objects	mechanism	2K_dev_1072
namely	mechanism	2K_dev_1072
a hand	mechanism	2K_dev_1072
a cell-phone	mechanism	2K_dev_1072
and a steering wheel Then	mechanism	2K_dev_1072
the geometric information is extracted to determine if a cell-phone is being used or how many hands are on the wheel	mechanism	2K_dev_1072
	mechanism	2K_dev_1072
The proposed approach is demonstrated and evaluated on the Vision for Intelligent Vehicles and Applications ( VIVA ) Challenge database and the challenging Strategic Highway Research Program ( SHRP-2 ) face view videos that was acquired to monitor drivers under naturalistic driving conditions The experimental Compare to the state-of-the-art cell-phone usage detection	method	2K_dev_1072
to automatically determine whether a driver is using a cell-phone as well as detect if his/her hands are on the steering wheel ( i	purpose	2K_dev_1072
e	purpose	2K_dev_1072
counting the number of hands on the wheel ) To robustly detect small objects such as hands	purpose	2K_dev_1072
What is a fair way to assign rooms to several housemates	background	2K_dev_1073
and divide the rent between them ? This is not just a theoretical question : many people have used the Spliddit website to obtain envy-free solutions to rent division instances	background	2K_dev_1073
But envy freeness	background	2K_dev_1073
in and of itself	background	2K_dev_1073
is insufficient to guarantee outcomes that people view as intuitive and acceptable	background	2K_dev_1073
Based on these results	background	2K_dev_1073
the maximin solution has been deployed on Spliddit since April 2015	background	2K_dev_1073
and identify the maximin solution	finding	2K_dev_1073
which maximizes the minimum utility subject to envy freeness	finding	2K_dev_1073
as the most attractive that the maximin solution gives rise to significant gains in terms of our optimization objectives demonstrates that people find the maximin solution to be significantly fairer than arbitrary envy-free solutions ; this user study is unprecedented in that it asks people about their real-world rent division instances	finding	2K_dev_1073
We develop a general algorithmic framework	mechanism	2K_dev_1073
We then study the relations between natural optimization objectives	method	2K_dev_1073
We demonstrate	method	2K_dev_1073
in theory and using experiments on real data from Spliddit	method	2K_dev_1073
Finally	method	2K_dev_1073
a user study with Spliddit users as subjects	method	2K_dev_1073
We therefore focus on solutions that optimize a criterion of social justice	purpose	2K_dev_1073
subject to the envy freeness constraint	purpose	2K_dev_1073
in order to pinpoint the `` fairest '' solutions	purpose	2K_dev_1073
that enables the computation of such solutions in polynomial time	purpose	2K_dev_1073
	purpose	2K_dev_1073
Weakly supervised methods have recently become one of the most popular machine learning methods since they are able to be used on large-scale datasets without the critical requirement of richly annotated data	background	2K_dev_1074
	background	2K_dev_1074
Our uniform method is able to achieve competitive results in various face analysis applications	finding	2K_dev_1074
such as occlusion detection	finding	2K_dev_1074
face recognition	finding	2K_dev_1074
gender classification	finding	2K_dev_1074
twins verification and facial attractiveness analysis	finding	2K_dev_1074
In this paper	mechanism	2K_dev_1074
we present a novel	mechanism	2K_dev_1074
self-taught	mechanism	2K_dev_1074
discriminative approach in the weakly supervised framework	mechanism	2K_dev_1074
Our method can find regions which are discriminative across classes yet consistent within a class and can solve many face related problems The proposed method first trains a deep face model with high discriminative capability to extract facial features The hypercolumn features are then used to give pixel level representation for better classification performance along with discriminative region detection	mechanism	2K_dev_1074
In addition	mechanism	2K_dev_1074
calibration approaches are proposed to enable the system to deal with multi-class and mixed-class problems The system is also able to detect multiple discriminative regions from one image	mechanism	2K_dev_1074
	mechanism	2K_dev_1074
	method	2K_dev_1074
facial feature analysis	purpose	2K_dev_1074
Component-based modeling can be used to split large models into partial models to reduce modeling complexity	background	2K_dev_1075
	background	2K_dev_1075
	finding	2K_dev_1075
In this paper	mechanism	2K_dev_1075
we propose a component-based hybrid system verification approach that combines the advantages of component-based modeling e	mechanism	2K_dev_1075
g	mechanism	2K_dev_1075
	mechanism	2K_dev_1075
reduced model complexity with the advantages of formal verification e	mechanism	2K_dev_1075
g	mechanism	2K_dev_1075
	mechanism	2K_dev_1075
guaranteed contract compliance Our strategy is to decompose the system into components	mechanism	2K_dev_1075
verify their local safety individually and compose them to form an overall system that provably satisfies a global contract	mechanism	2K_dev_1075
without proving the whole system We introduce the necessary formalism and a technique such that safety properties provably emerge from component safety	mechanism	2K_dev_1075
	method	2K_dev_1075
We study a component-based approach to simplify the challenges of verifying large-scale hybrid systems	purpose	2K_dev_1075
Yet	purpose	2K_dev_1075
verification results also need to transfer from components to composites	purpose	2K_dev_1075
to define the structure and behavior of components how to compose components	purpose	2K_dev_1075
Learning video concept detectors automatically from the big but noisy web data with no additional manual annotations is a novel but challenging area in the multimedia and the machine learning community	background	2K_dev_1076
	background	2K_dev_1076
The efficacy and the scalability of WELL have been extensively demonstrated The comprehensive results demonstrate that WELL outperforms state-of-the-art studies by a statically significant margin on learning concepts from noisy web video data	finding	2K_dev_1076
In addition	finding	2K_dev_1076
the results also verify that WELL is robust to the level of noisiness in the video data	finding	2K_dev_1076
Notably	finding	2K_dev_1076
WELL trained on sufficient noisy web labels is able to achieve a comparable accuracy to supervised learning methods trained on the clean manually-labeled data	finding	2K_dev_1076
	finding	2K_dev_1076
this paper proposes a novel method called WEbly-Labeled Learning ( WELL )	mechanism	2K_dev_1076
which is established on the state-of-the-art machine learning algorithm inspired by the learning process of human WELL introduces a number of novel multi-modal approaches to incorporate meaningful prior knowledge called curriculum from the noisy web videos	mechanism	2K_dev_1076
To investigate this problem	method	2K_dev_1076
we empirically study the curriculum constructed from the multi-modal features of the videos collected from YouTube and Flickr	method	2K_dev_1076
on two public benchmarks	method	2K_dev_1076
including the largest multimedia dataset and the largest manually-labeled video set experimental	method	2K_dev_1076
A considerable amount of videos on the web are associated with rich but noisy contextual information	purpose	2K_dev_1076
such as the title	purpose	2K_dev_1076
which provides weak annotations or labels about the video content	purpose	2K_dev_1076
To leverage the big noisy web labels	purpose	2K_dev_1076
Brain-computer interfaces ( BCIs ) have the potential to restore motor abilities to paralyzed individuals	background	2K_dev_1077
These systems act by reading motor intent signals directly from the brain and using them to control	background	2K_dev_1077
for example	background	2K_dev_1077
the movement of a cursor on a computer screen or the motion of a robotic limb	background	2K_dev_1077
To construct a BCI	background	2K_dev_1077
a mapping must be specified that dictates how neural activity will actuate the device	background	2K_dev_1077
	background	2K_dev_1077
	finding	2K_dev_1077
Here we forward an alternate approach to the BCI design problem	mechanism	2K_dev_1077
using ideas from optimal control theory	mechanism	2K_dev_1077
We first argue that the brain can be considered as an optimal controller	mechanism	2K_dev_1077
We then introduce a mathematical definition of BCI usability	mechanism	2K_dev_1077
and formulate the BCI design problem as a constrained optimization problem that maximizes this usability	mechanism	2K_dev_1077
	mechanism	2K_dev_1077
	method	2K_dev_1077
How should these mappings be constructed to maximize user performance ? Most approaches have focused on this problem from an estimation standpoint	purpose	2K_dev_1077
i	purpose	2K_dev_1077
e	purpose	2K_dev_1077
	purpose	2K_dev_1077
mappings are designed to implement the best estimate of motor intent possible	purpose	2K_dev_1077
under various sets of assumptions about how the recorded neural signals represent motor intent	purpose	2K_dev_1077
	purpose	2K_dev_1077
Teaching chess to students with learning disabilities has been shown to benefit their school performance in unrelated domains At the same time	background	2K_dev_1078
chess involves skills that are highly correlated with dyslexia	background	2K_dev_1078
such as visuospatial and calculation abilities Therefore	background	2K_dev_1078
dyslexia might have an impact on how people learn and play chess using a computer	background	2K_dev_1078
suggesting that chess may be useful as a fun way to help people with dyslexia improve their abilities	background	2K_dev_1078
	background	2K_dev_1078
We could not find significant differences on four dependent measures out of the twelve measures we collected	finding	2K_dev_1078
	finding	2K_dev_1078
In this paper	mechanism	2K_dev_1078
we created a online chess game	mechanism	2K_dev_1078
we carried out a within-subject experiment with 62 participants	method	2K_dev_1078
31 of them with diagnosed dyslexia	method	2K_dev_1078
Participants used an instrumented web-based chess learning platform that we developed to ( i ) complete lessons on how to play chess and about chess theory	method	2K_dev_1078
( ii ) work through exercises designed to test and reaffirm their skills	method	2K_dev_1078
and ( iii ) play chess against a computer opponent	method	2K_dev_1078
designed for people with dyslexia and seek to understand whether people with dyslexia learn and play chess online in ways that differ from other students and whether such differences may be leveraged to improve classroom performance To test how people with dyslexia learn to play chess	purpose	2K_dev_1078
	background	2K_dev_1079
	finding	2K_dev_1079
	mechanism	2K_dev_1079
	method	2K_dev_1079
	purpose	2K_dev_1079
The attacker performs an integrity attack in order to move the system to a target state while evading detection over a finite time window	background	2K_dev_1080
Finally	finding	2K_dev_1080
we demonstrate our proposed attack strategy	finding	2K_dev_1080
We formulate and solve an optimal control problem We provide a sufficient condition for the existence of an optimal attack sequence	mechanism	2K_dev_1080
	mechanism	2K_dev_1080
in a numerical example	method	2K_dev_1080
	method	2K_dev_1080
This paper studies attackers with specific objectives against a cyber physical system	purpose	2K_dev_1080
that captures the attacker 's objective - the solution gives the optimal sequence of attacks	purpose	2K_dev_1080
	purpose	2K_dev_1080
	background	2K_dev_1081
we prove that the procedure is faithful in the population setting	finding	2K_dev_1081
yielding no false negatives The approach leads to computational and statistical advantages over fitting a full model	finding	2K_dev_1081
and provides an effective	finding	2K_dev_1081
practical approach to variable screening in convex regression	finding	2K_dev_1081
Under the assumption that the true regression function is convex and sparse	mechanism	2K_dev_1081
we develop a screening procedure Our approach is a two-stage quadratic programming method that estimates a sum of one-dimensional convex functions	mechanism	2K_dev_1081
followed by one-dimensional concave regression fits on the residuals	mechanism	2K_dev_1081
In contrast to previous methods for sparse additive models	mechanism	2K_dev_1081
the optimization is finite dimensional and requires no tuning parameters for smoothness	mechanism	2K_dev_1081
and introduce algorithms	mechanism	2K_dev_1081
Under appropriate assumptions We give a finite sample statistical analysis	method	2K_dev_1081
	method	2K_dev_1081
We study the problem of variable selection in convex nonparametric regression to select a subset of variables that contains the relevant variables	purpose	2K_dev_1081
for efficiently carrying out the required quadratic programs	purpose	2K_dev_1081
	purpose	2K_dev_1081
Imperfect-recall abstraction has emerged as the leading paradigm for practical large-scale equilibrium computation in imperfect-information games	background	2K_dev_1082
	background	2K_dev_1082
They show that running counterfactual regret minimization on such abstractions leads to good strategies in the original games	finding	2K_dev_1082
	finding	2K_dev_1082
We develop the first general	mechanism	2K_dev_1082
algorithm-agnostic	mechanism	2K_dev_1082
solution quality guarantees for Nash equilibria and approximate self-trembling equilibria computed in imperfect-recall abstractions	mechanism	2K_dev_1082
when implemented in the original ( perfect-recall ) game	mechanism	2K_dev_1082
Our results are for a class of games that generalizes the only previously known class of imperfect-recall abstractions for which any such results have been obtained Further	mechanism	2K_dev_1082
our analysis is tighter in two ways	mechanism	2K_dev_1082
each of which can lead to an exponential reduction in the solution quality error bound	mechanism	2K_dev_1082
We then show that for extensive-form games that satisfy certain properties	mechanism	2K_dev_1082
the problem of computing a bound-minimizing abstraction for a single level of the game reduces to a clustering problem	mechanism	2K_dev_1082
where the increase in our bound is the distance function This reduction leads to the first imperfect-recall abstraction algorithm with solution quality bounds	mechanism	2K_dev_1082
We proceed to show a divide in the class of abstraction problems	mechanism	2K_dev_1082
If payoffs are at the same scale at all information sets considered for abstraction	mechanism	2K_dev_1082
the input forms a metric space	mechanism	2K_dev_1082
and this immediately yields a $ 2 $ -approximation algorithm for abstraction Conversely	mechanism	2K_dev_1082
if this condition is not satisfied	mechanism	2K_dev_1082
we show that the input does not form a metric space	mechanism	2K_dev_1082
Finally	method	2K_dev_1082
we provide computational experiments to evaluate the practical usefulness of the abstraction techniques	method	2K_dev_1082
	method	2K_dev_1082
However	purpose	2K_dev_1082
imperfect-recall abstractions are poorly understood	purpose	2K_dev_1082
and only weak algorithm-specific guarantees on solution quality are known	purpose	2K_dev_1082
	purpose	2K_dev_1082
With the availability of high resolution digital technology	background	2K_dev_1083
there has been increased interest in developing statistical and image processing techniques that can enhance the existing capabilities of analyzing works of art for authenticity This method is also valuable in determining whether an original painting has undergone any modifications	background	2K_dev_1083
given that a representation of the initial version is available	background	2K_dev_1083
we are not only able to distinguish between a low-quality digitized representation of a painting and its forgery	finding	2K_dev_1083
but also specifically indicate where the differences occur and where the replica is particularly faithful to the original	finding	2K_dev_1083
	finding	2K_dev_1083
This work explores the merits of using advanced correlation filters in supplementing art experts efforts We show that by training the optimal trade-off synthetic discriminant function ( OTSDF ) filter on each section of a coarsely parceled image of an original painting	mechanism	2K_dev_1083
	mechanism	2K_dev_1083
	method	2K_dev_1083
in identifying forgeries among disputed paintings	purpose	2K_dev_1083
	purpose	2K_dev_1083
Abstract SummaryWith the rapid advances in technologies of microarray and massively parallel sequencing	background	2K_dev_1084
data of multiple omics sources from a large patient cohort are now frequently seen in many consortium studies Effective multi-level omics data integration has brought new statistical challenges	background	2K_dev_1084
One important biological objective of such integrative analysis is to cluster patients in order to identify clinically relevant disease subtypes	background	2K_dev_1084
which will form basis for tailored treatment and personalized medicine	background	2K_dev_1084
Several methods have been proposed in the literature for this purpose	background	2K_dev_1084
including the popular iCluster method used in many cancer applications	background	2K_dev_1084
When clustering high-dimensional omics data	background	2K_dev_1084
effective feature selection is critical for better clustering accuracy and biological interpretation	background	2K_dev_1084
It is also common that a portion of `` scattered samples '' has patterns distinct from all major clusters and should not be assigned into any cluster as they may represent a rare disease subcategory or be in transition between disease subtypes	background	2K_dev_1084
	finding	2K_dev_1084
of the iCluster factor model by an overlapping sparse group lasso penalty on the omics features using prior knowledge of inter-omics regulatory flows	mechanism	2K_dev_1084
We then perform regularization over samples to allow clustering with scattered samples and generate tight clusters	mechanism	2K_dev_1084
The proposed group structured tight iCluster method will be evaluated by two real breast cancer examples and simulations to demonstrate its improved clustering accuracy	method	2K_dev_1084
biological interpretation	method	2K_dev_1084
and ability to generate coherent tight clusters	method	2K_dev_1084
In this paper	purpose	2K_dev_1084
we firstly propose to improve feature selection	purpose	2K_dev_1084
Computational offloading services at the edge of the Internet for mobile devices are becoming a reality	background	2K_dev_1085
We present experimental results that confirm substantial wins from edge computing for highly interactive mobile applications	finding	2K_dev_1085
	finding	2K_dev_1085
Using a wide range of mobile applications	mechanism	2K_dev_1085
	mechanism	2K_dev_1085
from WiFi and 4G LTE networks	method	2K_dev_1085
we explore how such infrastructure improves latency and energy consumption relative to the cloud	purpose	2K_dev_1085
Demand response is seeing increased popularity worldwide and industrial loads are actively taking part in this trend	background	2K_dev_1086
As a host of energy-intensive industrial processes	background	2K_dev_1086
steel plants have both the motivation and potential to provide demand response	background	2K_dev_1086
	background	2K_dev_1086
	finding	2K_dev_1086
and propose methods such as adding cuts and implementing an application-specific branch and bound algorithm	mechanism	2K_dev_1086
	method	2K_dev_1086
However	purpose	2K_dev_1086
the scheduling of steel plants is very complex and the involved computations are intense	purpose	2K_dev_1086
In this paper	purpose	2K_dev_1086
we focus on these difficulties to make the computations more tractable	purpose	2K_dev_1086
	purpose	2K_dev_1086
Algorithmic systems that employ machine learning play an increasing role in making substantive decisions in modern society	background	2K_dev_1087
ranging from online personalization to insurance and credit decisions to predictive policing	background	2K_dev_1087
	background	2K_dev_1087
demonstrates that QII measures are a useful transparency mechanism when black box access to the learning system is available	finding	2K_dev_1087
In particular	finding	2K_dev_1087
they provide better explanations than standard associative measures for a host of scenarios that we consider Further	finding	2K_dev_1087
we show that in the situations we consider	finding	2K_dev_1087
QII is efficiently approximable and can be made differentially private while preserving accuracy	finding	2K_dev_1087
We develop a formal foundation Specifically	mechanism	2K_dev_1087
we introduce a family of Quantitative Input Influence ( QII ) measures that capture the degree of influence of inputs on outputs of systems	mechanism	2K_dev_1087
These measures provide a foundation for the design of transparency reports that accompany system decisions ( e	mechanism	2K_dev_1087
g	mechanism	2K_dev_1087
	mechanism	2K_dev_1087
explaining a specific credit decision ) and for testing tools useful for internal and external oversight ( e	mechanism	2K_dev_1087
g	mechanism	2K_dev_1087
	mechanism	2K_dev_1087
to detect algorithmic discrimination ) Distinctively	mechanism	2K_dev_1087
our causal QII measures carefully account for correlated inputs while measuring influence They support a general class of transparency queries and can	mechanism	2K_dev_1087
in particular	mechanism	2K_dev_1087
explain decisions about individuals ( e	mechanism	2K_dev_1087
g	mechanism	2K_dev_1087
	mechanism	2K_dev_1087
a loan decision ) and groups ( e	mechanism	2K_dev_1087
g	mechanism	2K_dev_1087
	mechanism	2K_dev_1087
disparate impact based on gender ) Finally	mechanism	2K_dev_1087
since single inputs may not always have high influence	mechanism	2K_dev_1087
the QII measures also quantify the joint influence of a set of inputs ( e	mechanism	2K_dev_1087
g	mechanism	2K_dev_1087
	mechanism	2K_dev_1087
age and income ) on outcomes ( e	mechanism	2K_dev_1087
g	mechanism	2K_dev_1087
loan decisions ) and the marginal influence of individual inputs within such a set ( e	mechanism	2K_dev_1087
g	mechanism	2K_dev_1087
	mechanism	2K_dev_1087
income )	mechanism	2K_dev_1087
Since a single input may be part of multiple influential sets	mechanism	2K_dev_1087
the average marginal influence of the input is computed using principled aggregation measures	mechanism	2K_dev_1087
such as the Shapley value	mechanism	2K_dev_1087
previously applied to measure influence in voting Further	mechanism	2K_dev_1087
since transparency reports could compromise privacy	mechanism	2K_dev_1087
we explore the transparency-privacy tradeoff and prove that a number of useful transparency reports can be made differentially private with very little addition of noise	mechanism	2K_dev_1087
	mechanism	2K_dev_1087
Our empirical validation with standard machine learning algorithms	method	2K_dev_1087
But their decision-making processes are often opaque -- it is difficult to explain why a certain decision was made to improve the transparency of such decision-making systems	purpose	2K_dev_1087
	purpose	2K_dev_1087
Cities are increasingly equipped with low-resolution cameras	background	2K_dev_1088
Video from some of these cameras is publicly accessible in real time	background	2K_dev_1088
	background	2K_dev_1088
	finding	2K_dev_1088
In particular	mechanism	2K_dev_1088
the end goal is to build a model Models learn different appearance of vehicles as seen from different viewpoints	mechanism	2K_dev_1088
A major difficulty with any type of analysis like this is the need for large amounts of training data	mechanism	2K_dev_1088
In our case	mechanism	2K_dev_1088
it is easy to collect unlabeled data from publicly available low-resolution low-framerate cameras in Pittsburgh or NYC	mechanism	2K_dev_1088
	method	2K_dev_1088
In this project	purpose	2K_dev_1088
the authors addressed the problem of building a traffic model for parts of the roads visible from publicly accessible cameras capable of detecting different types of vehicles in images in various weather conditions and times of the day except night	purpose	2K_dev_1088
	purpose	2K_dev_1088
Multimedia event detection has been receiving increasing attention in recent years	background	2K_dev_1089
Besides recognizing an event	background	2K_dev_1089
the discovery of evidences ( which is refered to as `` recounting '' ) is also crucial for user to better understand the searching result	background	2K_dev_1089
and demonstrate the promising results obtained by our method	finding	2K_dev_1089
	finding	2K_dev_1089
we propose a weakly supervised evidence discovery method based on self-paced learning framework	mechanism	2K_dev_1089
which follows a learning process from easy `` evidences '' to gradually more complex ones	mechanism	2K_dev_1089
and simultaneously exploit more and more positive evidence samples from numerous weakly annotated video segments	mechanism	2K_dev_1089
	mechanism	2K_dev_1089
Moreover	method	2K_dev_1089
to evaluate our method quantitatively	method	2K_dev_1089
we also propose two metrics	method	2K_dev_1089
\textit { PctOverlap } and \textit { F1-score }	method	2K_dev_1089
for measuring the performance of evidence localization specifically	method	2K_dev_1089
The experiments are conducted on a subset of TRECVID MED dataset	method	2K_dev_1089
Due to the difficulty of evidence annotation	purpose	2K_dev_1089
only limited supervision of event labels are available for training a recounting model	purpose	2K_dev_1089
To deal with the problem	purpose	2K_dev_1089
	purpose	2K_dev_1089
Given a large-scale and high-order tensor	background	2K_dev_1090
how can we find dense blocks in it ? Can we find them in near-linear time but with a quality guarantee ? Extensive previous work has shown that dense blocks in tensors as well as graphs indicate anomalous or fraudulent behavior e	background	2K_dev_1090
g	background	2K_dev_1090
	background	2K_dev_1090
lockstep behavior in social networks	background	2K_dev_1090
	background	2K_dev_1090
upito 114 $ $ \times $ $ faster than state-of-the-art methods with similar accuracy 4 Effective : M-Zoom successfully detected edit wars and bot activities and spotted network attacks with near-perfect accuracy AUCi=i0	finding	2K_dev_1090
98	finding	2K_dev_1090
The data and software related to this paper are available at http : //www	finding	2K_dev_1090
cs	finding	2K_dev_1090
cmu	finding	2K_dev_1090
edu/~kijungs/codes/mzoom/	finding	2K_dev_1090
	finding	2K_dev_1090
In this work	mechanism	2K_dev_1090
we propose M-Zoom	mechanism	2K_dev_1090
a flexible framework which works with a broad class of density measures	mechanism	2K_dev_1090
M-Zoom has the following properties : 1 Scalable : M-Zoom scales linearly with all aspects of tensors and is 2 Provably accurate : M-Zoom provides a guarantee on the lowest density of the blocks it finds	mechanism	2K_dev_1090
3 Flexible : M-Zoom supports multi-block detection and size bounds as well as diverse density measures	mechanism	2K_dev_1090
	mechanism	2K_dev_1090
in Wikipedia	method	2K_dev_1090
from a TCP dump	method	2K_dev_1090
However	purpose	2K_dev_1090
available methods for detecting such dense blocks are not satisfactory in terms of speed	purpose	2K_dev_1090
accuracy	purpose	2K_dev_1090
or flexibility for finding dense blocks in tensors	purpose	2K_dev_1090
	background	2K_dev_1091
The LBC layer affords significant parameter savings	finding	2K_dev_1091
9x to 169x in the number of learnable parameters compared to a standard convolutional layer results in up to 9x to 169x savings in model size compared to a standard convolutional layer	finding	2K_dev_1091
that our local binary convolution layer is a good approximation of a standard convolutional layer	finding	2K_dev_1091
CNNs with LBC layers	finding	2K_dev_1091
called local binary convolutional neural networks ( LBCNN )	finding	2K_dev_1091
reach state-of-the-art performance on a range of visual datasets ( MNIST	finding	2K_dev_1091
SVHN	finding	2K_dev_1091
CIFAR-10	finding	2K_dev_1091
and a subset of ImageNet ) while enjoying significant computational savings	finding	2K_dev_1091
We propose local binary convolution ( LBC )	mechanism	2K_dev_1091
The design principles of LBC are motivated by local binary patterns ( LBP )	mechanism	2K_dev_1091
The LBC layer comprises of a set of fixed sparse pre-defined binary convolutional filters that are not updated during the training process	mechanism	2K_dev_1091
a non-linear activation function and a set of learnable linear weights	mechanism	2K_dev_1091
The linear weights combine the activated filter responses to approximate the corresponding activated filter responses of a standard convolutional layer	mechanism	2K_dev_1091
Furthermore	mechanism	2K_dev_1091
due to lower model complexity and sparse and binary nature of the weights also	mechanism	2K_dev_1091
We demonstrate both theoretically and experimentally Empirically	method	2K_dev_1091
an efficient alternative to convolutional layers in standard convolutional neural networks ( CNN )	purpose	2K_dev_1091
	purpose	2K_dev_1091
	background	2K_dev_1092
	finding	2K_dev_1092
	mechanism	2K_dev_1092
	method	2K_dev_1092
	purpose	2K_dev_1092
	background	2K_dev_1093
We show that this approach leads to state of the art results on the task	finding	2K_dev_1093
	finding	2K_dev_1093
we propose an approach using the Abstract Meaning Representation ( AMR ) formalism	mechanism	2K_dev_1093
We construct meaning representation graphs for the given text and for each question-answer pair by merging the AMRs of comprising sentences using cross-sentential phenomena such as coreference and rhetorical structures	mechanism	2K_dev_1093
Then	mechanism	2K_dev_1093
we reduce machine comprehension to a graph containment problem We posit that there is a latent mapping of the question-answer meaning representation graph onto the text meaning representation graph that explains the answer	mechanism	2K_dev_1093
We present a unified max-margin framework that learns to find this mapping ( given a corpus of texts and question-answer pairs )	mechanism	2K_dev_1093
and uses what it learns to answer questions on novel texts	mechanism	2K_dev_1093
	mechanism	2K_dev_1093
	method	2K_dev_1093
Machine comprehension tests the systems ability to understand a piece of text through a reading comprehension task	purpose	2K_dev_1093
For this task	purpose	2K_dev_1093
	purpose	2K_dev_1093
Rapid advances in biology demand new tools for more active research dissemination and engaged teaching	background	2K_dev_1094
While existing views communicate the same information	finding	2K_dev_1094
study participants found the interactive	finding	2K_dev_1094
karyogram-based views much easier and likable to use We additionally discuss feedback from biology and genomics faculty	finding	2K_dev_1094
	finding	2K_dev_1094
This paper presents Synteny Explorer	mechanism	2K_dev_1094
an interactive visualization application designed The tool visualizes synteny blocks : segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct	mechanism	2K_dev_1094
ancestral species	mechanism	2K_dev_1094
We take a karyogram-based approach to create an interactive synteny visualization	mechanism	2K_dev_1094
leading to a more appealing and engaging design for undergraduate-level genome evolution education	mechanism	2K_dev_1094
	mechanism	2K_dev_1094
For validation	method	2K_dev_1094
we conduct three user studies : two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context who judge Synteny Explorer 's fitness for use in classrooms	method	2K_dev_1094
to let college students explore genome evolution of mammalian species	purpose	2K_dev_1094
	purpose	2K_dev_1094
	background	2K_dev_1095
we discover that the most recent users ' actions can better reflect users ' current intentions and preferences	finding	2K_dev_1095
TDAP achieves good accuracy : it improves at least 5	finding	2K_dev_1095
6 % in terms of prediction accuracy	finding	2K_dev_1095
and TDAP scales well : it runs 4 times faster when the number of machines increases from 2 to 10	finding	2K_dev_1095
	finding	2K_dev_1095
Under this observation	mechanism	2K_dev_1095
we thereby propose a novel time-decaying online learning algorithm derived from the state-of-the-art FTRL-proximal algorithm	mechanism	2K_dev_1095
called Time-Decaying Adaptive Prediction ( TDAP ) algorithm	mechanism	2K_dev_1095
To scale Big Data	mechanism	2K_dev_1095
we further parallelize our algorithm following the data parallel scheme under both BSP and SSP consistency model	mechanism	2K_dev_1095
Based on the analysis of users ' behaviors in Video-On-Demand ( VoD ) recommender systems	method	2K_dev_1095
We experimentally evaluate our TDAP algorithm on real IPTV VoD datasets using two state-of-the-art distributed computing platforms	method	2K_dev_1095
compared to FTRL-proximal algorithm ;	method	2K_dev_1095
Online learning is used in a wide range of real applications	purpose	2K_dev_1095
e	purpose	2K_dev_1095
g	purpose	2K_dev_1095
	purpose	2K_dev_1095
predicting ad click-through rates ( CTR ) and personalized recommendations	purpose	2K_dev_1095
	purpose	2K_dev_1095
An interesting challenge for the cryptography community is to design authentication protocols that are so simple that a human can execute them without relying on a fully trusted computer	background	2K_dev_1096
For these schemes	finding	2K_dev_1096
we prove that forging passwords is equivalent to recovering the secret mapping	finding	2K_dev_1096
Thus	finding	2K_dev_1096
our human computable password schemes can maintain strong security guarantees even after an adversary has observed the user login to many different accounts	finding	2K_dev_1096
	finding	2K_dev_1096
We propose several candidate authentication protocols -- - a computer that stores information and performs computations correctly but does not provide confidentiality Our schemes use a semi-trusted computer to store and display public challenges $ C_i\in [ n ] ^k $	mechanism	2K_dev_1096
The human user memorizes a random secret mapping $ \sigma : [ n ] \rightarrow\mathbb { Z } _d $ and authenticates by computing responses $ f ( \sigma ( C_i ) ) $ to a sequence of public challenges where $ f : \mathbb { Z } _d^k\rightarrow\mathbb { Z } _d $ is a function that is easy for the human to evaluate	mechanism	2K_dev_1096
We prove that any statistical adversary needs to sample $ m=\tilde { \Omega } ( n^ { s ( f ) } ) $ challenge-response pairs to recover $ \sigma $	mechanism	2K_dev_1096
for a security parameter $ s ( f ) $ that depends on two key properties of $ f $	mechanism	2K_dev_1096
To obtain our results	mechanism	2K_dev_1096
we apply the general hypercontractivity theorem to lower bound the statistical dimension of the distribution over challenge-response pairs induced by $ f $ and $ \sigma $	mechanism	2K_dev_1096
Our lower bounds apply to arbitrary functions $ f $ ( not just to functions that are easy for a human to evaluate )	mechanism	2K_dev_1096
and generalize recent results of Feldman et al	mechanism	2K_dev_1096
	mechanism	2K_dev_1096
As an application	method	2K_dev_1096
we propose a family of human computable password functions $ f_ { k_1	method	2K_dev_1096
k_2 } $ in which the user needs to perform $ 2k_1+2k_2+1 $ primitive operations ( e	method	2K_dev_1096
g	method	2K_dev_1096
	method	2K_dev_1096
adding two digits or remembering $ \sigma ( i ) $ )	method	2K_dev_1096
and we show that $ s ( f ) 0 \min\ { k_1+1	method	2K_dev_1096
( k_2+1 ) /2\ } $	method	2K_dev_1096
	method	2K_dev_1096
for a setting in which the human user can only receive assistance from a semi-trusted computer	purpose	2K_dev_1096
	background	2K_dev_1097
show the superiority of our approach	finding	2K_dev_1097
	finding	2K_dev_1097
To achieve this	mechanism	2K_dev_1097
videos are represented in terms of detected visual concepts	mechanism	2K_dev_1097
which are then scored as relevant or irrelevant according to their similarity with a given textual query	mechanism	2K_dev_1097
In this paper	mechanism	2K_dev_1097
we propose a more robust approach in order to alleviate many of the brittleness and low precision problems of previous work	mechanism	2K_dev_1097
Not only do we jointly consider semantic relatedness	mechanism	2K_dev_1097
visual reliability	mechanism	2K_dev_1097
and discriminative power	mechanism	2K_dev_1097
To handle noise and non-linearities in the ranking scores of the selected concepts	mechanism	2K_dev_1097
we propose a novel pairwise order matrix approach for score aggregation	mechanism	2K_dev_1097
Extensive experiments on the large-scale TRECVID Multimedia Event Detection data	method	2K_dev_1097
Vast quantities of videos are now being captured at astonishing rates	purpose	2K_dev_1097
but the majority of these are not labelled	purpose	2K_dev_1097
To cope with such data	purpose	2K_dev_1097
we consider the task of content-based activity recognition in videos without any manually labelled examples	purpose	2K_dev_1097
also known as zero-shot video recognition	purpose	2K_dev_1097
for scoring concepts	purpose	2K_dev_1097
Counterfactual Regret Minimization ( CFR ) is the most popular iterative algorithm for solving zero-sum imperfect-information games	background	2K_dev_1098
Regret-Based Pruning ( RBP ) is an improvement that allows poorly-performing actions to be temporarily pruned	background	2K_dev_1098
thus speeding up CFR	background	2K_dev_1098
	background	2K_dev_1098
We prove that in zero-sum games it asymptotically prunes any action that is not part of a best response to some Nash equilibrium	finding	2K_dev_1098
This leads to provably faster convergence and lower space requirements	finding	2K_dev_1098
show that Total RBP results in an order of magnitude reduction in space	finding	2K_dev_1098
and the reduction factor increases with game size	finding	2K_dev_1098
We introduce Total RBP	mechanism	2K_dev_1098
a new form of RBP as actions are pruned	mechanism	2K_dev_1098
Experiments	method	2K_dev_1098
that reduces the space requirements of CFR	purpose	2K_dev_1098
Many applications collect a large number of time series	background	2K_dev_1099
for example	background	2K_dev_1099
the financial data of companies quoted in a stock exchange	background	2K_dev_1099
the health care data of all patients that visit the emergency room of a hospital	background	2K_dev_1099
or the temperature sequences continuously measured by weather stations across the US	background	2K_dev_1099
These data are often referred to as un structured The first task in its analytics is to derive a low dimensional representation	background	2K_dev_1099
a graph or discrete manifold	background	2K_dev_1099
that describes well the inter relations among the time series and their intra relations across time	background	2K_dev_1099
	background	2K_dev_1099
The adjacency matrices estimated with the new method are close to the true graph in the simulated data and consistent with prior physical knowledge in the real dataset tested	finding	2K_dev_1099
This paper presents a computationally tractable algorithm The resulting graph is directed and weighted	mechanism	2K_dev_1099
possibly capturing causal relations	mechanism	2K_dev_1099
not just reciprocal correlations as in many existing approaches in the literature	mechanism	2K_dev_1099
	mechanism	2K_dev_1099
A convergence analysis is carried out	method	2K_dev_1099
The algorithm is demonstrated on random graph datasets and real network time series datasets	method	2K_dev_1099
and its performance is compared to that of related methods	method	2K_dev_1099
	method	2K_dev_1099
for estimating this graph that structures the data	purpose	2K_dev_1099
	purpose	2K_dev_1099
	background	2K_dev_1100
	finding	2K_dev_1100
A method is presented The invention provides correctness guarantees for CPS executions at runtime Offline verification of CPS models are combined with runtime validation of system executions for compliance with the model	mechanism	2K_dev_1100
The invention ensures that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model	mechanism	2K_dev_1100
assuming the system dynamics deviation is bounded If	mechanism	2K_dev_1100
at some point	mechanism	2K_dev_1100
the observed behavior no longer complies with the model	mechanism	2K_dev_1100
such that offline verification results no longer apply	mechanism	2K_dev_1100
provably safe fallback actions are initiated	mechanism	2K_dev_1100
The invention includes a systematic technique to synthesize provably correct monitors automatically from CPS proofs in differential dynamic logic	mechanism	2K_dev_1100
	method	2K_dev_1100
for ensuring that verification results about models apply to cyber-physical systems ( CPS ) implementations	purpose	2K_dev_1100
Pooling plays an important role in generating a discriminative video representation	background	2K_dev_1101
	background	2K_dev_1101
and we prove new and closed-form proximal steps	finding	2K_dev_1101
and achieve promising improvements	finding	2K_dev_1101
	finding	2K_dev_1101
In this paper	mechanism	2K_dev_1101
we propose a new semantic pooling approach especially when only a few shots/segments are relevant to the event of interest while many other shots are irrelevant or even misleading	mechanism	2K_dev_1101
The commonly adopted pooling strategies aggregate the shots indifferently in one way or another	mechanism	2K_dev_1101
resulting in a great loss of information	mechanism	2K_dev_1101
Instead	mechanism	2K_dev_1101
in this work we first define a novel notion of semantic saliency that assesses the relevance of each shot with the event of interest We then prioritize the shots according to their saliency scores since shots that are semantically more salient are expected to contribute more to the final event analysis	mechanism	2K_dev_1101
Next	mechanism	2K_dev_1101
we propose a new isotonic regularizer that is able to exploit the constructed semantic ordering information The resulting nearly-isotonic support vector machine classifier exhibits higher discriminative power in event analysis tasks	mechanism	2K_dev_1101
Computationally	method	2K_dev_1101
we develop an efficient implementation using the proximal gradient algorithm	method	2K_dev_1101
We conduct extensive experiments on three real-world video datasets	method	2K_dev_1101
for challenging event analysis tasks ( e	purpose	2K_dev_1101
g	purpose	2K_dev_1101
	purpose	2K_dev_1101
event detection	purpose	2K_dev_1101
recognition	purpose	2K_dev_1101
and recounting ) in long untrimmed Internet videos	purpose	2K_dev_1101
	purpose	2K_dev_1101
	background	2K_dev_1102
	finding	2K_dev_1102
	mechanism	2K_dev_1102
	method	2K_dev_1102
	purpose	2K_dev_1102
Recently	background	2K_dev_1103
there has been a surge of interest in using spectral methods for estimating latent variable models	background	2K_dev_1103
Our method is competitive with other baselines on synthetic and real problems and is also very computationally efficient	finding	2K_dev_1103
	finding	2K_dev_1103
By leveraging some recent advances in continuous linear algebra and numerical analysis	mechanism	2K_dev_1103
we develop a computationally efficient spectral algorithm for learning nonparametric HMMs Our technique is based on computing an SVD on nonparametric estimates of density functions by viewing them as \emph { continuous matrices }	mechanism	2K_dev_1103
We derive sample complexity bounds via concentration results for nonparametric density estimation and novel perturbation theory results for continuous matrices	mechanism	2K_dev_1103
	mechanism	2K_dev_1103
In this paper	method	2K_dev_1103
we study the estimation of an $ m $ -state hidden Markov model ( HMM ) with only smoothness assumptions	method	2K_dev_1103
such as H\ '' olderian conditions	method	2K_dev_1103
on the emission densities	method	2K_dev_1103
We implement our method using Chebyshev polynomial approximations	method	2K_dev_1103
	method	2K_dev_1103
However	purpose	2K_dev_1103
it is usually assumed that the distribution of the observations conditioned on the latent variables is either discrete or belongs to a parametric family	purpose	2K_dev_1103
	purpose	2K_dev_1103
Meeting tail latency Service Level Objectives ( SLOs ) in shared cloud networks is both important and challenging	background	2K_dev_1104
One primary challenge is determining limits on the multi-tenancy such that SLOs are met	background	2K_dev_1104
Doing so involves estimating latency	background	2K_dev_1104
which is difficult	background	2K_dev_1104
especially when tenants exhibit bursty behavior as is common in production environments	background	2K_dev_1104
Nevertheless	background	2K_dev_1104
recent papers in the past two years ( Silo	background	2K_dev_1104
QJump	background	2K_dev_1104
and PriorityMeister ) show techniques for calculating latency based on a branch of mathematical modeling called Deterministic Network Calculus ( DNC )	background	2K_dev_1104
The DNC theory is designed for adversarial worst-case conditions	background	2K_dev_1104
which is sometimes necessary	background	2K_dev_1104
but is often overly conservative	background	2K_dev_1104
	background	2K_dev_1104
SNC-Meister supports 75 % more tenants than the state-of-the-art	finding	2K_dev_1104
	finding	2K_dev_1104
This paper describes SNC-Meister	mechanism	2K_dev_1104
a new admission control system SNC-Meister improves upon the state-of-the-art DNC-based systems by using a new theory	mechanism	2K_dev_1104
Stochastic Network Calculus ( SNC )	mechanism	2K_dev_1104
which is designed for tail latency percentiles Focusing on tail latency percentiles	mechanism	2K_dev_1104
rather than the adversarial worst-case DNC latency	mechanism	2K_dev_1104
allows SNC-Meister to pack together many more tenants	mechanism	2K_dev_1104
: in experiments with production traces	method	2K_dev_1104
	method	2K_dev_1104
Typical tenants do not require strict worst-case guarantees	purpose	2K_dev_1104
but are only looking for SLOs at lower percentiles ( e	purpose	2K_dev_1104
g	purpose	2K_dev_1104
	purpose	2K_dev_1104
99th	purpose	2K_dev_1104
99	purpose	2K_dev_1104
9th ) for tail latency SLOs	purpose	2K_dev_1104
	purpose	2K_dev_1104
	background	2K_dev_1105
the robustness and effectiveness of the proposed system	finding	2K_dev_1105
	finding	2K_dev_1105
This paper presents a robust	mechanism	2K_dev_1105
fully automatic and semi self-training system Based on the observation that some certain facial areas	mechanism	2K_dev_1105
e	mechanism	2K_dev_1105
g	mechanism	2K_dev_1105
cheeks	mechanism	2K_dev_1105
do not typically contain any facial hair whereas the others	mechanism	2K_dev_1105
e	mechanism	2K_dev_1105
g	mechanism	2K_dev_1105
brows	mechanism	2K_dev_1105
often contain facial hair	mechanism	2K_dev_1105
a self-trained model is first built using a testing image itself	mechanism	2K_dev_1105
To overcome the limitation of that facial hairs in brows regions and beard/moustache regions are different in length	mechanism	2K_dev_1105
density	mechanism	2K_dev_1105
color	mechanism	2K_dev_1105
etc	mechanism	2K_dev_1105
	mechanism	2K_dev_1105
a pre-trained model is also constructed using training data The pre-trained model is only pursued when the self-trained model produces low confident classification results	mechanism	2K_dev_1105
In the proposed system	mechanism	2K_dev_1105
we employ the superpixel together a combination of two classifiers	mechanism	2K_dev_1105
i	mechanism	2K_dev_1105
e	mechanism	2K_dev_1105
Random Ferns ( rFerns ) and Support Vector Machines ( SVM ) to obtain good classification performance as well as improve time efficiency	mechanism	2K_dev_1105
A feature vector	mechanism	2K_dev_1105
consisting of Histogram of Gabor ( HoG ) and Histogram of Oriented Gradient of Gabor ( HOGG ) at different directions and frequencies	mechanism	2K_dev_1105
is generated from both the bounding box of the superpixel and the super pixel foreground	mechanism	2K_dev_1105
The segmentation result is then refined by our proposed aggregately searching strategy in order to deal with inaccurate landmarking points	mechanism	2K_dev_1105
Detect and segment beard/moustache simultaneouslyUse advantages of both pre-trained model and self-trained modelWork on superpixelPropose an aggregate searching strategy to overcome the limits of landmarkerPropose a new feature that is able to emphasize high frequency information of facial hair	mechanism	2K_dev_1105
Experimental results have demonstrated It is evaluated in images drawn from three entire databases i	method	2K_dev_1105
e	method	2K_dev_1105
the Multiple Biometric Grand Challenge ( MBGC ) still face database	method	2K_dev_1105
the NIST color Facial Recognition Technology FERET database and a large subset from Pinellas County database	method	2K_dev_1105
	method	2K_dev_1105
to detect and segment facial beard/moustache simultaneously in challenging facial images	purpose	2K_dev_1105
	purpose	2K_dev_1105
The best prior complete algorithm has significantly worse complexity and has	background	2K_dev_1106
to our knowledge	background	2K_dev_1106
never been implemented	background	2K_dev_1106
	finding	2K_dev_1106
We present a complete algorithm in games with more than two players	mechanism	2K_dev_1106
The main components of our tree-search-based method are a node-selection strategy	mechanism	2K_dev_1106
an exclusion oracle	mechanism	2K_dev_1106
and a subdivision scheme	mechanism	2K_dev_1106
The node-selection strategy determines the next region to be explored -- -based on the region 's size and an estimate of whether the region contains an equilibrium The exclusion oracle provides a provably correct sufficient condition for there not to exist an equilibrium in the region	mechanism	2K_dev_1106
The subdivision scheme determines how the region is split if it can not be excluded	mechanism	2K_dev_1106
Unlike well-known incomplete methods	mechanism	2K_dev_1106
our method does not need to proceed locally	mechanism	2K_dev_1106
which avoids it getting stuck in a local minimum that may be far from any actual equilibrium	mechanism	2K_dev_1106
The run time grows rapidly with the game size	mechanism	2K_dev_1106
and this suggests a hybrid scheme where one of the relatively fast prior incomplete algorithms is run	mechanism	2K_dev_1106
and if it fails to find an equilibrium	mechanism	2K_dev_1106
then our method is used	mechanism	2K_dev_1106
	mechanism	2K_dev_1106
	method	2K_dev_1106
for finding an epsilon-Nash equilibrium for arbitrarily small epsilon	purpose	2K_dev_1106
Multimodal sentiment analysis is drawing an increasing amount of attention these days	background	2K_dev_1107
It enables mining of opinions in video reviews and surveys which are now available aplenty on online platforms like YouTube	background	2K_dev_1107
	background	2K_dev_1107
we show how SAL improves the generalizability of state-of-the-art models	finding	2K_dev_1107
We increase prediction accuracy significantly in all three modalities ( text	finding	2K_dev_1107
audio	finding	2K_dev_1107
video )	finding	2K_dev_1107
as well as in their fusion	finding	2K_dev_1107
We show how SAL	finding	2K_dev_1107
achieves good accuracy across test datasets	finding	2K_dev_1107
	finding	2K_dev_1107
Then we propose a Select-Additive Learning ( SAL ) procedure SAL is a two-phase learning method	mechanism	2K_dev_1107
In Selection phase	mechanism	2K_dev_1107
it selects the confounding learned representation	mechanism	2K_dev_1107
In Addition phase	mechanism	2K_dev_1107
it forces the classifier to discard confounded representations by adding Gaussian noise	mechanism	2K_dev_1107
	mechanism	2K_dev_1107
In this paper	method	2K_dev_1107
we first examine the data and verify the existence of this dependence problem	method	2K_dev_1107
In our experiments	method	2K_dev_1107
even when trained on one dataset	method	2K_dev_1107
	method	2K_dev_1107
However	purpose	2K_dev_1107
the limited number of high-quality multimodal sentiment data samples may introduce the problem of the sentiment being dependent on the individual specific features in the dataset	purpose	2K_dev_1107
This results in a lack of generalizability of the trained models for classification on larger online platforms that improves the generalizability of trained discriminative neural networks	purpose	2K_dev_1107
	purpose	2K_dev_1107
We discuss the implications of our results for market design in general	background	2K_dev_1108
and kidney exchange in particular	background	2K_dev_1108
	background	2K_dev_1108
Our main result asserts that	finding	2K_dev_1108
	finding	2K_dev_1108
any fixed optimal matching is likely to be individually rational up to lower-order terms We also show that a simple and practical mechanism is ( fully ) individually rational	finding	2K_dev_1108
and likely to be optimal up to lower-order terms	finding	2K_dev_1108
	finding	2K_dev_1108
by considering an arbitrary graph	mechanism	2K_dev_1108
but assuming that vertices are associated with players at random	mechanism	2K_dev_1108
under certain conditions	method	2K_dev_1108
We revisit the problem of designing optimal	purpose	2K_dev_1108
individually rational matching mechanisms ( in a general sense	purpose	2K_dev_1108
allowing for cycles in directed graphs )	purpose	2K_dev_1108
where each player -- -who is associated with a subset of vertices -- -matches as many of his own vertices when he opts into the matching mechanism as when he opts out We offer a new perspective on this problem	purpose	2K_dev_1108
A descending clock auction ( DCA ) is for buying items from multiple sellers	background	2K_dev_1109
The literature has focused on the case where each bidder has two options : to accept or reject the offered price	background	2K_dev_1109
	background	2K_dev_1109
show that the optimization-based approach dramatically outperforms the percentile-based approach -- because it takes feasibility into account in pricing	finding	2K_dev_1109
Both pricing techniques scale to the large	finding	2K_dev_1109
	finding	2K_dev_1109
We present a multi-option DCA ( MDCA ) framework where at each round	mechanism	2K_dev_1109
the auctioneer offers each bidder different prices for different options	mechanism	2K_dev_1109
and a bidder may find multiple options still acceptable Setting prices during a MDCA is trickier than in a DCA	mechanism	2K_dev_1109
We develop a Markov chain model ( which options are still acceptable )	mechanism	2K_dev_1109
We leverage it This is unlike most auctions which only compute the next price vector	mechanism	2K_dev_1109
Computing the trajectory enables better planning	mechanism	2K_dev_1109
We reoptimize the trajectory after each round	mechanism	2K_dev_1109
Each optimization minimizes total payment while ensuring feasibility in a stochastic sense We also introduce percentile-based approaches to decrementing prices	mechanism	2K_dev_1109
	mechanism	2K_dev_1109
Experiments with real FCC incentive auction interference constraint data	method	2K_dev_1109
However	purpose	2K_dev_1109
in many settings -- such as the FCC 's imminent incentive auction -- each bidder may be able to sell one from a set of options	purpose	2K_dev_1109
for the dynamics of each bidder 's state to optimize the trajectory of price offers to different bidders for different options	purpose	2K_dev_1109
	purpose	2K_dev_1109
	background	2K_dev_1110
confirm the significance of the problem and the effectiveness of FlexRR 's solution	finding	2K_dev_1110
Using FlexRR	finding	2K_dev_1110
we consistently observe near-ideal run-times ( relative to no performance jitter ) across all real and injected straggler behaviors tested	finding	2K_dev_1110
FlexRR FlexRR combines a more flexible synchronization model with dynamic peer-to-peer re-assignment of work among workers	mechanism	2K_dev_1110
Experiments with real straggler behavior observed on Amazon EC2 and Microsoft Azure	method	2K_dev_1110
as well as injected straggler behavior stress tests	method	2K_dev_1110
	method	2K_dev_1110
provides a scalable	purpose	2K_dev_1110
efficient solution to the straggler problem for iterative machine learning ( ML )	purpose	2K_dev_1110
The frequent ( e	purpose	2K_dev_1110
g	purpose	2K_dev_1110
	purpose	2K_dev_1110
per iteration ) barriers used in traditional BSP-based distributed ML implementations cause every transient slowdown of any worker thread to delay all others	purpose	2K_dev_1110
to address straggler threads	purpose	2K_dev_1110
	purpose	2K_dev_1110
	background	2K_dev_1111
	finding	2K_dev_1111
A method and apparatus A touch image is received	mechanism	2K_dev_1111
and this touch image has at least a first area that corresponds to an area of the touchscreen that has an elongated interface object positioned at least proximate to it	mechanism	2K_dev_1111
The elongated interface object has a pitch and a yaw with respect to the touchscreen surface	mechanism	2K_dev_1111
A first transformation is performed to obtain a first transformation image of the touch image	mechanism	2K_dev_1111
and a second transformation is performed to obtain a second transformation image of the touch image	mechanism	2K_dev_1111
The first transformation differs from the second transformation The yaw is determined for the elongated interface object based on both the first and second transformation images	mechanism	2K_dev_1111
The pitch is determined based on at least one of the first and second transformation images	mechanism	2K_dev_1111
	mechanism	2K_dev_1111
	method	2K_dev_1111
for determining pitch and yaw of an elongated interface object as it interacts with a touchscreen surface	purpose	2K_dev_1111
	purpose	2K_dev_1111
Which team is the best in the league ? How does my team fare with respect to the rest of the league ? These are questions that every sports fan is interested in knowing the answers to	background	2K_dev_1112
In other cases	background	2K_dev_1112
such as in college sports	background	2K_dev_1112
knowing the answer to these questions is crucial for shaping the picture of spe- cific contests	background	2K_dev_1112
In professional sports	background	2K_dev_1112
sports networks provide power rankings regularly - typically every week or month de- pending on the season length of the league - based on their experts opinion	background	2K_dev_1112
We finally propose an ad- vanced ranking technique based on tensor decomposition	background	2K_dev_1112
	background	2K_dev_1112
we show that the cycles in the network are significantly correlated with the performance	finding	2K_dev_1112
In this work we propose an alternative	mechanism	2K_dev_1112
ob- jective and network-based In brief	mechanism	2K_dev_1112
our method is based on analyzing a directed network formed between the teams of the corresponding leagues that captures their win-lose relationships Using data from the National Football League and the National Basketball As- sociation	mechanism	2K_dev_1112
we show that even simple network theory metrics ( e	mechanism	2K_dev_1112
g	mechanism	2K_dev_1112
	mechanism	2K_dev_1112
Page Rank ) can provide a ranking that has the same ac- curacy in predicting winners of upcoming match-ups as more complicated systems ( e	mechanism	2K_dev_1112
g	mechanism	2K_dev_1112
	mechanism	2K_dev_1112
Cortana	mechanism	2K_dev_1112
We further explore the impact of the network structure on the prediction accuracy and	method	2K_dev_1112
way of ranking sports teams	purpose	2K_dev_1112
	purpose	2K_dev_1112
	background	2K_dev_1113
	finding	2K_dev_1113
	mechanism	2K_dev_1113
	method	2K_dev_1113
	purpose	2K_dev_1113
Describing videos with natural language is one of the ultimate goals of video understanding	background	2K_dev_1114
Video records multi-modal information including image	background	2K_dev_1114
motion	background	2K_dev_1114
aural	background	2K_dev_1114
speech and so on	background	2K_dev_1114
	background	2K_dev_1114
results show the effectiveness of multi-modal fusion encoder trained in the end-to-end framework	finding	2K_dev_1114
which achieved top performance in both common metrics evaluation and human evaluation	finding	2K_dev_1114
	finding	2K_dev_1114
In this paper	mechanism	2K_dev_1114
we propose the multi-modal fusion encoder and integrate it with text sequence decoder into an end-to-end video caption framework	mechanism	2K_dev_1114
Features from visual	mechanism	2K_dev_1114
aural	mechanism	2K_dev_1114
speech and meta modalities are fused together to represent the video contents	mechanism	2K_dev_1114
Long Short-Term Memory Recurrent Neural Networks ( LSTM-RNNs ) are then used as the decoder to generate natural language sentences	mechanism	2K_dev_1114
	mechanism	2K_dev_1114
Experimental	method	2K_dev_1114
MSR Video to Language Challenge provides a good chance to study multi-modality fusion in caption task	purpose	2K_dev_1114
	purpose	2K_dev_1114
We envision that by casting accountability theories in computing and control systems in terms of causal information flow	background	2K_dev_1115
we can provide a common foundation to develop a theory for CPS that compose elements from both domains	background	2K_dev_1115
	background	2K_dev_1115
we summarize our results	finding	2K_dev_1115
We envision that a unified theory of accountability in CPS can be built on a foundation of causal information flow analysis	mechanism	2K_dev_1115
This theory will support design and analysis of mechanisms at various stages of the accountability regime : attack detection	mechanism	2K_dev_1115
responsibility-assignment ( e	mechanism	2K_dev_1115
g	mechanism	2K_dev_1115
	mechanism	2K_dev_1115
attack identification or localization )	mechanism	2K_dev_1115
and corrective measures ( e	mechanism	2K_dev_1115
g	mechanism	2K_dev_1115
	mechanism	2K_dev_1115
via resilient control ) As an initial step in this direction	mechanism	2K_dev_1115
We use the Kullback-Liebler ( KL ) divergence as a causal information flow measure	mechanism	2K_dev_1115
We then recover	mechanism	2K_dev_1115
using information flow analyses	mechanism	2K_dev_1115
a set of existing results in the literature that were previously proved using different techniques	mechanism	2K_dev_1115
These results cover passive detection	mechanism	2K_dev_1115
stealthy attack characterization	mechanism	2K_dev_1115
and active detection	mechanism	2K_dev_1115
This research direction is related to recent work on accountability in computational systems [ 1 ]	mechanism	2K_dev_1115
[ 2 ]	mechanism	2K_dev_1115
[ 3 ]	mechanism	2K_dev_1115
[ 4 ]	mechanism	2K_dev_1115
	mechanism	2K_dev_1115
on attack detection in control systems	method	2K_dev_1115
	method	2K_dev_1115
Our position is that a key component of securing cyber-physical systems ( CPS ) is to develop a theory of accountability that encompasses both control and computing systems	purpose	2K_dev_1115
Electric vehicles ( EVs )	background	2K_dev_1116
specifically Battery EVs ( BEVs )	background	2K_dev_1116
can offer significant energy and emission savings over internal combustion engine based vehicles	background	2K_dev_1116
Norway has a long history of research and government incentives for BEVs	background	2K_dev_1116
	background	2K_dev_1116
The results suggest significant positive effects of BEV technology improvement	finding	2K_dev_1116
toll waivers and charging station density on BEV sales for both personal consumers and business buyers	finding	2K_dev_1116
except that bus lanes access may have a negative impact for personal consumers	finding	2K_dev_1116
possibly due to consumers ' concern regarding bus lane congestion The effects on business buyers are generally less pronounced than on personal consumers	finding	2K_dev_1116
In addition	finding	2K_dev_1116
we find significant heterogeneity in consumer preferences over BEV price and car specifications In particular	finding	2K_dev_1116
a 9	finding	2K_dev_1116
500 NOK increases in consumer income can lead to approximately 10 % decrease in price sensitivity on average	finding	2K_dev_1116
In other words	finding	2K_dev_1116
individual consumers with higher income would be less price-sensitive than those with lower income	finding	2K_dev_1116
Significant heterogeneity in incentive policy impacts on different brands are also found	finding	2K_dev_1116
especially for Renault	finding	2K_dev_1116
Ford	finding	2K_dev_1116
Nissan ( all three being a good compromise of prices and ranges ) and Tesla ( with an exceptionally long range )	finding	2K_dev_1116
we use Random-Coefficient Discrete Choice Model ( referred to BLP model )	mechanism	2K_dev_1116
	mechanism	2K_dev_1116
The BEV market and ample data sets in Norway Our study is instantiated on the entire BEV sales data in Norway from 2011 to 2013	method	2K_dev_1116
as well as demographics information at municipality level	method	2K_dev_1116
allow us to fully examine consumers ' BEV choices influenced by car specifications	purpose	2K_dev_1116
prices and government incentives ( public bus lanes access	purpose	2K_dev_1116
toll waivers and charging stations )	purpose	2K_dev_1116
To capture the choices of heterogeneous personal consumers and business buyers	purpose	2K_dev_1116
Green and Laffonti ? [ 13 ] proved that one can not generically achieve both	background	2K_dev_1117
show that the inefficiency for a simple randomized mechanism is 5 -- -100 times smaller than the worst case	finding	2K_dev_1117
This relative difference increases with the number ofi ? agents	finding	2K_dev_1117
	finding	2K_dev_1117
We consider strategyproof budget-balanced mechanisms that are approximately efficient For deterministic mechanisms	mechanism	2K_dev_1117
we show that a strategyproof and budget-balanced mechanism must have a sink agent whose valuation function is ignored in selecting an alternative	mechanism	2K_dev_1117
and she is compensated with the payments made by the other agents	mechanism	2K_dev_1117
We assume the valuations of the agents come from a bounded open interval	mechanism	2K_dev_1117
This result strengthens Green and Laffont 's impossibility result by showing that even in a restricted domain of valuations	mechanism	2K_dev_1117
there does not exist a mechanism that is strategyproof	mechanism	2K_dev_1117
budget balanced	mechanism	2K_dev_1117
and takes every agent 's valuation into consideration -- a corollary of which is that it can not be efficient	mechanism	2K_dev_1117
Using this result	mechanism	2K_dev_1117
we find a tight lower bound on the inefficiencies of strategyproof	mechanism	2K_dev_1117
budget-balanced mechanisms in this domain	mechanism	2K_dev_1117
The bound shows that the inefficiency asymptotically disappears when the number of agents is large -- a result close in spirit to Green and Laffonti ? [ 13	mechanism	2K_dev_1117
Theorem 9	mechanism	2K_dev_1117
4 ]	mechanism	2K_dev_1117
However	mechanism	2K_dev_1117
our results provide worst-case bounds and the best possible rate of convergence Next	mechanism	2K_dev_1117
we consider minimizing any convex combination of inefficiency and budget imbalance	mechanism	2K_dev_1117
We show that if the valuations are unrestricted	mechanism	2K_dev_1117
no deterministic mechanism can do asymptotically better than minimizing inefficiency alone	mechanism	2K_dev_1117
Finally	mechanism	2K_dev_1117
we investigate randomized mechanisms and provide improved lower bounds on expected inefficiency We give a tight lower bound for an interesting class of strategyproof	mechanism	2K_dev_1117
budget-balanced	mechanism	2K_dev_1117
randomized mechanisms	mechanism	2K_dev_1117
We also use an optimization-based approach -- in the spirit of automated mechanism design -- to provide a lower bound on the minimum achievable inefficiency of any randomized mechanism	mechanism	2K_dev_1117
	mechanism	2K_dev_1117
Experiments with real data from two applications	method	2K_dev_1117
We study efficiency and budget balance for designing mechanisms in general quasi-linear domains	purpose	2K_dev_1117
	purpose	2K_dev_1117
	background	2K_dev_1118
	finding	2K_dev_1118
	mechanism	2K_dev_1118
	method	2K_dev_1118
	purpose	2K_dev_1118
The Next-Generation Airborne Collision Avoidance System ( ACAS X ) is intended to be installed on all large aircraft to give advice to pilots and prevent mid-air collisions with other aircraft	background	2K_dev_1119
It is currently being developed by the Federal Aviation Administration ( FAA ) Our approach is general and could also be used to identify unsafe advice issued by other collision avoidance systems or confirm their safety	background	2K_dev_1119
	finding	2K_dev_1119
In this paper	mechanism	2K_dev_1119
we determine the geometric configurations under a precise set of assumptions and using hybrid systems theorem proving techniques We consider subsequent advisories and show how to adapt our formal verification to take them into account	mechanism	2K_dev_1119
We examine the current version of the real ACAS X system and discuss some cases where our safety theorem conflicts with the actual advisory given by that version	mechanism	2K_dev_1119
demonstrating how formal hybrid systems proving approaches are helping to ensure the safety of ACAS X	mechanism	2K_dev_1119
	mechanism	2K_dev_1119
	method	2K_dev_1119
under which the advice given by ACAS X is safe formally verify these configurations	purpose	2K_dev_1119
Low engagement rates and high attrition rates have been formidable challenges for mobile apps and their long-term success	background	2K_dev_1120
especially for those whose revenues come mainly from in-app purchases	background	2K_dev_1120
To date	background	2K_dev_1120
still little is known about how companies can comprehensively identify user engagement stages so as to improve business revenues	background	2K_dev_1120
Our structural-model- and field-experimentation-based findings are nontrivial and suggest	background	2K_dev_1120
with respect to the crucial role of modeling user engagement	background	2K_dev_1120
potential overall welfare improvements in the mobile app market	background	2K_dev_1120
Interestingly	finding	2K_dev_1120
we found that such an engagement-specific pricing strategy leads	finding	2K_dev_1120
simultaneously	finding	2K_dev_1120
to lower average prices for consumers and higher overall business revenues for the app	finding	2K_dev_1120
Our experimental results provide more causal evidence that a personalized promotion strategy targeting user engagement stages can both decrease costs to app users and enhance overall business performance	finding	2K_dev_1120
	finding	2K_dev_1120
This paper proposes a structural econometric framework that accounts for both the time-varying nature of engagement and consumer forward-looking consumption behavior Our policy simulation enabled us to tailor	mechanism	2K_dev_1120
based on the model-detected engagement stages	mechanism	2K_dev_1120
an optimal pricing strategy to each consumer	mechanism	2K_dev_1120
	mechanism	2K_dev_1120
The present study analyzed a fine-grained mobile tapstream dataset on mobile users ' continuous content consumption behavior in a popular mobile reading app	method	2K_dev_1120
To further evaluate the effectiveness of our method	method	2K_dev_1120
we conducted a randomized field experiment on a mobile app platform	method	2K_dev_1120
for modeling of consumer latent engagement stages	purpose	2K_dev_1120
An increasingly prevalent technique for improving response time in queueing systems is the use of redundancy	background	2K_dev_1121
In a system with redundant requests	background	2K_dev_1121
each job that arrives to the system is copied and dispatched to multiple servers	background	2K_dev_1121
As soon as the first copy completes service	background	2K_dev_1121
the job is considered complete	background	2K_dev_1121
and all remaining copies are deleted	background	2K_dev_1121
	background	2K_dev_1121
We also find asymptotically exact expressions for the distribution of response time as the number of servers approaches infinity	finding	2K_dev_1121
We propose a theoretical model of redundancy	mechanism	2K_dev_1121
the Redundancy- d system	mechanism	2K_dev_1121
in which each job sends redundant copies to d servers chosen uniformly at random	mechanism	2K_dev_1121
We derive the first exact expressions for mean response time in Redundancy-d systems with any finite number of servers	mechanism	2K_dev_1121
	method	2K_dev_1121
A great deal of empirical work has demonstrated that redundancy can significantly reduce response time in systems ranging from Google 's BigTable service to kidney transplant waitlists	purpose	2K_dev_1121
	purpose	2K_dev_1121
	background	2K_dev_1122
	finding	2K_dev_1122
	mechanism	2K_dev_1122
	method	2K_dev_1122
	purpose	2K_dev_1122
Practical implications As many marketers are interested in hoarding consumers personal information	background	2K_dev_1123
privacy advocates call for methods that would ensure careful and well-informed disclosure Offering reversibility to a decision to disclose personal information	background	2K_dev_1123
or merely pointing out the irreversibility of that decision	background	2K_dev_1123
can make consumers reevaluate the sensitivity of the situation	background	2K_dev_1123
leading to more careful disclosures Originality/value Although previous research on reversibility in consumer behavior focused on product return policies and showed that reversibility increases purchases	background	2K_dev_1123
none have studied how reversibility affects self-disclosure and how it can decrease it	background	2K_dev_1123
	background	2K_dev_1123
Findings showed that consumers disclose less in both the reversible and irreversible conditions	finding	2K_dev_1123
compared to the control condition showed that this is because consumers treat reversibility as a cue to the sensitivity of the information they are asked to divulge	finding	2K_dev_1123
and that leads them to disclose less when reversibility or irreversibility is made explicitly salient beforehand	finding	2K_dev_1123
	mechanism	2K_dev_1123
Design/methodology/approach Three studies examined how informing consumers they may ( reversible condition ) or may not ( irreversible condition ) revise their personal information in the future affected their propensity to disclose personal information	method	2K_dev_1123
compared to a control condition Study 1 ( which included three experiments with different time intervals between initial and revised disclosure Studies 2 and 3	method	2K_dev_1123
Purpose This paper aims to examine how reversibility in disclosing personal information that is	purpose	2K_dev_1123
having ( vs not having ) to option to later revise or retract personal information can impact consumers willingness to divulge personal information	purpose	2K_dev_1123
The approach finds a dual flow solution to this linear system through a sequence of flow adjustments along cycles	background	2K_dev_1124
	background	2K_dev_1124
Our methods demonstrate significant speedups over previous implementations	finding	2K_dev_1124
and are competitive with standard numerical routines	finding	2K_dev_1124
We study both data structure oriented and recursive methods The primary difficulty faced by this approach	mechanism	2K_dev_1124
updating and querying long cycles	mechanism	2K_dev_1124
motivated us to study an important special case : instances where all cycles are formed by fundamental cycles on a length $ n $ path	mechanism	2K_dev_1124
	mechanism	2K_dev_1124
	method	2K_dev_1124
We study the performance of linear solvers for graph Laplacians based on the combinatorial cycle adjustment methodology proposed by [ Kelner-Orecchia-Sidford-Zhu STOC-13 ]	purpose	2K_dev_1124
for handling these adjustments	purpose	2K_dev_1124
	purpose	2K_dev_1124
	background	2K_dev_1125
	finding	2K_dev_1125
This paper studies an attacker against a cyber-physical system ( CPS ) The attacker 's probability of being detected is related to the nonnegative bias induced by his or her attack on the CPS ' detection statistic We formulate a linear quadratic cost function that captures the attacker 's control goal and establish constraints on the induced bias that reflect the attacker 's detection-avoidance objectives When the attacker is constrained to be detected at the false-alarm rate of the detector	mechanism	2K_dev_1125
we show that the optimal attack strategy reduces to a linear feedback of the attacker 's state estimate In the case that the attacker 's bias is upper bounded by a positive constant	mechanism	2K_dev_1125
we provide two algorithms -- an optimal algorithm and a sub-optimal	mechanism	2K_dev_1125
less computationally intensive algorithm --	mechanism	2K_dev_1125
Finally	method	2K_dev_1125
we illustrate our attack strategies in numerical examples based on a remotely-controlled helicopter under attack	method	2K_dev_1125
	method	2K_dev_1125
whose goal is to move the state of a CPS to a target state while ensuring that his or her probability of being detected does not exceed a given bound	purpose	2K_dev_1125
to find suitable attack sequences	purpose	2K_dev_1125
	purpose	2K_dev_1125
	background	2K_dev_1126
	finding	2K_dev_1126
	mechanism	2K_dev_1126
	method	2K_dev_1126
	purpose	2K_dev_1126
Real-time virtualization techniques have been investigated with the primary goal of consolidating multiple real-time systems onto a single hardware platform while ensuring timing predictability However	background	2K_dev_1127
a shared last-level cache ( LLC ) on recent multi-core platforms can easily hamper timing predictability due to the resulting temporal interference among consolidated workloads	background	2K_dev_1127
results show that our techniques can effectively control the cache allocation of tasks in VMs	finding	2K_dev_1127
Our cache management scheme yields a significant utilization benefit compared to other approaches	finding	2K_dev_1127
	finding	2K_dev_1127
In this paper	mechanism	2K_dev_1127
we propose a real-time cache management framework Our framework introduces two hypervisor-level techniques	mechanism	2K_dev_1127
vLLC and vColoring	mechanism	2K_dev_1127
that enable the cache allocation of individual tasks running in a virtual machine ( VM )	mechanism	2K_dev_1127
which is not achievable by the current state of the art Our framework also provides a cache management scheme that determines cache allocation to tasks	mechanism	2K_dev_1127
designs VMs in a cache-aware manner	mechanism	2K_dev_1127
and minimizes the aggregated utilization of VMs to be consolidated	mechanism	2K_dev_1127
	mechanism	2K_dev_1127
As a proof of concept	method	2K_dev_1127
we implemented vLLC and vColoring in the KVM hypervisor running on x86 and ARM multi-core platforms	method	2K_dev_1127
Experimental with three different guest OSs	method	2K_dev_1127
namely Linux/RK	method	2K_dev_1127
vanilla Linux and MS Windows Embedded	method	2K_dev_1127
	method	2K_dev_1127
Since such interference caused by the LLC is highly variable and may have not even existed in legacy systems to be consolidated	purpose	2K_dev_1127
it poses a significant challenge for real-time virtualization	purpose	2K_dev_1127
for multi-core virtualization	purpose	2K_dev_1127
When navigating indoors	background	2K_dev_1128
blind people are often unaware of key visual information	background	2K_dev_1128
such as posters	background	2K_dev_1128
signs	background	2K_dev_1128
and exit doors	background	2K_dev_1128
With VizMap	background	2K_dev_1128
we move towards integrating the strengths of the end user	background	2K_dev_1128
on-site crowd	background	2K_dev_1128
online crowd	background	2K_dev_1128
and computer vision to solve a long-standing challenge in indoor blind exploration	background	2K_dev_1128
	background	2K_dev_1128
	finding	2K_dev_1128
Our VizMap system uses computer vision and crowdsourcing VizMap starts with videos taken by on-site sighted volunteers and uses these to create a 3D spatial model	mechanism	2K_dev_1128
These video frames are semantically labeled by remote crowd workers with key visual information	mechanism	2K_dev_1128
These semantic labels are located within and embedded into the reconstructed 3D model	mechanism	2K_dev_1128
forming a query-able spatial representation of the environment	mechanism	2K_dev_1128
VizMap can then localize the user with a photo from their smartphone	mechanism	2K_dev_1128
and enable them to explore the visual elements that are nearby	mechanism	2K_dev_1128
We explore a range of example applications enabled by our reconstructed spatial representation	method	2K_dev_1128
	method	2K_dev_1128
to collect this information and make it available non-visually	purpose	2K_dev_1128
Electrical Impedance Tomography ( EIT ) was recently employed in the HCI domain to detect hand gestures using an instrumented smartwatch	background	2K_dev_1129
This prior work demonstrated great promise for non-invasive	background	2K_dev_1129
high accuracy recognition of gestures for interactive control shed light on the future feasibility of EIT for sensing human input	background	2K_dev_1129
	background	2K_dev_1129
	finding	2K_dev_1129
We introduce a new system In turn	mechanism	2K_dev_1129
this enables superior interior reconstruction and gesture recognition	mechanism	2K_dev_1129
More importantly	method	2K_dev_1129
we use our new system as a vehicle for experimentation ' we compare two EIT sensing methods and three different electrode resolutions	method	2K_dev_1129
Results from in-depth empirical evaluations and a user study	method	2K_dev_1129
that offers improved sampling speed and resolution	purpose	2K_dev_1129
	purpose	2K_dev_1129
	background	2K_dev_1130
demonstrate that our approach achieves high accuracy in multiclass classification and outperforms other classification approaches	finding	2K_dev_1130
We present that is based on the regularization of graph signals	mechanism	2K_dev_1130
Our approach is based on the theory of discrete signal processing on graphs where the graph represents similarities between data and we interpret labels for the dataset elements as a signal indexed by the nodes of the graph	mechanism	2K_dev_1130
We postulate that true labels form a low-frequency graph signal and the classifier finds the smoothest graph signal that satisfies constraints given by known data labels	mechanism	2K_dev_1130
	mechanism	2K_dev_1130
Our experiments	method	2K_dev_1130
a novel data classifier	purpose	2K_dev_1130
	background	2K_dev_1131
suggesting that AuraSense can be low latency and robust across users and environments	finding	2K_dev_1131
	finding	2K_dev_1131
In this work	mechanism	2K_dev_1131
we introduce AuraSense	mechanism	2K_dev_1131
using electric field sensing as an adapted device	mechanism	2K_dev_1131
We identified four configurations that can support six well-known modalities of particular interest and utility	mechanism	2K_dev_1131
including gestures above or in close proximity to watches	mechanism	2K_dev_1131
and touchscreen-like finger tracking on the skin	mechanism	2K_dev_1131
	mechanism	2K_dev_1131
To explore how this sensing approach could enhance smartwatch interactions	method	2K_dev_1131
we considered different antenna configurations and how they could enable useful interaction modalities We quantify the feasibility of these input modalities	method	2K_dev_1131
	method	2K_dev_1131
Existing smartwatches rely on touchscreens for display and input	purpose	2K_dev_1131
which inevitably leads to finger occlusion and confines interactivity to a small area	purpose	2K_dev_1131
which enables rich	purpose	2K_dev_1131
around-device	purpose	2K_dev_1131
smartwatch interactions	purpose	2K_dev_1131
	background	2K_dev_1132
Longitudinally	finding	2K_dev_1132
the geodesic distance was found to be proportional to the elapsed time separating the two scans in question we found that each structures annualized rate of change in the geodesic distance followed the order of AD > MCI > HC	finding	2K_dev_1132
with statistical significance being reached in every case In addition	finding	2K_dev_1132
for each of the six structures of interest	finding	2K_dev_1132
within the same time interval ( e	finding	2K_dev_1132
g	finding	2K_dev_1132
	finding	2K_dev_1132
from baseline to the 6th month )	finding	2K_dev_1132
we observed significant correlations between the geodesic distance and the cognitive deterioration as quantified by the ADAS-cog increase and the MMSE decrease Furthermore	finding	2K_dev_1132
as the disease progresses over time	finding	2K_dev_1132
this linkage between the inter-shape geodesic distance and the cognitive decline becomes considerably stronger and more significant	finding	2K_dev_1132
	finding	2K_dev_1132
We propose a geodesic distance on a Grassmannian manifold Cross-sectionally	mechanism	2K_dev_1132
utilizing a linear mixed-effects statistical model	mechanism	2K_dev_1132
Longitudinal magnetic resonance imaging ( MRI ) scans of 754 subjects ( 3092 scans in total ) were used in this study	method	2K_dev_1132
	method	2K_dev_1132
that can be used to quantify the shape progression patterns of the bilateral hippocampi	purpose	2K_dev_1132
amygdalas	purpose	2K_dev_1132
and lateral ventricles in healthy control ( HC )	purpose	2K_dev_1132
mild cognitive impairment ( MCI )	purpose	2K_dev_1132
and Alzheimer 's disease ( AD )	purpose	2K_dev_1132
	purpose	2K_dev_1132
The world is full of physical interfaces that are inaccessible to blind people	background	2K_dev_1133
from microwaves and information kiosks to thermostats and checkout terminals	background	2K_dev_1133
Blind people can not independently use such devices without at least first learning their layout	background	2K_dev_1133
and usually only after labeling them with sighted assistance and foreshadows a future of increasingly powerful interactive applications that would be currently impossible with either alone	background	2K_dev_1133
We show that VizLens provides accurate and usable real-time feedback and our crowdsourcing labeling workflow was fast ( 8 minutes )	finding	2K_dev_1133
accurate ( 99	finding	2K_dev_1133
7 % )	finding	2K_dev_1133
and cheap ( $ 1	finding	2K_dev_1133
15 )	finding	2K_dev_1133
	finding	2K_dev_1133
We introduce VizLens - an accessible mobile application and supporting backend that can robustly and interactively VizLens users capture a photo of an inaccessible interface and send it to multiple crowd workers	mechanism	2K_dev_1133
who work in parallel to quickly label and describe elements of the interface to make subsequent computer vision easier	mechanism	2K_dev_1133
The VizLens application helps users recapture the interface in the field of the camera	mechanism	2K_dev_1133
and uses computer vision to interactively describe the part of the interface beneath their finger ( updating 8 times per second )	mechanism	2K_dev_1133
We then explore extensions of VizLens that allow it to ( i ) adapt to state changes in dynamic interfaces	mechanism	2K_dev_1133
( ii ) combine crowd labeling with OCR technology to handle dynamic displays	mechanism	2K_dev_1133
and ( iii ) benefit from head-mounted cameras VizLens robustly solves a long-standing challenge in accessibility by deeply integrating crowdsourcing and computer vision	mechanism	2K_dev_1133
	mechanism	2K_dev_1133
in a study with 10 blind participants	method	2K_dev_1133
help blind people use nearly any interface they encounter	purpose	2K_dev_1133
	background	2K_dev_1134
The empirical results show that the patterns of parameters as a seizure approach and the method is efficient in analyzing nonlinear epilepsy electroencephalogram data	finding	2K_dev_1134
The accuracy of estimating the optimal parameters is improved by using the nonlinear dynamic model	finding	2K_dev_1134
We propose a nonlinear dynamic model for an invasive electroencephalogram analysis via the LevenbergMarquardt algorithm	mechanism	2K_dev_1134
We introduce the crucial windows where the estimated parameters present patterns before seizure onset The optimal parameters minimizes the error between the observed signal and the generated signal by the model	mechanism	2K_dev_1134
The proposed approach effectively discriminates between healthy signals and epileptic seizure signals	mechanism	2K_dev_1134
	mechanism	2K_dev_1134
	mechanism	2K_dev_1134
We evaluate the proposed method using an electroencephalogram dataset with normal and epileptic seizure sequences	method	2K_dev_1134
that learns the optimal parameters of the neural population model	purpose	2K_dev_1134
Smartwatches and wearables are unique in that they reside on the body	background	2K_dev_1135
presenting great potential for always-available input and interaction	background	2K_dev_1135
Their position on the wrist makes them ideal for capturing bio-acoustic signals	background	2K_dev_1135
Overall	background	2K_dev_1135
our contributions unlock user interface techniques that previously relied on special-purpose and/or cumbersome instrumentation	background	2K_dev_1135
making such interactions considerably more feasible for inclusion in future consumer devices	background	2K_dev_1135
	background	2K_dev_1135
	finding	2K_dev_1135
We developed a custom smartwatch kernel For example	mechanism	2K_dev_1135
we can use bio-acoustic data to classify hand gestures such as flicks	mechanism	2K_dev_1135
claps	mechanism	2K_dev_1135
scratches	mechanism	2K_dev_1135
and taps	mechanism	2K_dev_1135
which combine with on-device motion tracking to create a wide range of expressive input modalities	mechanism	2K_dev_1135
Bio-acoustic sensing can also detect the vibrations of grasped mechanical or motor-powered objects	mechanism	2K_dev_1135
enabling passive object recognition that can augment everyday experiences with context-aware functionality Finally	mechanism	2K_dev_1135
we can generate structured vibrations using a transducer	mechanism	2K_dev_1135
and show that data can be transmitted through the human body	mechanism	2K_dev_1135
	mechanism	2K_dev_1135
Using this new source of high-fidelity data	method	2K_dev_1135
we uncovered a wide range of applications	method	2K_dev_1135
that boosts the sampling rate of a smartwatch 's existing accelerometer to 4 kHz	purpose	2K_dev_1135
	purpose	2K_dev_1135
Given `` who-trusts/distrusts-whom '' information	background	2K_dev_1136
how can we propagate the trust and distrust ? With the appearance of fraudsters in social network sites	background	2K_dev_1136
the importance of trust prediction has increased	background	2K_dev_1136
	background	2K_dev_1136
confirm that PIN-TRUST is scalable and outperforms existing methods in terms of prediction accuracy	finding	2K_dev_1136
achieving up to 50	finding	2K_dev_1136
4 percentage relative improvement	finding	2K_dev_1136
	finding	2K_dev_1136
In this paper	mechanism	2K_dev_1136
we propose PIN -TRUST	mechanism	2K_dev_1136
a novel method The novelties of our method are the following : ( a ) it is carefully designed	mechanism	2K_dev_1136
to take into account positive	mechanism	2K_dev_1136
implicit	mechanism	2K_dev_1136
and negative information	mechanism	2K_dev_1136
( b ) it is scalable ( i	mechanism	2K_dev_1136
e	mechanism	2K_dev_1136
	mechanism	2K_dev_1136
linear on the input size )	mechanism	2K_dev_1136
( c ) most importantly	mechanism	2K_dev_1136
it is effective and accurate	mechanism	2K_dev_1136
Our extensive experiments with a real dataset	method	2K_dev_1136
Epinions	method	2K_dev_1136
com data	method	2K_dev_1136
of 100K nodes and 1M edges	method	2K_dev_1136
	method	2K_dev_1136
Most such methods use only explicit and implicit trust information ( e	purpose	2K_dev_1136
g	purpose	2K_dev_1136
	purpose	2K_dev_1136
if Smith likes several of Johnson 's reviews	purpose	2K_dev_1136
then Smith implicitly trusts Johnson )	purpose	2K_dev_1136
but they do not consider distrust to handle all three types of interaction information : explicit trust	purpose	2K_dev_1136
implicit trust	purpose	2K_dev_1136
and explicit distrust	purpose	2K_dev_1136
	purpose	2K_dev_1136
Many applications in speech	background	2K_dev_1137
robotics	background	2K_dev_1137
finance	background	2K_dev_1137
and biology deal with sequential data	background	2K_dev_1137
where ordering matters and recurrent structures are common	background	2K_dev_1137
where the predictive uncertainties provided by GP-LSTM are uniquely valuable	finding	2K_dev_1137
	finding	2K_dev_1137
we propose expressive closed-form kernel functions for Gaussian processes	mechanism	2K_dev_1137
The resulting model	mechanism	2K_dev_1137
GP-LSTM	mechanism	2K_dev_1137
fully encapsulates the inductive biases of long short-term memory ( LSTM ) recurrent networks	mechanism	2K_dev_1137
while retaining the non-parametric probabilistic advantages of Gaussian processes We learn the properties of the proposed kernels by optimizing the Gaussian process marginal likelihood using a new provably convergent semi-stochastic procedure and exploit the structure of these kernels for fast and scalable training and prediction	mechanism	2K_dev_1137
	mechanism	2K_dev_1137
We demonstrate state-of-the-art performance on several benchmarks	method	2K_dev_1137
and thoroughly investigate a consequential autonomous driving application	method	2K_dev_1137
	method	2K_dev_1137
However	purpose	2K_dev_1137
this structure can not be easily captured by standard kernel functions	purpose	2K_dev_1137
To model such structure	purpose	2K_dev_1137
	purpose	2K_dev_1137
	background	2K_dev_1138
	finding	2K_dev_1138
	mechanism	2K_dev_1138
	method	2K_dev_1138
	purpose	2K_dev_1138
As mobile computing and cloud computing converge	background	2K_dev_1139
the sensing and interaction capabilities of mobile devices can be seamlessly fused with compute-intensive and data-intensive processing in the cloud	background	2K_dev_1139
Cloudlets are important architectural components in this convergence	background	2K_dev_1139
representing the middle tier of a mobile device cloudlet cloud hierarchy	background	2K_dev_1139
	background	2K_dev_1139
	finding	2K_dev_1139
We describe a plug-and-play architecture	mechanism	2K_dev_1139
	method	2K_dev_1139
and a proof of concept using Google Glass	method	2K_dev_1139
	method	2K_dev_1139
We show how cloudlets enable a new genre of applications called cognitive assistance applications that augment human perception and cognition for cognitive assistance	purpose	2K_dev_1139
In the human genome	background	2K_dev_1140
distal enhancers are involved in regulating target genes through proximal promoters by forming enhancer-promoter interactions This work shows for the first time that sequence-based features alone can reliably predict enhancer-promoter interactions genome-wide	background	2K_dev_1140
which provides important insights into the sequence determinants for long-range gene regulation	background	2K_dev_1140
demonstrate that SPEID is effective in predicting enhancer-promoter interactions as compared to state-of-the-art methods that use non-sequence features from functional genomic signals	finding	2K_dev_1140
	finding	2K_dev_1140
Here we report a new computational method ( named `` SPEID '' ) using deep learning models based on sequence-based features only	mechanism	2K_dev_1140
when the locations of putative enhancers and promoters in a particular cell type are given	mechanism	2K_dev_1140
	mechanism	2K_dev_1140
Our results across six different cell types	method	2K_dev_1140
However	purpose	2K_dev_1140
although recently developed high-throughput experimental approaches have allowed us to recognize potential enhancer-promoter interactions genome-wide	purpose	2K_dev_1140
it is still largely unknown whether there are sequence-level instructions encoded in our genome that help govern such interactions	purpose	2K_dev_1140
to predict enhancer-promoter interactions	purpose	2K_dev_1140
Sensorized commercial buildings are a rich target for building a new class of applications that improve operational and energy efficiency of building operations that take into account human activities The attendees would be able to create example buildings and write their own queries	background	2K_dev_1141
	background	2K_dev_1141
show application queries that extracts relevant metadata from these buildings	finding	2K_dev_1141
	finding	2K_dev_1141
Our demo presents Brick [ 4 ]	mechanism	2K_dev_1141
a uniform schema Our schema defines a concrete ontology for sensors	mechanism	2K_dev_1141
subsystems and relationships among them	mechanism	2K_dev_1141
which enables portable applications	mechanism	2K_dev_1141
	mechanism	2K_dev_1141
Using a web application	method	2K_dev_1141
we will demonstrate real buildings that have been mapped to the Brick schema	method	2K_dev_1141
and	method	2K_dev_1141
Such applications	purpose	2K_dev_1141
however	purpose	2K_dev_1141
rarely experience widespread adoption due to the lack of a common descriptive schema that would enable porting these applications and systems to different buildings	purpose	2K_dev_1141
for representing metadata in buildings	purpose	2K_dev_1141
	background	2K_dev_1142
demonstrate that our algorithm can continuously execute using energy harvested from indoor solar panels we see that we can detect motions with an average of 85 % recall rate and perform occupancy counting with an average error of 10 % in terms of maximum occupancy	finding	2K_dev_1142
In this paper	mechanism	2K_dev_1142
we present a platform The system transmits a wide-band ultrasonic signal into a room and then processes the superposition of the reflections recorded by a microphone The system has two modes of operation	mechanism	2K_dev_1142
one for presence detection and one for estimating the number of occupants in a region	mechanism	2K_dev_1142
The presence detection uses the difference between multiple transmissions in succession with a set of general classifiers that make a binary decision about if the room contains occupants	mechanism	2K_dev_1142
We then use a semi-supervised learning approach based on Weighted Principal Component Analysis ( WPCA ) that requires minimal training data to estimate the number of occupants We also present the design of an energy harvesting embedded platform and The platform has a dual Bluetooth Low-Energy and 802	mechanism	2K_dev_1142
15	mechanism	2K_dev_1142
4 interface to communicate with a gateway or nearby mobile phone that runs an interface that aids in collecting training data	mechanism	2K_dev_1142
	mechanism	2K_dev_1142
We evaluate our algorithm on a wide-variety of indoor spaces as well as benchmark the hardware in terms of sampling rate given an energy budget On more than three weeks of data	method	2K_dev_1142
designed for low-power real-time sensing of the number of occupants in indoor spaces	purpose	2K_dev_1142
Commercial buildings have long since been a primary target for applications from a number of areas : from cyber-physical systems to building energy use to improved human interactions in built environments	background	2K_dev_1143
While technological advances have been made in these areas	background	2K_dev_1143
such solutions rarely experience widespread adoption due to the lack of a common descriptive schema which would reduce the now-prohibitive cost of porting these applications and systems to different buildings	background	2K_dev_1143
	background	2K_dev_1143
We demonstrate the completeness and effectiveness of Brick	finding	2K_dev_1143
this paper describes Brick	mechanism	2K_dev_1143
a uniform schema Our schema defines a concrete ontology for sensors	mechanism	2K_dev_1143
subsystems and relationships among them	mechanism	2K_dev_1143
which enables portable applications	mechanism	2K_dev_1143
by using it to represent the entire vendor-specific sensor metadata of six diverse buildings across different campuses	method	2K_dev_1143
comprising 17	method	2K_dev_1143
700 data points	method	2K_dev_1143
and running eight complex unmodified applications on these buildings	method	2K_dev_1143
	method	2K_dev_1143
Recent attempts have sought to address this issue through data standards and metadata schemes	purpose	2K_dev_1143
but fail to capture the set of relationships and entities required by real applications	purpose	2K_dev_1143
Building upon these works	purpose	2K_dev_1143
for representing metadata in buildings	purpose	2K_dev_1143
Several generations of inexpensive depth cameras have opened the possibility for new kinds of interaction on everyday surfaces	background	2K_dev_1144
A number of research systems have demonstrated that depth cameras	background	2K_dev_1144
combined with projectors for output	background	2K_dev_1144
can turn nearly any reasonably flat surface into a touch-sensitive display	background	2K_dev_1144
	background	2K_dev_1144
Results show that our technique boosts touch detection accuracy by 15 % and reduces positional error by 55 % compared to the next best-performing technique	finding	2K_dev_1144
	finding	2K_dev_1144
In this paper we present DIRECT	mechanism	2K_dev_1144
that merges depth and infrared imagery captured by a commodity sensor This yields significantly better touch tracking than from depth data alone	mechanism	2K_dev_1144
as well as any prior system	mechanism	2K_dev_1144
Further extending prior work	mechanism	2K_dev_1144
DIRECT supports arbitrary user orientation and requires no prior calibration or background capture	mechanism	2K_dev_1144
We describe the implementation of our system and	mechanism	2K_dev_1144
quantify its accuracy through a comparison study of previously published	method	2K_dev_1144
depth-based touch-tracking algorithms	method	2K_dev_1144
However	purpose	2K_dev_1144
even with the latest generation of depth cameras	purpose	2K_dev_1144
it has been difficult to obtain sufficient sensing fidelity across a table-sized surface to get much beyond a proof-of-concept demonstration a novel touch-tracking algorithm	purpose	2K_dev_1144
	background	2K_dev_1145
generating a tightly synchronized PPS output that is able to adjust for the distance between the nodes	finding	2K_dev_1145
Even without communication	finding	2K_dev_1145
the devices maintain synchronization over multiple seconds	finding	2K_dev_1145
In this demonstration we present Pulsar	mechanism	2K_dev_1145
a speed-of-light propagation-aware time synchronization platform	mechanism	2K_dev_1145
Pulsar uses ultra-wideband ( UWB ) radios for time transfer with each node backed by a chip scale atomic clock ( CSAC ) that in combination are able due to a stable CSAC clocking the system	mechanism	2K_dev_1145
	mechanism	2K_dev_1145
The demonstration will show two Pulsar boards	method	2K_dev_1145
to provide accuracy on the order of 10 's of nanoseconds for indoor applications	purpose	2K_dev_1145
	purpose	2K_dev_1145
Cohesion and structural equivalence are two competing network models to explain diffusion of innovation	background	2K_dev_1146
	background	2K_dev_1146
We found subpopulation size in such million-node network only falls in two levels	finding	2K_dev_1146
200 and 500	finding	2K_dev_1146
in the extraction step The results show CRBT adoption is affected by both cohesion and structural equivalence The size and direction of network influence both change with the size of group	finding	2K_dev_1146
Structural equivalence has a negative effect on adoption when group size is at about 200	finding	2K_dev_1146
and has a positive effect when group size is at about 500	finding	2K_dev_1146
The effect of cohesion	finding	2K_dev_1146
on the other hand	finding	2K_dev_1146
is consistent	finding	2K_dev_1146
Since this societal scale network is very large	mechanism	2K_dev_1146
we use a novel technique Using a new auto-probit model with network terms	mechanism	2K_dev_1146
	mechanism	2K_dev_1146
we then compare the competing influences of cohesion and structural equivalence on each of the subpopulation extracted	method	2K_dev_1146
Finally we use meta-analysis to summarize the estimated parameters from all subpopulations	method	2K_dev_1146
	method	2K_dev_1146
The dispute of which model plays a more influential role has not been resolved This paper attempts to reconcile this problem in a large network setting adoption of caller ringback tone ( CRBT ) in a cellular telephone conversation network to extract multiple densely connected and self-contained subpopulations from the network	purpose	2K_dev_1146
To respond to environmental changes	background	2K_dev_1147
such as drought	background	2K_dev_1147
plants must regulate numerous cellular processes	background	2K_dev_1147
The work provides a framework for understanding and modulating plant responses to stress	background	2K_dev_1147
	background	2K_dev_1147
	finding	2K_dev_1147
Working in the model plant Arabidopsis	mechanism	2K_dev_1147
Song et al	mechanism	2K_dev_1147
profiled the binding of 21 transcription factors to chromatin and	mechanism	2K_dev_1147
	method	2K_dev_1147
mapped the complex gene regulatory networks involved in the response to the plant hormone abscisic acid	purpose	2K_dev_1147
	background	2K_dev_1148
Furthermore	finding	2K_dev_1148
we show that	finding	2K_dev_1148
once the model is trained	finding	2K_dev_1148
the algorithm can perform inference	finding	2K_dev_1148
In this paper we introduce BOLT	mechanism	2K_dev_1148
a novel approach that performs online binary matrix factorization on a sequence of high frequency current cycles collected in a building to infer additive subcomponents of the current signal	mechanism	2K_dev_1148
The system learns these constituent current waveforms in an unsupervised fashion and	mechanism	2K_dev_1148
in a subsequent step	mechanism	2K_dev_1148
seeks to find combinations of these subcomponents that constitute appliances By doing so	mechanism	2K_dev_1148
points in time when appliances are active and	mechanism	2K_dev_1148
to some degree	mechanism	2K_dev_1148
their power consumption can be estimated by BOLT	mechanism	2K_dev_1148
Our system treats energy disaggregation as a binary matrix factorization problem and uses a neural network	mechanism	2K_dev_1148
with binary activations in the one but last layer and a linear output layer	mechanism	2K_dev_1148
to solve it	mechanism	2K_dev_1148
which allows leveraging high-frequency information without having to explicitly transmit and store large amounts of data to a centralized repository	mechanism	2K_dev_1148
	mechanism	2K_dev_1148
The algorithmic performance of the proposed method is evaluated on a publicly available dataset in real-time on inexpensive off-the-shelf and general purpose hardware	method	2K_dev_1148
for the problem of energy disaggregation	purpose	2K_dev_1148
Deep kernel learning combines the non-parametric flexibility of kernel methods with the inductive biases of deep learning architectures	background	2K_dev_1149
We show improved performance	finding	2K_dev_1149
We propose a novel deep kernel learning model and stochastic variational inference procedure which generalizes deep kernel learning approaches Specifically	mechanism	2K_dev_1149
we apply additive base kernels to subsets of output features from deep neural architectures	mechanism	2K_dev_1149
and jointly learn the parameters of the base kernels and deep network through a Gaussian process marginal likelihood objective	mechanism	2K_dev_1149
Within this framework	mechanism	2K_dev_1149
we derive an efficient form of stochastic variational inference which leverages local kernel interpolation	mechanism	2K_dev_1149
inducing points	mechanism	2K_dev_1149
and structure exploiting algebra	mechanism	2K_dev_1149
	mechanism	2K_dev_1149
over stand alone deep networks	method	2K_dev_1149
SVMs	method	2K_dev_1149
and state of the art scalable Gaussian processes on several classification benchmarks	method	2K_dev_1149
including an airline delay dataset containing 6 million training points	method	2K_dev_1149
CIFAR	method	2K_dev_1149
and ImageNet	method	2K_dev_1149
to enable classification	purpose	2K_dev_1149
multi-task learning	purpose	2K_dev_1149
additive covariance structures	purpose	2K_dev_1149
and stochastic gradient training	purpose	2K_dev_1149
	purpose	2K_dev_1149
In graph signal processing	background	2K_dev_1150
the graph adjacency matrix or the graph Laplacian commonly define the shift operator	background	2K_dev_1150
The spectral decomposition of the shift operator plays an important role in that the eigenvalues represent frequencies and the eigenvectors provide a spectral basis	background	2K_dev_1150
This is useful	background	2K_dev_1150
for example	background	2K_dev_1150
in the design of filters	background	2K_dev_1150
The main results characterize the form of the solution to an important system of equations that leads to this deterministic distribution function and significantly reduce the number of equations that must be solved to find the solution for a given set of model parameters are provided for sample parameters	finding	2K_dev_1150
formed by including each link of a D-dimensional lattice supergraph independently with identical probability	mechanism	2K_dev_1150
a percolation model	mechanism	2K_dev_1150
Using the stochastic canonical equation methods developed by Girko for symmetric matrices with independent upper triangular entries	mechanism	2K_dev_1150
a deterministic distribution is found that asymptotically approximates the empirical spectral distribution of the scaled adjacency matrix for a model with arbitrary parameters	mechanism	2K_dev_1150
Simulations comparing the expected empirical spectral distributions and the computed deterministic distributions	method	2K_dev_1150
However	purpose	2K_dev_1150
the graph or network may be uncertain due to stochastic influences in construction and maintenance	purpose	2K_dev_1150
and	purpose	2K_dev_1150
under such conditions	purpose	2K_dev_1150
the eigenvalues of the shift matrix become random variables This paper examines the spectral distribution of the eigenvalues of random networks	purpose	2K_dev_1150
Existing approaches for trilateration require three or more beacons to determine a unique position solution	background	2K_dev_1151
our approach is able to reduce the number of beacons between 22 % and 60 % ( 33 % on an average ) as compared to standard trilateration	finding	2K_dev_1151
We show that with prior knowledge of the map and a model of beacon coverage	mechanism	2K_dev_1151
it is possible This not only reduces installation cost by requiring fewer nodes	mechanism	2K_dev_1151
but can also improve robustness One of the main challenges with respect to beacon placement algorithms is defining a metric for estimating performance We propose augmenting the commonly used Geometric Dilution of Precision ( GDOP ) metric	mechanism	2K_dev_1151
We then use this enhanced GDOP metric as part of a toolchain to compare various beacon placement algorithms in terms of coverage and expected accuracy	method	2K_dev_1151
When applied to a set of real floor plans	method	2K_dev_1151
	method	2K_dev_1151
In this paper	purpose	2K_dev_1151
we address the problem of range-based beacon placement given a floor plan to support indoor localization systems to uniquely localize with only two beacons	purpose	2K_dev_1151
to account for indoor spaces	purpose	2K_dev_1151
	purpose	2K_dev_1151
With the potential to enhance the power system 's operational flexibility in a cost-effective way	background	2K_dev_1152
demand response is gaining increased attention worldwide	background	2K_dev_1152
Industrial loads such as cement crushing plants consume large amounts of electric energy and therefore are prime candidates for the provision of significant amounts of demand response	background	2K_dev_1152
They have the capability to turn on/off an arbitrary number of their crushers thereby adjusting their electric power consumption	background	2K_dev_1152
	background	2K_dev_1152
	finding	2K_dev_1152
In this paper	mechanism	2K_dev_1152
we propose a coordination method based on model predictive control	mechanism	2K_dev_1152
	method	2K_dev_1152
However	purpose	2K_dev_1152
the change in power consumption by cement crushing plants and also other industrial loads are often not granular enough to provide valuable ancillary services such as regulation and load following	purpose	2K_dev_1152
to overcome the granularity restriction with the help of an energy storage	purpose	2K_dev_1152
	background	2K_dev_1153
	finding	2K_dev_1153
	mechanism	2K_dev_1153
	method	2K_dev_1153
	purpose	2K_dev_1153
	background	2K_dev_1154
and demonstrate data transmission rates up to four times faster than prior camera-based techniques	finding	2K_dev_1154
highlighting different interaction techniques CapCam enables	finding	2K_dev_1154
We present CapCam	mechanism	2K_dev_1154
a novel technique	mechanism	2K_dev_1154
simply by pressing a device to the screen 's surface Pairing data	mechanism	2K_dev_1154
used to bootstrap a conventional wireless connection	mechanism	2K_dev_1154
is transmitted optically to the phone 's rear camera	mechanism	2K_dev_1154
This approach utilizes the near-ubiquitous rear camera on smart devices	mechanism	2K_dev_1154
making it applicable to a wide range of devices	mechanism	2K_dev_1154
both new and old	mechanism	2K_dev_1154
CapCam also tracks phones ' physical positions on the host capacitive touchscreen without any instrumentation	mechanism	2K_dev_1154
enabling a wide range of targeted interactions	mechanism	2K_dev_1154
We quantify the communication performance of our pairing approach To demonstrate the unique capability and utility of our system	method	2K_dev_1154
we built a series of example applications	method	2K_dev_1154
	method	2K_dev_1154
that enables smartphones ( and similar devices ) to establish quick	purpose	2K_dev_1154
ad-hoc connections with a host touchscreen device	purpose	2K_dev_1154
	background	2K_dev_1155
	finding	2K_dev_1155
	mechanism	2K_dev_1155
	method	2K_dev_1155
	purpose	2K_dev_1155
Stochastic gradient-based Monte Carlo methods such as stochastic gradient Langevin dynamics are useful tools for posterior inference on large scale datasets in many machine learning applications	background	2K_dev_1156
These methods scale to large datasets by using noisy gradients calculated using a mini-batch or subset of the dataset These theoretical and empirical contributions combine to make a compelling case for using variance reduction in stochastic Monte Carlo methods	background	2K_dev_1156
	background	2K_dev_1156
We show that our proposed method has better theoretical guarantees on convergence rate than stochastic Langevin dynamics This is complemented by impressive empirical results obtained	finding	2K_dev_1156
In this paper	mechanism	2K_dev_1156
we present techniques by reducing the variance in the stochastic gradient	mechanism	2K_dev_1156
	mechanism	2K_dev_1156
on a variety of real world datasets	method	2K_dev_1156
and on four different machine learning tasks ( regression	method	2K_dev_1156
classification	method	2K_dev_1156
independent component analysis and mixture modeling )	method	2K_dev_1156
However	purpose	2K_dev_1156
the high variance inherent in these noisy gradients degrades performance and leads to slower mixing for reducing variance in stochastic gradient Langevin dynamics	purpose	2K_dev_1156
yielding novel stochastic Monte Carlo methods that improve performance	purpose	2K_dev_1156
The core number of a node is the highest k-core in which the node participates	background	2K_dev_1157
Core numbers are useful in many graph mining tasks	background	2K_dev_1157
especially ones that involve finding communities of nodes	background	2K_dev_1157
influential spreaders and dense subgraphs	background	2K_dev_1157
Large graphs often do not fit on the memory of a single machine	background	2K_dev_1157
demonstrate that NimbleCore gives space savings up to 60X	finding	2K_dev_1157
while accurately estimating core numbers with average relative error less than 2	finding	2K_dev_1157
3 %	finding	2K_dev_1157
	finding	2K_dev_1157
We propose NimbleCore	mechanism	2K_dev_1157
an iterative external-memory algorithm	mechanism	2K_dev_1157
using O ( n log d max ) space	mechanism	2K_dev_1157
where n is the number of nodes and d max is the maximum node-degree in the graph	mechanism	2K_dev_1157
We also show that NimbleCore requires O ( n ) space for graphs with power-law degree distributions	mechanism	2K_dev_1157
	mechanism	2K_dev_1157
Experiments on forty-eight large graphs from various domains	method	2K_dev_1157
We address the problem of estimating core numbers of nodes by reading edges of a large graph stored in external memory Existing external memory solutions do not give bounds on the required space	purpose	2K_dev_1157
In practice	purpose	2K_dev_1157
existing solutions also do not scale with the size of the graph which estimates core numbers of nodes	purpose	2K_dev_1157
	background	2K_dev_1158
it is shown that the proposed algorithms lead to consistent parameter estimates at each agent	finding	2K_dev_1158
the distributed estimators are shown to yield order-optimal convergence rates	finding	2K_dev_1158
i	finding	2K_dev_1158
e	finding	2K_dev_1158
	finding	2K_dev_1158
as far as the order of pathwise convergence is concerned	finding	2K_dev_1158
the local agent estimates are as good as the optimal centralized nonlinear least squares estimator having access to the entire network observation data at all times	finding	2K_dev_1158
Conforming to a given inter-agent communication or interaction topology	mechanism	2K_dev_1158
distributed recursive estimators of the consensus + innovations type are presented in which at every observation sampling epoch the network agents exchange a single round of messages with their communication neighbors and recursively update their local parameter estimates by simultaneously processing the received neighborhood data and the new information ( innovation ) embedded in the observation sample	mechanism	2K_dev_1158
Under rather weak conditions on the connectivity of the inter-agent communication and a global observability criterion	method	2K_dev_1158
Furthermore	method	2K_dev_1158
under standard smoothness assumptions on the sensing nonlinearities	method	2K_dev_1158
	method	2K_dev_1158
This paper studies recursive nonlinear least squares parameter estimation in inference networks with observations distributed across multiple agents and sensed sequentially over time	purpose	2K_dev_1158
	purpose	2K_dev_1158
How can we design a product or movie that will attract	background	2K_dev_1159
for example	background	2K_dev_1159
the interest of Pennsylvania adolescents or liberal newspaper critics ? What should be the genre of that movie and who should be in the cast	background	2K_dev_1159
and show that it is highly scalable and effectively provides movie designs oriented towards different groups of users	finding	2K_dev_1159
including men	finding	2K_dev_1159
women	finding	2K_dev_1159
and adolescents	finding	2K_dev_1159
We formulate the movie design as an optimization problem over the inference of user-feature scores and selection of the features that maximize the number of attracted users Our approach	mechanism	2K_dev_1159
PNP	mechanism	2K_dev_1159
is based on a heterogeneous	mechanism	2K_dev_1159
tripartite graph of users	mechanism	2K_dev_1159
movies	mechanism	2K_dev_1159
and features ( e	mechanism	2K_dev_1159
g	mechanism	2K_dev_1159
actors	mechanism	2K_dev_1159
directors	mechanism	2K_dev_1159
genres )	mechanism	2K_dev_1159
where users rate movies and features contribute to movies	mechanism	2K_dev_1159
We learn the preferences by leveraging user similarities defined through different types of relations	mechanism	2K_dev_1159
and show that our method outperforms state-of-the-art approaches	mechanism	2K_dev_1159
including matrix factorization and other heterogeneous graph-based analysis	mechanism	2K_dev_1159
	mechanism	2K_dev_1159
We evaluate PNP on publicly available real-world data	method	2K_dev_1159
In this work	purpose	2K_dev_1159
we seek to identify how we can design new movies with features tailored to a specific user population	purpose	2K_dev_1159
	purpose	2K_dev_1159
The World Wide Web ( WWW ) has become a rapidly growing platform consisting of numerous sources which provide supporting or contradictory information about claims ( e	background	2K_dev_1160
g	background	2K_dev_1160
	background	2K_dev_1160
`` Chicken meat is healthy '' )	background	2K_dev_1160
In order to decide whether a claim is true or false	background	2K_dev_1160
one needs to analyze content of different sources of information on the Web	background	2K_dev_1160
measure credibility of information sources	background	2K_dev_1160
and aggregate all these information	background	2K_dev_1160
we demonstrate ClaimEval 's capability in determining validity of a set of claims	finding	2K_dev_1160
resulting in improved accuracy compared to state-of-the-art baselines	finding	2K_dev_1160
	finding	2K_dev_1160
In this paper	mechanism	2K_dev_1160
we present ClaimEval	mechanism	2K_dev_1160
a novel and integrated approach which given a set of claims to validate	mechanism	2K_dev_1160
extracts a set of pro and con arguments from the Web information sources	mechanism	2K_dev_1160
and jointly ClaimEval uses Probabilistic Soft Logic ( PSL )	mechanism	2K_dev_1160
resulting in a flexible and principled framework which makes it easy to state and incorporate different forms of prior-knowledge	mechanism	2K_dev_1160
Through extensive experiments on real-world datasets	method	2K_dev_1160
	method	2K_dev_1160
This is a tedious process and the Web search engines address only part of the overall problem	purpose	2K_dev_1160
viz	purpose	2K_dev_1160
	purpose	2K_dev_1160
producing only a list of relevant sources	purpose	2K_dev_1160
estimates credibility of sources and correctness of claims	purpose	2K_dev_1160
	purpose	2K_dev_1160
Human-Computer Music Performance for popular music - where musical structure is important	background	2K_dev_1161
but where musicians often decide on the spur of the moment exactly what the musical form will be - presents many challenges to make computer systems that are flexible and adaptable to human musicians	background	2K_dev_1161
	finding	2K_dev_1161
We present new formalisms and representations	mechanism	2K_dev_1161
and a corresponding implementation	mechanism	2K_dev_1161
	method	2K_dev_1161
One particular challenge is that humans easily follow scores and chord charts	purpose	2K_dev_1161
adapt these to new performance plans	purpose	2K_dev_1161
and understand media locations in musical terms ( beats and measures )	purpose	2K_dev_1161
while computer music systems often use rigid and even numerical representations that are difficult to work with	purpose	2K_dev_1161
where musical material in various media is synchronized	purpose	2K_dev_1161
where musicians can quickly alter the performance order by specifying ( re- ) arrangements of the material	purpose	2K_dev_1161
and where interfaces are supported in a natural way by music notation	purpose	2K_dev_1161
	purpose	2K_dev_1161
In networks such as the smart grid	background	2K_dev_1162
communication networks	background	2K_dev_1162
and social networks	background	2K_dev_1162
local measurements/observations are scattered over a wide geographical area	background	2K_dev_1162
Centralized inference algorithm are based on gathering all the observations at a central processing unit	background	2K_dev_1162
We discover and show that the message information matrix converges exponentially fast to a unique positive definite limit matrix for arbitrary positive semidefinite initialization	finding	2K_dev_1162
	finding	2K_dev_1162
using factor graphs and a distributed inference algorithm based on Gaussian belief propagation The distributed inference involves only local computation of the information matrix and of the mean vector and message passing between neighbors We provide the necessary and sufficient convergence condition for the belief mean vector to converge to the optimal centralized estimator	mechanism	2K_dev_1162
An easily verifiable sufficient convergence condition on the topology of a factor graph is further provided	mechanism	2K_dev_1162
analytically	method	2K_dev_1162
However	purpose	2K_dev_1162
with data explosion and ever-increasing network sizes	purpose	2K_dev_1162
centralized inference suffers from large communication overhead	purpose	2K_dev_1162
heavy computation burden at the center	purpose	2K_dev_1162
and susceptibility to central node failure This paper considers inference over networks	purpose	2K_dev_1162
	background	2K_dev_1163
	finding	2K_dev_1163
	mechanism	2K_dev_1163
	method	2K_dev_1163
	purpose	2K_dev_1163
High performance dense linear algebra ( DLA ) libraries often rely on a general matrix multiply ( Gemm ) kernel that is implemented using assembly or with vector intrinsics	background	2K_dev_1164
In particular	background	2K_dev_1164
the real-valued Gemm kernels provide the overwhelming fraction of performance for the complex-valued Gemm kernels	background	2K_dev_1164
along with the entire level-3 BLAS and many of the real and complex LAPACK routines	background	2K_dev_1164
Thus	background	2K_dev_1164
achieving high performance for the Gemm kernel translates into a high performance linear algebra stack above this kernel	background	2K_dev_1164
However	background	2K_dev_1164
it is a monumental task for a domain expert to manually implement the kernel for every library-supported architecture	background	2K_dev_1164
This leads to the belief that the craft of a Gemm kernel is more dark art than science	background	2K_dev_1164
It is this premise that drives the popularity of autotuning with code generation in the domain of DLA	background	2K_dev_1164
	background	2K_dev_1164
results demonstrate that our approach yields generated kernels with performance that is competitive with kernels implemented manually or using empirical search	finding	2K_dev_1164
	finding	2K_dev_1164
This paper	mechanism	2K_dev_1164
instead	mechanism	2K_dev_1164
focuses on an analytical approach to code generation of the Gemm kernel for different architecture	mechanism	2K_dev_1164
We distill the implementation of the kernel into an even smaller kernel	mechanism	2K_dev_1164
an outer-product	mechanism	2K_dev_1164
and analytically determine how available SIMD instructions can be used to compute the outer-product efficiently We codify this approach into a system to automatically generate a high performance SIMD implementation of the Gemm kernel	mechanism	2K_dev_1164
Experimental	method	2K_dev_1164
in order to shed light on the details or voo-doo required for implementing a high performance Gemm kernel	purpose	2K_dev_1164
Many real-world graphs	background	2K_dev_1165
such as those that arise from the web	background	2K_dev_1165
biology and transportation	background	2K_dev_1165
appear random and without a structure that can be exploited for performance on modern computer architectures	background	2K_dev_1165
They focus primarily on reducing storage requirements and improving the cost of certain matrix operations for these large data sets	background	2K_dev_1165
	background	2K_dev_1165
we outperform the state of the art for graphs with up to 10 7 non-zero edges	finding	2K_dev_1165
	finding	2K_dev_1165
Therefore	mechanism	2K_dev_1165
we propose a data structure in a sparse and hierarchical fashion By maintaining the structure of the graph	mechanism	2K_dev_1165
we preserve locality in the graph and in the cache	mechanism	2K_dev_1165
For synthetic scale-free graph data	method	2K_dev_1165
However	purpose	2K_dev_1165
these graphs have a scale-free graph topology that can be leveraged for locality	purpose	2K_dev_1165
Existing sparse data formats are not designed to take advantage of this structure	purpose	2K_dev_1165
for storing real-world scale-free graphs	purpose	2K_dev_1165
We also suggest several useful extensions of this method for increasing interpretability of predictive models and prediction performance	background	2K_dev_1166
	finding	2K_dev_1166
We present a novel subset scan method This form of model checking and goodness-of-fit test provides a way to interpretably detect the presence of classifier bias and poor classifier fit	mechanism	2K_dev_1166
not just in one or two dimensions of features of a priori interest	mechanism	2K_dev_1166
but in the space of all possible feature subgroups	mechanism	2K_dev_1166
We use subset scan and parametric bootstrap methods to efficiently address the difficulty of assessing the exponentially many possible subgroups	mechanism	2K_dev_1166
	method	2K_dev_1166
to detect if a probabilistic binary classifier has statistically significant bias -- over or under predicting the risk -- for some subgroup	purpose	2K_dev_1166
and identify the characteristics of this subgroup	purpose	2K_dev_1166
Understanding how brain functions has been an intriguing topic for years With the recent progress on collecting massive data and developing advanced technology	background	2K_dev_1167
people have become interested in addressing the challenge of decoding brain wave data into meaningful mind states	background	2K_dev_1167
with many machine learning models and algorithms being revisited and developed	background	2K_dev_1167
especially the ones that handle time series data because of the nature of brain waves	background	2K_dev_1167
	background	2K_dev_1167
and reach a significant better results compared to traditional methods	finding	2K_dev_1167
	finding	2K_dev_1167
In this paper	mechanism	2K_dev_1167
we propose an extension of State Space Model to work with different sources of information together with its learning and inference algorithms	mechanism	2K_dev_1167
	mechanism	2K_dev_1167
We apply this model to decode the mind state of students during lectures based on their brain waves	method	2K_dev_1167
However	purpose	2K_dev_1167
many of these time series models	purpose	2K_dev_1167
like HMM with hidden state in discrete space or State Space Model with hidden state in continuous space	purpose	2K_dev_1167
only work with one source of data and can not handle different sources of information simultaneously	purpose	2K_dev_1167
	purpose	2K_dev_1167
	background	2K_dev_1168
	finding	2K_dev_1168
Abstract This paper presents a Grammar-aware Driver Parsing ( GDP ) algorithm	mechanism	2K_dev_1168
with deep features	mechanism	2K_dev_1168
A deep model is first trained to extract highly discriminative features of the driver	mechanism	2K_dev_1168
Then	mechanism	2K_dev_1168
a grammatical structure on the deep features is defined to be used as prior knowledge for a semi-supervised proposal candidate generation The Region with Convolutional Neural Networks ( R-CNN ) method is ultimately utilized to precisely segment parts of the driver	mechanism	2K_dev_1168
The proposed method not only aims to automatically find parts of the driver in challenging drivers in the wild databases	mechanism	2K_dev_1168
i	mechanism	2K_dev_1168
e	mechanism	2K_dev_1168
the standardized Strategic Highway Research Program ( SHRP-2 ) and the challenging Vision for Intelligent Vehicles and Application ( VIVA )	mechanism	2K_dev_1168
but is also able to investigate seat belt usage and the position of the driver 's hands ( on a phone vs on a steering wheel )	mechanism	2K_dev_1168
We conduct experiments on various applications and compare our GDP method against other state-of-the-art detection and segmentation approaches	method	2K_dev_1168
i	method	2K_dev_1168
e	method	2K_dev_1168
SDS [ 1 ]	method	2K_dev_1168
CRF-RNN [ 2 ]	method	2K_dev_1168
DJTL [ 3 ]	method	2K_dev_1168
and R-CNN [ 4 ] on SHRP-2 and VIVA databases	method	2K_dev_1168
to provide a novel driver behavior situational awareness system ( DB-SAW )	purpose	2K_dev_1168
Mobile botnets have proliferated with the popularization of mobile and portable devices	background	2K_dev_1169
being a simple and powerful method to launch Distributed Denial of Service ( DDoS ) attacks	background	2K_dev_1169
	background	2K_dev_1169
	finding	2K_dev_1169
This letter presents a stochastic adaptive model to generate DDoS attacks	mechanism	2K_dev_1169
The bots collaborations combine reinforcement and fading rules based upon the level of servers activity and map to a time-varying weighted directed graph This model can explain the natural emergence of two distinct time-scales when bots massively attack a server	mechanism	2K_dev_1169
	method	2K_dev_1169
for mobile botnets dynamics and their self-organized and self-adaptive behavior	purpose	2K_dev_1169
Recent computer systems research has proposed using redundant requests to reduce latency	background	2K_dev_1170
The idea is to replicate a request so that it joins the queue at multiple servers	background	2K_dev_1170
The request is considered complete as soon as any one copy of the request completes	background	2K_dev_1170
Redundancy is beneficial because it allows us to overcome server-side variability the fact that the server we choose might be temporarily slow due to factors such as background load	background	2K_dev_1170
network interrupts	background	2K_dev_1170
and garbage collection	background	2K_dev_1170
When there is significant server-side variability	background	2K_dev_1170
replicating requests can greatly reduce response times	background	2K_dev_1170
In the past few years	background	2K_dev_1170
queueing theorists have begun to study redundancy	background	2K_dev_1170
first via approximations	background	2K_dev_1170
and	background	2K_dev_1170
more recently	background	2K_dev_1170
via exact analysis	background	2K_dev_1170
Unfortunately	background	2K_dev_1170
for analytical tractability	background	2K_dev_1170
most existing theoretical analysis has assumed an Independent Runtimes ( IR ) model	background	2K_dev_1170
wherein the replicas of a job each experience independent runtimes ( service times ) at different servers	background	2K_dev_1170
	background	2K_dev_1170
and has provably excellent performance	finding	2K_dev_1170
This paper introduces a much more realistic model of redundancy	mechanism	2K_dev_1170
Our model allows us where we track both S and X for each job	mechanism	2K_dev_1170
Analysis within the S & X model is	mechanism	2K_dev_1170
of course	mechanism	2K_dev_1170
much more difficult	mechanism	2K_dev_1170
Nevertheless	mechanism	2K_dev_1170
we design a policy	mechanism	2K_dev_1170
Redundant-to-Idle-Queue ( RIQ ) which is both analytically tractable within the S & X model	mechanism	2K_dev_1170
	method	2K_dev_1170
The IR model is unrealistic and has led to theoretical results which can be at odds with computer systems implementation results to decouple the inherent job size ( X ) from the server-side slowdown ( S )	purpose	2K_dev_1170
	purpose	2K_dev_1170
The kernel trick becomes a burden for some machine learning tasks such as dictionary learning	background	2K_dev_1171
where a huge amount of training samples are needed	background	2K_dev_1171
making the kernel matrix gigantic and infeasible to store or process	background	2K_dev_1171
	background	2K_dev_1171
yields much better results than its image space counterparts	finding	2K_dev_1171
	finding	2K_dev_1171
We have shown	mechanism	2K_dev_1171
in the context of missing data recovery through joint dictionary learning i	mechanism	2K_dev_1171
e	mechanism	2K_dev_1171
periocular-based full face hallucination	mechanism	2K_dev_1171
that the approximated kernel expansion using Fastfood transform for joint dictionary learning Also	mechanism	2K_dev_1171
explicit kernel expansion through Fastfood allows us to de-kernelize the reconstructed image in the feature space back to the image space	mechanism	2K_dev_1171
enabling applications that require reconstructive dictionaries such as cross-domain reconstruction	mechanism	2K_dev_1171
image super-resolution	mechanism	2K_dev_1171
missing data recovery	mechanism	2K_dev_1171
etc	mechanism	2K_dev_1171
	mechanism	2K_dev_1171
	method	2K_dev_1171
In this work	purpose	2K_dev_1171
we propose to alleviate this problem and achieve Gaussian RBF kernel expansion explicitly for dictionary learning using Fastfood transform	purpose	2K_dev_1171
which is an approximation of full kernel expansion	purpose	2K_dev_1171
Policy approaches for addressing emerging consumer privacy concerns increasingly rely on providing consumers with more information and control over the usage of their personal data	background	2K_dev_1172
Our results suggest that choice mechanisms alone may not reliably serve policy maker goals of protecting consumers privacy in the face of emerging data practices by firms	background	2K_dev_1172
We find that consumers decision frames and thus	finding	2K_dev_1172
their propensity to select privacy protective alternatives can be subtly but powerfully influenced by commonplace heterogeneity in the presentation of privacy choices	finding	2K_dev_1172
	mechanism	2K_dev_1172
In three experiments	method	2K_dev_1172
we evaluate the efficacy of such mechanisms in the face of subtle but common variation in the presentation of privacy choices to consumers	purpose	2K_dev_1172
	purpose	2K_dev_1172
Counterfactual Regret Minimization ( CFR ) is a popular iterative algorithm for approximating Nash equilibria in imperfect-information multi-step two-player zero-sum games	background	2K_dev_1173
	background	2K_dev_1173
demonstrate that one can improve overall convergence in a game by first running CFR on a smaller	finding	2K_dev_1173
coarser abstraction of the game and then using the strategy in the abstract game to warm start CFR in the full game	finding	2K_dev_1173
We introduce the first general	mechanism	2K_dev_1173
principled method Our approach requires only a strategy for each player	mechanism	2K_dev_1173
and accomplishes the warm start at the cost of a single traversal of the game tree	mechanism	2K_dev_1173
The method provably warm starts CFR to as many iterations as it would have taken to reach a strategy profile of the same quality as the input strategies	mechanism	2K_dev_1173
and does not alter the convergence bounds of the algorithms	mechanism	2K_dev_1173
Unlike prior approaches to warm starting	mechanism	2K_dev_1173
ours can be applied in all cases Our method is agnostic to the origins of the input strategies	mechanism	2K_dev_1173
For example	mechanism	2K_dev_1173
they can be based on human domain knowledge	mechanism	2K_dev_1173
the observed strategy of a strong agent	mechanism	2K_dev_1173
the solution of a coarser abstraction	mechanism	2K_dev_1173
or the output of some algorithm that converges rapidly at first but slowly as it gets closer to an equilibrium	mechanism	2K_dev_1173
Experiments	method	2K_dev_1173
for warm starting CFR	purpose	2K_dev_1173
	purpose	2K_dev_1173
Long-standing policy approaches to privacy protection are centered on consumer notice and control and assume that privacy decision making is a deliberative process of comparison between costs and benefits from information disclosure	background	2K_dev_1174
An emerging body of work	background	2K_dev_1174
however	background	2K_dev_1174
documents the powerful effects of factors unrelated to objective trade-offs in privacy settings	background	2K_dev_1174
Our results confirm that understanding how differences in privacy choice emerge can help harmonize disparate perspectives on privacy decision making	background	2K_dev_1174
	background	2K_dev_1174
We find that effects of rational and behavioral factors are associated with differences in the order and valence of queries considered in privacy settings	finding	2K_dev_1174
	mechanism	2K_dev_1174
In an online experiment	method	2K_dev_1174
we borrow from query-theory literature and measure individuals ' considerations ( that is	method	2K_dev_1174
queries ) across manipulations of rational and behavioral factors	method	2K_dev_1174
In this paper	purpose	2K_dev_1174
we investigate how focusing on the process by which individuals make privacy choices can help explain the impact of rational and behavioral factors on privacy decision making	purpose	2K_dev_1174
	background	2K_dev_1175
	finding	2K_dev_1175
	mechanism	2K_dev_1175
	method	2K_dev_1175
	purpose	2K_dev_1175
Recent advances in Unmanned Aerial Vehicles ( UAVs ) have enabled a myriad of new applications many of which provide aerial vision-based sensing In intrusion detection or target tracking applications	background	2K_dev_1176
it is important to reach a given area of interest in the shortest time	background	2K_dev_1176
and create an online data streaming connection to a monitoring station for immediate delivery of content to the operator	background	2K_dev_1176
	background	2K_dev_1176
we validate our approach We show a seven-fold increase in the refresh rate of the AOI coverage	finding	2K_dev_1176
we can cooperatively use multiple UAVs creating an array of moving cameras	mechanism	2K_dev_1176
that always remain connected without breaks in communication	mechanism	2K_dev_1176
We propose an optimal solution	mechanism	2K_dev_1176
In this work	method	2K_dev_1176
with a simulation that captures physical models and the application layer of each UAV	method	2K_dev_1176
as well as the wireless network when comparing to a solution without the optimal sweeping and decentralised formation control	method	2K_dev_1176
However	purpose	2K_dev_1176
if the area of interest ( AOI ) is not contained in the field of view of a single UAV	purpose	2K_dev_1176
it is necessary to move the sensor-UAV to sweep the region in order to provide the most fresh information as possible	purpose	2K_dev_1176
In order to improve the collection time of the AOI to sweep the AOI as well as a decentralised formation control algorithm that maintains UAVs equally separated along the optimal path that covers the whole AOI	purpose	2K_dev_1176
even with external disturbances such as wind gusts	purpose	2K_dev_1176
	background	2K_dev_1177
	finding	2K_dev_1177
	mechanism	2K_dev_1177
	method	2K_dev_1177
	purpose	2K_dev_1177
	background	2K_dev_1178
	finding	2K_dev_1178
	mechanism	2K_dev_1178
	method	2K_dev_1178
	purpose	2K_dev_1178
Robust face detection is one of the most important preprocessing steps to support facial expression analysis	background	2K_dev_1179
facial landmarking	background	2K_dev_1179
face recognition	background	2K_dev_1179
pose estimation	background	2K_dev_1179
building of 3D facial models	background	2K_dev_1179
etc	background	2K_dev_1179
	background	2K_dev_1179
results show that our proposed approach consistently achieves highly competitive results with the state-of-the-art performance against other recent face detection methods	finding	2K_dev_1179
	finding	2K_dev_1179
In this paper	mechanism	2K_dev_1179
we present a novel approach named Multiple Scale Faster Region-based Convolutional Neural Network ( MS-FRCNN )	mechanism	2K_dev_1179
The proposed approach is benchmarked on two challenging face detection databases	method	2K_dev_1179
i	method	2K_dev_1179
e	method	2K_dev_1179
the Wider Face database and the Face Detection Dataset and Benchmark ( FDDB )	method	2K_dev_1179
and compared against recent other face detection methods	method	2K_dev_1179
e	method	2K_dev_1179
g	method	2K_dev_1179
Two-stage CNN	method	2K_dev_1179
Multi-scale Cascade CNN	method	2K_dev_1179
Faceness	method	2K_dev_1179
Aggregate Chanel Features	method	2K_dev_1179
HeadHunter	method	2K_dev_1179
Multi-view Face Detection	method	2K_dev_1179
Cascade CNN	method	2K_dev_1179
etc	method	2K_dev_1179
The experimental	method	2K_dev_1179
Although this topic has been intensely studied for decades	purpose	2K_dev_1179
it is still challenging due to numerous variants of face images in real-world scenarios	purpose	2K_dev_1179
to robustly detect human facial regions from images collected under various challenging conditions	purpose	2K_dev_1179
e	purpose	2K_dev_1179
g large occlusions	purpose	2K_dev_1179
extremely low resolutions	purpose	2K_dev_1179
facial expressions	purpose	2K_dev_1179
strong illumination variations	purpose	2K_dev_1179
etc	purpose	2K_dev_1179
	purpose	2K_dev_1179
	background	2K_dev_1180
	finding	2K_dev_1180
	mechanism	2K_dev_1180
	method	2K_dev_1180
	purpose	2K_dev_1180
	background	2K_dev_1181
	finding	2K_dev_1181
	mechanism	2K_dev_1181
	method	2K_dev_1181
	purpose	2K_dev_1181
	background	2K_dev_1182
	finding	2K_dev_1182
	mechanism	2K_dev_1182
	method	2K_dev_1182
	purpose	2K_dev_1182
5aural speech by converting it into visual text with less than a five second delay	background	2K_dev_1183
Keeping the delay short 6 allows end-users to follow and participate in conversations	background	2K_dev_1183
These results show the potential to 17 reliably capture speech even during sudden bursts of speed	background	2K_dev_1183
as well as for generating enhanced captions	background	2K_dev_1183
18 unlike other human-powered captioning approaches	background	2K_dev_1183
We show that both hearing and DHH participants preferred 15 and followed collaborative captions better than those generated by automatic speech recognition ( ASR ) or 16 professionals due to the more consistent flow of the resulting captions	finding	2K_dev_1183
	mechanism	2K_dev_1183
We 8 first surveyed the audio characteristics of 240 one-hour-long captioned lectures on YouTube	method	2K_dev_1183
such as speed 9 and duration of speaking bursts We then analyzed how these characteristics impact caption generation and 10 readability	method	2K_dev_1183
considering specifically our human-powered collaborative captioning approach	method	2K_dev_1183
We note that 11 most of these characteristics are also present in more general domains	method	2K_dev_1183
For our caption comparison evalu12 ation	method	2K_dev_1183
we transcribed a classroom lecture in real-time using all three captioning approaches	method	2K_dev_1183
We recruited 13 48 participants ( 24 DHH ) to watch these classroom transcripts in an eye-tracking laboratory	method	2K_dev_1183
We presented 14 these captions in a randomized	method	2K_dev_1183
balanced order	method	2K_dev_1183
	method	2K_dev_1183
This article focuses on the fundamental prob7 lem that makes real-time captioning difficult : sequential keyboard typing is much slower than speaking	purpose	2K_dev_1183
	purpose	2K_dev_1183
Kidney exchange is a type of barter market where patients exchange willing but incompatible donors	background	2K_dev_1184
These exchanges are conducted via cycleswhere each incompatible patient-donor pair in the cycle both gives and receives a kidneyand chains	background	2K_dev_1184
which are started by an altruist donor who does not need a kidney in return	background	2K_dev_1184
	background	2K_dev_1184
Algorithms from our group autonomously make the transplant plans for that exchange	finding	2K_dev_1184
our new solver scales significantly better than the prior leading approaches	finding	2K_dev_1184
	finding	2K_dev_1184
We develop a provably correct which also necessarily changes the algorithm 's complexity	mechanism	2K_dev_1184
as well as other improvements to the search algorithm A cap is desirable in practice since if even one edge in the chain fails	mechanism	2K_dev_1184
the rest of the chain fails : the cap precludes very long chains that are extremely unlikely to execute and instead causes the solution to have more parallel chains and cycles that are more likely to succeed We work with the UNOS nationwide kidney exchange	mechanism	2K_dev_1184
which uses a chain cap	mechanism	2K_dev_1184
	mechanism	2K_dev_1184
Next	method	2K_dev_1184
we compare our solver to the leading constraint-generation-based solver and to the best prior correct branch-and-price-based solver	method	2K_dev_1184
We focus on the setting where chains have a length cap	method	2K_dev_1184
On that real data and demographically-accurate generated data	method	2K_dev_1184
	method	2K_dev_1184
Finding the best combination of cycles and chains is hard The leading algorithms for this optimization problem use either branch and pricea combination of branch and bound and column generationor constraint generation	purpose	2K_dev_1184
We show a correctness error in the leading prior branch-and-price-based approach [ Glorie et al	purpose	2K_dev_1184
2014 ] fix to it	purpose	2K_dev_1184
	background	2K_dev_1185
that shows that in this model	finding	2K_dev_1185
it is not possible to locally converge to an MIS in sub-polynomial time	finding	2K_dev_1185
which allow us to circumvent the lower bound and find an MIS in polylogarithmic time	finding	2K_dev_1185
it is possible to find an MIS in \ ( \mathcal O ( \log ^3 n ) \ ) time	finding	2K_dev_1185
then we can also find an MIS in \ ( \mathcal O ( \log ^3 n ) \ ) time	finding	2K_dev_1185
we can find an MIS in \ ( \mathcal O ( \log ^2 n ) \ ) time	finding	2K_dev_1185
it is also possible to find an MIS in \ ( \mathcal O ( \log ^2 n ) \ ) time	finding	2K_dev_1185
	finding	2K_dev_1185
in an extremely harsh broadcast model that relies only on carrier sensing The model consists of an anonymous broadcast network in which nodes have no knowledge about the topology of the network or even an upper bound on its size	mechanism	2K_dev_1185
Furthermore	mechanism	2K_dev_1185
it is assumed that an adversary chooses at which time slot each node wakes up	mechanism	2K_dev_1185
At each time slot a node can either beep	mechanism	2K_dev_1185
that is	mechanism	2K_dev_1185
emit a signal	mechanism	2K_dev_1185
or be silent	mechanism	2K_dev_1185
At a particular time slot	mechanism	2K_dev_1185
beeping nodes receive no feedback	mechanism	2K_dev_1185
while silent nodes can only differentiate between none of its neighbors beeping	mechanism	2K_dev_1185
or at least one of its neighbors beeping	mechanism	2K_dev_1185
	mechanism	2K_dev_1185
We start by proving a lower bound We then study four different relaxations of the model First	method	2K_dev_1185
we show that if a polynomial upper bound on the network size is known	method	2K_dev_1185
Second	method	2K_dev_1185
if we assume sleeping nodes are awoken by neighboring beeps Third	method	2K_dev_1185
if in addition to this wakeup assumption we allow sender-side collision detection	method	2K_dev_1185
that is	method	2K_dev_1185
beeping nodes can distinguish whether at least one neighboring node is beeping concurrently or not	method	2K_dev_1185
Finally	method	2K_dev_1185
if instead we endow nodes with synchronous clocks	method	2K_dev_1185
	method	2K_dev_1185
We consider the problem of computing a maximal independent set ( MIS )	purpose	2K_dev_1185
	background	2K_dev_1186
	finding	2K_dev_1186
	mechanism	2K_dev_1186
	method	2K_dev_1186
	purpose	2K_dev_1186
	background	2K_dev_1187
and demonstrate our attack strategy	finding	2K_dev_1187
The cyber-physical system is equipped with a Kalman filter and an attack detector that uses the innovations process of the Kalman filter	mechanism	2K_dev_1187
The attacker performs an integrity attack on the actuators and sensors of the system with the aim of moving the system to a target state under the constraint that the probability of him or her being detected is equal to the false alarm probability of the attack detector	mechanism	2K_dev_1187
We formulate and solve a constrained optimization problem	mechanism	2K_dev_1187
in a numerical example	method	2K_dev_1187
This paper studies attackers with control objectives and explicit detection constraints against cyber-physical systems	purpose	2K_dev_1187
that gives the optimal sequence of attacks	purpose	2K_dev_1187
Having a shared and accurate sense of time is critical to distributed Cyber-Physical Systems ( CPS ) and the Internet of Things ( IoT )	background	2K_dev_1188
Thanks to decades of research in clock technologies and synchronization protocols	background	2K_dev_1188
it is now possible to measure and synchronize time across distributed systems with unprecedented accuracy However	background	2K_dev_1188
applications have not benefited to the same extent due to limitations of the system services that help manage time	background	2K_dev_1188
and hardware-OS and OS-application interfaces through which timing information flows to the application	background	2K_dev_1188
	background	2K_dev_1188
Results from its evaluation are also presented	finding	2K_dev_1188
We advocate the adoption of a holistic notion of Quality of Time ( QoT ) that captures metrics such as resolution	mechanism	2K_dev_1188
accuracy	mechanism	2K_dev_1188
and stability	mechanism	2K_dev_1188
Building on this notion we propose an architecture in which the local perception of time is a controllable operating system primitive with observable uncertainty	mechanism	2K_dev_1188
and where time synchronization balances applications ' timing demands with system resources such as energy and bandwidth Our architecture features an expressive application programming interface that is centered around the abstraction of a timeline a virtual temporal coordinate frame that is defined by an application to provide its components with a shared sense of time	mechanism	2K_dev_1188
with a desired accuracy and resolution	mechanism	2K_dev_1188
The timeline abstraction enables developers	mechanism	2K_dev_1188
Leveraging open source hardware and software components	method	2K_dev_1188
we have implemented an initial Linux realization of the proposed timeline-driven QoT stack on a standard embedded computing platform	method	2K_dev_1188
	method	2K_dev_1188
Due to the importance of time awareness in a broad range of emerging applications	purpose	2K_dev_1188
running on commodity platforms and operating systems	purpose	2K_dev_1188
it is imperative to rethink how time is handled across the system stack	purpose	2K_dev_1188
to easily write applications whose activities are choreographed across time and space	purpose	2K_dev_1188
indicating potentials of the grounded modeling for semantic extraction and language understanding applications	background	2K_dev_1189
	background	2K_dev_1189
show significant superiority of our approach in topic perplexity and key entity identification	finding	2K_dev_1189
	finding	2K_dev_1189
In this paper	mechanism	2K_dev_1189
we propose a structured topic representation based on an entity taxonomy from a knowledge base A probabilistic model is developed Each topic is equipped with a random walk over the entity hierarchy to extract semantically grounded and coherent themes	mechanism	2K_dev_1189
Accurate entity modeling is achieved by leveraging rich textual features from the knowledge base	mechanism	2K_dev_1189
	mechanism	2K_dev_1189
Experiments	method	2K_dev_1189
Topic models represent latent topics as probability distributions over words which can be hard to interpret due to the lack of grounded semantics	purpose	2K_dev_1189
to infer both hidden topics and entities from text corpora	purpose	2K_dev_1189
	purpose	2K_dev_1189
Formative assessments allow learners to quickly identify knowledge gaps Our results suggest Questimator may be useful for assessing learning in topics for which there is not an existing quiz	background	2K_dev_1190
	background	2K_dev_1190
we found that participants ' scores on Questimator-generated quizzes correlated well with their scores on existing online quizzes on topics ranging from philosophy to economics	finding	2K_dev_1190
Also Questimator generates questions with comparable discriminatory power as existing online quizzes	finding	2K_dev_1190
This paper introduces Questimator	mechanism	2K_dev_1190
an automated system that generates multiple-choice assessment questions for any topic contained within Wikipedia	mechanism	2K_dev_1190
Given a topic	mechanism	2K_dev_1190
Questimator traverses the Wikipedia graph to find and rank related topics	mechanism	2K_dev_1190
and uses article text to form questions	mechanism	2K_dev_1190
answers and distractor options	mechanism	2K_dev_1190
	mechanism	2K_dev_1190
In a study with 833 participants from Mechanical Turk	method	2K_dev_1190
	method	2K_dev_1190
In traditional educational settings	purpose	2K_dev_1190
expert instructors can create assessments	purpose	2K_dev_1190
but in informal learning environment	purpose	2K_dev_1190
it is difficult for novice learners to self assess because they do n't know what they do n't know	purpose	2K_dev_1190
Concurrent C0 is an imperative programming language in the C family with session-typed message-passing concurrency	background	2K_dev_1191
and show the results obtained	finding	2K_dev_1191
While the abstract measure of span always decreases ( or remains unchanged )	finding	2K_dev_1191
only a few of the examples reap a practical benefit	finding	2K_dev_1191
A key idea is to postpone message reception as much as possible by interpreting receive commands as a request for a message	mechanism	2K_dev_1191
We implemented our ideas as a translation from a blocking intermediate language to a non-blocking language	mechanism	2K_dev_1191
Finally	method	2K_dev_1191
we evaluated our techniques with several benchmark programs	method	2K_dev_1191
The previously proposed semantics implements asynchronous ( non-blocking ) output ; we extend it here with non-blocking input	purpose	2K_dev_1191
	purpose	2K_dev_1191
	background	2K_dev_1192
that outperforms traditional message passing techniques	finding	2K_dev_1192
We describe Concurrent C0 with contracts and session-typed communication over channels	mechanism	2K_dev_1192
Concurrent C0 supports an operation called forwarding which allows channels to be combined in a well-defined way The language 's type system enables elegant expression of session types and message-passing concurrent programs	mechanism	2K_dev_1192
We provide a Go-based implementation with language based optimizations	method	2K_dev_1192
a type-safe C-like language	purpose	2K_dev_1192
Matrix-parametrized models ( MPMs ) are widely used in machine learning ( ML ) applications	background	2K_dev_1193
	background	2K_dev_1193
to show that SFB guarantees convergence of algorithms ( under full broadcasting ) without requiring a centralized synchronization mechanism	finding	2K_dev_1193
corroborate SFB 's efficiency	finding	2K_dev_1193
we offer two contributions : first	mechanism	2K_dev_1193
we develop a computation model for a large family of MPMs	mechanism	2K_dev_1193
which share the following property : the parameter update computed on each data sample is a rank-1 matrix	mechanism	2K_dev_1193
i	mechanism	2K_dev_1193
e	mechanism	2K_dev_1193
the outer product of two `` sufficient factors '' ( SFs ) Second	mechanism	2K_dev_1193
we implement a decentralized	mechanism	2K_dev_1193
peer-to-peer system	mechanism	2K_dev_1193
Sufficient Factor Broadcasting ( SFB )	mechanism	2K_dev_1193
which broadcasts the SFs among worker machines	mechanism	2K_dev_1193
and reconstructs the update matrices locally at each worker	mechanism	2K_dev_1193
SFB takes advantage of small rank-1 matrix updates and efficient partial broadcasting strategies to dramatically improve communication efficiency We propose a graph optimization based partial broadcasting scheme	mechanism	2K_dev_1193
which minimizes the delay of information dissemination under the constraint that each machine only communicates with a subset rather than all of machines	mechanism	2K_dev_1193
Furthermore	method	2K_dev_1193
we provide theoretical analysis Experiments on four MPMs	method	2K_dev_1193
	method	2K_dev_1193
In large-scale ML problems	purpose	2K_dev_1193
the parameter matrix of a MPM can grow at an unexpected rate	purpose	2K_dev_1193
resulting in high communication and parameter synchronization costs	purpose	2K_dev_1193
To address this issue	purpose	2K_dev_1193
	purpose	2K_dev_1193
	background	2K_dev_1194
	finding	2K_dev_1194
Regular SGVB estimators rely on sampling of parameters once per minibatch of data	mechanism	2K_dev_1194
and have variance that is constant w	mechanism	2K_dev_1194
r	mechanism	2K_dev_1194
t	mechanism	2K_dev_1194
the minibatch size	mechanism	2K_dev_1194
The efficiency of such estimators can be drastically improved upon by translating uncertainty about global parameters into local noise that is independent across datapoints in the minibatch	mechanism	2K_dev_1194
Such reparameterizations with local noise can be trivially parallelized and have variance that is inversely proportional to the minibatch size	mechanism	2K_dev_1194
generally leading to much faster convergence	mechanism	2K_dev_1194
We find an important connection with regularization by dropout : the original Gaussian dropout objective corresponds to SGVB with local noise	mechanism	2K_dev_1194
a scale-invariant prior and proportionally fixed posterior variance	mechanism	2K_dev_1194
Our method allows ; specifically	mechanism	2K_dev_1194
we propose \emph { variational dropout }	mechanism	2K_dev_1194
a generalization of Gaussian dropout	mechanism	2K_dev_1194
but with a more flexibly parameterized posterior	mechanism	2K_dev_1194
	mechanism	2K_dev_1194
The method is demonstrated through several experiments	method	2K_dev_1194
We explore an as yet unexploited opportunity for drastically improving the efficiency of stochastic gradient variational Bayes ( SGVB ) with global model parameters inference of more flexibly parameterized posteriors often leading to better generalization	purpose	2K_dev_1194
A well-established approach -- which we refer to as implicit utilitarian voting -- assumes that voters have latent utility functions that induce the reported rankings	background	2K_dev_1195
and seeks voting rules that approximately maximize utilitarian social welfare	background	2K_dev_1195
Our methods underlie the design and implementation of an upcoming social choice website	background	2K_dev_1195
results show that regret-based rules are more compelling than distortion-based rules	finding	2K_dev_1195
leading us to focus on developing a scalable implementation for the optimal ( deterministic ) regret-based rule	finding	2K_dev_1195
We extend this approach to the design of rules that select a subset of alternatives	mechanism	2K_dev_1195
We derive analytical bounds on the performance of optimal ( deterministic as well as randomized ) rules in terms of two measures	mechanism	2K_dev_1195
distortion and regret	mechanism	2K_dev_1195
	mechanism	2K_dev_1195
Empirical	method	2K_dev_1195
How should one aggregate ordinal preferences expressed by voters into a measurably superior social choice ?	purpose	2K_dev_1195
The GFT is the mapping from the signal set into its representation by a direct sum of irreducible shift invariant subspaces : 1 ) this decomposition may not be unique ; and 2 ) there is freedom in the choice of basis for each component subspace	background	2K_dev_1196
These issues are particularly relevant when the graph shift has repeated eigenvalues as is the case in many real-world applications ; by ignoring them	background	2K_dev_1196
there is no way of knowing if different researchers are using the same definition of the GFT and whether their results are comparable or not	background	2K_dev_1196
	background	2K_dev_1196
An illustrative example	finding	2K_dev_1196
We develop a quasi -coordinate free definition of the GFT and graph spectral decomposition of graph signals that we implement through oblique spectral projectors	mechanism	2K_dev_1196
We present properties of the GFT and of the spectral projectors and discuss a generalized Parseval 's inequality	mechanism	2K_dev_1196
	mechanism	2K_dev_1196
for a large real-world urban traffic dataset is provided	method	2K_dev_1196
This paper considers the definition of the graph Fourier transform ( GFT ) and of the spectral decomposition of graph signals	purpose	2K_dev_1196
Current literature does not address the lack of unicity of the GFT	purpose	2K_dev_1196
The paper presents how to resolve the above degrees of freedom	purpose	2K_dev_1196
Optical music recognition ( OMR ) is the task of recognizing images of musical scores	background	2K_dev_1197
	background	2K_dev_1197
	finding	2K_dev_1197
In this paper	mechanism	2K_dev_1197
improved algorithms were developed	mechanism	2K_dev_1197
which facilitated bulk annotation of scanned scores for use in an interactive score display system	mechanism	2K_dev_1197
Creating an initial annotation by OMR and verifying by hand substantially reduced the manual effort required to process scanned scores to be used in a live performance setting	mechanism	2K_dev_1197
	method	2K_dev_1197
for the first steps of optical music recognition	purpose	2K_dev_1197
Computer music systems can interact with humans at different levels	background	2K_dev_1198
including scores	background	2K_dev_1198
phrases	background	2K_dev_1198
notes	background	2K_dev_1198
beats	background	2K_dev_1198
and gestures	background	2K_dev_1198
However	background	2K_dev_1198
most current systems lack basic musicianship skills	background	2K_dev_1198
and claim that a more human-like interaction is achieved	finding	2K_dev_1198
	finding	2K_dev_1198
We have built an artificial pianist that can automatically improve its ability to sense and coordinate with a human pianist	mechanism	2K_dev_1198
learning from rehearsal experience	mechanism	2K_dev_1198
We describe different machine learning algorithms to learn musicianship for duet interaction	mechanism	2K_dev_1198
	mechanism	2K_dev_1198
explore the properties of the learned models	method	2K_dev_1198
such as dominant features	method	2K_dev_1198
limits of validity	method	2K_dev_1198
and minimal training size	method	2K_dev_1198
	method	2K_dev_1198
As a consequence	purpose	2K_dev_1198
the results of human-computer interaction are often far less musical than the interaction between human musicians	purpose	2K_dev_1198
In this paper	purpose	2K_dev_1198
we explore the possibility of learning some basic music performance skills from rehearsal data	purpose	2K_dev_1198
In particular	purpose	2K_dev_1198
we consider the piano duet scenario where two musicians expressively interact with each other	purpose	2K_dev_1198
Our work extends previous automatic accompaniment systems	purpose	2K_dev_1198
	purpose	2K_dev_1198
Processes such as disease propagation and information diffusion often spread over some latent network structure which must be learned from observation	background	2K_dev_1199
we show that our method learns a structure similar to the true underlying graph	finding	2K_dev_1199
but enables faster and more accurate detection	finding	2K_dev_1199
Motivated by new theoretical results on the consistency of constrained and unconstrained subset scans	mechanism	2K_dev_1199
we propose a novel framework by comparing the most anomalous subsets detected with and without the graph constraints	mechanism	2K_dev_1199
Our framework uses the mean normalized log-likelihood ratio score to measure the quality of a graph structure	mechanism	2K_dev_1199
and efficiently searches for the highest-scoring graph structure	mechanism	2K_dev_1199
Using simulated disease outbreaks injected into real-world Emergency Department data from Allegheny County	method	2K_dev_1199
	method	2K_dev_1199
Given a set of unlabeled training examples representing occurrences of an event type of interest ( e	purpose	2K_dev_1199
g	purpose	2K_dev_1199
	purpose	2K_dev_1199
a disease outbreak )	purpose	2K_dev_1199
our goal is to learn a graph structure that can be used to accurately detect future events of that type	purpose	2K_dev_1199
for learning graph structure from unlabeled data	purpose	2K_dev_1199
	background	2K_dev_1200
Our results show that identical highly expressed geolocations can be identified with the inexact method and the method based on eigenvector projections	finding	2K_dev_1200
while reducing computation time by a factor of 26	finding	2K_dev_1200
000 and reducing energy dispersal among the spectral components corresponding to the multiple zero eigenvalue	finding	2K_dev_1200
	finding	2K_dev_1200
We propose an inexact method as defined by the signal decomposition over the Jordan subspaces of the graph adjacency matrix	mechanism	2K_dev_1200
This method projects the signal over the generalized eigenspaces of the adjacency matrix	mechanism	2K_dev_1200
which accelerates the transform computation over large	mechanism	2K_dev_1200
sparse	mechanism	2K_dev_1200
and directed adjacency matrices The trade-off between execution time and fidelity to the original graph structure is discussed	mechanism	2K_dev_1200
In addition	mechanism	2K_dev_1200
properties such as a generalized Parseval 's identity and total variation ordering of the generalized eigenspaces are discussed	mechanism	2K_dev_1200
The method is applied to 2010-2013 NYC taxi trip data to identify traffic hotspots on the Manhattan grid	method	2K_dev_1200
	method	2K_dev_1200
for the graph Fourier transform of a graph signal	purpose	2K_dev_1200
Design of filters for graph signal processing benefits from knowledge of the spectral decomposition of matrices that encode graphs	background	2K_dev_1201
such as the adjacency matrix and the Laplacian matrix	background	2K_dev_1201
used to define the shift operator	background	2K_dev_1201
For shift matrices with real eigenvalues	background	2K_dev_1201
which arise for symmetric graphs	background	2K_dev_1201
the empirical spectral distribution captures the eigenvalue locations	background	2K_dev_1201
Under realistic circumstances	background	2K_dev_1201
stochastic influences often affect the network structure and	background	2K_dev_1201
consequently	background	2K_dev_1201
the shift matrix empirical spectral distribution	background	2K_dev_1201
Nevertheless	background	2K_dev_1201
deterministic functions may often be found to approximate the asymptotic behavior of empirical spectral distributions of random matrices	background	2K_dev_1201
	background	2K_dev_1201
demonstrate the results for sample parameters	finding	2K_dev_1201
	finding	2K_dev_1201
This paper uses stochastic canonical equation methods developed by Girko	mechanism	2K_dev_1201
Included simulations	method	2K_dev_1201
to derive such deterministic equivalent distributions for the empirical spectral distributions of random graphs formed by structured	purpose	2K_dev_1201
non-uniform percolation of a D-dimensional lattice supergraph	purpose	2K_dev_1201
	purpose	2K_dev_1201
	background	2K_dev_1202
	finding	2K_dev_1202
	mechanism	2K_dev_1202
	method	2K_dev_1202
	purpose	2K_dev_1202
Robust principal component analysis PCA is one of the most important dimension-reduction techniques for handling high-dimensional data with outliers	background	2K_dev_1203
	background	2K_dev_1203
illustrate the effectiveness and superiority of the proposed method	finding	2K_dev_1203
	finding	2K_dev_1203
In this letter	mechanism	2K_dev_1203
we equivalently reformulate the objective of conventional PCA and learn the optimal projection directions by maximizing the sum of projected difference between each pair of instances based on -norm	mechanism	2K_dev_1203
The proposed method is robust to outliers and also invariant to rotation	mechanism	2K_dev_1203
More important	mechanism	2K_dev_1203
the reformulated objective not only automatically avoids the calculation of optimal mean and makes the assumption of centered data unnecessary	mechanism	2K_dev_1203
but also theoretically connects to the minimization of reconstruction error	mechanism	2K_dev_1203
To solve the proposed nonsmooth problem	mechanism	2K_dev_1203
we exploit an efficient optimization algorithm to soften the contributions from outliers by reweighting each data point iteratively	mechanism	2K_dev_1203
We theoretically analyze the convergence and computational complexity of the proposed algorithm	mechanism	2K_dev_1203
	mechanism	2K_dev_1203
Extensive experimental results on several benchmark data sets	method	2K_dev_1203
However	purpose	2K_dev_1203
most of the existing robust PCA presupposes that the mean of the data is zero and incorrectly utilizes the average of data as the optimal mean of robust PCA In fact	purpose	2K_dev_1203
this assumption holds only for the squared -norm-based traditional PCA	purpose	2K_dev_1203
	purpose	2K_dev_1203
Biological adaptation is a powerful mechanism that makes many disorders hard to combat	background	2K_dev_1204
	background	2K_dev_1204
We show that for the development of regulatory cells	finding	2K_dev_1204
sequential plans yield significantly higher utility than the best static therapy In contrast	finding	2K_dev_1204
for developing effector cells	finding	2K_dev_1204
we find that ( at least for the given simulator	finding	2K_dev_1204
objective function	finding	2K_dev_1204
action possibilities	finding	2K_dev_1204
and measurement possibilities ) single-step plans suffice for optimal treatment	finding	2K_dev_1204
We propose a general approach where we leverage Monte Carlo tree search and the biological entity is modeled by a black-box simulator that the planner calls during planning We show that the framework can be used to steer a biological entity modeled via a complex signaling pathway network that has numerous feedback loops that operate at different rates and have hard-to-understand aggregate behavior We apply the framework to steering the adaptation of a patient 's immune system	mechanism	2K_dev_1204
In particular	mechanism	2K_dev_1204
we apply it to a leading T cell simulator ( available in the biological modeling package BioNetGen	mechanism	2K_dev_1204
We run experiments with two alternate goals : developing regulatory T cells or developing effector T cells	method	2K_dev_1204
The former is important for preventing autoimmune diseases while the latter is associated with better survival rates in cancer patients We are especially interested in the effect of sequential plans	method	2K_dev_1204
an approach that has not been explored extensively in the biological literature	method	2K_dev_1204
	method	2K_dev_1204
In this paper we study steering such adaptation through sequential planning to compute a treatment plan	purpose	2K_dev_1204
As publishers gather more information about their users	background	2K_dev_1205
they can use that information to enable advertisers to create increasingly targeted campaigns	background	2K_dev_1205
This enables better usage of advertising inventory	background	2K_dev_1205
	background	2K_dev_1205
	finding	2K_dev_1205
it yields two orders of magnitude improvement in run time and significant improvement in abstraction quality These benefits hold both for guaranteed and non-guaranteed campaigns	finding	2K_dev_1205
	finding	2K_dev_1205
We develop an optimal anytime algorithm The performance stems from three improvements : 1 ) a quadratic-time ( as opposed to doubly exponential or heuristic ) algorithm for finding an optimal split of an abstract segment	mechanism	2K_dev_1205
2 ) a better scoring function for evaluating splits	mechanism	2K_dev_1205
and 3 ) splitting time lossily like any other targeting attribute ( instead of losslessly segmenting time first )	mechanism	2K_dev_1205
Compared to the segment abstraction algorithm by Walsh et al	method	2K_dev_1205
[ 2010 ] for the same problem	method	2K_dev_1205
However	purpose	2K_dev_1205
it also dramatically increases the complexity that the publisher faces when optimizing campaign admission decisions and inventory allocation to campaigns	purpose	2K_dev_1205
for abstracting fine-grained audience segments into coarser abstract segments that are not too numerous for use in such optimization	purpose	2K_dev_1205
Learning detectors that can recognize concepts	background	2K_dev_1206
such as people actions	background	2K_dev_1206
objects	background	2K_dev_1206
etc	background	2K_dev_1206
	background	2K_dev_1206
in video content is an interesting but challenging problem	background	2K_dev_1206
To the best of our knowledge	background	2K_dev_1206
WELL achieves by far the best reported performance on these two webly-labeled big video datasets	background	2K_dev_1206
The efficacy and the scalability of WELL have been extensively demonstrated Experimental results show that WELL significantly outperforms the state-of-the-art methods	finding	2K_dev_1206
we propose a novel method called WEbly-Labeled Learning ( WELL )	mechanism	2K_dev_1206
It is established on two theories called curriculum learning and self-paced learning and exhibits useful properties that can be theoretically verified	mechanism	2K_dev_1206
We provide compelling insights on the latent non-convex robust loss that is being minimized on the noisy data	mechanism	2K_dev_1206
In addition	mechanism	2K_dev_1206
we propose two novel techniques that not only enable WELL to be applied to big data but also lead to more accurate results	mechanism	2K_dev_1206
	mechanism	2K_dev_1206
on two public benchmarks	method	2K_dev_1206
including the largest multimedia dataset and the largest manually-labeled video set	method	2K_dev_1206
	method	2K_dev_1206
In this paper	purpose	2K_dev_1206
we study the problem of automatically learning detectors from the big video data on the web without any additional manual annotations	purpose	2K_dev_1206
The contextual information available on the web provides noisy labels to the video content	purpose	2K_dev_1206
To leverage the noisy web labels	purpose	2K_dev_1206
State-of-the-art applications of Stackelberg security games -- including wildlife protection -- offer a wealth of data	background	2K_dev_1207
which can be used to learn the behavior of the adversary	background	2K_dev_1207
	background	2K_dev_1207
We also validate our approach	finding	2K_dev_1207
We develop a new approach	mechanism	2K_dev_1207
by observing how the attacker responds to only three defender strategies	mechanism	2K_dev_1207
using experiments on real and synthetic data	method	2K_dev_1207
But existing approaches either make strong assumptions about the structure of the data	purpose	2K_dev_1207
or gather new data through online algorithms that are likely to play severely suboptimal strategies	purpose	2K_dev_1207
to learning the parameters of the behavioral model of a bounded rational attacker ( thereby pinpointing a near optimal strategy )	purpose	2K_dev_1207
Robust principal component analysis ( PCA ) is one of the most important dimension reduction techniques to handle high-dimensional data with outliers	background	2K_dev_1208
Some experimental results demonstrate the effectiveness and superiority of the proposed approaches on image reconstruction and recognition	finding	2K_dev_1208
In this paper	mechanism	2K_dev_1208
we equivalently reformulate the maximization of variances for robust PCA	mechanism	2K_dev_1208
such that the optimal projection directions are learned by maximizing the sum of the projected difference between each pair of instances	mechanism	2K_dev_1208
rather than the difference between each instance and the mean of the Based on this reformulation	mechanism	2K_dev_1208
we propose a novel robust PCA to automatically avoid the calculation of the optimal mean based on l1-norm distance This strategy also makes the assumption of centered data unnecessary	mechanism	2K_dev_1208
Additionally	mechanism	2K_dev_1208
we intuitively extend the proposed robust PCA to its 2D version for image recognition Efficient non-greedy algorithms are exploited to solve the proposed robust PCA and 2D robust PCA with fast convergence and low computational complexity	mechanism	2K_dev_1208
	mechanism	2K_dev_1208
on benchmark data sets	method	2K_dev_1208
However	purpose	2K_dev_1208
the existing robust PCA presupposes that the mean of the data is zero and incorrectly utilizes the Euclidean distance based optimal mean for robust PCA with l1-norm	purpose	2K_dev_1208
Some studies consider this issue and integrate the estimation of the optimal mean into the dimension reduction objective	purpose	2K_dev_1208
which leads to expensive computation	purpose	2K_dev_1208
	purpose	2K_dev_1208
	background	2K_dev_1209
	finding	2K_dev_1209
	mechanism	2K_dev_1209
	method	2K_dev_1209
	purpose	2K_dev_1209
	background	2K_dev_1210
	finding	2K_dev_1210
	mechanism	2K_dev_1210
	method	2K_dev_1210
	purpose	2K_dev_1210
End-to-end learning of CNN/RNNs is currently not possible for whole videos due to GPU memory limitations and so a common practice is to use sampled frames as inputs along with the video labels as supervision	background	2K_dev_1211
show that a simple maximum pooling on the sparsely sampled local features leads to significant performance improvement	finding	2K_dev_1211
We therefore propose to instead treat the deep networks trained on local inputs as local feature extractors	mechanism	2K_dev_1211
The local features are then aggregated to form global features which are used to assign video-level labels through a second classification stage	mechanism	2K_dev_1211
We investigate a number of design choices for this local feature approach	mechanism	2K_dev_1211
	mechanism	2K_dev_1211
Experimental results on the HMDB51 and UCF101 datasets	method	2K_dev_1211
We investigate the problem of representing an entire video using CNN features for human action recognition	purpose	2K_dev_1211
However	purpose	2K_dev_1211
the global video labels might not be suitable for all of the temporally local samples as the videos often contain content besides the action of interest	purpose	2K_dev_1211
	purpose	2K_dev_1211
Hybrid systems verification is quite important for developing correct controllers for physical systems	background	2K_dev_1212
but is also challenging	background	2K_dev_1212
Verification engineers	background	2K_dev_1212
thus	background	2K_dev_1212
need to be empowered with ways of guiding hybrid systems verification while receiving as much help from automation as possible	background	2K_dev_1212
We also share thoughts how the success of such a user interface design could be evaluated and anecdotal observations about it	background	2K_dev_1212
	background	2K_dev_1212
Unsurprisingly	finding	2K_dev_1212
the most difficult user interface challenges come from the desire to integrate automation and human guidance	finding	2K_dev_1212
This paper presents the design ideas behind the user interface for the hybrid systems theorem prover KeYmaera X	mechanism	2K_dev_1212
	method	2K_dev_1212
Due to undecidability	purpose	2K_dev_1212
verification tools need sufficient means for intervening during the verification and need to allow verification engineers to provide system design insights	purpose	2K_dev_1212
We discuss how they make it easier to prove hybrid systems as well as help learn how to conduct proofs in the first place	purpose	2K_dev_1212
	purpose	2K_dev_1212
In human-robot teams	background	2K_dev_1213
humans often start with an inaccurate model of the robot capabilities	background	2K_dev_1213
As they interact with the robot	background	2K_dev_1213
they infer the robot 's capabilities and partially adapt to the robot	background	2K_dev_1213
i	background	2K_dev_1213
e	background	2K_dev_1213
	background	2K_dev_1213
they might change their actions based on the observed outcomes and the robot 's actions	background	2K_dev_1213
without replicating the robot 's policy	background	2K_dev_1213
	background	2K_dev_1213
We prove that the optimal policy can be computed efficiently	finding	2K_dev_1213
that the proposed model significantly improves human-robot team performance	finding	2K_dev_1213
	finding	2K_dev_1213
We present a game-theoretic model where the human responds to the robot 's actions by maximizing a reward function that changes stochastically over time	mechanism	2K_dev_1213
The robot can then use this model to decide optimally between taking actions that reveal its capabilities to the human and taking the best action given the information that the human currently has	mechanism	2K_dev_1213
under certain observability assumptions We demonstrate through a human subject experiment compared to policies that assume complete adaptation of the human to the robot	method	2K_dev_1213
	method	2K_dev_1213
of human partial adaptation to the robot capturing the evolution of their expectations of the robot 's capabilities	purpose	2K_dev_1213
	purpose	2K_dev_1213
Biological systems are increasingly being studied by high throughput profiling of molecular data over time	background	2K_dev_1214
TPS can thus serve as a key design strategy for high throughput time series experiments	background	2K_dev_1214
the points selected by TPS can be used to reconstruct an accurate representation for the expression values of the non selected points	finding	2K_dev_1214
	finding	2K_dev_1214
Here we present the Time Point Selection ( TPS ) method in a principled and practical way TPS utilizes expression data from a small set of genes sampled at a high rate	mechanism	2K_dev_1214
Further	mechanism	2K_dev_1214
even though the selection is only based on gene expression	mechanism	2K_dev_1214
these points are also appropriate for representing a much larger set of protein	mechanism	2K_dev_1214
miRNA and DNA methylation changes over time	mechanism	2K_dev_1214
As we show by applying TPS to study mouse lung development	method	2K_dev_1214
Determining the set of time points to sample in studies that profile several different types of molecular data is still challenging	purpose	2K_dev_1214
that solves this combinatorial problem	purpose	2K_dev_1214
Identifying a masked suspect is one of the toughest challenges in biometrics that exist	background	2K_dev_1215
This is an important problem faced in many law-enforcement applications on almost a daily basis	background	2K_dev_1215
	background	2K_dev_1215
	finding	2K_dev_1215
Herein	mechanism	2K_dev_1215
a practical method is presented	mechanism	2K_dev_1215
This approach reconstructs the entire frontal face based on an image of an individual 's periocular region	mechanism	2K_dev_1215
By using an approach based on a modified sparsifying dictionary learning algorithm	mechanism	2K_dev_1215
faces can be effectively reconstructed more accurately than with conventional methods	mechanism	2K_dev_1215
Further	mechanism	2K_dev_1215
various methods presented herein are open set	mechanism	2K_dev_1215
and thus can reconstruct faces even if the algorithms are not specifically trained using those faces	mechanism	2K_dev_1215
	mechanism	2K_dev_1215
	method	2K_dev_1215
In such situations	purpose	2K_dev_1215
investigators often only have access to the periocular region of a suspect 's face and	purpose	2K_dev_1215
unfortunately	purpose	2K_dev_1215
conventional commercial matchers are unable to process these images in such a way that the suspect can be identified	purpose	2K_dev_1215
to hallucinate a full frontal face given only a periocular region of a face	purpose	2K_dev_1215
Complex event detection has been progressively researched in recent years for the broad interest of video indexing and retrieval	background	2K_dev_1216
To fulfill the purpose of event detection	background	2K_dev_1216
one needs to train a classifier using both positive and negative examples	background	2K_dev_1216
Current classifier training treats the negative videos as equally negative	background	2K_dev_1216
	background	2K_dev_1216
have validated the efficacy of our proposed approach	finding	2K_dev_1216
we use a statistical method on both the positive and negative examples to get the decisive attributes of a specific event	mechanism	2K_dev_1216
Based on these decisive attributes	mechanism	2K_dev_1216
we assign the fine-grained labels to negative examples to treat them differently for more effective exploitation	mechanism	2K_dev_1216
The resulting fine-grained labels may be not optimal to capture the discriminative cues from the negative videos	mechanism	2K_dev_1216
Hence	mechanism	2K_dev_1216
we propose to jointly optimize the fine-grained labels with the classifier learning	mechanism	2K_dev_1216
which brings mutual reciprocality	mechanism	2K_dev_1216
Meanwhile	mechanism	2K_dev_1216
the labels of positive examples are supposed to remain unchanged	mechanism	2K_dev_1216
We thus additionally introduce a constraint for this purpose On the other hand	mechanism	2K_dev_1216
the state-of-the-art deep convolutional neural network features are leveraged in our approach for event detection to further boost the performance	mechanism	2K_dev_1216
Extensive experiments on the challenging TRECVID MED 2014 dataset	method	2K_dev_1216
However	purpose	2K_dev_1216
we notice that many negative videos resemble the positive videos in different degrees	purpose	2K_dev_1216
Intuitively	purpose	2K_dev_1216
we may capture more informative cues from the negative videos if we assign them fine-grained labels	purpose	2K_dev_1216
thus benefiting the classifier learning	purpose	2K_dev_1216
Aiming for this	purpose	2K_dev_1216
	purpose	2K_dev_1216
Generalized canonical correlation analysis ( GCCA ) aims at extracting common structure from multiple 'views '	background	2K_dev_1217
i	background	2K_dev_1217
e	background	2K_dev_1217
	background	2K_dev_1217
high-dimensional matrices representing the same objects in different feature domains an extension of classical two-view CCA	background	2K_dev_1217
	background	2K_dev_1217
further reduce the runtime significantly ( by 30 % ) if multiple cores are available	finding	2K_dev_1217
to showcase the effectiveness of the proposed algorithms	finding	2K_dev_1217
we propose a GCCA algorithm whose memory and computational costs scale linearly in the problem dimension and the number of nonzero data elements	mechanism	2K_dev_1217
respectively Consequently	mechanism	2K_dev_1217
the proposed algorithm can easily handle very large sparse views whose sample and feature dimensions both exceed 100	mechanism	2K_dev_1217
000 while the current approaches can only handle thousands of features / samples	mechanism	2K_dev_1217
Our second contribution is a distributed algorithm for GCCA	mechanism	2K_dev_1217
which computes the canonical components of different views in parallel and thus can	mechanism	2K_dev_1217
in experiments Judiciously designed synthetic and real-data experiments using a multilingual dataset are employed	method	2K_dev_1217
Existing ( G ) CCA algorithms have serious scalability issues	purpose	2K_dev_1217
since they involve square root factorization of the correlation matrices of the views	purpose	2K_dev_1217
The memory and computational complexity associated with this step grow as a quadratic and cubic function of the problem dimension ( the number of samples / features )	purpose	2K_dev_1217
respectively	purpose	2K_dev_1217
To circumvent such difficulties	purpose	2K_dev_1217
Display appropriation provides a means by which mobile users can cyber-forage local display hardware to provide them with access to a high-quality output device	background	2K_dev_1218
	background	2K_dev_1218
	finding	2K_dev_1218
In this demonstration we show a system that presents an alternative vision in which users are able to cyber-forage for both display and compute resources in their local area enabling them The demonstration leverages a cohesive suite of existing systems	mechanism	2K_dev_1218
i	mechanism	2K_dev_1218
e	mechanism	2K_dev_1218
cloudlets	mechanism	2K_dev_1218
Internet Suspend/Resume ( ISR )	mechanism	2K_dev_1218
Yarely and Tacita	mechanism	2K_dev_1218
to deliver this vision	mechanism	2K_dev_1218
	mechanism	2K_dev_1218
	method	2K_dev_1218
However	purpose	2K_dev_1218
displays are of little use without applications to drive them and yet the nature of application support has been largely ignored in the field with the prevailing assumption being that applications will be cloud-based and Web-centric	purpose	2K_dev_1218
to execute high-performance applications that would not be possible using purely Web-centric technologies	purpose	2K_dev_1218
	purpose	2K_dev_1218
	background	2K_dev_1219
that reduces execution time from 3	finding	2K_dev_1219
000 days to less than a day	finding	2K_dev_1219
This paper presents a two-part solution space and time design considerations with Dijkstra 's algorithm	mechanism	2K_dev_1219
with HTCondor Our contribution is to present a solution	mechanism	2K_dev_1219
with detailed analysis of the necessary design decisions	method	2K_dev_1219
	method	2K_dev_1219
We seek to extract and explore statistics that characterize New York City traffic flows based on 700 million taxi trips in the 20102013 New York City taxi data	purpose	2K_dev_1219
for intensive computation : for estimating taxi trajectories and job parallelization and scheduling	purpose	2K_dev_1219
	background	2K_dev_1220
Our first contribution is two discoveries : ( i ) the number of comments grows as a power-law on the number of votes and ( ii ) the time between a submission creation and a user 's reaction obeys a log-logistic distribution	finding	2K_dev_1220
VnC outperformed state-of-the-art baselines on accuracy Additionally	finding	2K_dev_1220
we illustrate VnC usefulness for forecasting and outlier detection	finding	2K_dev_1220
	finding	2K_dev_1220
Based on these patterns	mechanism	2K_dev_1220
we propose VnC ( Vote-and-Comment )	mechanism	2K_dev_1220
a parsimonious but accurate and scalable model	mechanism	2K_dev_1220
We analyzed over 20	method	2K_dev_1220
000 submissions corresponding to more than 100 million user interactions from three social voting Web sites : Reddit	method	2K_dev_1220
Imgur and Digg In our experiments on real data	method	2K_dev_1220
In social voting Web sites	purpose	2K_dev_1220
how do the user actions up-votes	purpose	2K_dev_1220
down-votes and comments evolve over time ? Are there relationships between votes and comments ? What is normal and what is suspicious ? These are the questions we focus on	purpose	2K_dev_1220
that models the coevolution of user activities	purpose	2K_dev_1220
	purpose	2K_dev_1220
Given a heterogeneous network	background	2K_dev_1221
with nodes of different types - e	background	2K_dev_1221
g	background	2K_dev_1221
	background	2K_dev_1221
products	background	2K_dev_1221
users and sellers from an online recommendation site like Amazon - and labels for a few nodes ( 'honest '	background	2K_dev_1221
'suspicious '	background	2K_dev_1221
etc )	background	2K_dev_1221
can we find a closed formula for Belief Propagation ( BP )	background	2K_dev_1221
exact or approximate ? Can we say whether it will converge ?	background	2K_dev_1221
( 4 ) Effectiveness ZooBP identifies fraudulent users with a near-perfect precision of 92	finding	2K_dev_1221
3 % over the top 300 results	finding	2K_dev_1221
We propose ZooBP	mechanism	2K_dev_1221
a method with provable convergence guarantees ZooBP has the following advantages : ( 1 ) Generality : It works on heterogeneous graphs with multiple types of nodes and edges ; ( 2 ) Closed-form solution : ZooBP gives a closed-form solution as well as convergence guarantees ; ( 3 ) Scalability : ZooBP is linear on the graph size and is up to 600 faster than BP	mechanism	2K_dev_1221
running on graphs with 3	mechanism	2K_dev_1221
3 million edges in a few seconds	mechanism	2K_dev_1221
	mechanism	2K_dev_1221
Applied on real data ( a Flipkart e-commerce network with users	method	2K_dev_1221
products and sellers )	method	2K_dev_1221
	method	2K_dev_1221
BP	purpose	2K_dev_1221
traditionally an inference algorithm for graphical models	purpose	2K_dev_1221
exploits so-called `` network effects '' to perform graph classification tasks when labels for a subset of nodes are provided ; and it has been successful in numerous settings like fraudulent entity detection in online retailers and classification in social networks	purpose	2K_dev_1221
However	purpose	2K_dev_1221
it does not have a closed-form nor does it provide convergence guarantees in general	purpose	2K_dev_1221
to perform fast BP on undirected heterogeneous graphs	purpose	2K_dev_1221
Many theories have emerged which investigate how in- variance is generated in hierarchical networks through sim- ple schemes such as max and mean pooling	background	2K_dev_1222
The restriction to max/mean pooling in theoretical and empirical studies has diverted attention away from a more general way of generating invariance to nuisance transformations	background	2K_dev_1222
	finding	2K_dev_1222
We utilize a novel pooling layer called adaptive pooling These networks with the learnt pooling weights have performances on object categorization tasks that are comparable to max/mean pooling networks In- terestingly	mechanism	2K_dev_1222
adaptive pooling can converge to mean pooling ( when initialized with random pooling weights )	mechanism	2K_dev_1222
find more general linear pooling schemes or even decide not to pool at all	mechanism	2K_dev_1222
We illustrate the general notion of selective invari- ance through object categorization experiments on large- scale datasets such as SVHN and ILSVRC 2012	method	2K_dev_1222
	method	2K_dev_1222
We con- jecture that hierarchically building selective invariance ( i	purpose	2K_dev_1222
e	purpose	2K_dev_1222
carefully choosing the range of the transformation to be in- variant to at each layer of a hierarchical network ) is im- portant for pattern recognition to find linear pooling weights within networks	purpose	2K_dev_1222
A k-core is the maximal subgraph where all vertices have degree at least k	background	2K_dev_1223
This concept has been applied to such diverse areas as hierarchical structure analysis	background	2K_dev_1223
graph visualization	background	2K_dev_1223
and graph clustering	background	2K_dev_1223
	background	2K_dev_1223
Our discoveries are as follows : ( 1 ) Mirror Pattern : coreness of vertices ( i	finding	2K_dev_1223
e	finding	2K_dev_1223
	finding	2K_dev_1223
maximum k such that each vertex belongs to the k-core ) is strongly correlated to their degree	finding	2K_dev_1223
( 2 ) Core-Triangle Pattern : degeneracy of a graph ( i	finding	2K_dev_1223
e	finding	2K_dev_1223
	finding	2K_dev_1223
maximum k such that the k-core exists in the graph ) obeys a 3-to-1 power law with respect to the count of triangles	finding	2K_dev_1223
( 3 ) Structured Core Pattern : degeneracy-cores are not cliques but have non-trivial structures such as core-periphery and communities	finding	2K_dev_1223
Our algorithmic contributions show the usefulness of these patterns	mechanism	2K_dev_1223
( 1 ) Core-A	mechanism	2K_dev_1223
which measures the deviation from Mirror Pattern	mechanism	2K_dev_1223
successfully finds anomalies in real-world graphs complementing densest-subgraph based anomaly detection methods	mechanism	2K_dev_1223
( 2 ) Core-D	mechanism	2K_dev_1223
a single-pass streaming algorithm based on Core-Triangle Pattern	mechanism	2K_dev_1223
accurately estimates the degeneracy of billion-scale graphs up to 7 faster than a recent multipass algorithm	mechanism	2K_dev_1223
( 3 ) Core-S	mechanism	2K_dev_1223
inspired by Structured Core Pattern	mechanism	2K_dev_1223
identifies influential spreaders up to 17 faster than top competitors with comparable accuracy	mechanism	2K_dev_1223
	mechanism	2K_dev_1223
	method	2K_dev_1223
How do the k-core structures of real-world graphs look like ? What are the common patterns and the anomalies ? How can we use them for algorithm design and applications ? Here	purpose	2K_dev_1223
we explore pervasive patterns that are related to k-cores and emerging in graphs from several diverse domains	purpose	2K_dev_1223
	purpose	2K_dev_1223
	background	2K_dev_1224
	finding	2K_dev_1224
Methods and apparatuses are provided In one aspect	mechanism	2K_dev_1224
a proximity image is received having proximity image data from which it can be determined which areas of the proximity sensitive surface sensed the elongated interface object during a period of time	mechanism	2K_dev_1224
A proximity blob is identified in the proximity image and the proximity image is transformed using a plurality of different transformations to obtain a plurality of differently transformed proximity images	mechanism	2K_dev_1224
A plurality of features is determined for the identified blob in the transformed proximity images and the pitch of the elongated interface object relative to the proximity sensitive surface is determined based upon the determined features and a multi dimensional heuristic regression model of the proximity sensitive surface ; and a yaw is determined based upon the pitch	mechanism	2K_dev_1224
	mechanism	2K_dev_1224
	method	2K_dev_1224
for determining a pitch and yaw of an elongated interface object relative to a proximity sensitive surface	purpose	2K_dev_1224
	purpose	2K_dev_1224
There are many cases where collections of subgraphs may be contrasted against each other	background	2K_dev_1225
For example	background	2K_dev_1225
they may be as- signed ground truth labels ( spam/not-spam )	background	2K_dev_1225
or it may be desired to directly compare the biological networks of different species or compound networks of different chemicals	background	2K_dev_1225
	background	2K_dev_1225
show findings that agree with human intuition on datasets from Amazon co-purchases	finding	2K_dev_1225
Congressional bill sponsorships and DBLP co-authorships	finding	2K_dev_1225
We also show that our approach of characterizing subgraphs is better suited for sense-making than discriminating classification approaches	finding	2K_dev_1225
We define this characterization problem as one of partitioning the attributes into as many groups as the number of classes	mechanism	2K_dev_1225
while maximizing the total attributed quality score of all the given subgraphs We show that our attribute-to-class assignment problem is NP-hard and an optimal ( 1 -- 1/e ) -approximation algorithm exists	mechanism	2K_dev_1225
We also propose two different faster heuristics that are linear-time in the number of attributes and subgraphs Unlike previous work where only attributes were taken into account for characterization	mechanism	2K_dev_1225
here we exploit both attributes and social ties ( i	mechanism	2K_dev_1225
e	mechanism	2K_dev_1225
graph structure )	mechanism	2K_dev_1225
	mechanism	2K_dev_1225
Through extensive experiments	method	2K_dev_1225
we compare our proposed algorithms	method	2K_dev_1225
	method	2K_dev_1225
Given a set of attributed subgraphs known to be from different classes	purpose	2K_dev_1225
how can we discover their differences ? In this work we introduce the problem of characterizing the differences between attributed subgraphs that belong to different classes	purpose	2K_dev_1225
	purpose	2K_dev_1225
The ubiquity of mobile devices and cloud services has led to an unprecedented growth of online personal photo and video collections	background	2K_dev_1226
Due to the scarcity of personal media search log data	background	2K_dev_1226
research to date has mainly focused on searching images and videos on the web	background	2K_dev_1226
To the best of our knowledge	background	2K_dev_1226
this paper is the first The insightful observations will not only be instrumental in guiding future personal media search methods	background	2K_dev_1226
but also benefit related tasks such as personal photo browsing and recommendation	background	2K_dev_1226
Our findings suggest there is a significant gap between personal queries and automatically detected concepts	finding	2K_dev_1226
which is responsible for the low accuracy of many personal media search queries verify the efficacy of the proposed method in improving personal media search	finding	2K_dev_1226
where the proposed method consistently outperforms baseline methods	finding	2K_dev_1226
	finding	2K_dev_1226
we propose the deep query understanding model to learn a mapping from the personal queries to the concepts in the clicked photos	mechanism	2K_dev_1226
	mechanism	2K_dev_1226
using large-scale real-world search logs	method	2K_dev_1226
We analyze different types of search sessions mined from Flickr search logs and discover a number of interesting characteristics of personal media search in terms of information needs and click behaviors	method	2K_dev_1226
Experimental results	method	2K_dev_1226
However	purpose	2K_dev_1226
in order to manage the exploding amount of personal photos and videos	purpose	2K_dev_1226
we raise a fundamental question : what are the differences and similarities when users search their own photos versus the photos on the web ? to study personal media search To bridge the gap	purpose	2K_dev_1226
	purpose	2K_dev_1226
	background	2K_dev_1227
	finding	2K_dev_1227
	mechanism	2K_dev_1227
	method	2K_dev_1227
	purpose	2K_dev_1227
	background	2K_dev_1228
	finding	2K_dev_1228
	mechanism	2K_dev_1228
	method	2K_dev_1228
	purpose	2K_dev_1228
With the ubiquitous development of mobile technologies	background	2K_dev_1229
many cities today have installed mobile-enabled bike sharing systems - both publicly and privately owned - in an effort to nudge dwellers towards a more sustainable mode of transportation However	background	2K_dev_1229
there is little evidence - apart from anecdote stories - for the success of these systems	background	2K_dev_1229
This can have significant implications that shared bike systems can shift transportation modes	background	2K_dev_1229
which consequently can have rippling effects for the economy and environment	background	2K_dev_1229
Our findings provide evidence that even when controlling for the lost parking space ( used to build the parking stations ) the parking demand in the nearby areas was reduced by approximately 2 %	finding	2K_dev_1229
In particular	finding	2K_dev_1229
our follow-up analyses indicate that the new bike share system could lead to a monthly reduction of 0	finding	2K_dev_1229
82 metric tones CO2 emissions per square mile	finding	2K_dev_1229
or approximately 4	finding	2K_dev_1229
381 metric tones of CO2 in the metro area of Pittsburgh	finding	2K_dev_1229
and using the difference-in-differences framework	mechanism	2K_dev_1229
The latter can be thought of as a lower bound for the car trips generated towards a specific area and has implications towards potential substitution effects between driving and biking	method	2K_dev_1229
In particular	method	2K_dev_1229
we use data from Healthy Ride	method	2K_dev_1229
the newly installed shared bike system in the city of Pittsburgh	method	2K_dev_1229
combined with data we obtained from the Pittsburgh Parking Authority	method	2K_dev_1229
	method	2K_dev_1229
In this work we are focusing on analyzing the impact of a shared bike system on the parking demand we quantify the impact of the bike stations on the parking demand around them	purpose	2K_dev_1229
	purpose	2K_dev_1229
Multi-aspect data appear frequently in many web-related applications	background	2K_dev_1230
For example	background	2K_dev_1230
product reviews are quadruplets of ( user	background	2K_dev_1230
product	background	2K_dev_1230
keyword	background	2K_dev_1230
timestamp )	background	2K_dev_1230
How can we analyze such web-scale multi-aspect data ? Can we analyze them on an off-the-shelf workstation with limited amount of memory ? Tucker decomposition has been widely used for discovering patterns in relationships among entities in multi-aspect data	background	2K_dev_1230
naturally expressed as high-order tensors	background	2K_dev_1230
S-HOT showed better scalability not only with the order but also with the dimensionality and the rank than baseline methods In particular	finding	2K_dev_1230
S-HOT decomposed tensors 1000 larger than baseline methods in terms dimensionality S- HOT also successfully analyzed real-world tensors that are both large-scale and high-order on an off-the-shelf workstation with limited amount of memory	finding	2K_dev_1230
while baseline methods failed The source code of S-HOT is publicly available at http : //dm	finding	2K_dev_1230
postech	finding	2K_dev_1230
ac	finding	2K_dev_1230
kr/shot to encourage reproducibility	finding	2K_dev_1230
we propose S-HOT	mechanism	2K_dev_1230
a scalable high-order tucker decomposition method that employs the on-the-fly computation Moreover	mechanism	2K_dev_1230
S-HOT is designed for handling disk-resident tensors	mechanism	2K_dev_1230
too large to fit in memory	mechanism	2K_dev_1230
without loading them all in memory at once	mechanism	2K_dev_1230
	mechanism	2K_dev_1230
We provide theoretical analysis on the amount of memory space and the number of scans of data required by S-HOT	method	2K_dev_1230
In our experiments	method	2K_dev_1230
However	purpose	2K_dev_1230
existing algorithms for Tucker decomposition have limited scalability	purpose	2K_dev_1230
and especially	purpose	2K_dev_1230
fail to decompose high-order tensors since they explicitly materialize intermediate data	purpose	2K_dev_1230
whose size rapidly grows as the order increases ( 4 )	purpose	2K_dev_1230
We call this problem M-Bottleneck ( `` Materialization Bottleneck '' )	purpose	2K_dev_1230
To avoid M-Bottleneck to minimize the materialized intermediate data	purpose	2K_dev_1230
How can we detect fraudulent lockstep behavior in large-scale multi-aspect data ( i	background	2K_dev_1231
e	background	2K_dev_1231
	background	2K_dev_1231
tensors ) ? Can we detect it when data are too large to fit in memory or even on a disk ? Past studies have shown that dense blocks in real-world tensors ( e	background	2K_dev_1231
g	background	2K_dev_1231
	background	2K_dev_1231
social media	background	2K_dev_1231
Wikipedia	background	2K_dev_1231
TCP dumps	background	2K_dev_1231
etc	background	2K_dev_1231
) signal anomalous or fraudulent behavior such as retweet boosting	background	2K_dev_1231
bot activities	background	2K_dev_1231
and network attacks	background	2K_dev_1231
Thus	background	2K_dev_1231
various approaches	background	2K_dev_1231
including tensor decomposition and search	background	2K_dev_1231
have been used for rapid and accurate dense-block detection in tensors	background	2K_dev_1231
	background	2K_dev_1231
D-Cube is ( 1 ) Memory Efficient : requires up to 1	finding	2K_dev_1231
600 times less memory and handles 1	finding	2K_dev_1231
000 times larger data ( 2	finding	2K_dev_1231
6TB )	finding	2K_dev_1231
( 2 ) Fast : up to 5 times faster due to its near-linear scalability with all aspects of data	finding	2K_dev_1231
( 3 ) Provably Accurate : gives a guarantee on the densities of the blocks it finds	finding	2K_dev_1231
and ( 4 ) Effective : successfully spotted network attacks from TCP dumps and synchronized behavior in rating data with the highest accuracy	finding	2K_dev_1231
we propose D-Cube	mechanism	2K_dev_1231
a disk-based dense-block detection method	mechanism	2K_dev_1231
which also can be run in a distributed manner across multiple machines	mechanism	2K_dev_1231
Compared with state-of-the-art methods	method	2K_dev_1231
However	purpose	2K_dev_1231
all such methods have low accuracy	purpose	2K_dev_1231
or assume that tensors are small enough to fit in main memory	purpose	2K_dev_1231
which is not true in many real-world applications such as social media and web	purpose	2K_dev_1231
To overcome these limitations	purpose	2K_dev_1231
Supervised CNNs	background	2K_dev_1232
due to their immense learning capacity	background	2K_dev_1232
have shown superior performance on a range of computer vision problems including optical flow prediction	background	2K_dev_1232
	background	2K_dev_1232
Our guided learning approach is competitive with or superior to state-of-the-art approaches	finding	2K_dev_1232
We therefore propose a novel framework in which proxy ground truth data generated from classical approaches is used The models are further refined in an unsupervised fashion using an image reconstruction loss yet is completely unsupervised and can run in real time	mechanism	2K_dev_1232
	mechanism	2K_dev_1232
on three standard benchmark datasets	method	2K_dev_1232
We study the unsupervised learning of CNNs for optical flow estimation using proxy ground truth data	purpose	2K_dev_1232
They however require the ground truth flow which is usually not accessible except on limited synthetic data	purpose	2K_dev_1232
Without the guidance of ground truth optical flow	purpose	2K_dev_1232
unsupervised CNNs often perform worse as they are naturally ill-conditioned to guide the CNN learning	purpose	2K_dev_1232
	purpose	2K_dev_1232
This generalizes a prior decomposition result for an M/M/k/staggeredsetup	background	2K_dev_1233
	background	2K_dev_1233
We show	finding	2K_dev_1233
the response time of an M/G/k/staggered-setup approximately decomposes into the sum of the response time for an M/G/k and the setup time	finding	2K_dev_1233
where the approximation is nearly exact	finding	2K_dev_1233
	finding	2K_dev_1233
	mechanism	2K_dev_1233
that	method	2K_dev_1233
for exponentially distributed setup times	method	2K_dev_1233
We consider the M/G/k/staggered-setup	purpose	2K_dev_1233
where idle servers are turned off to save cost	purpose	2K_dev_1233
necessitating a setup time for turning a server back on ; however	purpose	2K_dev_1233
at most one server may be in setup mode at any time	purpose	2K_dev_1233
	purpose	2K_dev_1233
A group of agents makes linear measurements of the unknown parameter	background	2K_dev_1234
The agent measurements are locally unobservable	background	2K_dev_1234
and the agents exchange information over a communication network in order to compute an estimate	background	2K_dev_1234
A subset of the agents is adversarial and exchanges false information in order to prevent the remaining	background	2K_dev_1234
normally-behaving agents from correctly estimating the parameter	background	2K_dev_1234
	background	2K_dev_1234
Finally	finding	2K_dev_1234
we provide examples of the performance of the FRDE algorithm	finding	2K_dev_1234
	finding	2K_dev_1234
We present Flag Raising Distributed Estimation ( FRDE ) algorithm The FRDE algorithm is a consensus+innovations type estimator in which agents combine estimates of neighboring agents ( consensus ) with local sensing information ( innovations )	mechanism	2K_dev_1234
Under the FRDE algorithm	mechanism	2K_dev_1234
global observability for connected normally-behaving agents is a necessary and sufficient condition to either correctly estimate the parameter or correctly detect the presence of an adversary	mechanism	2K_dev_1234
If FRDE detects an adversary	mechanism	2K_dev_1234
we show how existing methods for attack identification in cyber-physical systems can be used to identify the adversarial agents	mechanism	2K_dev_1234
and analyze numerical	method	2K_dev_1234
This paper studies the resilient distributed estimation of an unknown vector parameter belonging to a compact set	purpose	2K_dev_1234
that allows the normally-behaving agents to perform parameter estimation and adversary detection	purpose	2K_dev_1234
	purpose	2K_dev_1234
Unmanned aerial vehicles ( UAVs ) recently enabled a myriad of new applications spanning domains from personal entertainment to surveillance	background	2K_dev_1235
We show that this platform is not omnidirectional in the horizontal plane and that UAV-to-UAV communication ceases around 75m the paper derives the optimal number of hops that maximize the end-to-end throughput	finding	2K_dev_1235
as well as the corresponding hop lengths	finding	2K_dev_1235
transmitting payloads up to 200m ( over 802	finding	2K_dev_1235
11g at 54MBps )	finding	2K_dev_1235
In this paper	mechanism	2K_dev_1235
we focus on using several small UAVs collaboratively We make use of 802	mechanism	2K_dev_1235
11 radios on low-cost commercial-off-the-shelf UAVs	mechanism	2K_dev_1235
set up a time-division multiple access overlay protocol to avoid mutual interference	mechanism	2K_dev_1235
and enable high channel utilization in multihop networks In particular	mechanism	2K_dev_1235
we provide a model for the quality of the UAV-to-UAV link	mechanism	2K_dev_1235
in terms of packet delivery ratio as a function of distance	mechanism	2K_dev_1235
packet size	mechanism	2K_dev_1235
and orientation	mechanism	2K_dev_1235
based on an extensive measurement campaign	mechanism	2K_dev_1235
Concerning the operation in a multihop mode to allow extending the network We validate our mathematical model with extensive experimental measurements	method	2K_dev_1235
to provide extended reach to an online video monitoring system for inspection of industrial installations	purpose	2K_dev_1235
Summary Successful application of two-photon imaging withgenetic tools in awake macaque monkeys will enable fundamental advances in our understanding of higher cognitive function at the level of molecular and neuronal circuits	background	2K_dev_1236
By providing two-photon imaging access to cortical neuronal populations at single-cell or single dendritic spine resolution in awake monkeys	background	2K_dev_1236
the techniques reported can help bridge the use of modern genetic and molecular tools and the study of higher cognitive function	background	2K_dev_1236
confirm that fluorescence activity is linearly proportional to neuronal spiking activity across a wide range of firing rates ( 10Hz to 150Hz )	finding	2K_dev_1236
	finding	2K_dev_1236
Here we report techniques Using genetically encoded indicators including GCaMP5 and GCaMP6s delivered by AAV2/1 into the visual cortex	mechanism	2K_dev_1236
we demonstrate that high-quality two-photon imaging of large neuronal populations can be achieved and maintained in awake monkeys for months	mechanism	2K_dev_1236
	mechanism	2K_dev_1236
Simultaneous intracellular recording and two-photon calcium imaging	method	2K_dev_1236
for long-term two-photon imaging in awake macaque monkeys	purpose	2K_dev_1236
Our work provides a solid step toward a systematic and quantitative wall-centric profiling of Facebook user activity	background	2K_dev_1237
Our key results can be summarized in the following points	finding	2K_dev_1237
First	finding	2K_dev_1237
we find that many wall activities	finding	2K_dev_1237
including number of posts	finding	2K_dev_1237
number of likes	finding	2K_dev_1237
number of posts of type photo	finding	2K_dev_1237
can be described by the PowerWall distribution	finding	2K_dev_1237
What is more surprising is that most of these distributions have similar slope	finding	2K_dev_1237
with a value close to 1 ! Second	finding	2K_dev_1237
we show how our patterns and metrics can help us spot surprising behaviors and anomalies	finding	2K_dev_1237
For example	finding	2K_dev_1237
we find a user posting every two days	finding	2K_dev_1237
exactly the same count of posts ; another user posting at midnight	finding	2K_dev_1237
with no other activity before or after	finding	2K_dev_1237
	finding	2K_dev_1237
In this work	mechanism	2K_dev_1237
we model Facebook user behavior : We propose PowerWall	mechanism	2K_dev_1237
a lesser known heavy-tailed distribution to fit our data	mechanism	2K_dev_1237
	mechanism	2K_dev_1237
we analyze the wall activities of users focusing on identifying common patterns and surprising phenomena	method	2K_dev_1237
We conduct an extensive study of roughly 7k users over 3 years during 4-month intervals each year	method	2K_dev_1237
How do people interact with their Facebook wall ? At a high level	purpose	2K_dev_1237
this question captures the essence of our work	purpose	2K_dev_1237
While most prior efforts focus on Twitter	purpose	2K_dev_1237
the much fewer Facebook studies focus on the friendship graph or are limited by the amount of users or the duration of the study	purpose	2K_dev_1237
	purpose	2K_dev_1237
To infer the histories of population admixture	background	2K_dev_1238
one important challenge with methods based on the admixture linkage disequilibrium ( ALD ) is to get rid of the effect of source LD ( SLD ) which is directly inherited from source populations	background	2K_dev_1238
In previous methods	background	2K_dev_1238
only the decay curve of weighted LD between pairs of sites whose genetic distance were larger than a certain starting distance was fitted by single or multiple exponential functions	background	2K_dev_1238
for the inference of recent single- or multiple-wave of admixture	background	2K_dev_1238
	background	2K_dev_1238
We showed that iMAAPs is a considerable improvement over other current methods and further facilitates the inference of the histories of complex population admixtures	finding	2K_dev_1238
We further developed a method	mechanism	2K_dev_1238
iMAAPs	mechanism	2K_dev_1238
by fitting ALD using Polynomial spectrum	mechanism	2K_dev_1238
	mechanism	2K_dev_1238
In this study	method	2K_dev_1238
we defined the SLD in the formularized weighted LD statistic under the two-way admixture model	method	2K_dev_1238
and proposed polynomial spectrum ( p-spectrum ) We also found reference populations could be used to reduce the SLD in weighted LD statistic	method	2K_dev_1238
We evaluated the performance of iMAAPs under various admixture models in simulated data and applied iMAAPs into analysis of genome-wide single nucleotide polymorphism data from the Human Genome Diversity Project ( HGDP ) and the HapMap Project	method	2K_dev_1238
However	purpose	2K_dev_1238
the effect of SLD has not been well defined and no tool has been developed to estimate the effect of SLD on weighted LD decay	purpose	2K_dev_1238
to study the weighted SLD and weighted LD	purpose	2K_dev_1238
to infer Multiple-wave Admixture	purpose	2K_dev_1238
	background	2K_dev_1239
Moreover	finding	2K_dev_1239
the family of models adapts well to capture the phenomenon of emergence and downfall of leaders in social networks	finding	2K_dev_1239
We formulate a set of time-varying stochastic networked dynamical systems The dynamics of the strength of connections abide by local laws of reinforcement and penalization due to interactions among the agents	mechanism	2K_dev_1239
The proposed stochastic dynamical systems exhibit a strong-attractor as a certain subset of the set of binary matrices	mechanism	2K_dev_1239
	mechanism	2K_dev_1239
as it will be illustrated via numerical simulations	method	2K_dev_1239
	method	2K_dev_1239
to model the evolution of tie strength among interacting agents	purpose	2K_dev_1239
Abstract Rapid advances in high-throughput sequencing and a growing realization of the importance of evolutionary theory to cancer genomics have led to a proliferation of phylogenetic studies of tumour progression These studies have yielded not only new insights but also a plethora of experimental approaches	background	2K_dev_1240
sometimes reaching conflicting or poorly supported conclusions	background	2K_dev_1240
closing with a perspective on the prospects and broader implications of this field	background	2K_dev_1240
	background	2K_dev_1240
	finding	2K_dev_1240
	mechanism	2K_dev_1240
We survey the range of methods and tools available to the researcher	method	2K_dev_1240
their key applications	method	2K_dev_1240
and the various unsolved problems	method	2K_dev_1240
Here	purpose	2K_dev_1240
we consider this body of work in light of the key computational principles underpinning phylogenetic inference	purpose	2K_dev_1240
with the goal of providing practical guidance on the design and analysis of scientifically rigorous tumour phylogeny studies	purpose	2K_dev_1240
	purpose	2K_dev_1240
Sparse iterative methods	background	2K_dev_1241
in particular first-order methods	background	2K_dev_1241
are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games	background	2K_dev_1241
The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on	background	2K_dev_1241
we show that	finding	2K_dev_1241
for the first time	finding	2K_dev_1241
the excessive gap technique can be made faster than the fastest counterfactual regret minimization algorithm	finding	2K_dev_1241
CFRP	finding	2K_dev_1241
in practice	finding	2K_dev_1241
We investigate the acceleration of first-order methods through better design of the dilated entropy function -- -a class of distance-generating functions related to the domains associated with the extensive-form games	mechanism	2K_dev_1241
By introducing a new weighting scheme for the dilated entropy function	mechanism	2K_dev_1241
we develop the first distance-generating function that only a logarithmic dependence on the branching factor of the player	mechanism	2K_dev_1241
This result improves the convergence rate of several first-order methods by a factor of ( b dd )	mechanism	2K_dev_1241
where b is the branching factor of the player	mechanism	2K_dev_1241
and d is the depth of the game tree	mechanism	2K_dev_1241
Thus far	mechanism	2K_dev_1241
counterfactual regret minimization methods have been faster in practice	mechanism	2K_dev_1241
and more popular	mechanism	2K_dev_1241
than first-order methods despite their theoretically inferior convergence rates	mechanism	2K_dev_1241
Using our new weighting scheme and practical tuning	method	2K_dev_1241
for solving extensive-form games for the strategy spaces of sequential games	purpose	2K_dev_1241
These graph-based problems are related to many real-world applications	background	2K_dev_1242
such as localizing stimulus in brain connectivity networks	background	2K_dev_1242
and mining traffic events in city street networks	background	2K_dev_1242
where the key issue is to find the supports of localized activated patterns	background	2K_dev_1242
Counterparts of these problems in classical signal/image processing	background	2K_dev_1242
such as impulse detection and foreground detection	background	2K_dev_1242
have been studied over the past few decades	background	2K_dev_1242
	background	2K_dev_1242
The analysis validates the effectiveness of the approach and suggests that graph signal processing tools may aid in urban planning and traffic forecasting	finding	2K_dev_1242
	finding	2K_dev_1242
tuning any thresholds	mechanism	2K_dev_1242
We use piecewise-constant graph signals where each piece indicates a localized pattern that exhibits homogeneous internal behavior and the number of pieces indicates the number of localized patterns For such signals	mechanism	2K_dev_1242
we show that decomposition and dictionary learning are natural extensions of localization	mechanism	2K_dev_1242
the goal of which is not only to efficiently approximate graph signals	mechanism	2K_dev_1242
but also to accurately find supports of localized patterns	mechanism	2K_dev_1242
we propose a specific graph signal model	mechanism	2K_dev_1242
an optimization problem	mechanism	2K_dev_1242
and a computationally efficient solver The proposed solvers directly find the supports of arbitrary localized activated patterns without	mechanism	2K_dev_1242
We then conduct an extensive empirical study to validate the proposed methods on both simulated and real data including the analysis of a large volume of spatio-temporal Manhattan urban data	method	2K_dev_1242
	method	2K_dev_1242
Motivated by the need to extract meaning from large amounts of complex structured data	purpose	2K_dev_1242
we consider three critical problems on graphs : localization	purpose	2K_dev_1242
decomposition	purpose	2K_dev_1242
and dictionary learning of piecewise-constant signals	purpose	2K_dev_1242
to model localized patterns For each of the three problems	purpose	2K_dev_1242
i	purpose	2K_dev_1242
e	purpose	2K_dev_1242
	purpose	2K_dev_1242
localization	purpose	2K_dev_1242
decomposition	purpose	2K_dev_1242
and dictionary learning	purpose	2K_dev_1242
	purpose	2K_dev_1242
Video semantic recognition usually suffers from the curse of dimensionality and the absence of enough high-quality labeled instances	background	2K_dev_1243
thus semisupervised feature selection gains increasing attentions for its efficiency and comprehensibility	background	2K_dev_1243
Most of the previous methods assume that videos with close distance ( neighbors ) have similar labels and characterize the intrinsic local structure through a predetermined graph of both labeled and unlabeled data	background	2K_dev_1243
illustrate the effectiveness and superiority of the proposed approach on video semantic recognition related tasks	finding	2K_dev_1243
	finding	2K_dev_1243
In this paper	mechanism	2K_dev_1243
we exploit a novel semisupervised feature selection method from a new perspective	mechanism	2K_dev_1243
The primary assumption underlying our model is that the instances with similar labels should have a larger probability of being neighbors	mechanism	2K_dev_1243
Instead of using a predetermined similarity graph	mechanism	2K_dev_1243
we incorporate the exploration of the local structure into the procedure of joint feature selection so as to learn the optimal graph simultaneously	mechanism	2K_dev_1243
Moreover	mechanism	2K_dev_1243
an adaptive loss function is exploited to measure the label fitness	mechanism	2K_dev_1243
which significantly enhances model 's robustness to videos with a small or substantial loss	mechanism	2K_dev_1243
We propose an efficient alternating optimization algorithm to solve the proposed challenging problem	mechanism	2K_dev_1243
together with analyses on its convergence and computational complexity in theory	mechanism	2K_dev_1243
	mechanism	2K_dev_1243
Finally	method	2K_dev_1243
extensive experimental results on benchmark datasets	method	2K_dev_1243
However	purpose	2K_dev_1243
besides the parameter tuning problem underlying the construction of the graph	purpose	2K_dev_1243
the affinity measurement in the original feature space usually suffers from the curse of dimensionality	purpose	2K_dev_1243
Additionally	purpose	2K_dev_1243
the predetermined graph separates itself from the procedure of feature selection	purpose	2K_dev_1243
which might lead to downgraded performance for video semantic recognition	purpose	2K_dev_1243
: Cellular Electron CryoTomography ( CECT ) enables 3D visualization of cellular organization at near-native state and in sub-molecular resolution	background	2K_dev_1244
making it a powerful tool for analyzing structures of macromolecular complexes and their spatial organizations inside single cells	background	2K_dev_1244
However	background	2K_dev_1244
high degree of structural complexity together with practical imaging limitations make the systematic de novo discovery of structures within cells challenging	background	2K_dev_1244
It would likely require averaging and classifying millions of subtomograms potentially containing hundreds of highly heterogeneous structural classes	background	2K_dev_1244
	background	2K_dev_1244
Results show that our new approach achieves significant improvements in both discrimination ability and scalability	finding	2K_dev_1244
More importantly	finding	2K_dev_1244
our new approach is able to discover new structural classes and recover structures that do not exist in training data	finding	2K_dev_1244
in this paper we propose a new approach for subdividing subtomograms into smaller but relatively homogeneous subsets	mechanism	2K_dev_1244
The structures in these subsets can then be separately recovered using existing computation intensive methods	mechanism	2K_dev_1244
Our approach is based on supervised structural feature extraction using deep learning	mechanism	2K_dev_1244
in combination with unsupervised clustering and reference-free classification	mechanism	2K_dev_1244
Our experiments compared to existing unsupervised rotation invariant feature and pose-normalization based approaches	method	2K_dev_1244
Motivation Although it is no longer difficult to acquire CECT data containing such amount of subtomograms due to advances in data acquisition automation	purpose	2K_dev_1244
existing computational approaches have very limited scalability or discrimination ability	purpose	2K_dev_1244
making them incapable of processing such amount of data	purpose	2K_dev_1244
To complement existing approaches	purpose	2K_dev_1244
The techniques developed in the paper for establishing weak convergence might be of independent interest	background	2K_dev_1245
	background	2K_dev_1245
	finding	2K_dev_1245
	method	2K_dev_1245
for observable macroscopic state variables of interacting particle systems ( e	purpose	2K_dev_1245
g	purpose	2K_dev_1245
	purpose	2K_dev_1245
voter and contact processes ) over fast time-varying sparse random networks of interactions	purpose	2K_dev_1245
	purpose	2K_dev_1245
	background	2K_dev_1246
	finding	2K_dev_1246
A method is disclosed Initially	mechanism	2K_dev_1246
a set of modulated ultrasound signals and a set of radio signals are separately broadcast from a group of transmitters	mechanism	2K_dev_1246
The ultrasound signals include at least one symbol configured for pulse compression	mechanism	2K_dev_1246
After the receipt of a demodulated ultrasound signal from a mobile device	mechanism	2K_dev_1246
wherein the demodulated ultrasound signal is derived from the modulated ultrasound signals	mechanism	2K_dev_1246
transmitter identifier and timing information are extracted from the demodulated ultrasound signal Timing information include	mechanism	2K_dev_1246
for example	mechanism	2K_dev_1246
the arrival time of the demodulated ultrasound signal in relation to the start time of its transmission	mechanism	2K_dev_1246
After the locations of the transmitters have been ascertained from the transmitter identifier information	mechanism	2K_dev_1246
the location of the mobile device can be determined based on the timing information and the locations of the transmitters	mechanism	2K_dev_1246
	method	2K_dev_1246
for locating a mobile device	purpose	2K_dev_1246
Researchers and educators have designed curricula and resources for introductory programming environments such as Scratch	background	2K_dev_1247
App Inventor	background	2K_dev_1247
and Kodu to foster computational thinking in K-12	background	2K_dev_1247
	background	2K_dev_1247
We found that the students who used physical manipulatives performed well in rule construction	finding	2K_dev_1247
whereas the students who engaged more with the rule editor of the programming environment had better mental simulation of the rules and understanding of the concepts	finding	2K_dev_1247
	mechanism	2K_dev_1247
In particular	method	2K_dev_1247
we investigated the impact of physical manipulatives on 3rd -- 5th grade students ' ability to understand	method	2K_dev_1247
recognize	method	2K_dev_1247
construct	method	2K_dev_1247
and use game programming design patterns	method	2K_dev_1247
This paper is an empirical study of the effectiveness and usefulness of tiles and flashcards developed for Microsoft Kodu Game Lab to support students in learning how to program and develop games	purpose	2K_dev_1247
	purpose	2K_dev_1247
Our result essentially states that under an appropriate dynamics of the underlying network of contacts	background	2K_dev_1248
the macroprocess ( Y N ( t ) ) becomes asymptotically ( in N ) Markov	background	2K_dev_1248
The vector macroprocess ( Y N ( t ) ) 0 ( Y N 1 ( t )	finding	2K_dev_1248
	finding	2K_dev_1248
Y N k ( t ) ) is not Markov since its evolution depends not only on its current state	finding	2K_dev_1248
but on finer real-time microscopic high-dimensional information of the system namely	finding	2K_dev_1248
the state of the N nodes X N ( t ) X N	finding	2K_dev_1248
	mechanism	2K_dev_1248
	method	2K_dev_1248
The main result presented in this paper ( whose proof can be found in [ 1 ] ) is that the fraction of agents ( Y N k ( t ) ) at state k X : 0 { 1	purpose	2K_dev_1248
	purpose	2K_dev_1248
K } associated with an interacting particle system over an appropriate dynamical communication network converges weakly to the solution of a differential equation	purpose	2K_dev_1248
	purpose	2K_dev_1248
Abstract The heterogeneity-gap between different modalities brings a significant challenge to multimedia information retrieval	background	2K_dev_1249
Some studies formalize the cross-modal retrieval tasks as a ranking problem and learn a shared multi-modal embedding space to measure the cross-modality similarity	background	2K_dev_1249
	background	2K_dev_1249
indicate that the proposed method achieves significant improvements over the state-of-the-arts in this literature	finding	2K_dev_1249
In this paper	mechanism	2K_dev_1249
we involve the self-paced learning theory with diversity into the cross-modal learning This strategy enhances the models robustness to outliers and achieves better generalization via training the model gradually from easy rankings by diverse queries to more complex ones	mechanism	2K_dev_1249
An efficient alternative algorithm is exploited to solve the proposed challenging problem with fast convergence in practice	mechanism	2K_dev_1249
Extensive experimental results on several benchmark datasets	method	2K_dev_1249
However	purpose	2K_dev_1249
previous methods often establish the shared embedding space based on linear mapping functions which might not be sophisticated enough to reveal more complicated inter-modal correspondences	purpose	2K_dev_1249
Additionally	purpose	2K_dev_1249
current studies assume that the rankings are of equal importance	purpose	2K_dev_1249
and thus all rankings are used simultaneously	purpose	2K_dev_1249
or a small number of rankings are selected randomly to train the embedding space at each iteration	purpose	2K_dev_1249
Such strategies	purpose	2K_dev_1249
however	purpose	2K_dev_1249
always suffer from outliers as well as reduced generalization capability due to their lack of insightful understanding of procedure of human cognition	purpose	2K_dev_1249
to rank and learn an optimal multi-modal embedding space based on non-linear mapping functions	purpose	2K_dev_1249
	purpose	2K_dev_1249
	background	2K_dev_1250
In addition	finding	2K_dev_1250
we prove that our algorithm is guaranteed to linearly converge to the unknown sparse and low-rank components up to the optimal statistical precision	finding	2K_dev_1250
demonstrate the superiority of our algorithm over the state-of-the-art algorithms and corroborate our theory	finding	2K_dev_1250
	finding	2K_dev_1250
	mechanism	2K_dev_1250
we propose a sparsity constrained maximum likelihood estimator based on matrix factorization	mechanism	2K_dev_1250
and an efficient alternating gradient descent algorithm with hard thresholding to solve it	mechanism	2K_dev_1250
Our algorithm is orders of magnitude faster than the convex relaxation based methods for LVGGM	mechanism	2K_dev_1250
Experiments on both synthetic and genomic data	method	2K_dev_1250
We study the estimation of the latent variable Gaussian graphical model ( LVGGM )	purpose	2K_dev_1250
where the precision matrix is the superposition of a sparse matrix and a low-rank matrix In order to speed up the estimation of the sparse plus low-rank components	purpose	2K_dev_1250
Despite progress in visual perception tasks such as image classification and detection	background	2K_dev_1251
computers still struggle to understand the interdependency of objects in the scene as a whole	background	2K_dev_1251
e	background	2K_dev_1251
g	background	2K_dev_1251
	background	2K_dev_1251
relations between objects or their attributes	background	2K_dev_1251
validate the superiority of VRL	finding	2K_dev_1251
which can achieve significantly better detection results on datasets involving thousands of relationship and attribute types	finding	2K_dev_1251
We also demonstrate that VRL is able to predict unseen types embedded in our action graph by learning correlations on shared graph nodes	finding	2K_dev_1251
we propose a deep Variation-structured Reinforcement Learning ( VRL ) framework to sequentially discover object relationships and attributes in the whole image	mechanism	2K_dev_1251
First	mechanism	2K_dev_1251
a directed semantic action graph is built using language priors to provide a rich and compact representation of semantic correlations between object categories	mechanism	2K_dev_1251
predicates	mechanism	2K_dev_1251
and attributes	mechanism	2K_dev_1251
Next	mechanism	2K_dev_1251
we use a variation-structured traversal over the action graph to construct a small	mechanism	2K_dev_1251
adaptive action set for each step based on the current state and historical actions	mechanism	2K_dev_1251
In particular	mechanism	2K_dev_1251
an ambiguity-aware object mining scheme is used to resolve semantic ambiguity among object categories that the object detector fails to distinguish	mechanism	2K_dev_1251
We then make sequential predictions using a deep RL framework	mechanism	2K_dev_1251
incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector	mechanism	2K_dev_1251
	mechanism	2K_dev_1251
Our experiments on the Visual Relationship Detection ( VRD ) dataset and the large-scale Visual Genome dataset	method	2K_dev_1251
Existing methods often ignore global context cues capturing the interactions among different object instances	purpose	2K_dev_1251
and can only recognize a handful of types by exhaustively training individual detectors for all possible relationships	purpose	2K_dev_1251
To capture such global interdependency	purpose	2K_dev_1251
	purpose	2K_dev_1251
	background	2K_dev_1252
	finding	2K_dev_1252
	mechanism	2K_dev_1252
	method	2K_dev_1252
	purpose	2K_dev_1252
	background	2K_dev_1253
14 The precision and recall of RBCs detection are 98	finding	2K_dev_1253
43 % and 94	finding	2K_dev_1253
99 % respectively	finding	2K_dev_1253
whereas those of WBCs detection are 99	finding	2K_dev_1253
12 % and 99	finding	2K_dev_1253
12 %	finding	2K_dev_1253
The F-measure of our proposed WBCs segmentation gets up to 95	finding	2K_dev_1253
8 %	finding	2K_dev_1253
This paper presents an end-to-end framework Our proposed system contains several components to solve different problems regarding RBCs and WBCs We first design a novel blood cell color representation which is able to emphasize the RBCs and WBCs in separate channels	mechanism	2K_dev_1253
Template matching technique is then employed to individually detect RBCs and WBCs in our proposed representation	mechanism	2K_dev_1253
In order to automatically segment the RBCs and nuclei from WBCs	mechanism	2K_dev_1253
we develop an adaptive level set-based segmentation method which makes use of both local and global information The detected and segmented RBCs	mechanism	2K_dev_1253
however	mechanism	2K_dev_1253
can be a single RBC	mechanism	2K_dev_1253
a connected RBC or an abnormal RBC Therefore	mechanism	2K_dev_1253
we first separate and reconstruct RBCs from the connected RBCs by our suggested modified template matching	mechanism	2K_dev_1253
Shape matching by inner distance is later used to classify the abnormal RBCs from the normal RBCs	mechanism	2K_dev_1253
Our proposed method has been tested and evaluated on different images from ALL-IDB	method	2K_dev_1253
10 WebPath	method	2K_dev_1253
24 UPMC	method	2K_dev_1253
23 Flicker datasets	method	2K_dev_1253
and the one used by Mohamed et al	method	2K_dev_1253
for automatically detecting and segmenting blood cells including normal red blood cells ( RBCs )	purpose	2K_dev_1253
connected RBCs	purpose	2K_dev_1253
abnormal RBCs ( i	purpose	2K_dev_1253
e	purpose	2K_dev_1253
tear drop	purpose	2K_dev_1253
burr cell	purpose	2K_dev_1253
helmet	purpose	2K_dev_1253
etc	purpose	2K_dev_1253
) and white blood cells ( WBCs )	purpose	2K_dev_1253
	purpose	2K_dev_1253
As smartphones and tablets have been widely adopted and mobile banking apps have come into ubiquitous use	background	2K_dev_1254
mobile devices have increasingly become new tools that customers use for banking	background	2K_dev_1254
payments	background	2K_dev_1254
budgeting	background	2K_dev_1254
and shopping	background	2K_dev_1254
This study has implications for banks managers related to the design and management of service delivery channels	background	2K_dev_1254
and for financial regulators related to the inclusiveness of financial system	background	2K_dev_1254
	background	2K_dev_1254
Our findings suggest that : ( 1 ) the use of the mobile channel increases customer demand for digital services ; ( 2 ) lower ATM density and higher branch channel density in the customers vicinity is associated with higher digital service demand ; ( 3 ) the mobile phone channel serves as a complement to the PC channel	finding	2K_dev_1254
the tablet channel substitutes for the PC channel	finding	2K_dev_1254
and the mobile phone channel and the tablet channel complement one another ; ( 4 ) customers acquire more information for financial decision-making following the use of the mobile channel	finding	2K_dev_1254
and mobile phone and tablet users are less likely to incur overdraft and credit card penalty fees	finding	2K_dev_1254
Net benefit of the mobile channel to the bank is $ 0	finding	2K_dev_1254
07 USD per month per ( average ) customer	finding	2K_dev_1254
	finding	2K_dev_1254
based on a novel large-scale dataset that contains 43 million individual transactions from 190	mechanism	2K_dev_1254
000 customers during April to June 2013 from a financial institution in the United States	mechanism	2K_dev_1254
Our analysis is validated	method	2K_dev_1254
This paper examines the impact of the mobile channel on customer service demand across banking digital channels	purpose	2K_dev_1254
and investigates how the use of the mobile channel influences customer financial decision-making	purpose	2K_dev_1254
Intelligent conversational assistants	background	2K_dev_1255
such as Apple 's Siri	background	2K_dev_1255
Microsoft 's Cortana	background	2K_dev_1255
and Amazon 's Echo	background	2K_dev_1255
have quickly become a part of our digital life	background	2K_dev_1255
Our observations could assist the deployment of crowd-powered conversation systems and crowd-powered systems in general	background	2K_dev_1255
Up to the first month of our deployment	finding	2K_dev_1255
59 users have held conversations with Chorus during 320 conversational sessions	finding	2K_dev_1255
	mechanism	2K_dev_1255
we developed a crowd-powered conversational assistant	mechanism	2K_dev_1255
Chorus	mechanism	2K_dev_1255
and deployed it to see how users and workers would interact together when mediated by the system Chorus sophisticatedly converses with end users over time by recruiting workers on demand	mechanism	2K_dev_1255
which in turn decide what might be the best response for each user sentence	mechanism	2K_dev_1255
	mechanism	2K_dev_1255
	method	2K_dev_1255
However	purpose	2K_dev_1255
these assistants have major limitations	purpose	2K_dev_1255
which prevents users from conversing with them as they would with human dialog partners This limits our ability to observe how users really want to interact with the underlying system	purpose	2K_dev_1255
To address this problem In this paper	purpose	2K_dev_1255
we present an account of Chorus ' deployment	purpose	2K_dev_1255
with a focus on four challenges : ( i ) identifying when conversations are over	purpose	2K_dev_1255
( ii ) malicious users and workers	purpose	2K_dev_1255
( iii ) on-demand recruiting	purpose	2K_dev_1255
and ( iv ) settings in which consensus is not enough	purpose	2K_dev_1255
	purpose	2K_dev_1255
Voting systems typically treat all voters equally	background	2K_dev_1256
We derive possibility and impossibility results for the existence of such weighting schemes	finding	2K_dev_1256
depending on whether the voting rule and the weighting scheme are deterministic or randomized	finding	2K_dev_1256
as well as on the social choice axioms satisfied by the voting rule	finding	2K_dev_1256
	finding	2K_dev_1256
we draw on no-regret learning	mechanism	2K_dev_1256
Specifically	mechanism	2K_dev_1256
given a voting rule	mechanism	2K_dev_1256
we wish to design a weighting scheme such that applying the voting rule	mechanism	2K_dev_1256
with voters weighted by the scheme	mechanism	2K_dev_1256
leads to choices that are almost as good as those endorsed by the best voter in hindsight	mechanism	2K_dev_1256
	method	2K_dev_1256
We argue that perhaps they should not : Voters who have supported good choices in the past should be given higher weight than voters who have supported bad ones	purpose	2K_dev_1256
To develop a formal framework for desirable weighting schemes	purpose	2K_dev_1256
Understanding traffic density from large-scale web camera ( webcam ) videos is a challenging problem because such videos have low spatial and temporal resolution	background	2K_dev_1257
high occlusion and large perspective	background	2K_dev_1257
and get insights from optimization based method to improve deep model FCN based method significantly reduces the mean absolute error from 10	finding	2K_dev_1257
99 to 5	finding	2K_dev_1257
31 on the public dataset TRANCOS compared with the state-of-the-art baseline	finding	2K_dev_1257
we explore both deep learning based and optimization based methods	mechanism	2K_dev_1257
both methods map the image into vehicle density map	mechanism	2K_dev_1257
one based on rank constrained regression and the other one based on fully convolution networks ( FCN ) The regression based method learns different weights for different blocks in the image to increase freedom degrees of weights and embed perspective information	mechanism	2K_dev_1257
The FCN based method jointly estimates vehicle density map and vehicle count with a residual learning framework to perform end-to-end dense prediction	mechanism	2K_dev_1257
allowing arbitrary image resolution	mechanism	2K_dev_1257
and adapting to different vehicle scales and perspectives	mechanism	2K_dev_1257
We analyze and compare both methods Since existing datasets do not cover all the challenges in our work	method	2K_dev_1257
we collected and labelled a large-scale traffic video dataset	method	2K_dev_1257
containing 60 million frames from 212 webcams Both methods are extensively evaluated and compared on different counting tasks and datasets	method	2K_dev_1257
	method	2K_dev_1257
To deeply understand traffic density To avoid individual vehicle detection and tracking	purpose	2K_dev_1257
	purpose	2K_dev_1257
	background	2K_dev_1258
	finding	2K_dev_1258
In this paper	mechanism	2K_dev_1258
we present reasoning techniques comprising discrete dynamics as well as continuous dynamics	mechanism	2K_dev_1258
in which the components have local responsibilities	mechanism	2K_dev_1258
Our approach supports component contracts i	mechanism	2K_dev_1258
e	mechanism	2K_dev_1258
	mechanism	2K_dev_1258
input assumptions and output guarantees of interfaces that are more general than previous component-based hybrid systems verification techniques in the following ways : We introduce change contracts	mechanism	2K_dev_1258
which characterize how current values exchanged between components along ports relate to previous values	mechanism	2K_dev_1258
We also introduce delay contracts	mechanism	2K_dev_1258
which describe the change relative to the time that has passed since the last value was exchanged Together	mechanism	2K_dev_1258
these contracts can take into account what has changed between two components in a given amount of time since the last exchange of information	mechanism	2K_dev_1258
Most crucially	mechanism	2K_dev_1258
we prove that the safety of compatible components implies safety of the composite	mechanism	2K_dev_1258
	mechanism	2K_dev_1258
The proof steps of the theorem are also implemented as a tactic in KeYmaerai ? X	method	2K_dev_1258
allowing automatic generation of a KeYmaerai ? X proof for the composite system from proofs of the concrete components	method	2K_dev_1258
for a component-based modeling and verification approach for hybrid systems	purpose	2K_dev_1258
Processes such as disease propagation and information diffusion often spread over some latent network structure that must be learned from observation	background	2K_dev_1259
	background	2K_dev_1259
the authors show that their method learns a structure similar to the true underlying graph	finding	2K_dev_1259
but enables faster and more accurate detection	finding	2K_dev_1259
They propose a novel framework by comparing the most anomalous subsets detected with and without the graph constraints	mechanism	2K_dev_1259
Their framework uses the mean normalized log-likelihood ratio score to measure the quality of a graph structure	mechanism	2K_dev_1259
and it efficiently searches for the highest-scoring graph structure	mechanism	2K_dev_1259
Using simulated disease outbreaks injected into real-world Emergency Department data from Allegheny County	method	2K_dev_1259
Given a set of unlabeled training examples representing occurrences of an event type of interest ( such as a disease outbreak )	purpose	2K_dev_1259
the authors aim to learn a graph structure that can be used to accurately detect future events of that type for learning graph structure from unlabeled data	purpose	2K_dev_1259
	background	2K_dev_1260
we show results on a synthetic world	finding	2K_dev_1260
where the agents communicate in ungrounded vocabulary	finding	2K_dev_1260
i	finding	2K_dev_1260
e	finding	2K_dev_1260
	finding	2K_dev_1260
symbols with no pre-specified meanings ( X	finding	2K_dev_1260
Y	finding	2K_dev_1260
Z ) We find that two bots invent their own communication protocol and start using certain symbols to ask/answer about certain visual attributes ( shape/color/style ) Thus	finding	2K_dev_1260
we demonstrate the emergence of grounded language and communication among 'visual ' dialog agents with no human supervision	finding	2K_dev_1260
and show that the RL 'fine-tuned ' agents significantly outperform SL agents	finding	2K_dev_1260
Interestingly	finding	2K_dev_1260
the RL Qbot learns to ask questions that Abot is good at	finding	2K_dev_1260
ultimately resulting in more informative dialog and a better team	finding	2K_dev_1260
We introduce the first goal-driven training Specifically	mechanism	2K_dev_1260
we pose a cooperative 'image guessing ' game between two agents -- Qbot and Abot -- who communicate in natural language dialog so that Qbot can select an unseen image from a lineup of images	mechanism	2K_dev_1260
We use deep reinforcement learning ( RL ) to learn the policies of these agents end-to-end -- from pixels to multi-agent multi-round dialog to game reward	mechanism	2K_dev_1260
We demonstrate two experimental results First	method	2K_dev_1260
as a 'sanity check ' demonstration of pure RL ( from scratch )	method	2K_dev_1260
Second	method	2K_dev_1260
we conduct large-scale real-image experiments on the VisDial dataset	method	2K_dev_1260
where we pretrain with supervised dialog data	method	2K_dev_1260
for visual question answering and dialog agents	purpose	2K_dev_1260
	purpose	2K_dev_1260
Chest X-ray ( CXR ) is one of the most commonly prescribed medical imaging procedures	background	2K_dev_1261
often with over 2-10x more scans than other imaging modalities such as MRI	background	2K_dev_1261
CT scan	background	2K_dev_1261
and PET scans	background	2K_dev_1261
These voluminous CXR scans place significant workloads on radiologists and medical practitioners	background	2K_dev_1261
surpassing the current state-of-the-art	background	2K_dev_1261
show that our method produces highly accurate and natural segmentation our model reaches human-level performance without relying on any existing trained model or dataset	finding	2K_dev_1261
Our method also generalizes well to CXR images from a different patient population and disease profiles	finding	2K_dev_1261
In this work	mechanism	2K_dev_1261
we propose Structure Correcting Adversarial Network ( SCAN ) SCAN incorporates a critic network to impose on the convolutional segmentation network the structural regularities emerging from human physiology	mechanism	2K_dev_1261
During training	mechanism	2K_dev_1261
the critic network learns to discriminate between the ground truth organ annotations from the masks synthesized by the segmentation network Through this adversarial process the critic network learns the higher order structures and guides the segmentation model to achieve realistic segmentation outcomes	mechanism	2K_dev_1261
Extensive experiments Using only very limited training data available	method	2K_dev_1261
	method	2K_dev_1261
Organ segmentation is a crucial step to obtain effective computer-aided detection on CXR	purpose	2K_dev_1261
to segment lung fields and the heart in CXR images	purpose	2K_dev_1261
	purpose	2K_dev_1261
	background	2K_dev_1262
	finding	2K_dev_1262
The disclosure describes a sensor system	mechanism	2K_dev_1262
and embodies both crowd sourcing and machine learning together Further	mechanism	2K_dev_1262
a sporadic crowd assessment is used to ensure continued sensor accuracy when the system is relying on machine learning analysis This sensor approach requires minimal and non-permanent sensor installation by utilizing any device with a camera as a sensor host	mechanism	2K_dev_1262
and provides human- centered and actionable sensor output	mechanism	2K_dev_1262
	mechanism	2K_dev_1262
	method	2K_dev_1262
that provides end users with intelligent sensing capabilities	purpose	2K_dev_1262
Modeling the long-term facial aging process is extremely challenging due to the presence of large and non-linear variations during the face development stages	background	2K_dev_1263
	background	2K_dev_1263
to further show the advantages of our proposed approach	finding	2K_dev_1263
	finding	2K_dev_1263
	mechanism	2K_dev_1263
this work first decomposes the aging process into multiple short-term stages	mechanism	2K_dev_1263
Then	mechanism	2K_dev_1263
a novel generative probabilistic model	mechanism	2K_dev_1263
named Temporal Non-Volume Preserving ( TNVP ) transformation	mechanism	2K_dev_1263
is presented Unlike Generative Adversarial Networks ( GANs )	mechanism	2K_dev_1263
which requires an empirical balance threshold	mechanism	2K_dev_1263
and Restricted Boltzmann Machines ( RBM )	mechanism	2K_dev_1263
an intractable model	mechanism	2K_dev_1263
our proposed TNVP approach guarantees a tractable density function	mechanism	2K_dev_1263
exact inference and evaluation for embedding the feature transformations between faces in consecutive stages	mechanism	2K_dev_1263
Our model shows its advantages not only in capturing the non-linear age related variance in each stage but also producing a smooth synthesis in age progression across faces	mechanism	2K_dev_1263
Our approach can model any face in the wild provided with only four basic landmark points	mechanism	2K_dev_1263
Moreover	mechanism	2K_dev_1263
the structure can be transformed into a deep convolutional network while keeping the advantages of probabilistic models with tractable log-likelihood density estimation	mechanism	2K_dev_1263
Our method is evaluated in both terms of synthesizing age-progressed faces and cross-age face verification and consistently shows the state-of-the-art results in various face aging databases	method	2K_dev_1263
i	method	2K_dev_1263
e	method	2K_dev_1263
FG-NET	method	2K_dev_1263
MORPH	method	2K_dev_1263
AginG Faces in the Wild ( AGFW )	method	2K_dev_1263
and Cross-Age Celebrity Dataset ( CACD ) A large-scale face verification on Megaface challenge 1 is also performed	method	2K_dev_1263
In order to efficiently address the problem to model the facial aging process at each stage	purpose	2K_dev_1263
	purpose	2K_dev_1263
Analyzing videos of human actions involves understanding the temporal relationships among video frames	background	2K_dev_1264
CNNs are the current state-of-the-art methods for action recognition in videos	background	2K_dev_1264
	background	2K_dev_1264
show that it achieves competitive accuracy with the two-stage approaches	finding	2K_dev_1264
In this paper	mechanism	2K_dev_1264
we present a novel CNN architecture that implicitly captures motion information	mechanism	2K_dev_1264
Our method is 10x faster than a two-stage approach	mechanism	2K_dev_1264
does not need to cache flow information	mechanism	2K_dev_1264
and is end-to-end trainable	mechanism	2K_dev_1264
	mechanism	2K_dev_1264
Experimental results on UCF101 and HMDB51	method	2K_dev_1264
However	purpose	2K_dev_1264
the CNN architectures currently being used have difficulty in capturing these relationships	purpose	2K_dev_1264
State-of-the-art action recognition approaches rely on traditional local optical flow estimation methods to pre-compute the motion information for CNNs	purpose	2K_dev_1264
Such a two-stage approach is computationally expensive	purpose	2K_dev_1264
storage demanding	purpose	2K_dev_1264
and not end-to-end trainable	purpose	2K_dev_1264
	purpose	2K_dev_1264
	background	2K_dev_1265
	finding	2K_dev_1265
	mechanism	2K_dev_1265
	method	2K_dev_1265
	purpose	2K_dev_1265
This transfer in learning suggests the modification of distance metrics in view- manifolds is more general and abstract	background	2K_dev_1266
likely at the levels of parts	background	2K_dev_1266
and independent of the specific objects or categories experienced during training	background	2K_dev_1266
suggesting that object persistence could be an important constraint in the development of perceptual similarity judgment in biological neural networks	background	2K_dev_1266
	background	2K_dev_1266
Interestingly	finding	2K_dev_1266
the resulting transformation of feature representation in the deep networks is found to significantly better match human perceptual similarity judgment than AlexNet	finding	2K_dev_1266
	finding	2K_dev_1266
We develop a model of perceptual similarity judgment based on re-training a deep convolution neural network ( DCNN ) that learns to associate different views of each 3D object The re-training process effectively performs distance metric learning under the object persistency constraints	mechanism	2K_dev_1266
to modify the view-manifold of object representations	mechanism	2K_dev_1266
It reduces the effective distance between the representations of different views of the same object without compromising the distance between those of the views of different objects	mechanism	2K_dev_1266
resulting in the untangling of the view-manifolds between individual objects within the same category and across categories	mechanism	2K_dev_1266
This untangling enables the model to discriminate and recognize objects within the same category	mechanism	2K_dev_1266
independent of viewpoints	mechanism	2K_dev_1266
We found that this ability is not limited to the trained objects	mechanism	2K_dev_1266
but transfers to novel objects in both trained and untrained categories	mechanism	2K_dev_1266
as well as to a variety of completely novel artificial synthetic objects	mechanism	2K_dev_1266
	mechanism	2K_dev_1266
	method	2K_dev_1266
to capture the notion of object persistence and continuity in our visual experience	purpose	2K_dev_1266
Given a collection of seasonal time-series	background	2K_dev_1267
how can we find regular ( cyclic ) patterns and outliers ( i	background	2K_dev_1267
e	background	2K_dev_1267
rare events ) ? These two types of patterns are hidden and mixed in the time-varying activities	background	2K_dev_1267
	background	2K_dev_1267
demonstrate the benefits of the proposed model and algorithm	finding	2K_dev_1267
in that the model can capture latent cyclic patterns	finding	2K_dev_1267
trends and rare events	finding	2K_dev_1267
and the algorithm outperforms the existing state-of-the-art approaches	finding	2K_dev_1267
CycloneFact was up to 5 times more accurate and 20 times faster than top competitors	finding	2K_dev_1267
	finding	2K_dev_1267
We present CycloneM	mechanism	2K_dev_1267
a unifying model and CycloneFact	mechanism	2K_dev_1267
a novel algorithm We also present an automatic mining framework AutoCyclone	mechanism	2K_dev_1267
based on CycloneM and CycloneFact Our method has the following properties ; ( a ) effective : it captures important cyclic features such as trend and seasonality	mechanism	2K_dev_1267
and distinguishes regular patterns and rare events clearly ; ( b ) robust and accurate : it detects the above features and patterns accurately against outliers ; ( c ) fast : CycloneFact takes linear time in the data size and typically converges in a few iterations ; ( d ) parameter free : our modeling framework frees the user from having to provide parameter values	mechanism	2K_dev_1267
	mechanism	2K_dev_1267
Extensive experiments on 4 real datasets	method	2K_dev_1267
How can we robustly separate regular patterns and outliers	purpose	2K_dev_1267
without requiring any prior information ? to capture both cyclic patterns and outliers	purpose	2K_dev_1267
which solves the above problem	purpose	2K_dev_1267
	purpose	2K_dev_1267
The recently developed variational autoencoders ( VAEs ) have proved to be an effective confluence of the rich representational power of neural networks with Bayesian methods	background	2K_dev_1268
Our method is able to discover highly interpretable activity hierarchies	finding	2K_dev_1268
and obtain improved clustering accuracy and generalization capacity based on the learned rich representations	finding	2K_dev_1268
	finding	2K_dev_1268
In this work	mechanism	2K_dev_1268
we propose hierarchical nonparametric variational autoencoders	mechanism	2K_dev_1268
which combines tree-structured Bayesian nonparametric priors with VAEs	mechanism	2K_dev_1268
Both the neural parameters and Bayesian priors are learned jointly using tailored variational inference	mechanism	2K_dev_1268
The resulting model induces a hierarchical structure of latent semantic concepts underlying the data corpus	mechanism	2K_dev_1268
and infers accurate representations of data instances	mechanism	2K_dev_1268
	mechanism	2K_dev_1268
We apply our model in video representation learning	method	2K_dev_1268
	method	2K_dev_1268
However	purpose	2K_dev_1268
most work on VAEs use a rather simple prior over the latent variables such as standard normal distribution	purpose	2K_dev_1268
thereby restricting its applications to relatively simple phenomena	purpose	2K_dev_1268
to enable infinite flexibility of the latent representation space	purpose	2K_dev_1268
	purpose	2K_dev_1268
	background	2K_dev_1269
	finding	2K_dev_1269
	mechanism	2K_dev_1269
	method	2K_dev_1269
	purpose	2K_dev_1269
Many problems in image processing and computer vision ( e	background	2K_dev_1270
g	background	2K_dev_1270
colorization	background	2K_dev_1270
style transfer ) can be posed as 'manipulating ' an input image into a corresponding output image given a user-specified guiding signal	background	2K_dev_1270
A holy-grail solution towards generic image manipulation should be able to efficiently alter an input image with any personalized signals ( even signals unseen during training )	background	2K_dev_1270
such as diverse paintings and arbitrary descriptive attributes	background	2K_dev_1270
show that our ZM-Net can perform high-quality image manipulation conditioned on different forms of guiding signals ( e	finding	2K_dev_1270
g	finding	2K_dev_1270
style images and attributes ) in real-time ( tens of milliseconds per image ) even for unseen signals	finding	2K_dev_1270
	finding	2K_dev_1270
We cast this problem as manipulating an input image according to a parametric model whose key parameters can be conditionally generated from any guiding signal ( even unseen ones ) To this end	mechanism	2K_dev_1270
we propose the Zero-shot Manipulation Net ( ZM-Net )	mechanism	2K_dev_1270
a fully-differentiable architecture that jointly optimizes an image-transformation network ( TNet ) and a parameter network ( PNet ) The PNet learns to generate key transformation parameters for the TNet given any guiding signal while the TNet performs fast zero-shot image manipulation according to both signal-dependent parameters from the PNet and signal-invariant parameters from the TNet itself Moreover	mechanism	2K_dev_1270
a large-scale style dataset with over 20	mechanism	2K_dev_1270
000 style images is also constructed	mechanism	2K_dev_1270
Extensive experiments	method	2K_dev_1270
However	purpose	2K_dev_1270
existing methods are either inefficient to simultaneously process multiple signals ( let alone generalize to unseen signals )	purpose	2K_dev_1270
or unable to handle signals from other modalities In this paper	purpose	2K_dev_1270
we make the first attempt to address the zero-shot image manipulation task to promote further research	purpose	2K_dev_1270
Reading	background	2K_dev_1271
tracing	background	2K_dev_1271
and explaining the behavior of code are strongly correlated with the ability to write code effectively	background	2K_dev_1271
Kodu reasoning problems appear to be a promising tool for assessing computational thinking in young programmers	background	2K_dev_1271
	background	2K_dev_1271
Explicitly teaching semantics proved helpful with one type of misconception but not with others We found different styles of student reasoning ( analytical and analogical ) that may correspond to distinct neo-Piagetian stages of development as described by Teague and Lister ( 2014 )	finding	2K_dev_1271
	finding	2K_dev_1271
	mechanism	2K_dev_1271
we introduced two groups of third graders to Microsoft 's Kodu Game Lab ; the second group was also given four semantic `` Laws of Kodu '' to better scaffold their reasoning and discourage some common misconceptions During each session	method	2K_dev_1271
students were asked to predict the behavior of short Kodu programs	method	2K_dev_1271
To investigate program understanding in young children	purpose	2K_dev_1271
	purpose	2K_dev_1271
	background	2K_dev_1272
We find that the collection and use of consumer data for targeting purposes affect consumer welfare through three distinct	finding	2K_dev_1272
and possibly countervailing	finding	2K_dev_1272
effects : match improvement	finding	2K_dev_1272
offer discrimination	finding	2K_dev_1272
and supply expansion	finding	2K_dev_1272
Furthermore	finding	2K_dev_1272
we find that the economic interests of the three agents can be misaligned	finding	2K_dev_1272
depending on the degree of heterogeneity in consumer preferences	finding	2K_dev_1272
Finally	finding	2K_dev_1272
we find that a strategic intermediary may choose to share with advertising firms only a subset of consumer data	finding	2K_dev_1272
maximizing its profits at their cost	finding	2K_dev_1272
	finding	2K_dev_1272
overlooking the other agents interests	finding	2K_dev_1272
regulation of data collection and sharing may increase consumers welfare	finding	2K_dev_1272
	finding	2K_dev_1272
	mechanism	2K_dev_1272
In situations where the intermediary has an incentive to reveal the information that maximizes its payoff	method	2K_dev_1272
We analyze how alternative consumer data handling regimes affect the welfare of consumers	purpose	2K_dev_1272
advertising firms	purpose	2K_dev_1272
and an intermediary Ad exchange in the context of targeted advertising	purpose	2K_dev_1272
	purpose	2K_dev_1272
When tasked to find fraudulent social network users	background	2K_dev_1273
what is a practitioner to do ?	background	2K_dev_1273
We report the signs of such behaviors	finding	2K_dev_1273
including oddities in local network connectivity	finding	2K_dev_1273
account attributes	finding	2K_dev_1273
and similarities and differences across fraud providers We discover several types of fraud behaviors	finding	2K_dev_1273
with the possibility of even more	finding	2K_dev_1273
which give exceptionally strong ( > 0	finding	2K_dev_1273
95 precision/recall ) discriminative power on ground-truth data	finding	2K_dev_1273
and which reduces misclassification rate by > 18 % over baselines and routes practitioner attention to samples at high-risk of misclassification	finding	2K_dev_1273
and building algorithms First	mechanism	2K_dev_1273
we set up honeypots	mechanism	2K_dev_1273
or `` dummy '' social network accounts on which we solicit fake followers ( after careful IRB approval )	mechanism	2K_dev_1273
We discuss how to leverage these insights in practice	mechanism	2K_dev_1273
build strongly performing entropy-based features	mechanism	2K_dev_1273
and propose OEC ( Open-ended Classification )	mechanism	2K_dev_1273
an approach for `` future-proofing '' existing algorithms to account for the complexities of link fraud	mechanism	2K_dev_1273
Our contributions are	mechanism	2K_dev_1273
( b ) features : we engineer features ( c ) algorithm : we motivate and discuss OEC	mechanism	2K_dev_1273
	mechanism	2K_dev_1273
by analyzing fraudulent behavioral patterns	method	2K_dev_1273
featurizing users to yield strong discriminative performance	method	2K_dev_1273
( a ) observations : we analyze our honeypot fraudster ecosystem and give insights regarding various fraud behaviors	method	2K_dev_1273
Traditional classification can lead to poor generalization and high misclassification given few and possibly biased labels We tackle this problem to handle new and multimodal fraud types	purpose	2K_dev_1273
Recent advances in Unmanned Aerial Vehicles ( UAVs ) have enabled countless new applications in the domain of aerial sensing	background	2K_dev_1274
In scenarios such as intrusion detection	background	2K_dev_1274
target tracking and facility monitoring it is important to reach a given area of interest ( AOI )	background	2K_dev_1274
and create an online data streaming connection to a monitoring ground station ( GS ) for immediate delivery of content to the operator	background	2K_dev_1274
In previous work	background	2K_dev_1274
we showed that a multi-hop line network can increase the range of the mission by finding the optimal number of relay UAVs	background	2K_dev_1274
and their optimal placement	background	2K_dev_1274
	background	2K_dev_1274
	finding	2K_dev_1274
We will also discuss how changing slot width online can overcome typical and less known TDMA in-efficiencies	mechanism	2K_dev_1274
and therefore reach maximum end-to-end throughput and low delay	mechanism	2K_dev_1274
	method	2K_dev_1274
In this demo	purpose	2K_dev_1274
we show that CSMA ( typical 802	purpose	2K_dev_1274
11 's medium access protocol ) behaves poorly in this type of networks due to mutual interference	purpose	2K_dev_1274
and that TDMA is a better alternative	purpose	2K_dev_1274
	purpose	2K_dev_1274
Most cameras are equipped with an auto-contrast feature that enables them to take high quality pictures in a wide range of lighting conditions	background	2K_dev_1275
Auto-contrast works by increasing the sensitivity of the camera to light in dimly lit surroundings	background	2K_dev_1275
but reducing it in bright conditions to ensure that images do not become saturated	background	2K_dev_1275
Our visual system is equipped with a similar feature	background	2K_dev_1275
Neurons in the visual system increase or decrease their sensitivity to light as appropriate to enable us to see in both dimly lit rooms and dazzling sunshine	background	2K_dev_1275
This process	background	2K_dev_1275
which is known as dynamic range adaptation	background	2K_dev_1275
also occurs in neurons that are sensitive to sound or touch	background	2K_dev_1275
This makes sense because in a 3D task	background	2K_dev_1275
which also features depth	background	2K_dev_1275
the neurons have a greater range of possible movement directions to encode	background	2K_dev_1275
These results presented by Rasmussen et al	background	2K_dev_1275
raise several additional questions	background	2K_dev_1275
Are the mechanisms that support dynamic range adaptation the same in sensory and motor neurons ? If these neurons also encode other aspects of movement	background	2K_dev_1275
such as speed	background	2K_dev_1275
would these also be included in the same range as direction or is the adaptation process segregated by specific parameter categories ? And how do these changes in sensitivity affect the movements that animals produce	background	2K_dev_1275
showed that neurons became less sensitive to the cursors direction of movement when the task switched from 2D to 3D	finding	2K_dev_1275
Conversely	finding	2K_dev_1275
the neurons became more sensitive to the direction of movement when the task switched from 3D to 2D	finding	2K_dev_1275
Under these circumstances the neurons can use activity that was previously dedicated to encoding depth to instead represent the 2D space in finer detail	finding	2K_dev_1275
	finding	2K_dev_1275
	mechanism	2K_dev_1275
Rasmussen et al	method	2K_dev_1275
trained two rhesus macaque monkeys to use their brain activity to move a cursor on a virtual reality screen in either 2D or 3D Studying this brain activity	method	2K_dev_1275
Rasmussen et al	purpose	2K_dev_1275
therefore wondered whether the same might hold true for neurons that encode non-sensory stimuli such as the direction of movement	purpose	2K_dev_1275
Would these neurons change their sensitivity to direction if presented with a wide range of possible directions instead of a narrow range ? If so	purpose	2K_dev_1275
this would suggest that dynamic range adaptation occurs throughout the nervous system	purpose	2K_dev_1275
To find out	purpose	2K_dev_1275
	background	2K_dev_1276
we prove that every limit point of the sequence generated by m-PAPG is a critical point of the objective function we prove that the function value decays linearly for every $ s $ steps ; we prove that the sequences generated by m-PAPG converge to the same critical point	finding	2K_dev_1276
provided that a proximal Lipschitz condition is satisfied	finding	2K_dev_1276
	finding	2K_dev_1276
In this work we propose m-PAPG	mechanism	2K_dev_1276
an implementation of the flexible proximal gradient algorithm in model parallel systems equipped with the partially asynchronous communication protocol The worker machines communicate asynchronously with a controlled staleness bound $ s $ and operate at different frequencies We characterize various convergence properties of m-PAPG :	mechanism	2K_dev_1276
1 ) Under a general non-smooth and non-convex setting	method	2K_dev_1276
; 2 ) Under an error bound condition	method	2K_dev_1276
3 ) Under the Kurdyka- $ { \L } $ ojasiewicz inequality	method	2K_dev_1276
	method	2K_dev_1276
With ever growing data volume and model size	purpose	2K_dev_1276
an error-tolerant	purpose	2K_dev_1276
communication efficient	purpose	2K_dev_1276
yet versatile distributed algorithm has become vital for the success of many large-scale machine learning applications	purpose	2K_dev_1276
Self-driving vehicle technologies are progressing rapidly and are expected to play a significant role in the future of transportation	background	2K_dev_1277
One of the main challenges for self-driving vehicles on public roads is the safe cooperation and collaboration among multiple vehicles using sensor-based perception and inter-vehicle communications	background	2K_dev_1277
When self-driving vehicles try to occupy the same spatial area simultaneously	background	2K_dev_1277
they might collide with one another	background	2K_dev_1277
might become deadlocked	background	2K_dev_1277
or might slam on the brakes making it uncomfortable or unsafe for passengers in a self-driving vehicle	background	2K_dev_1277
	background	2K_dev_1277
results show that our traffic protocol has higher traffic throughput	finding	2K_dev_1277
compared to simple traffic protocols	finding	2K_dev_1277
while ensuring safety	finding	2K_dev_1277
We present a safe protocol for merge points named Autonomous Vehicle Protocol for Merge Points	mechanism	2K_dev_1277
where self-driving vehicles use both vehicular communications and their own perception systems	mechanism	2K_dev_1277
Our simulation	method	2K_dev_1277
In this paper	purpose	2K_dev_1277
we study how a self-driving vehicle can safely navigate merge points	purpose	2K_dev_1277
where two lanes with different priorities meet	purpose	2K_dev_1277
for cooperating with other self-driving and/or human-driven vehicles	purpose	2K_dev_1277
	purpose	2K_dev_1277
	background	2K_dev_1278
	finding	2K_dev_1278
	mechanism	2K_dev_1278
	method	2K_dev_1278
	purpose	2K_dev_1278
Gaussian belief propagation ( BP ) has been widely used for distributed estimation in large-scale networks such as the smart grid	background	2K_dev_1279
communication networks	background	2K_dev_1279
and social networks	background	2K_dev_1279
where local meansurements/observations are scattered over a wide geographical area	background	2K_dev_1279
	background	2K_dev_1279
that the exchanged message information matrix converges for arbitrary positive semidefinite initial value	finding	2K_dev_1279
and its distance to the unique positive definite limit matrix decreases exponentially fast	finding	2K_dev_1279
focusing in particular on the convergence of the information matrix	mechanism	2K_dev_1279
We show analytically	method	2K_dev_1279
However	purpose	2K_dev_1279
the convergence of Gaussian BP is still an open issue In this paper	purpose	2K_dev_1279
we consider the convergence of Gaussian BP	purpose	2K_dev_1279
	purpose	2K_dev_1279
Intelligent personalization systems are becoming increasingly reliant on contextually-relevant devices and services	background	2K_dev_1280
such as those available within modern IoT deployments	background	2K_dev_1280
An IoT context may emerge -- -or become pervasive -- -when the intelligent system generates knowledge from dialogue-based interactions with the end-user ; the context is strengthened even further by incorporating state representations about the environment ( e	background	2K_dev_1280
g	background	2K_dev_1280
	background	2K_dev_1280
generated from wireless sensor data ) into the knowledge graph	background	2K_dev_1280
This is crucial for pervasive applications like digital assistance in IoT	background	2K_dev_1280
where context-aware systems need to adapt quickly : activities like leaving work home-bound	background	2K_dev_1280
driving to the grocery store	background	2K_dev_1280
arriving at home	background	2K_dev_1280
and walking the dog	background	2K_dev_1280
for example	background	2K_dev_1280
can occur in a relatively short period of time -- - during which an intelligent assistant must be able to support user requests in a consistent and coherent manner	background	2K_dev_1280
Given that computational ontologies can serve as semantic models for heterogeneous data	background	2K_dev_1280
they are becoming increasingly viable for reasoning across different IoT contexts	background	2K_dev_1280
This involves : ( a ) federation and dynamic pruning of multiple modular ontologies	background	2K_dev_1280
ideally	background	2K_dev_1280
to comprehensively capture only the knowledge that will facilitate execution of a multi-context task ; ( b ) fast consistency-checking and ontology-based inferences	background	2K_dev_1280
aided by rules-based execution environments that can evaluate/transform ambient wireless sensor network ( WSN ) data	background	2K_dev_1280
in real-time ; and ( c ) run-time execution of ontology-based control procedures	background	2K_dev_1280
through rule-engine actuation commands sent across the WSN	background	2K_dev_1280
Only by realizing these functionalities may intelligent systems be capable of reasoning over device properties	background	2K_dev_1280
system states	background	2K_dev_1280
and user activities	background	2K_dev_1280
while appropriately delegating commands to other intelligent agents or other relevant IoT services	background	2K_dev_1280
Preliminary results are also discussed	finding	2K_dev_1280
In this poster	mechanism	2K_dev_1280
we illustrate how a multi-context knowledge base can be structured on the basis of modular ontologies and integrated with a distributed rules-based inference engine in multiple smart-building environments	mechanism	2K_dev_1280
The approach we describe is also partially based on the Ubiquitous Personal Assistant ( UPA ) project	mechanism	2K_dev_1280
Bosch Research 's largest research initiative worldwide	mechanism	2K_dev_1280
	mechanism	2K_dev_1280
This work is conducted through the partnership of Bosch Research Pittsburgh and Carnegie Mellon University ( CMU )	method	2K_dev_1280
and is in partial satisfaction of CMU 's Bosch Energy Research Network ( BERN ) grant	method	2K_dev_1280
awarded for developments in intelligent building solutions	method	2K_dev_1280
in order to enable scalable contextual reasoning for intelligent assistance	purpose	2K_dev_1280
	background	2K_dev_1281
	finding	2K_dev_1281
	mechanism	2K_dev_1281
	method	2K_dev_1281
	purpose	2K_dev_1281
	background	2K_dev_1282
	finding	2K_dev_1282
	mechanism	2K_dev_1282
	method	2K_dev_1282
	purpose	2K_dev_1282
Traditional generative adversarial networks ( GAN ) and many of its variants are trained by minimizing the KL or JS-divergence loss that measures how close the generated data distribution is from the true data distribution A recent advance called the WGAN based on Wasserstein distance can improve on the KL and JS-divergence based GANs	background	2K_dev_1283
and alleviate the gradient vanishing	background	2K_dev_1283
instability	background	2K_dev_1283
and mode collapse issues that are common in the GAN training	background	2K_dev_1283
	background	2K_dev_1283
that the proposed GoGAN can reduce the gap between the true data distribution and the generated data distribution by at least half in an optimally trained WGAN	finding	2K_dev_1283
and have seen both visual and quantitative improvement over baseline WGAN	finding	2K_dev_1283
by first generalizing its discriminator loss to a margin-based one	mechanism	2K_dev_1283
which leads to a better discriminator	mechanism	2K_dev_1283
and in turn a better generator	mechanism	2K_dev_1283
and then carrying out a progressive training paradigm involving multiple GANs to contribute to the maximum margin ranking loss so that the GAN at later stages will improve upon early stages We call this method Gang of GANs ( GoGAN ) We have also proposed a new way of measuring GAN quality which is based on image completion tasks	mechanism	2K_dev_1283
	mechanism	2K_dev_1283
We have shown theoretically We have evaluated our method on four visual datasets : CelebA	method	2K_dev_1283
LSUN Bedroom	method	2K_dev_1283
CIFAR-10	method	2K_dev_1283
and 50K-SSFF	method	2K_dev_1283
	method	2K_dev_1283
In this work	purpose	2K_dev_1283
we aim at improving on the WGAN	purpose	2K_dev_1283
The problems of hand detection have been widely addressed in many areas	background	2K_dev_1284
e	background	2K_dev_1284
g	background	2K_dev_1284
human computer interaction environment	background	2K_dev_1284
driver behaviors monitoring	background	2K_dev_1284
etc	background	2K_dev_1284
Our proposed method achieves the state-of-the-art results with 20 % of the detection accuracy higher than the second best one in the VIVA challenge	finding	2K_dev_1284
	finding	2K_dev_1284
This paper presents the Multiple Scale Faster Region-based Convolutional Neural Network ( MS-FRCNN ) Our proposed method introduces a multiple scale deep feature extraction approach in order to handle the challenging factors to provide a robust hand detection algorithm	mechanism	2K_dev_1284
	mechanism	2K_dev_1284
The method is evaluated on the challenging hand database	method	2K_dev_1284
i	method	2K_dev_1284
e	method	2K_dev_1284
the Vision for Intelligent Vehicles and Applications ( VIVA ) Challenge	method	2K_dev_1284
and compared against various recent hand detection methods	method	2K_dev_1284
	method	2K_dev_1284
However	purpose	2K_dev_1284
the detection accuracy in recent hand detection systems are still far away from the demands in practice due to a number of challenges	purpose	2K_dev_1284
e	purpose	2K_dev_1284
g	purpose	2K_dev_1284
hand variations	purpose	2K_dev_1284
highly occlusions	purpose	2K_dev_1284
low-resolution and strong lighting conditions	purpose	2K_dev_1284
to handle the problems of hand detection in given digital images collected under challenging conditions	purpose	2K_dev_1284
	purpose	2K_dev_1284
While only recently developed	background	2K_dev_1285
the ability to profile expression data in single cells ( scRNA-Seq ) has already led to several important studies and findings	background	2K_dev_1285
Such database queries ( which can be performed using our web server ) will enable researchers to better characterize cells when analyzing heterogeneous scRNA-Seq samples	background	2K_dev_1285
	background	2K_dev_1285
We show that the NN method improves upon prior methods in both	finding	2K_dev_1285
the ability to correctly group cells in experiments not used in the training and the ability to correctly infer cell type or state by querying a database of tens of thousands of single cell profiles	finding	2K_dev_1285
we develop and test a method based on neural networks ( NN ) We tested various NN architectures	mechanism	2K_dev_1285
some biologically motivated	mechanism	2K_dev_1285
and used these to obtain a reduced dimension representation of the single cell expression data	mechanism	2K_dev_1285
	mechanism	2K_dev_1285
	method	2K_dev_1285
However	purpose	2K_dev_1285
this technology has also raised several new computational challenges including questions related to handling the noisy and sometimes incomplete data	purpose	2K_dev_1285
how to identify unique group of cells in such experiments and how to determine the state or function of specific cells based on their expression profile	purpose	2K_dev_1285
To address these issues for the analysis and retrieval of single cell RNA-Seq data	purpose	2K_dev_1285
	purpose	2K_dev_1285
	background	2K_dev_1286
	finding	2K_dev_1286
High Assurance SPIRAL ( HA-SPIRAL ) is a tool that At the heart of HA-SPIRAL is a mathematical identity rewrite engine based on a computer algebra system	mechanism	2K_dev_1286
The rewrite engine refines the mathematical expression provided by a control engineer	mechanism	2K_dev_1286
through mathematical identities	mechanism	2K_dev_1286
into an equivalent mathematical expression that can be implemented in code	mechanism	2K_dev_1286
	mechanism	2K_dev_1286
	method	2K_dev_1286
synthesizes a faithful and high performance implementation from the mathematical specification of a given controller or monitor	purpose	2K_dev_1286
In this paper	purpose	2K_dev_1286
we discuss the use of HA-SPIRAL in generating provably-correct and high-performance implementations for different controllers and monitors for autonomous land and air vehicles	purpose	2K_dev_1286
	purpose	2K_dev_1286
The recent explosion in the adoption of search engines and new media such as blogs and Twitter have facilitated the faster propagation of news and rumors	background	2K_dev_1287
	background	2K_dev_1287
demonstrate that S pike M accurately and succinctly describes all patterns of the rise and fall spikes in social networks	finding	2K_dev_1287
In this article	mechanism	2K_dev_1287
we propose S pike M	mechanism	2K_dev_1287
a concise yet flexible analytical model of Our model has the following advantages First	mechanism	2K_dev_1287
unification power : it explains earlier empirical observations and generalizes theoretical models including the SI and SIR models We provide the threshold of the take-off versus die-out conditions for S pike M and discuss the generality of our model by applying it to an arbitrary graph topology Second	mechanism	2K_dev_1287
practicality : it matches the observed behavior of diverse sets of real data Third	mechanism	2K_dev_1287
parsimony : it requires only a handful of parameters	mechanism	2K_dev_1287
Fourth	mechanism	2K_dev_1287
usefulness : it makes it possible to perform analytic tasks such as forecasting	mechanism	2K_dev_1287
spotting anomalies	mechanism	2K_dev_1287
and interpretation by reverse engineering the system parameters of interest ( quality of news	mechanism	2K_dev_1287
number of interested bloggers	mechanism	2K_dev_1287
etc	mechanism	2K_dev_1287
) We also introduce an efficient and effective algorithm namely S pike S tream	mechanism	2K_dev_1287
which identifies multiple diffusion patterns in a large collection of online event streams	mechanism	2K_dev_1287
	mechanism	2K_dev_1287
Extensive experiments on real datasets	method	2K_dev_1287
How quickly does a piece of news spread over these media ? How does its popularity diminish over time ? Does the rising and falling pattern follow a simple universal law ? the rise and fall patterns of information diffusion for the real-time monitoring of information diffusion	purpose	2K_dev_1287
	purpose	2K_dev_1287
In face recognition tasks	background	2K_dev_1288
the changing pose of the face can cause enough information to be lost to cause the recognition to fail so being able to determine the pose of the face beforehand can allow for some better recognition performance	background	2K_dev_1288
	background	2K_dev_1288
We show this method can perform pose estimation with a high accuracy of 85	finding	2K_dev_1288
21 % and an accuracy of 98	finding	2K_dev_1288
42 % when allowing a 15 tolerance on the pose estimate on the CUbiC FacePix dataset	finding	2K_dev_1288
with our methods achieving 77	finding	2K_dev_1288
01 % accuracy on yaw estimation	finding	2K_dev_1288
	finding	2K_dev_1288
We propose method in which the training data itself is the underlying structure of a classifier	mechanism	2K_dev_1288
This is accomplished through the use of matrix decomposition equations However	mechanism	2K_dev_1288
instead of decomposing a matrix	mechanism	2K_dev_1288
one is created by carefully selecting the terms in the decomposition equation such that the resulting matrix has the desired properties for classification	mechanism	2K_dev_1288
We show two recomposition methods using the Spectral Decomposition and Singular Value Decomposition equations	mechanism	2K_dev_1288
We also show results on both yaw and pitch estimation on the Pointing'04 dataset	method	2K_dev_1288
Many methods used for pose estimation tasks rely on finding some underlying structure of the data given to create a classifier	purpose	2K_dev_1288
an alternative	purpose	2K_dev_1288
The mechanism classes we study are significantly different from well-understood function classes typically found in machine learning	background	2K_dev_1289
so bounding their complexity requires a sharp understanding of the interplay between mechanism parameters and buyer valuations	background	2K_dev_1289
	finding	2K_dev_1289
We present a single	mechanism	2K_dev_1289
overarching theorem that uses empirical Rademacher complexity	mechanism	2K_dev_1289
including affine maximizer auctions	mechanism	2K_dev_1289
mixed-bundling auctions	mechanism	2K_dev_1289
and second-price item auctions Despite the extensive applicability of our main theorem	mechanism	2K_dev_1289
we match and improve over the best-known generalization guarantees for many auction classes	mechanism	2K_dev_1289
This all-encompassing theorem also applies to multi- and single-item pricing mechanisms in both multi- and single-unit settings	mechanism	2K_dev_1289
such as linear and non-linear pricing mechanisms	mechanism	2K_dev_1289
Finally	mechanism	2K_dev_1289
our central theorem allows us to easily derive generalization guarantees for every class in several finely grained hierarchies of auction and pricing mechanism classes	mechanism	2K_dev_1289
	mechanism	2K_dev_1289
Instead the mechanism designer receives a set of samples from this distribution and his goal is to use the sample to design a pricing mechanism or auction with high expected profit	method	2K_dev_1289
We provide generalization guarantees which bound the difference between average profit on the sample and expected profit over the distribution	method	2K_dev_1289
These bounds are directly proportional to the intrinsic complexity of the mechanism class the designer is optimizing over	method	2K_dev_1289
	method	2K_dev_1289
We study the design of pricing mechanisms and auctions when the mechanism designer does not know the distribution of buyers ' values	purpose	2K_dev_1289
to measure the intrinsic complexity of a variety of widely-studied single- and multi-item auction classes We demonstrate how to determine the precise level in a hierarchy with the optimal tradeoff between profit and generalization using structural profit maximization	purpose	2K_dev_1289
	purpose	2K_dev_1289
Rapid improvements in the precision of mobile technologies make it possible for advertisers to go beyond using the real-time static location and contextual information about consumers Our finding suggests that highly targeted mobile promotions can have the inadvertent impact of reducing impulse purchase behavior by customers who are in an exploratory shopping stage	background	2K_dev_1290
On a broader note	background	2K_dev_1290
our work can be viewed as a first step towards studying the large-scale	background	2K_dev_1290
fine-grained digital trace of individual physical behavior	background	2K_dev_1290
and how it can be used to predict and market to individual anticipated future behavior	background	2K_dev_1290
We find that trajectory-based mobile targeting can lead to higher redemption probability	finding	2K_dev_1290
faster redemption behavior	finding	2K_dev_1290
and higher transaction amount from customers compared to other baselines	finding	2K_dev_1290
It also facilitates higher revenues for the focal store as well as the overall shopping mall	finding	2K_dev_1290
Moreover	finding	2K_dev_1290
the effect of trajectory-based targeting comes not only from improvements in the efficiency of customers current shopping process	finding	2K_dev_1290
but also from its ability to nudge customers towards changing their future shopping patterns and generate additional revenues	finding	2K_dev_1290
Finally	finding	2K_dev_1290
we find significant heterogeneity in the impact of trajectory-based targeting	finding	2K_dev_1290
It is especially effective in influencing high-income consumers Interestingly	finding	2K_dev_1290
it becomes less effective in boosting the revenues of the shopping mall during the weekends and for those shoppers who like to explore across products categories	finding	2K_dev_1290
In this study	mechanism	2K_dev_1290
we propose a novel trajectory-based targeting strategy that leverages full information on consumers physical movement trajectories using granular behavioral information from different mobility dimensions	mechanism	2K_dev_1290
To analyze the effectiveness of this new strategy	method	2K_dev_1290
we design a large-scale randomized field experiment in a large shopping mall that involved 83	method	2K_dev_1290
370 unique user responses for a 14-day period in June 2014	method	2K_dev_1290
for mobile recommendation	purpose	2K_dev_1290
Common appliances have shifted toward flat interface panels	background	2K_dev_1291
making them inaccessible to blind people	background	2K_dev_1291
Although blind people can label appliances with Braille stickers	background	2K_dev_1291
doing so generally requires sighted assistance to identify the original functions and apply the labels	background	2K_dev_1291
	background	2K_dev_1291
We demonstrate the viability of Facade	finding	2K_dev_1291
We introduce Facade - a crowdsourced fabrication pipeline by adding a 3D printed augmentation of tactile buttons overlaying the original panel Facade users capture a photo of the appliance with a readily available fiducial marker ( a dollar bill ) for recovering size information This image is sent to multiple crowd workers	mechanism	2K_dev_1291
who work in parallel to quickly label and describe elements of the interface	mechanism	2K_dev_1291
Facade then generates a 3D model for a layer of tactile and pressable buttons that fits over the original controls Finally	mechanism	2K_dev_1291
a home 3D printer or commercial service fabricates the layer	mechanism	2K_dev_1291
which is then aligned and attached to the interface by the blind person	mechanism	2K_dev_1291
	mechanism	2K_dev_1291
in a study with 11 blind participants	method	2K_dev_1291
	method	2K_dev_1291
to help blind people independently make physical interfaces accessible	purpose	2K_dev_1291
	background	2K_dev_1292
	finding	2K_dev_1292
	mechanism	2K_dev_1292
	method	2K_dev_1292
	purpose	2K_dev_1292
The same techniques can be applied to monitor other types of traffic data	background	2K_dev_1293
We are able to approximately recover the taxi-pick activities in Manhattan by sampling at only 5 selected intersections	finding	2K_dev_1293
This paper proposes a series of sampling	mechanism	2K_dev_1293
recovery and representation techniques based on graph signal processing	mechanism	2K_dev_1293
We validate our proposed techniques on Manhattan 's taxi pickups during the years of 2014 and 2015	method	2K_dev_1293
	method	2K_dev_1293
Is it possible to monitor the entire traffic in Manhattan at a few intersections ? to handle complex	purpose	2K_dev_1293
nonsmooth graph signals	purpose	2K_dev_1293
	purpose	2K_dev_1293
	background	2K_dev_1294
Our method effectively transfers discriminability of connectives to the implicit features	finding	2K_dev_1294
and achieves state-of-the-art performance on the PDTB benchmark	finding	2K_dev_1294
	finding	2K_dev_1294
We propose a feature imitation framework in which an implicit relation network is driven to learn from another neural network with access to connectives	mechanism	2K_dev_1294
and thus encouraged We develop an adversarial model through competition between the implicit network and a rival feature discriminator	mechanism	2K_dev_1294
	method	2K_dev_1294
Implicit discourse relation classification is of great challenge due to the lack of connectives as strong linguistic cues	purpose	2K_dev_1294
which motivates the use of annotated implicit connectives to improve the recognition	purpose	2K_dev_1294
to extract similarly salient features for accurate classification	purpose	2K_dev_1294
to enable an adaptive imitation scheme	purpose	2K_dev_1294
Hearing-impaired people and non-native speakers rely on captions for access to video content Based on our results	background	2K_dev_1295
we outline opportunities for future research and provide design suggestions to deliver cost-efficient captioning solutions	background	2K_dev_1295
Our findings show that BandCaption enables crowd workers who have different needs and strengths to accomplish micro-tasks and make complementary contributions	finding	2K_dev_1295
	finding	2K_dev_1295
In this paper	mechanism	2K_dev_1295
we present the design	mechanism	2K_dev_1295
implementation and evaluation of BandCaption	mechanism	2K_dev_1295
a system that combines automatic speech recognition with input from crowd workers Each group has different abilities and incentives	mechanism	2K_dev_1295
which our workflow leverages	mechanism	2K_dev_1295
	mechanism	2K_dev_1295
We consider four stakeholder groups as our source of crowd workers : ( i ) individuals with hearing impairments	method	2K_dev_1295
( ii ) second-language speakers with low proficiency	method	2K_dev_1295
( iii ) second-language speakers with high proficiency	method	2K_dev_1295
and ( iv ) native speakers	method	2K_dev_1295
	method	2K_dev_1295
yet most videos remain uncaptioned or have machine-generated captions with high error rates	purpose	2K_dev_1295
to provide a cost-efficient captioning solution for accessible online videos	purpose	2K_dev_1295
	purpose	2K_dev_1295
The promise of smart environments and the Internet of Things ( IoT ) relies on robust sensing of diverse environmental facets	background	2K_dev_1296
	background	2K_dev_1296
the results of which show the versatility	finding	2K_dev_1296
accuracy and potential utility of our approach	finding	2K_dev_1296
	finding	2K_dev_1296
Further	mechanism	2K_dev_1296
through what we call Synthetic Sensors	mechanism	2K_dev_1296
we can virtualize raw sensor data into actionable feeds	mechanism	2K_dev_1296
whilst simultaneously mitigating immediate privacy issues	mechanism	2K_dev_1296
	mechanism	2K_dev_1296
A series of structured	method	2K_dev_1296
formative studies informed the development of our new sensor hardware and accompanying information architecture	method	2K_dev_1296
We deployed our system across many months and environments	method	2K_dev_1296
	method	2K_dev_1296
Traditional approaches rely on direct and distributed sensing	purpose	2K_dev_1296
most often by measuring one particular aspect of an environment with a special purpose sensor	purpose	2K_dev_1296
This approach can be costly to deploy	purpose	2K_dev_1296
hard to maintain	purpose	2K_dev_1296
and aesthetically and socially obtrusive In this work	purpose	2K_dev_1296
we explore the notion of general purpose sensing	purpose	2K_dev_1296
wherein a single enhanced sensor can indirectly monitor a large context	purpose	2K_dev_1296
without direct instrumentation of objects	purpose	2K_dev_1296
	purpose	2K_dev_1296
Introduction Drug overdoses are an increasingly serious problem in the United States and worldwide	background	2K_dev_1297
The CDC estimates that 47	background	2K_dev_1297
055 drug overdose deaths occurred in the United States in 2014	background	2K_dev_1297
61 % of which involved opioids ( including heroin	background	2K_dev_1297
pain relievers such as oxycodone	background	2K_dev_1297
and synthetics )	background	2K_dev_1297
1 Overdose deaths involving opioids increased 3-fold from 2000 to 2014	background	2K_dev_1297
1 These statistics motivate public health to identify emerging trends in overdoses	background	2K_dev_1297
including geographic	background	2K_dev_1297
demographic	background	2K_dev_1297
and behavioral patterns ( e	background	2K_dev_1297
g	background	2K_dev_1297
	background	2K_dev_1297
which combinations of drugs are involved )	background	2K_dev_1297
Early detection can inform prevention and response efforts	background	2K_dev_1297
as well as quantifying the effects of drug legislation and other policy changes	background	2K_dev_1297
The fast subset scan 2 detects significant spatial patterns of disease by efficiently maximizing a log-likelihood ratio statistic over subsets of data points	background	2K_dev_1297
and has recently been extended to multidimensional data ( MD-Scan )	background	2K_dev_1297
Conclusions Retrospective analysis of Allegheny County overdose data suggests high potential utility for a prospective overdose surveillance system	background	2K_dev_1297
which would enable public health users to identify emerging patterns of overdoses in their early stages and facilitate targeted and effective health interventions	background	2K_dev_1297
The MDTS approach can also be used for other multidimensional public health surveillance tasks	background	2K_dev_1297
such as STI surveillance	background	2K_dev_1297
where the patterns or outbreaks of interest may have demographic	background	2K_dev_1297
geographic	background	2K_dev_1297
and behavioral components	background	2K_dev_1297
	finding	2K_dev_1297
and demonstrate the utility of this approach for discovering emerging geographic	finding	2K_dev_1297
demographic	finding	2K_dev_1297
and behavioral trends in fatal drug overdoses	finding	2K_dev_1297
Results The highest-scoring clusters discovered by MDTS were shared with Allegheny Countys Dept	finding	2K_dev_1297
of Human Services and their feedback obtained	finding	2K_dev_1297
One set of potentially relevant findings from our analysis involved fentanyl	finding	2K_dev_1297
a dangerous and potent opioid which has been a serious problem in western PA	finding	2K_dev_1297
In addition to identifying two well- known	finding	2K_dev_1297
large clusters of overdoses14 deaths in January 2014 and 26 deaths in March-April 2015MDTS was able to provide additional information about each cluster	finding	2K_dev_1297
For example	finding	2K_dev_1297
the first cluster was likely due to fentanyl-laced heroin	finding	2K_dev_1297
while the second was more likely due to fentanyl disguised as heroin ( only 11 victims had heroin in their system )	finding	2K_dev_1297
Moreover	finding	2K_dev_1297
the second cluster was initially confined to the Pittsburgh suburb of McKeesport and a typical demographic ( white males ages 20-49 )	finding	2K_dev_1297
before spreading across the county	finding	2K_dev_1297
Our analysis demonstrated that prospective surveillance using MDTS would have identified the cluster as early as March 29th	finding	2K_dev_1297
enabling targeted prevention efforts	finding	2K_dev_1297
MDTS also discovered a previously unidentified	finding	2K_dev_1297
highly localized cluster of fentanyl-related overdoses affecting an unusual and underserved demographic ( elderly black males near downtown Pittsburgh )	finding	2K_dev_1297
This cluster occurred in January- February 2015	finding	2K_dev_1297
and may have been related to the larger cluster of fentanyl-related overdoses that occurred two months later Finally	finding	2K_dev_1297
we identified multiple overdose clusters involving combinations of methadone and Xanax between 2008 and 2012	finding	2K_dev_1297
and observed dramatic reductions in these clusters corresponding to the passage of the Methadone Death and Incident Review Act ( October 2012 )	finding	2K_dev_1297
which increased state oversight of methadone clinics and prescribing physicians	finding	2K_dev_1297
We present the multidimensional tensor scan ( MDTS )	mechanism	2K_dev_1297
a new method Methods The multidimensional tensor scan ( MDTS ) is a new approach In addition to detecting the spatial area ( subset of locations ) and time window affected by an emerging outbreak	mechanism	2K_dev_1297
MDTS can also identify the affected subset of values for each observed attribute	mechanism	2K_dev_1297
For example	mechanism	2K_dev_1297
given the drug overdose surveillance data described below	mechanism	2K_dev_1297
MDTS can identify the affected genders	mechanism	2K_dev_1297
races	mechanism	2K_dev_1297
age ranges	mechanism	2K_dev_1297
and which drugs were involved	mechanism	2K_dev_1297
MDTS finds subsets of the attribute space with higher than expected case counts	mechanism	2K_dev_1297
first using a novel tensor decomposition approach to estimate the expected counts MDTS then iteratively applies a conditional optimization step	mechanism	2K_dev_1297
optimizing over all subsets of values for each attribute conditional on the current subsets of values for all other attributes 3	mechanism	2K_dev_1297
and using the linear-time subset scanning property 2 to make each conditional optimization step computationally efficient The resulting approach has high power to detect and characterize emerging trends which may only affect a subset of the monitored population ( e	mechanism	2K_dev_1297
g	mechanism	2K_dev_1297
	mechanism	2K_dev_1297
specific ages	mechanism	2K_dev_1297
genders	mechanism	2K_dev_1297
neighborhoods	mechanism	2K_dev_1297
or users of particular combinations of drugs	mechanism	2K_dev_1297
We used MDTS to analyze publicly available data from the Allegheny County	method	2K_dev_1297
PA medical examiners office and to detect emerging overdose patterns and trends The dataset consists of ~2000 fatal accidental drug overdoses between 2008 and 2015	method	2K_dev_1297
For each overdose victim	method	2K_dev_1297
we have date	method	2K_dev_1297
location ( zip code )	method	2K_dev_1297
age decile	method	2K_dev_1297
gender race	method	2K_dev_1297
and the presence/absence of 27 commonly abused drugs in their system	method	2K_dev_1297
Objective for identifying emerging patterns in multidimensional spatio-temporal data 3 While MD-Scan is a potentially useful tool for drug overdose surveillance	purpose	2K_dev_1297
the high dimensionality and sparsity of the data requires a new approach to estimate and represent baselines ( expected counts )	purpose	2K_dev_1297
maintaining both accuracy and efficient computation when searching over subsets	purpose	2K_dev_1297
to subset scanning in multidimensional data	purpose	2K_dev_1297
	purpose	2K_dev_1297
Homes	background	2K_dev_1298
offices and many other environments will be increasingly saturated with connected	background	2K_dev_1298
computational appliances	background	2K_dev_1298
forming the `` Internet of Things '' ( IoT )	background	2K_dev_1298
At present	background	2K_dev_1298
most of these devices rely on mechanical inputs	background	2K_dev_1298
webpages	background	2K_dev_1298
or smartphone apps for control	background	2K_dev_1298
	background	2K_dev_1298
suggests high accuracy 98	finding	2K_dev_1298
8 % recognition accuracy among 17 appliances	finding	2K_dev_1298
	finding	2K_dev_1298
We propose an approach where users simply tap a smartphone to an appliance To achieve this	mechanism	2K_dev_1298
our prototype smartphone recognizes physical contact with uninstrumented appliances	mechanism	2K_dev_1298
and summons appliance-specific interfaces	mechanism	2K_dev_1298
Our user study Finally	method	2K_dev_1298
to underscore the immediate feasibility and utility of our system	method	2K_dev_1298
we built twelve example applications	method	2K_dev_1298
including six fully functional end-to-end demonstrations	method	2K_dev_1298
	method	2K_dev_1298
However	purpose	2K_dev_1298
as IoT devices proliferate	purpose	2K_dev_1298
these existing interaction methods will become increasingly cumbersome	purpose	2K_dev_1298
Will future smart-home owners have to scroll though pages of apps to select and dim their lights to discover and rapidly utilize contextual functionality	purpose	2K_dev_1298
	purpose	2K_dev_1298
Small	background	2K_dev_1299
local groups who share protected resources ( e	background	2K_dev_1299
g	background	2K_dev_1299
	background	2K_dev_1299
families	background	2K_dev_1299
work teams	background	2K_dev_1299
student organizations ) have unmet authentication needs	background	2K_dev_1299
	background	2K_dev_1299
Our results suggest that ( 1 ) individuals who enter the same shared thumprint are distinguishable from one another	finding	2K_dev_1299
( 2 ) that people can enter thumprints consistently over time	finding	2K_dev_1299
and ( 3 ) that thumprints are resilient to casual adversaries	finding	2K_dev_1299
	finding	2K_dev_1299
we designed Thumprint : inclusive group authentication with a shared secret knock	mechanism	2K_dev_1299
All group members share one secret knock	mechanism	2K_dev_1299
but individual expressions of the secret are discernible	mechanism	2K_dev_1299
	mechanism	2K_dev_1299
We evaluated the usability and security of our concept through two user studies with 30 participants	method	2K_dev_1299
	method	2K_dev_1299
For these groups	purpose	2K_dev_1299
existing authentication strategies either create unnecessary social divisions ( e	purpose	2K_dev_1299
g	purpose	2K_dev_1299
	purpose	2K_dev_1299
biometrics )	purpose	2K_dev_1299
do not identify individuals ( e	purpose	2K_dev_1299
g	purpose	2K_dev_1299
	purpose	2K_dev_1299
shared passwords )	purpose	2K_dev_1299
do not equitably distribute security responsibility ( e	purpose	2K_dev_1299
g	purpose	2K_dev_1299
	purpose	2K_dev_1299
individual passwords )	purpose	2K_dev_1299
or make it difficult to share or revoke access ( e	purpose	2K_dev_1299
g	purpose	2K_dev_1299
	purpose	2K_dev_1299
physical keys )	purpose	2K_dev_1299
To explore an alternative	purpose	2K_dev_1299
	purpose	2K_dev_1299
Infrastructure monitoring applications currently lack a cost-effective and reliable solution for supporting the last communication hop for low-power devices	background	2K_dev_1300
The use of cellular infrastructure requires contracts and complex radios that are often too power hungry and cost prohibitive for sensing applications that require just a few bits of data each day	background	2K_dev_1300
New low-power	background	2K_dev_1300
sub-GHz	background	2K_dev_1300
long-range radios are an ideal technology to help fill this communication void by providing access points that are able to cover multiple kilometers of urban space with thousands of end-point devices	background	2K_dev_1300
These new Low-Power Wide-Area Networking ( LPWAN ) platforms provide a cost-effective and highly deployable option that could piggyback off of existing public and private wireless networks ( WiFi	background	2K_dev_1300
Cellular	background	2K_dev_1300
etc )	background	2K_dev_1300
	background	2K_dev_1300
	finding	2K_dev_1300
In this paper	mechanism	2K_dev_1300
we present OpenChirp	mechanism	2K_dev_1300
a prototype end-to-end LPWAN architecture built using LoRa Wide-Area Network ( LoRaWAN ) We present a software architecture that exposes an application layer We define a service model on top of LoRaWAN that acts as a session layer At the device-level	mechanism	2K_dev_1300
we introduce and benchmark an open-source hardware platform that uses Bluetooth Low-Energy ( BLE )	mechanism	2K_dev_1300
We evaluate the system in terms of end-node energy consumption	method	2K_dev_1300
radio penetration into buildings as well as coverage provided by a network currently deployed at Carnegie Mellon University	method	2K_dev_1300
	method	2K_dev_1300
with the goal of simplifying the design and deployment of Internet-of-Things ( IoT ) devices across wide areas like campuses and cities allowing users to register devices	purpose	2K_dev_1300
describe transducer properties	purpose	2K_dev_1300
transfer data and retrieve historical values	purpose	2K_dev_1300
to provide basic encoding and syntax to raw data streams	purpose	2K_dev_1300
to help provision LoRa clients that can be extended with custom transducers	purpose	2K_dev_1300
whereas previous models	background	2K_dev_1301
assuming no exogenous infection	background	2K_dev_1301
showed dependency only on the infection and healing rates	background	2K_dev_1301
We show that the sufficient condition for infection to become extinct not only depends on the ratio of infection and healing rates but also on N	finding	2K_dev_1301
the size of the network	finding	2K_dev_1301
	finding	2K_dev_1301
We relate the time-limiting behavior of a network epidemics process to the spectral radius of the underlying network Our analysis differs from previous work in that the scaled SIS process accounts for the possibility that a healthy individual has a nonzero probability of becoming infected even when all of its neighbors are healthy	mechanism	2K_dev_1301
For example	mechanism	2K_dev_1301
the source of infection may be outside a human only contact network for diseases with animal to human transmissions such as Ebola	mechanism	2K_dev_1301
	method	2K_dev_1301
The process we study is the scaled SIS network process	purpose	2K_dev_1301
a continuous-time Markov process on a static network	purpose	2K_dev_1301
The proliferation of mobile and sensor technologies has contributed to the rise of location-based mobile targeting	background	2K_dev_1302
Beyond the location	background	2K_dev_1302
time and spatial context of individuals	background	2K_dev_1302
the social context wherein they are embedded can reveal rich information about their behavior	background	2K_dev_1302
Such real-time social dynamics can help mobile advertisers to more fully understand consumer contextual preferences and	background	2K_dev_1302
thereby	background	2K_dev_1302
provide better digital experiences Overall	background	2K_dev_1302
our study demonstrates the potential of inferring individuals social contexts in real time from their movement trajectories as well as the value of leveraging such real-time social dynamics for improved mobile-targeting effectiveness	background	2K_dev_1302
Our analyses indicated significant heterogeneity in consumer behavior under different real-time social contexts	finding	2K_dev_1302
We found	finding	2K_dev_1302
for example	finding	2K_dev_1302
that a customer in a group with others is on average 1	finding	2K_dev_1302
97 times more responsive to mobile promotions than is a solo shopper	finding	2K_dev_1302
and that this impact increases with increased group size ( from dyad to triad )	finding	2K_dev_1302
Interestingly	finding	2K_dev_1302
we also found that couples seemed to have an attention deficit with respect to mobile promotions and were the least responsive compared with the other social groups	finding	2K_dev_1302
Meanwhile	finding	2K_dev_1302
high-income customers and male customers were more likely to respond to mobile promotions when shopping alone than when shopping with social groups	finding	2K_dev_1302
Our analyses also revealed significant heterogeneity in the interaction effect between mobile promotion design and real-time social contexts	finding	2K_dev_1302
	finding	2K_dev_1302
we automatically detected based on their detailed GPS trajectories using state-of-the-art machine-learning methods	mechanism	2K_dev_1302
To evaluate the effectiveness of mobile targeting under different social contexts	method	2K_dev_1302
we designed a randomized field experiment for a large shopping mall in Asia based on 52	method	2K_dev_1302
500 unique user responses for 252 stores over the course of a 21-day period in April 2015	method	2K_dev_1302
	method	2K_dev_1302
In this study	purpose	2K_dev_1302
the real-time social contexts of customers	purpose	2K_dev_1302
	background	2K_dev_1303
We show that PSNR=29	finding	2K_dev_1303
90 dB is recovered for graph signals reconstructed from 70 % of the graph frequency components We illustrate that graph frequency components reveal taxi behaviors that are not obvious from the raw signal	finding	2K_dev_1303
We apply graph signal processing based on 20102013 New York City taxi data	mechanism	2K_dev_1303
Such analysis requires a signal extraction method that involves computing shortest paths between the start and end locations for each of the 700 million trip records	mechanism	2K_dev_1303
	mechanism	2K_dev_1303
We perform spectral analysis on these graph signals	method	2K_dev_1303
for which it is necessary to address the challenge of finding the eigendecomposition of the 6K-node directed Manhattan road network	method	2K_dev_1303
	method	2K_dev_1303
to the study of taxi movement in New York City	purpose	2K_dev_1303
Current touch input technologies are best suited for small and flat applications	background	2K_dev_1304
such as smartphones	background	2K_dev_1304
tablets and kiosks	background	2K_dev_1304
	background	2K_dev_1304
we show that Electrick can enable new interactive opportunities on a diverse set of objects and surfaces that were previously static	finding	2K_dev_1304
	finding	2K_dev_1304
We introduce Electrick	mechanism	2K_dev_1304
a low-cost and versatile sensing technique This is achieved by using electric field tomography in concert with an electrically conductive material	mechanism	2K_dev_1304
which can be easily and cheaply added to objects and surfaces We show that our technique is compatible with commonplace manufacturing methods	mechanism	2K_dev_1304
such as spray/brush coating	mechanism	2K_dev_1304
vacuum forming	mechanism	2K_dev_1304
and casting/molding enabling a wide range of possible uses and outputs Our technique can also bring touch interactivity to rapidly fabricated objects	mechanism	2K_dev_1304
including those that are laser cut or 3D printed	mechanism	2K_dev_1304
Through a series of studies and illustrative example uses	method	2K_dev_1304
	method	2K_dev_1304
In general	purpose	2K_dev_1304
they are too expensive to scale to large surfaces	purpose	2K_dev_1304
such as walls and furniture	purpose	2K_dev_1304
and can not provide input on objects having irregular and complex geometries	purpose	2K_dev_1304
such as tools and toys that enables touch input on a wide variety of objects and surfaces	purpose	2K_dev_1304
whether small or large	purpose	2K_dev_1304
flat or irregular	purpose	2K_dev_1304
Blind people often need to identify objects around them	background	2K_dev_1305
from packages of food to items of clothing	background	2K_dev_1305
Automatic object recognition continues to provide limited assistance in such tasks because models tend to be trained on images taken by sighted people with different background clutter	background	2K_dev_1305
scale	background	2K_dev_1305
viewpoints	background	2K_dev_1305
occlusion	background	2K_dev_1305
and image quality than in photos taken by blind users	background	2K_dev_1305
demonstrate the feasibility of our approach	finding	2K_dev_1305
which reaches accuracies over 90 % for some participants	finding	2K_dev_1305
	finding	2K_dev_1305
We adopt transfer learning with a deep learning system for user-defined multi-label k-instance classification	mechanism	2K_dev_1305
	mechanism	2K_dev_1305
Experiments with blind participants We analyze user data and feedback to explore effects of sample size	method	2K_dev_1305
photo-quality variance	method	2K_dev_1305
and object shape ; and contrast models trained on photos by blind participants to those by sighted participants and generic recognizers	method	2K_dev_1305
We explore personal object recognizers	purpose	2K_dev_1305
where visually impaired people train a mobile application with a few snapshots of objects of interest and provide custom labels	purpose	2K_dev_1305
	purpose	2K_dev_1305
Current tools for screening dyslexia use linguistic elements	background	2K_dev_1306
since most dyslexia manifestations are related to difficulties in reading and writing	background	2K_dev_1306
	finding	2K_dev_1306
In this paper	mechanism	2K_dev_1306
we propose a method and present DysMusic	mechanism	2K_dev_1306
a prototype The advantages of DysMusic are that the approach is language independent and could be used with younger children	mechanism	2K_dev_1306
i	mechanism	2K_dev_1306
e	mechanism	2K_dev_1306
	mechanism	2K_dev_1306
pre-readers	mechanism	2K_dev_1306
	mechanism	2K_dev_1306
The prototype was designed with the help of five children and five parents who tested the game using the think aloud protocol and being observed while playing	method	2K_dev_1306
	method	2K_dev_1306
These tools can only be used with children that have already acquired some reading skills and ; sometimes	purpose	2K_dev_1306
this detection comes too late to apply proper remediation which aims to predict risk of having dyslexia before acquiring reading skills	purpose	2K_dev_1306
	purpose	2K_dev_1306
	background	2K_dev_1307
	finding	2K_dev_1307
In this paper	mechanism	2K_dev_1307
we present an end-to-end zero-slack rate-monotonic scheme ( ZSRM ) based on real-time pipelines	mechanism	2K_dev_1307
called the ZSRM pipeline scheduler	mechanism	2K_dev_1307
Under ZSRM	mechanism	2K_dev_1307
each task is associated with a parameter called zero-slack instant	mechanism	2K_dev_1307
and whenever a higher-criticality job has not finished at its zero-slack instant relative to its arrival time	mechanism	2K_dev_1307
all jobs of lower criticality are suspended to meet the deadline of the higher-criticality job	mechanism	2K_dev_1307
We develop a new schedulability test and algorithm	mechanism	2K_dev_1307
	method	2K_dev_1307
While a number of schemes exist for mixed-criticality scheduling in a single processor setting	purpose	2K_dev_1307
no solution exists to cover the industry need for end-to-end scheduling across multiple processors in a pipeline that addresses this need	purpose	2K_dev_1307
for computing the zero-slack instants of tasks scheduled across a pipeline	purpose	2K_dev_1307
	purpose	2K_dev_1307
	background	2K_dev_1308
	finding	2K_dev_1308
	mechanism	2K_dev_1308
	method	2K_dev_1308
	purpose	2K_dev_1308
Information cascades are ubiquitous in both physical society and online social media	background	2K_dev_1309
taking on large variations in structures	background	2K_dev_1309
dynamics and semantics potentially providing insights into intrinsic mechanisms governing information spreading in nature and new models to forecast as well as to impose good control over information cascades in real applications	background	2K_dev_1309
We find that the structural complexity of information cascades is far beyond the previous conjectures	finding	2K_dev_1309
finding some brand new structure patterns of information cascades	finding	2K_dev_1309
	finding	2K_dev_1309
In this paper	mechanism	2K_dev_1309
we explore a large-scale dataset including 432 million information cascades with explicit records of spreading traces We first propose seven-dimensional metrics	mechanism	2K_dev_1309
which reflect size and spreading orientation aspects	mechanism	2K_dev_1309
	mechanism	2K_dev_1309
Further	method	2K_dev_1309
we analyze the correlations of these metrics	method	2K_dev_1309
	method	2K_dev_1309
Although there has been much progress on understanding the dynamics and semantics of information cascades	purpose	2K_dev_1309
little is known about their structural patterns to quantify the structural characteristics of millions of information cascades	purpose	2K_dev_1309
This paper continues the program initiated in [ 5 ]	background	2K_dev_1310
	background	2K_dev_1310
The applicability of the method is demonstrated	finding	2K_dev_1310
towards a derivation system The general idea is that complex protocols can be formally derived	mechanism	2K_dev_1310
starting from basic security components	mechanism	2K_dev_1310
using a sequence of refinements and transformations	mechanism	2K_dev_1310
just like logical proofs are derived starting from axioms	mechanism	2K_dev_1310
using proof rules and transformations	mechanism	2K_dev_1310
The claim is that in practice	mechanism	2K_dev_1310
many protocols are already derived in such a way	mechanism	2K_dev_1310
but informally Capturing this practice in a suitable formalism turns out to be a considerable task	mechanism	2K_dev_1310
The present paper proposes rules In general	mechanism	2K_dev_1310
security protocols are	mechanism	2K_dev_1310
of course	mechanism	2K_dev_1310
not compositional : information revealed by one may interfere with the security of the other	mechanism	2K_dev_1310
However	mechanism	2K_dev_1310
annotating protocol steps by pre- and post-conditions	mechanism	2K_dev_1310
allows secure sequential composition	mechanism	2K_dev_1310
Establishing that protocol components satisfy each other 's invariants allows more general forms of composition	mechanism	2K_dev_1310
ensuring that the individually secure sub-protocols will not interact insecurely in the composite protocol	mechanism	2K_dev_1310
	mechanism	2K_dev_1310
on modular derivations of two standard protocols	method	2K_dev_1310
together with their simple security properties	method	2K_dev_1310
for security protocols	purpose	2K_dev_1310
for composing security protocols from given security components	purpose	2K_dev_1310
	purpose	2K_dev_1310
	background	2K_dev_1311
	finding	2K_dev_1311
	mechanism	2K_dev_1311
	method	2K_dev_1311
	purpose	2K_dev_1311
Feature extraction and encoding represent two of the most crucial steps in an action recognition system	background	2K_dev_1312
	finding	2K_dev_1312
This work proposes a new approach that allows us to obtain real-time frame rate processing for an action recognition system	mechanism	2K_dev_1312
The motion information represents an important source of information within the video	mechanism	2K_dev_1312
The common approach to extract the motion information is to compute the optical flow	mechanism	2K_dev_1312
However	mechanism	2K_dev_1312
the estimation of optical flow is very demanding in terms of computational cost	mechanism	2K_dev_1312
in many cases being the most significant processing step within the overall pipeline of the target video analysis application	mechanism	2K_dev_1312
In this work we propose an efficient approach to capture the motion information within the video	mechanism	2K_dev_1312
Our proposed descriptor	mechanism	2K_dev_1312
Histograms of Motion Gradients ( HMG )	mechanism	2K_dev_1312
is based on a simple temporal and spatial derivation	mechanism	2K_dev_1312
which captures the changes between two consecutive frames For the encoding step a widely adopted method is the Vector of Locally Aggregated Descriptors ( VLAD )	mechanism	2K_dev_1312
which is an efficient encoding method	mechanism	2K_dev_1312
however	mechanism	2K_dev_1312
it considers only the difference between local descriptors and their centroids	mechanism	2K_dev_1312
In this work we propose Shape Difference VLAD ( SD-VLAD )	mechanism	2K_dev_1312
an encoding method which brings complementary information by using the shape information within the encoding process	mechanism	2K_dev_1312
	mechanism	2K_dev_1312
and we propose also a real-time framework for action recognition	mechanism	2K_dev_1312
	mechanism	2K_dev_1312
We validated our proposed pipeline for action recognition on three challenging datasets UCF50	method	2K_dev_1312
UCF101 and HMDB51	method	2K_dev_1312
For building a powerful action recognition pipeline it is important that both steps are efficient and in the same time provide reliable performance for feature extraction and encoding	purpose	2K_dev_1312
As online fraudsters invest more resources	background	2K_dev_1313
including purchasing large pools of fake user accounts and dedicated IPs	background	2K_dev_1313
fraudulent attacks become less obvious and their detection becomes increasingly challenging	background	2K_dev_1313
showed that HoloScope achieved significant accuracy improvements on synthetic and real data	finding	2K_dev_1313
compared with state-of-the-art fraud detection methods	finding	2K_dev_1313
	finding	2K_dev_1313
Hence	mechanism	2K_dev_1313
we propose HoloScope	mechanism	2K_dev_1313
which uses information from graph topology and temporal spikes In terms of graph topology	mechanism	2K_dev_1313
we introduce `` contrast suspiciousness	mechanism	2K_dev_1313
'' a dynamic weighting approach	mechanism	2K_dev_1313
which allows us to more accurately detect fraudulent blocks	mechanism	2K_dev_1313
particularly low-density blocks	mechanism	2K_dev_1313
In terms of temporal spikes	mechanism	2K_dev_1313
HoloScope takes into account the sudden bursts and drops of fraudsters ' attacking patterns In addition	mechanism	2K_dev_1313
we provide theoretical bounds for how much this increases the time cost needed for fraudsters to conduct adversarial attacks Additionally	mechanism	2K_dev_1313
from the perspective of ratings	mechanism	2K_dev_1313
HoloScope incorporates the deviation of rating scores in order to catch fraudsters more accurately	mechanism	2K_dev_1313
Moreover	mechanism	2K_dev_1313
HoloScope has a concise framework and sub-quadratic time complexity	mechanism	2K_dev_1313
making the algorithm reproducible and scalable	mechanism	2K_dev_1313
Extensive experiments	method	2K_dev_1313
Existing approaches such as average degree maximization suffer from the bias of including more nodes than necessary	purpose	2K_dev_1313
resulting in lower accuracy and increased need for manual verification	purpose	2K_dev_1313
to more accurately detect groups of fraudulent users	purpose	2K_dev_1313
In comparison-shopping services ( CSS )	background	2K_dev_1314
there exist frauds who perform excessive clicks on a target item in order to boost the popularity of it	background	2K_dev_1314
	finding	2K_dev_1314
propose three anomaly scores designed based on click behaviors of users in CSS	mechanism	2K_dev_1314
	mechanism	2K_dev_1314
	method	2K_dev_1314
In this paper	purpose	2K_dev_1314
we introduce the problem of detecting frauds in CSS and	purpose	2K_dev_1314
As one of the featured initiatives in smart grids	background	2K_dev_1315
demand response is enabling active participation of electricity consumers in the supply/demand balancing process	background	2K_dev_1315
thereby enhancing the power systems operational flexibility in a costeffective way	background	2K_dev_1315
Industrial load plays an important role in demand response because of its intense power consumption	background	2K_dev_1315
already existing advanced monitoring and control infrastructure	background	2K_dev_1315
and its strong economic incentive due to the high energy costs	background	2K_dev_1315
As typical industrial loads	background	2K_dev_1315
cement plants are able to quickly adjust their power consumption rate by switching on/off the crushers	background	2K_dev_1315
	finding	2K_dev_1315
by proposing methods that enable these loads to provide regulation or load following with the support of an on-site energy storage system	mechanism	2K_dev_1315
	method	2K_dev_1315
However	purpose	2K_dev_1315
in the cement plant as well as other industrial loads	purpose	2K_dev_1315
switching on/off the loading units only achieves discrete power changes	purpose	2K_dev_1315
which restricts the load from offering valuable ancillary services such as regulation and load following	purpose	2K_dev_1315
as continuous power changes are required for these services	purpose	2K_dev_1315
In this paper	purpose	2K_dev_1315
we overcome this restriction of poor granularity	purpose	2K_dev_1315
Large graph datasets have caused renewed interest for graph partitioning	background	2K_dev_1316
	background	2K_dev_1316
	finding	2K_dev_1316
Towards this	mechanism	2K_dev_1316
we introduce the idea of skew-resistant graph partitioning	mechanism	2K_dev_1316
where Skewresistant graph partitioning tries to mitigate skewness by taking the characteristics of both the target workload and the graph structure into consideration	mechanism	2K_dev_1316
	mechanism	2K_dev_1316
	method	2K_dev_1316
However	purpose	2K_dev_1316
existing well-studied graph partitioners often assume that vertices of the graph are always active during the computation	purpose	2K_dev_1316
which may lead to time-varying skewness for traversal-style graph workloads	purpose	2K_dev_1316
like Breadth First Search	purpose	2K_dev_1316
since they only explore part of the graph in each superstep	purpose	2K_dev_1316
Additionally	purpose	2K_dev_1316
existing solutions do not consider what vertices each partition will have	purpose	2K_dev_1316
as a result	purpose	2K_dev_1316
high-degree vertices may be concentrated into a few partitions	purpose	2K_dev_1316
causing imbalance the objective is to create an initial partitioning that will `` hold well '' over time without suffering from skewness	purpose	2K_dev_1316
	purpose	2K_dev_1316
	background	2K_dev_1317
our evaluation shows that these algorithms are able to detect proxy use instances that would be difficult to find using existing techniques	finding	2K_dev_1317
and subsequently remove them while maintaining acceptable classification performance	finding	2K_dev_1317
This paper presents an approach In contrast to prior work	mechanism	2K_dev_1317
we focus on use restrictions on proxies ( i	mechanism	2K_dev_1317
e	mechanism	2K_dev_1317
strong predictors ) of protected information types Our definition relates proxy use to intermediate computations that occur in a program	mechanism	2K_dev_1317
and identify two essential properties that characterize this behavior : 1 ) its result is strongly associated with the protected information type in question	mechanism	2K_dev_1317
and 2 ) it is likely to causally affect the final output of the program	mechanism	2K_dev_1317
For a specific instantiation of this definition	mechanism	2K_dev_1317
we present a program analysis technique that detects instances of proxy use in a model	mechanism	2K_dev_1317
and provides a witness that identifies which parts of the corresponding program exhibit the behavior Recognizing that not all instances of proxy use of a protected information type are inappropriate	mechanism	2K_dev_1317
we make use of a normative judgment oracle that makes this inappropriateness determination for a given witness	mechanism	2K_dev_1317
Our repair algorithm uses the witness of an inappropriate proxy use to transform the model into one that provably does not exhibit proxy use	mechanism	2K_dev_1317
while avoiding changes that unduly affect classification accuracy	mechanism	2K_dev_1317
	mechanism	2K_dev_1317
Using a corpus of social datasets	method	2K_dev_1317
	method	2K_dev_1317
to formalizing and enforcing a class of use privacy properties in data-driven systems	purpose	2K_dev_1317
	background	2K_dev_1318
	finding	2K_dev_1318
	mechanism	2K_dev_1318
	method	2K_dev_1318
	purpose	2K_dev_1318
Learning video concept detectors automatically from the big but noisy web data with no additional manual annotations is a novel but challenging area in the multimedia and the machine learning community	background	2K_dev_1319
	background	2K_dev_1319
results demonstrate that WELL-MM outperforms state-of-the-art studies by a statically significant margin on learning concepts from noisy web video data	finding	2K_dev_1319
In addition	finding	2K_dev_1319
the results also verify that WELL-MM is robust to the level of noisiness in the video data	finding	2K_dev_1319
Notably	finding	2K_dev_1319
WELL-MM trained on sufficient noisy web labels is able to achieve a better accuracy to supervised learning methods trained on the clean manually labeled data	finding	2K_dev_1319
	finding	2K_dev_1319
We propose a novel method called Multi-modal WEbly-Labeled Learning ( WELL-MM )	mechanism	2K_dev_1319
which is established on the state-of-the-art machine learning algorithm inspired by the learning process of human	mechanism	2K_dev_1319
WELL-MM introduces a novel multi-modal approach to incorporate meaningful prior knowledge called curriculum from the noisy web videos	mechanism	2K_dev_1319
	mechanism	2K_dev_1319
We empirically study the curriculum constructed from the multi-modal features of the Internet videos and images The comprehensive experimental on FCVID and YFCC100M	method	2K_dev_1319
A considerable amount of videos on the web is associated with rich but noisy contextual information	purpose	2K_dev_1319
such as the title and other multi-modal information	purpose	2K_dev_1319
which provides weak annotations or labels about the video content	purpose	2K_dev_1319
To tackle the problem of large-scale noisy learning	purpose	2K_dev_1319
Summary Cryo-electron tomography ( cryo-ET ) captures the 3Delectron density distribution of macromolecular complexes in close to native state	background	2K_dev_1320
With the rapid advance of cryo-ET acquisition technologies	background	2K_dev_1320
it is possible to generate large numbers ( > 100	background	2K_dev_1320
000 ) of subtomograms	background	2K_dev_1320
each containing a macromolecular complex	background	2K_dev_1320
Often	background	2K_dev_1320
these subtomograms represent a heterogeneous sample due to variations in the structure and composition of a complex insitu form or because particles are a mixture of different complexes	background	2K_dev_1320
In this case subtomograms must be classified	background	2K_dev_1320
	finding	2K_dev_1320
This paper introduces an open source software platform	mechanism	2K_dev_1320
TomoMiner Its scalable and robust parallel processing allows efficient classification of tens to hundreds of thousands of subtomograms	mechanism	2K_dev_1320
In addition	mechanism	2K_dev_1320
TomoMiner provides a pre-configured TomoMinerCloud computing service permitting users without sufficient computing resources instant access to TomoMiners high-performance features	mechanism	2K_dev_1320
	method	2K_dev_1320
However	purpose	2K_dev_1320
classification of large numbers of subtomograms is a time-intensive task and often a limiting bottleneck for large-scale subtomogram classification	purpose	2K_dev_1320
template matching	purpose	2K_dev_1320
subtomogram averaging	purpose	2K_dev_1320
and alignment	purpose	2K_dev_1320
	purpose	2K_dev_1320
The Kinect sensing devices have been widely used in current Human-Computer Interaction entertainment	background	2K_dev_1321
The results show that our method has its advantage for motion detection in a real-time Kinect entertaining environment	finding	2K_dev_1321
In this paper	mechanism	2K_dev_1321
we tackle it by proposing a linear algorithm	mechanism	2K_dev_1321
which is augmented by feature interaction	mechanism	2K_dev_1321
The linear property guarantees its speed whereas feature interaction captures the higher order effect from the data to enhance its accuracy The Schatten-p norm is leveraged to integrate the main linear effect and the higher order nonlinear effect by mining the correlation between them	mechanism	2K_dev_1321
The resulted classification model is a desirable combination of speed and accuracy We propose a novel solution to solve our objective function	mechanism	2K_dev_1321
	mechanism	2K_dev_1321
Experiments are performed on three public Kinect-based entertainment data sets related to fitness and gaming	method	2K_dev_1321
	method	2K_dev_1321
A fundamental issue involved is to detect users motions accurately and quickly	purpose	2K_dev_1321
Different from general image localization task through matching	background	2K_dev_1322
the appearance of an environment during significant events varies greatly from its daily appearance	background	2K_dev_1322
since there are usually crowds	background	2K_dev_1322
decorations or even destruction when a major event happens	background	2K_dev_1322
	background	2K_dev_1322
Experimental results show that our solution significantly improves over matching on whole images and the automatically learned saliency is a strong predictor of distinctive building areas	finding	2K_dev_1322
Based on this observation	mechanism	2K_dev_1322
we formulate the problem as joint saliency estimation and matching at the image region level	mechanism	2K_dev_1322
as opposed to the key point or whole-image level	mechanism	2K_dev_1322
As image-level labels of daily environment are easily generated with GPS information	mechanism	2K_dev_1322
we treat region based saliency estimation and matching as a weakly labeled learning problem over the training data	mechanism	2K_dev_1322
Our solution is to iteratively optimize saliency and the region-matching model	mechanism	2K_dev_1322
For saliency optimization	mechanism	2K_dev_1322
we derive a closed form solution	mechanism	2K_dev_1322
which has an intuitive explanation	mechanism	2K_dev_1322
For region matching model optimization	mechanism	2K_dev_1322
we use self-paced learning to learn from the pseudo labels generated by ( sub-optimal ) saliency values	mechanism	2K_dev_1322
We conduct extensive experiments on two challenging public datasets : Boston Marathon 2013 and Tokyo Time Machine	method	2K_dev_1322
	method	2K_dev_1322
In this paper	purpose	2K_dev_1322
we study automatic geo-localization of online event videos This introduces a major challenge : matching the event environment to the daily environment	purpose	2K_dev_1322
e	purpose	2K_dev_1322
g	purpose	2K_dev_1322
as recorded by Google Street View	purpose	2K_dev_1322
We observe that some regions in the image	purpose	2K_dev_1322
as part of the environment	purpose	2K_dev_1322
still preserve the daily appearance even though the whole image ( environment ) looks quite different	purpose	2K_dev_1322
	purpose	2K_dev_1322
Utility maximization under a budget constraint is a classical problem in economics and management science	background	2K_dev_1323
It is commonly assumed that the utility is a `` nice '' known analytic function	background	2K_dev_1323
for example	background	2K_dev_1323
continuous and concave	background	2K_dev_1323
In many domains	background	2K_dev_1323
such as marketing	background	2K_dev_1323
increased availability of computational resources and data has enabled the development of sophisticated simulations to evaluate the impact of allocating a fixed budget among alternatives ( e	background	2K_dev_1323
g	background	2K_dev_1323
	background	2K_dev_1323
marketing channels ) on outcomes	background	2K_dev_1323
such as demand	background	2K_dev_1323
While simulations enable high resolution evaluation of alternative budget allocation strategies	background	2K_dev_1323
they significantly complicate the associated budget optimization problem	background	2K_dev_1323
demonstrates the effectiveness of our approach	finding	2K_dev_1323
by first converting the problem into a multi-choice knapsack optimization problem with unknown weights We show that if weights ( corresponding to marginal impact thresholds for each channel ) are well approximated	mechanism	2K_dev_1323
we can achieve a solution within a factor of 2 of optimal	mechanism	2K_dev_1323
and this bound is tight	mechanism	2K_dev_1323
We then develop several parsimonious query algorithms	mechanism	2K_dev_1323
Experimental evaluation	method	2K_dev_1323
In particular	purpose	2K_dev_1323
simulation runs are time consuming	purpose	2K_dev_1323
significantly limiting the space of options that can be explored	purpose	2K_dev_1323
An important second challenge is the common presence of budget complementarities	purpose	2K_dev_1323
where non-negligible budget increments are required for an appreciable marginal impact from a channel	purpose	2K_dev_1323
This introduces a combinatorial structure on the decision space We propose to address these challenges for achieving this approximation in an online fashion	purpose	2K_dev_1323
	purpose	2K_dev_1323
Deep generative models have achieved impressive success in recent years	background	2K_dev_1324
show generality and effectiveness of the imported extensions	finding	2K_dev_1324
through a new formulation of GANs and VAEs	mechanism	2K_dev_1324
We show that GANs and VAEs are essentially minimizing KL divergences with opposite directions and reversed latent/visible treatments	mechanism	2K_dev_1324
extending the two learning phases of classic wake-sleep algorithm	mechanism	2K_dev_1324
respectively	mechanism	2K_dev_1324
The unified view provides a powerful tool to analyze a diverse set of existing model variants	mechanism	2K_dev_1324
and enables to exchange ideas across research lines in a principled way For example	mechanism	2K_dev_1324
we transfer the importance weighting method in VAE literatures for improved GAN learning	mechanism	2K_dev_1324
and enhance VAEs with an adversarial mechanism	mechanism	2K_dev_1324
	mechanism	2K_dev_1324
Quantitative experiments	method	2K_dev_1324
Generative Adversarial Networks ( GANs ) and Variational Autoencoders ( VAEs )	purpose	2K_dev_1324
as powerful frameworks for deep generative model learning	purpose	2K_dev_1324
have largely been considered as two distinct paradigms and received extensive independent study respectively	purpose	2K_dev_1324
This paper establishes formal connections between deep generative modeling approaches	purpose	2K_dev_1324
In total	background	2K_dev_1325
this work substantially expands the scope and scale of problems that can be solved using semidefinite programming methods	background	2K_dev_1325
	background	2K_dev_1325
We show that for certain problems	finding	2K_dev_1325
the method is strictly decreasing and guaranteed to converge to a critical point	finding	2K_dev_1325
In all settings	finding	2K_dev_1325
we demonstrate improvement over the existing state of the art along various dimensions	finding	2K_dev_1325
In this paper	mechanism	2K_dev_1325
we propose a coordinate descent approach The approach	mechanism	2K_dev_1325
which we call the Mixing method	mechanism	2K_dev_1325
is extremely simple to implement	mechanism	2K_dev_1325
has no free parameters	mechanism	2K_dev_1325
and typically attains an order of magnitude or better improvement in optimization performance over the current state of the art	mechanism	2K_dev_1325
	mechanism	2K_dev_1325
We then apply the algorithm to three separate domains : solving the maximum cut semidefinite relaxation	method	2K_dev_1325
solving a ( novel ) maximum satisfiability relaxation	method	2K_dev_1325
and solving the GloVe word embedding optimization problem	method	2K_dev_1325
	method	2K_dev_1325
to low-rank structured semidefinite programming	purpose	2K_dev_1325
	purpose	2K_dev_1325
	background	2K_dev_1326
	finding	2K_dev_1326
	mechanism	2K_dev_1326
	method	2K_dev_1326
	purpose	2K_dev_1326
	background	2K_dev_1327
demonstrates that H-FUSE reconstructs the original data 30 81 % better than the least squares method	finding	2K_dev_1327
	finding	2K_dev_1327
We propose H-FUSE	mechanism	2K_dev_1327
a novel method that solves above problems by allowing injection of domain knowl- edge in a principled way	mechanism	2K_dev_1327
and turning the task into a well- defined optimization problem H-FUSE has the following desirable properties : ( a ) Effectiveness	mechanism	2K_dev_1327
recovering histori- cal data from aggregated reports with high accuracy ; ( b ) Self-awareness	mechanism	2K_dev_1327
providing an assessment of when the re- covery is not reliable ; ( c ) Scalability	mechanism	2K_dev_1327
computationally lin- ear on the size of the input data	mechanism	2K_dev_1327
	mechanism	2K_dev_1327
Experiments on the real data ( epidemiology counts from the Tycho project [ 13 ]	method	2K_dev_1327
In this paper	purpose	2K_dev_1327
we address the challenge of recovering a time sequence of counts from aggregated historical data	purpose	2K_dev_1327
For example	purpose	2K_dev_1327
given a mixture of the monthly and weekly sums	purpose	2K_dev_1327
how can we find the daily counts of people infected with flu ? In general	purpose	2K_dev_1327
what is the best way to recover historical counts from aggregated	purpose	2K_dev_1327
possibly overlapping historical reports	purpose	2K_dev_1327
in the presence of missing values ? Equally importantly	purpose	2K_dev_1327
how much should we trust this reconstruction ?	purpose	2K_dev_1327
Occupancy estimation is an important primitive for a wide range of applications including building energy efficiency	background	2K_dev_1328
safety	background	2K_dev_1328
and security	background	2K_dev_1328
we observe that FORK achieves over 99 % accuracy in real-time ( 4-9 FPS ) in occupancy estimation	finding	2K_dev_1328
	finding	2K_dev_1328
In this work	mechanism	2K_dev_1328
we develop a prototype system called FORK using off-the-shelf components that performs the entire depth data processing on a cheaper and low power ARM processor in real-time	mechanism	2K_dev_1328
As ARM processors are extremely weak in running computer vision algorithms	mechanism	2K_dev_1328
FORK is designed to detect humans and track them in a very efficient way by leveraging a novel lightweight model based approach instead of traditional approaches based on histogram of oriented gradients ( HOG ) features Unlike other camera based approaches	mechanism	2K_dev_1328
FORK is much less privacy invasive ( even if the sensor is compromised )	mechanism	2K_dev_1328
	mechanism	2K_dev_1328
Based on a complete implementation	method	2K_dev_1328
real-world deployment	method	2K_dev_1328
and extensive evaluation at realistic scenarios	method	2K_dev_1328
In this paper	purpose	2K_dev_1328
we explore the potential of using depth sensors to detect	purpose	2K_dev_1328
estimate	purpose	2K_dev_1328
identify	purpose	2K_dev_1328
and track occupants in buildings While depth sensors have been widely used for human detection and gesture recognition	purpose	2K_dev_1328
computer vision algorithms are typically run on a powerful computer like XBOX or Intel R CoreTM i7 processor	purpose	2K_dev_1328
	purpose	2K_dev_1328
	background	2K_dev_1329
	finding	2K_dev_1329
We present OpenFace	mechanism	2K_dev_1329
our new that approaches state-of-the-art accuracy	mechanism	2K_dev_1329
Integrating OpenFace with inter-frame tracking	mechanism	2K_dev_1329
we build RTFace	mechanism	2K_dev_1329
a mechanism that selectively blurs faces according to specified policies at full frame rates	mechanism	2K_dev_1329
This enables privacy management for live video analytics while providing a secure approach for handling retrospective policy exceptions	mechanism	2K_dev_1329
Finally	mechanism	2K_dev_1329
we present a scalable	mechanism	2K_dev_1329
privacy-aware architecture	mechanism	2K_dev_1329
	method	2K_dev_1329
open-source face recognition system for denaturing video streams for large camera networks using RTFace	purpose	2K_dev_1329
	purpose	2K_dev_1329
As video cameras proliferate	background	2K_dev_1330
the ability to scalably capture and search their data becomes important	background	2K_dev_1330
	finding	2K_dev_1330
In this setting	mechanism	2K_dev_1330
we describe interactive data exploration ( IDE )	mechanism	2K_dev_1330
which refers using predicates that may not have been part of any prior indexing We also describe a new technique called just-in-time indexing ( JITI ) that improves response times in IDE	mechanism	2K_dev_1330
	mechanism	2K_dev_1330
	method	2K_dev_1330
Scalability is improved by performing video analytics on cloudlets at the edge of the Internet	purpose	2K_dev_1330
and only shipping extracted index information and meta-data to the cloud	purpose	2K_dev_1330
to human-in-the-loop content-based retrospective search	purpose	2K_dev_1330
Due to the advent of active safety features and automated driving capabilities	background	2K_dev_1331
the complexity of embedded computing systems within automobiles continues to increase	background	2K_dev_1331
Such advanced driver assistance systems ( ADAS ) are inherently safetycritical and must tolerate failures in any subsystem	background	2K_dev_1331
Recent work has studied the use of software-based faulttolerance techniques that utilize task-level hot and cold standbys to tolerate fail-stop processor and task failures	background	2K_dev_1331
The benefit of using standbys is maximal when a task and any of its standbys obey the placement constraint of not being co-located on the same processor	background	2K_dev_1331
that saves at least one processor up to 40 % of the time relative to the best known heuristic to date	finding	2K_dev_1331
finds that our heuristic uses no more than one additional processor in most cases relative to an optimal allocation that we construct for evaluation purposes using a creative technique	finding	2K_dev_1331
	finding	2K_dev_1331
We propose based on a `` tiered '' placement constraint	mechanism	2K_dev_1331
and show that our heuristic produces a better task assignment We then introduce a task allocation algorithm that	mechanism	2K_dev_1331
for the first time to our knowledge	mechanism	2K_dev_1331
leverages the run-time attributes of cold standbys We have designed and implemented our software fault-tolerance framework in AUTOSAR	mechanism	2K_dev_1331
an automotive industry standard	mechanism	2K_dev_1331
	mechanism	2K_dev_1331
Our empirical study We use this implementation to provide an experimental evaluation of our task-level fault-tolerance features	method	2K_dev_1331
Finally	method	2K_dev_1331
we present an analysis of the worst-case behavior of our task recovery features	method	2K_dev_1331
	method	2K_dev_1331
However	purpose	2K_dev_1331
fault-tolerance in safety-critical systems has been traditionally supported by hardware replication	purpose	2K_dev_1331
which is prohibitively expensive in terms of cost	purpose	2K_dev_1331
weight	purpose	2K_dev_1331
and size for the automotive market	purpose	2K_dev_1331
a new heuristic	purpose	2K_dev_1331
Audience Participation Games challenge traditional assumptions about gameplay by blurring the line between audience and player	background	2K_dev_1332
allowing audience members to impact gameplay in a meaningful way	background	2K_dev_1332
Their recent rise in popularity has created new opportunities for game research and development Our results show the breadth of opportunities and challenges that designers face in creating engaging Audience Participation Games	background	2K_dev_1332
	background	2K_dev_1332
	finding	2K_dev_1332
we developed several versions of two prototype games as design probes We livestreamed them to an online audience in order	mechanism	2K_dev_1332
	method	2K_dev_1332
To better understand this design space	purpose	2K_dev_1332
to develop a framework for audience motivations and participation styles	purpose	2K_dev_1332
to explore ways in which mechanics can affect audience members ' sense of agency	purpose	2K_dev_1332
and to identify promising design spaces	purpose	2K_dev_1332
	background	2K_dev_1333
	finding	2K_dev_1333
	mechanism	2K_dev_1333
	method	2K_dev_1333
	purpose	2K_dev_1333
Nanosecond-level clock synchronization is a missing capability for many real-time applications like next-generation wireless systems that leverage spatial multiplexing to improve channel capacity and provide services like time-of-flight localization	background	2K_dev_1334
With finegrained synchronization	background	2K_dev_1334
both clock stability and propagation delays introduce significant sources of error	background	2K_dev_1334
	background	2K_dev_1334
to show a clock synchronization of better than five nanoseconds per hop with an average of 2	finding	2K_dev_1334
12 ns and a standard deviation of 0	finding	2K_dev_1334
84 ns	finding	2K_dev_1334
The platform is able to identify and avoid clock error in cases where there is heavy multi-path or non-Line-of-Sight signals	finding	2K_dev_1334
	finding	2K_dev_1334
In this paper	mechanism	2K_dev_1334
we introduce Pulsar	mechanism	2K_dev_1334
a wireless time transfer platform to better than five nanosecond between indoor or GPS-denied devices	mechanism	2K_dev_1334
Pulsar leverages a stable clock source derived from a Chip-Scale Atomic Clock ( CSAC ) along with an Ultra-WideBand ( UWB ) radio able to perform sub-nanosecond packet timestamping to estimate and correct for clock offsets	mechanism	2K_dev_1334
We design and evaluate a proof-ofconcept network-wide synchronization protocol for Pulsar that selects low-jitter links to both estimate the location of nodes and reduce cumulative synchronization error across multiple hops	mechanism	2K_dev_1334
The Pulsar platform and protocol together provide a phase synchronized one pulse per second ( 1PPS ) signal and 10 MHz reference clock that can be easily integrated with typical enduser applications like software-defined radios and communication systems	mechanism	2K_dev_1334
	mechanism	2K_dev_1334
We experimentally evaluate the Pulsar platform in terms of clock synchronization accuracy	method	2K_dev_1334
Allan deviation between pairwise clocks and ranging accuracy	method	2K_dev_1334
that can achieve clock synchronization	purpose	2K_dev_1334
	background	2K_dev_1335
We show that even though GAN optimization does not correspond to a convex-concave game	finding	2K_dev_1335
even for simple parameterizations	finding	2K_dev_1335
under proper conditions	finding	2K_dev_1335
equilibrium points of this optimization procedure are still locally asymptotically stable for the traditional GAN formulation	finding	2K_dev_1335
On the other hand	finding	2K_dev_1335
we show that the recently-proposed Wasserstein GAN can have non-convergent limit cycles near equilibrium	finding	2K_dev_1335
	finding	2K_dev_1335
Motivated by this stability analysis	mechanism	2K_dev_1335
we propose an additional regularization term for gradient descent GAN updates	mechanism	2K_dev_1335
	mechanism	2K_dev_1335
In this paper	method	2K_dev_1335
we analyze the `` gradient descent '' form of GAN optimization ( i	method	2K_dev_1335
e	method	2K_dev_1335
	method	2K_dev_1335
the natural setting where we simultaneously take small gradient steps in both generator and discriminator parameters )	method	2K_dev_1335
	method	2K_dev_1335
Despite their growing prominence	purpose	2K_dev_1335
optimization in generative adversarial networks ( GANs ) is still a poorly-understood topic which is able to guarantee local stability for both the WGAN and for the traditional GAN	purpose	2K_dev_1335
and also shows practical promise in speeding up convergence and addressing mode collapse	purpose	2K_dev_1335
	purpose	2K_dev_1335
Consider a stream of retweet events - how can we spot fraudulent lock-step behavior in such multi-aspect data ( i	background	2K_dev_1336
e	background	2K_dev_1336
	background	2K_dev_1336
tensors ) evolving over time ? Can we detect it in real time	background	2K_dev_1336
with an accuracy guarantee ? Past studies have shown that dense subtensors tend to indicate anomalous or even fraudulent behavior in many tensor data	background	2K_dev_1336
including social media	background	2K_dev_1336
Wikipedia	background	2K_dev_1336
and TCP dumps	background	2K_dev_1336
updates by our algorithms are up to a million times faster than the fastest batch algorithms Effective : our DENSESALERT successfully spots anomalies especially those overlooked by existing algorithms	finding	2K_dev_1336
	finding	2K_dev_1336
We propose DENSESTREAM	mechanism	2K_dev_1336
an incremental algorithm that maintains and updates a dense subtensor in a tensor stream ( i	mechanism	2K_dev_1336
e	mechanism	2K_dev_1336
	mechanism	2K_dev_1336
a sequence of changes in a tensor )	mechanism	2K_dev_1336
and DENSESALERT	mechanism	2K_dev_1336
an incremental algorithm spotting the sudden appearances of dense subtensors	mechanism	2K_dev_1336
Our algorithms are : ( 1 ) Fast and `` any time '' :	mechanism	2K_dev_1336
( 2 ) Provably accurate : our algorithms guarantee a lower bound on the density of the subtensor they maintain	mechanism	2K_dev_1336
and ( 3 )	mechanism	2K_dev_1336
in real-world tensors	method	2K_dev_1336
	method	2K_dev_1336
Thus	purpose	2K_dev_1336
several algorithms have been proposed for detecting dense subtensors rapidly and accurately	purpose	2K_dev_1336
However	purpose	2K_dev_1336
existing algorithms assume that tensors are static	purpose	2K_dev_1336
while many real-world tensors	purpose	2K_dev_1336
including those mentioned above	purpose	2K_dev_1336
evolve over time	purpose	2K_dev_1336
	purpose	2K_dev_1336
	background	2K_dev_1337
showed that depth continuity is a prerequisite for facilitation of Gabor target detection in the context of flanking Gabors	finding	2K_dev_1337
and that	finding	2K_dev_1337
similarly	finding	2K_dev_1337
surface continuity in purely disparity-defined slanted surfaces was strongly enhanced in distributed patch detections as a function of stimulus duration in this dual discrimination task	finding	2K_dev_1337
	finding	2K_dev_1337
showing that the perceptual processing of disparity and integration of 3D surface information across depth cues has time courses of several seconds	finding	2K_dev_1337
attesting to complexity of the neural processing hardware showed how surface reconstruction could be accomplished across the typically sparse depth information available	finding	2K_dev_1337
and integrated among sparse	finding	2K_dev_1337
incommensurate cue modalities	finding	2K_dev_1337
	finding	2K_dev_1337
in a computational model based on a novel Leaky Drift Diffusion Theory that we developed for the underlying neural signals	mechanism	2K_dev_1337
which can serve as an analytic basis for the time course of all neural decision processes	mechanism	2K_dev_1337
Three complementary computational modeling projects from three collaborating laboratories	mechanism	2K_dev_1337
Psychophysical studies The time course of depth surface perception was studied in a coordinated trio of psychophysical	method	2K_dev_1337
neurophysiological and functional imaging studies	method	2K_dev_1337
Abstract : The multidisciplinary goal was to develop an integrated conceptualization of the mid-level encoding of 3D object structure from multiple surface cues	purpose	2K_dev_1337
The unprecedented dips of performance reduction in the component psychometric functions was captured	purpose	2K_dev_1337
Deep learning models can take weeks to train on a single GPU-equipped machine	background	2K_dev_1338
necessitating scaling out DL training to a GPU-cluster	background	2K_dev_1338
We show that Poseidon is applicable to different DL frameworks We show that Poseidon enables Caffe and TensorFlow to achieve 15	finding	2K_dev_1338
5x speed-up on 16 single-GPU machines	finding	2K_dev_1338
even with limited bandwidth ( 10GbE ) and the challenging VGG19-22K network for image classification Moreover	finding	2K_dev_1338
Poseidon-enabled TensorFlow achieves 31	finding	2K_dev_1338
5x speed-up with 32 single-GPU machines on Inception-V3	finding	2K_dev_1338
a 50 % improvement over the open-source TensorFlow ( 20x speed-up	finding	2K_dev_1338
We present Poseidon	mechanism	2K_dev_1338
an efficient communication architecture Poseidon exploits the layered model structures in DL programs to overlap communication and computation	mechanism	2K_dev_1338
reducing bursty network communication Moreover	mechanism	2K_dev_1338
Poseidon uses a hybrid communication scheme that optimizes the number of bytes required to synchronize each layer	mechanism	2K_dev_1338
according to layer properties and the number of machines	mechanism	2K_dev_1338
by plugging Poseidon into Caffe and TensorFlow	method	2K_dev_1338
	method	2K_dev_1338
However	purpose	2K_dev_1338
current distributed DL implementations can scale poorly due to substantial parameter synchronization over the network	purpose	2K_dev_1338
because the high throughput of GPUs allows more data batches to be processed per unit time than CPUs	purpose	2K_dev_1338
leading to more frequent network synchronization for distributed DL on GPUs	purpose	2K_dev_1338
	purpose	2K_dev_1338
Recent advances in Unmanned Aerial Vehicles ( UAVs ) have enabled countless new applications in the domain of aerial sensing	background	2K_dev_1339
In scenarios such as intrusion detection	background	2K_dev_1339
target tracking and facility monitoring it is important to reach a given area of interest ( AOI )	background	2K_dev_1339
and create an online data streaming connection to a monitoring ground station ( GS ) for immediate delivery of content to the operator	background	2K_dev_1339
In previous work	background	2K_dev_1339
we showed that a multi-hop line network can increase the range of the mission by finding the optimal number of relay UAVs	background	2K_dev_1339
and their optimal placement	background	2K_dev_1339
	background	2K_dev_1339
	finding	2K_dev_1339
In this demo	mechanism	2K_dev_1339
we show that CSMA ( typical 802	mechanism	2K_dev_1339
11 's medium access protocol ) and that TDMA is a better alternative	mechanism	2K_dev_1339
We will also discuss how changing slot width online can overcome typical and less known TDMA inefficiencies	mechanism	2K_dev_1339
and therefore reach maximum end-to-end throughput and low delay	mechanism	2K_dev_1339
	method	2K_dev_1339
behaves poorly in this type of networks due to mutual interference	purpose	2K_dev_1339
	purpose	2K_dev_1339
Gaussian belief propagation ( BP ) has been widely used for distributed inference in large-scale networks such as the smart grid	background	2K_dev_1340
sensor networks	background	2K_dev_1340
and social networks	background	2K_dev_1340
where local measurements/observations are scattered over a wide geographical area One particular case is when two neighboring agents share a common observation	background	2K_dev_1340
For example	background	2K_dev_1340
to estimate voltage in the direct current ( DC ) power flow model	background	2K_dev_1340
the current measurement over a power line is proportional to the voltage difference between two neighboring buses	background	2K_dev_1340
	background	2K_dev_1340
that the updating information matrix converges at a geometric rate to a unique positive definite matrix with arbitrary positive semidefinite initial value and further provide the necessary and sufficient convergence condition for the belief mean vector to the optimal estimate	finding	2K_dev_1340
	finding	2K_dev_1340
of Gaussian BP for this pairwise linear Gaussian model	mechanism	2K_dev_1340
	mechanism	2K_dev_1340
We show analytically	method	2K_dev_1340
When applying the Gaussian BP algorithm to this type of problem	purpose	2K_dev_1340
the convergence condition remains an open issue	purpose	2K_dev_1340
In this paper	purpose	2K_dev_1340
we analyze the convergence properties	purpose	2K_dev_1340
Developing a remote exploit is not easy	background	2K_dev_1341
It requires a comprehensive understanding of a vulnerability and delicate techniques to bypass defense mechanisms	background	2K_dev_1341
As a result	background	2K_dev_1341
attackers may prefer to reuse an existing exploit and make necessary changes over developing a new exploit from scratch	background	2K_dev_1341
One such adaptation is the replacement of the original shellcode ( i	background	2K_dev_1341
e	background	2K_dev_1341
	background	2K_dev_1341
the attacker-injected code that is executed as the final step of the exploit ) in the original exploit with a replacement shellcode	background	2K_dev_1341
resulting in a modified exploit that carries out the actions desired by the attacker as opposed to the original exploit author	background	2K_dev_1341
We call this a shellcode transplant	background	2K_dev_1341
	background	2K_dev_1341
Among the 100 test cases	finding	2K_dev_1341
our system successfully generated 88 % of the exploits	finding	2K_dev_1341
	finding	2K_dev_1341
we present ShellSwap	mechanism	2K_dev_1341
a system that uses symbolic tracing	mechanism	2K_dev_1341
with a combination of shellcode layout remediation and path kneading	mechanism	2K_dev_1341
We evaluated the ShellSwap system on a combination of 20 exploits and 5 pieces of shellcode that are independently developed and different from the original exploit	method	2K_dev_1341
Current automated shellcode placement methods are insufficient because they over-constrain the replacement shellcode	purpose	2K_dev_1341
and so can not be used to achieve shellcode transplant	purpose	2K_dev_1341
For example	purpose	2K_dev_1341
these systems consider the shellcode as an integrated memory chunk and require that the execution path of the modified exploit must be same as the original one	purpose	2K_dev_1341
To resolve these issues	purpose	2K_dev_1341
to achieve shellcode transplant	purpose	2K_dev_1341
The availability of large idea repositories ( e	background	2K_dev_1342
g	background	2K_dev_1342
	background	2K_dev_1342
the U	background	2K_dev_1342
S	background	2K_dev_1342
patent database ) could significantly accelerate innovation and discovery by providing people with inspiration from solutions to analogous problems Our results suggest a promising approach to enabling computational analogy at scale is to learn and leverage weaker structural representations	background	2K_dev_1342
	background	2K_dev_1342
We demonstrate that these learned vectors allow us to find analogies with higher precision and recall than traditional information-retrieval methods	finding	2K_dev_1342
analogies retrieved by our models significantly increased people 's likelihood of generating creative ideas compared to analogies retrieved by traditional methods	finding	2K_dev_1342
	finding	2K_dev_1342
specifically	mechanism	2K_dev_1342
`` problem schemas ''	mechanism	2K_dev_1342
which specify the purpose of a product and the mechanisms by which it achieves that purpose	mechanism	2K_dev_1342
Our approach combines crowdsourcing and recurrent neural networks to extract purpose and mechanism vector representations from product descriptions	mechanism	2K_dev_1342
	mechanism	2K_dev_1342
In an ideation experiment	method	2K_dev_1342
	method	2K_dev_1342
However	purpose	2K_dev_1342
finding useful analogies in these large	purpose	2K_dev_1342
messy	purpose	2K_dev_1342
real-world repositories remains a persistent challenge for either human or automated methods	purpose	2K_dev_1342
Previous approaches include costly hand-created databases that have high relational structure ( e	purpose	2K_dev_1342
g	purpose	2K_dev_1342
	purpose	2K_dev_1342
predicate calculus representations ) but are very sparse	purpose	2K_dev_1342
Simpler machine-learning/information-retrieval similarity metrics can scale to large	purpose	2K_dev_1342
natural-language datasets	purpose	2K_dev_1342
but struggle to account for structural similarity	purpose	2K_dev_1342
which is central to analogy	purpose	2K_dev_1342
In this paper we explore the viability and value of learning simpler structural representations	purpose	2K_dev_1342
	purpose	2K_dev_1342
Our results significantly expand knowledge of eutherian genome evolution and will facilitate greater understanding of the role of chromosome rearrangements in adaptation	background	2K_dev_1343
speciation	background	2K_dev_1343
and the etiology of inherited and spontaneously occurring diseases	background	2K_dev_1343
Orangutan was found to have eight chromosomes that were completely conserved in homologous sequence order and orientation with the eutherian ancestor	finding	2K_dev_1343
the largest number for any species	finding	2K_dev_1343
Ruminant artiodactyls had the highest frequency of intrachromosomal rearrangements	finding	2K_dev_1343
and interchromosomal rearrangements dominated in murid rodents	finding	2K_dev_1343
A total of 162 chromosomal breakpoints in evolution of the eutherian ancestral genome to the human genome were identified ; however	finding	2K_dev_1343
the rate of rearrangements was significantly lower ( 0	finding	2K_dev_1343
80/My ) during the first 60 My of eutherian evolution	finding	2K_dev_1343
then increased to greater than 2	finding	2K_dev_1343
0/My along the five primate lineages studied	finding	2K_dev_1343
	finding	2K_dev_1343
we developed an algorithm ( DESCHRAMBLER ) that probabilistically determines the adjacencies of syntenic fragments using chromosome-scale and fragmented genome assemblies	mechanism	2K_dev_1343
The reconstructed chromosomes of the eutherian	mechanism	2K_dev_1343
boreoeutherian	mechanism	2K_dev_1343
and euarchontoglires ancestor each included > 80 % of the entire length of the human genome	mechanism	2K_dev_1343
whereas reconstructed chromosomes of the most recent common ancestor of simians	mechanism	2K_dev_1343
catarrhini	mechanism	2K_dev_1343
great apes	mechanism	2K_dev_1343
and humans and chimpanzees included > 90 % of human genome sequence These high-coverage reconstructions permitted reliable identification of chromosomal rearrangements over 105 My of eutherian evolution	mechanism	2K_dev_1343
	method	2K_dev_1343
Abstract Whole-genome assemblies of 19 placental mammals and two outgroup species were used to reconstruct the order and orientation of syntenic fragments in chromosomes of the eutherian ancestor and six other descendant ancestors leading to human	purpose	2K_dev_1343
For ancestral chromosome reconstructions	purpose	2K_dev_1343
With the explosion in the availability of user-generated videos documenting any conflicts and human rights abuses around the world	background	2K_dev_1344
analysts and researchers increasingly find themselves overwhelmed with massive amounts of video data to acquire and analyze useful information	background	2K_dev_1344
	background	2K_dev_1344
We show our framework 's efficacy on localizing intense audio event like gunshot	finding	2K_dev_1344
and further experiments also indicate that our methods can be generalized to localizing other audio events in noisy videos	finding	2K_dev_1344
	finding	2K_dev_1344
In this paper	mechanism	2K_dev_1344
we develop a temporal localization framework The proposed method utilizes Localized Self-Paced Reranking ( LSPaR ) to refine the localization results LSPaR utilizes samples from easy to noisier ones so that it can overcome the noisiness of the initial retrieval results from user-generated videos	mechanism	2K_dev_1344
	mechanism	2K_dev_1344
	method	2K_dev_1344
for intense audio events in videos which addresses the problem	purpose	2K_dev_1344
	purpose	2K_dev_1344
Previous work has replaced structural assumptions on the noise with a worst-case approach that aims to choose an outcome that minimizes the maximum error with respect to any feasible true ranking	background	2K_dev_1345
This approach underlies algorithms that have recently been deployed on the social choice website RoboVote	background	2K_dev_1345
org	background	2K_dev_1345
	background	2K_dev_1345
We derive ( mostly sharp ) analytical bounds on the expected error and establish the practical benefits of our approach	finding	2K_dev_1345
We take a less conservative viewpoint by minimizing the average error with respect to the set of feasible ground truth rankings	mechanism	2K_dev_1345
	mechanism	2K_dev_1345
through experiments	method	2K_dev_1345
We revisit the classic problem of designing voting rules that aggregate objective opinions	purpose	2K_dev_1345
in a setting where voters have noisy estimates of a true ranking of the alternatives	purpose	2K_dev_1345
	purpose	2K_dev_1345
Low-income families pay substantial portions of their total expenditure on household energy bills	background	2K_dev_1346
making them vulnerable to rising energy costs Habitat for Humanity houses are built for low-income families and made affordable with volunteer work and construction material donations While specific enclosure suggestions apply to this case-study	background	2K_dev_1346
the utilized approach on exploring different options to identify opportunities to save energy can be used to understand impact on the lives of low-income families	background	2K_dev_1346
The results show that it is possible to reduce the energy cost of these houses without significantly increasing the construction costs through exploration of different wall and window options	finding	2K_dev_1346
	finding	2K_dev_1346
In collaboration with Habitat for Humanity of Westchester	mechanism	2K_dev_1346
we created an energy simulation model of an existing low-income house and calculated the homeOs annual energy usage with different design alternatives for windows and walls	mechanism	2K_dev_1346
	mechanism	2K_dev_1346
The resulting estimated annual energy savings are then evaluated alongside their initial investment costs	method	2K_dev_1346
which were retrieved from RS Means standard construction cost data and quotations from industry	method	2K_dev_1346
	method	2K_dev_1346
Hence	purpose	2K_dev_1346
the trade-off between the homesO initial construction costs and their life-time energy costs must be evaluated carefully	purpose	2K_dev_1346
This paper targets to support better-informed decisions that balance the affordability of certain construction materials with their potential for energy efficiency	purpose	2K_dev_1346
It is known that such allocations can be computed using O ( n ln ( 1/e ) ) operations in the standard Robertson-Webb Model	background	2K_dev_1347
implies that allocations that are exactly equitable can not be computed	background	2K_dev_1347
	background	2K_dev_1347
Importantly	finding	2K_dev_1347
our result	finding	2K_dev_1347
We establish a lower bound of ( ln ( 1/e ) /lnln ( 1/e ) ) on the complexity of this problem	mechanism	2K_dev_1347
which is almost tight for a constant number of players	mechanism	2K_dev_1347
	method	2K_dev_1347
We are interested in the problem of dividing a cake -- a heterogeneous divisible good -- among n players	purpose	2K_dev_1347
in a way that is e- equitable : every pair of players must have the same value for their own allocated pieces	purpose	2K_dev_1347
up to a difference of at most e	purpose	2K_dev_1347
	purpose	2K_dev_1347
In the era of social media	background	2K_dev_1348
a large number of user-generated videos are uploaded to the Internet every day	background	2K_dev_1348
capturing events all over the world	background	2K_dev_1348
show that the proposed method achieves excellent precision and robustness	finding	2K_dev_1348
In this paper	mechanism	2K_dev_1348
we propose a hierarchical approach Our system utilizes clustered audio-signatures to align video pairs	mechanism	2K_dev_1348
Global alignment for all videos is then achieved via forming alignable video groups with self-paced learning	mechanism	2K_dev_1348
Experiments on the Boston Marathon dataset	method	2K_dev_1348
Reconstructing the event truth based on information mined from these videos has been an emerging challenging task Temporal alignment of videos in the wild which capture different moments at different positions with different perspectives is the critical step to synchronize videos	purpose	2K_dev_1348
	purpose	2K_dev_1348
Mainstream crowdwork platforms treat microtasks as indivisible units We reflect on the implications of these findings for the design of future crowd work platforms that effectively harness the potential of subcontracting workflows	background	2K_dev_1349
Finally	finding	2K_dev_1349
we describe the outcome of two tasks on Mechanical Turk meant to simulate aspects of subcontracting	finding	2K_dev_1349
	finding	2K_dev_1349
: real-time assistance	mechanism	2K_dev_1349
task management	mechanism	2K_dev_1349
and task improvement	mechanism	2K_dev_1349
and reflect on potential use cases and implementation considerations associated with each	mechanism	2K_dev_1349
After describing the value proposition of subcontracting	method	2K_dev_1349
we then define three models for microtask subcontracting	method	2K_dev_1349
; however	purpose	2K_dev_1349
in this article	purpose	2K_dev_1349
we propose that there is value in re-examining this assumption We argue that crowdwork platforms can improve their value proposition for all stakeholders by supporting subcontracting within microtasks	purpose	2K_dev_1349
	purpose	2K_dev_1349
	background	2K_dev_1350
	finding	2K_dev_1350
	mechanism	2K_dev_1350
	method	2K_dev_1350
	purpose	2K_dev_1350
The world is full of physical interfaces that are inaccessible to blind people	background	2K_dev_1351
from microwaves and information kiosks to thermostats and checkout terminals	background	2K_dev_1351
Blind people can not independently use such devices without at least first learning their layout	background	2K_dev_1351
and usually only after labeling them with sighted assistance	background	2K_dev_1351
	background	2K_dev_1351
	finding	2K_dev_1351
we introduce VizLens -- -a robust and interactive screen reader for interfaces in the real world	mechanism	2K_dev_1351
VizLens users take a picture of an interface they would like to use	mechanism	2K_dev_1351
it is interpreted quickly and robustly by multiple crowd workers in parallel	mechanism	2K_dev_1351
and then computer vision is able to give interactive feedback and guidance to users to help them use the interface in real time Built on top of VizLens	mechanism	2K_dev_1351
we developed automatically generating tactile overlays to physical interfaces to provide blind people with a permanent static solution	mechanism	2K_dev_1351
	mechanism	2K_dev_1351
We introduce Facade -- -a crowdsourced fabrication pipeline to help blind people independently make physical interfaces accessible by adding a 3D printed augmentation of tactile buttons overlaying the original panel	method	2K_dev_1351
	method	2K_dev_1351
To address this problem	purpose	2K_dev_1351
	purpose	2K_dev_1351
Crowd work is an increasingly prevalent and important kind of work	background	2K_dev_1352
Because of its flexible nature	background	2K_dev_1352
crowd work may offer benefits for people with disabilities Given ongoing and upcoming changes to the world economy and technological progress	background	2K_dev_1352
we believe it is important to find a way to make sure people with disabilities are able to equally participate in this kind of work	background	2K_dev_1352
	finding	2K_dev_1352
	mechanism	2K_dev_1352
In this paper	method	2K_dev_1352
we first characterize the accessibility of the tasks posted to a popular crowd marketplace	method	2K_dev_1352
Amazon Mechanical Turk	method	2K_dev_1352
by performing manual and automatic checks on 120 tasks from several common types	method	2K_dev_1352
We then outline research directions that could have positive impact on this problem	method	2K_dev_1352
Unfortunately	purpose	2K_dev_1352
people with disabilities currently lack access to much of this work because the tasks that are posted are often inaccessible	purpose	2K_dev_1352
Providing navigation assistance to people with visual impairments often requires augmenting the environment with after-market technology	background	2K_dev_1353
	background	2K_dev_1353
	finding	2K_dev_1353
LuzDeploy is a computational method We use LuzDeploy to orchestrate volunteers to install physical infrastructure for the navigation assistance of people with visual impairments Our system provides on-the-go enrollment so that volunteers can participate to the collective action whenever they have time	mechanism	2K_dev_1353
coming and leaving as needed	mechanism	2K_dev_1353
Providing automated instructions also allows to avoid instructing participants directly	mechanism	2K_dev_1353
so experts do not need to be available on-site	mechanism	2K_dev_1353
	mechanism	2K_dev_1353
	method	2K_dev_1353
However	purpose	2K_dev_1353
installing navigation infrastructure in large environments requires a critical mass of trained personnel	purpose	2K_dev_1353
Recruiting	purpose	2K_dev_1353
training and managing participants for such a task is difficult	purpose	2K_dev_1353
to recruit	purpose	2K_dev_1353
instruct and orchestrate volunteers to perform physical crowdsourcing tasks	purpose	2K_dev_1353
	purpose	2K_dev_1353
What can humans compute in their heads ? We are thinking of a variety of Crypto Protocols	background	2K_dev_1354
games like Sudoku	background	2K_dev_1354
Crossword Puzzles	background	2K_dev_1354
Speed Chess	background	2K_dev_1354
and so on	background	2K_dev_1354
	finding	2K_dev_1354
we propose a rigorous model of human computation and associated measures of complexity We apply the model and measures first and foremost to the problem of ( 1 ) humanly computable password generation	mechanism	2K_dev_1354
and then consider related problems of ( 2 ) humanly computable `` one-way functions '' and ( 3 ) humanly computable `` pseudorandom generators '' The theory of Human Computability developed here plays by different rules than standard computability	mechanism	2K_dev_1354
and this takes some getting used to For reasons to be made clear	mechanism	2K_dev_1354
the polynomial versus exponential time divide of modern computability theory is irrelevant to human computation In human computability	mechanism	2K_dev_1354
the step-counts for both humans and computers must be more concrete	mechanism	2K_dev_1354
Specifically	mechanism	2K_dev_1354
we restrict the adversary to at most 10^24 ( Avogadro number of ) steps	mechanism	2K_dev_1354
An alternate view of this work is that it deals with the analysis of algorithms and counting steps for the case that inputs are small as opposed to the usual case of inputs large-in-the-limit	mechanism	2K_dev_1354
	method	2K_dev_1354
The intent of this paper is to apply the ideas and methods of theoretical computer science to better understand what humans can compute in their heads	purpose	2K_dev_1354
For example	purpose	2K_dev_1354
can a person compute a function in their head so that an eavesdropper with a powerful computer -- - who sees the responses to random input -- - still can not infer responses to new inputs ? To address such questions	purpose	2K_dev_1354
	purpose	2K_dev_1354
How do the k-core structures of real-world graphs look like ? What are the common patterns and the anomalies ? How can we exploit them for applications ? A k-core is the maximal subgraph in which all vertices have degree at least k	background	2K_dev_1355
This concept has been applied to such diverse areas as hierarchical structure analysis	background	2K_dev_1355
graph visualization	background	2K_dev_1355
and graph clustering	background	2K_dev_1355
Our discoveries are : ( 1 ) Mirror Pattern : coreness ( i	finding	2K_dev_1355
e	finding	2K_dev_1355
	finding	2K_dev_1355
maximum k such that each vertex belongs to the k-core ) is strongly correlated with degree	finding	2K_dev_1355
( 2 ) Core-Triangle Pattern : degeneracy ( i	finding	2K_dev_1355
e	finding	2K_dev_1355
	finding	2K_dev_1355
maximum k such that the k-core exists ) obeys a 3-to-1 power-law with respect to the count of triangles	finding	2K_dev_1355
( 3 ) Structured Core Pattern : degeneracycores are not cliques but have non-trivial structures such as coreperiphery and communities	finding	2K_dev_1355
	finding	2K_dev_1355
Our algorithmic contributions show the usefulness of these patterns	mechanism	2K_dev_1355
( 1 ) Core-A	mechanism	2K_dev_1355
which measures the deviation from Mirror Pattern	mechanism	2K_dev_1355
successfully spots anomalies in real-world graphs	mechanism	2K_dev_1355
( 2 ) Core-D	mechanism	2K_dev_1355
a single-pass streaming algorithm based on Core-Triangle Pattern	mechanism	2K_dev_1355
accurately estimates degeneracy up to 12\ ( \times \ ) faster than its competitor ( 3 ) Core-S	mechanism	2K_dev_1355
inspired by Structured Core Pattern	mechanism	2K_dev_1355
identifies influential spreaders up to 17\ ( \times \ ) faster than its competitors with comparable accuracy	mechanism	2K_dev_1355
	method	2K_dev_1355
Here	purpose	2K_dev_1355
we explore pervasive patterns related to k-cores and emerging in graphs from diverse domains	purpose	2K_dev_1355
	purpose	2K_dev_1355
Systems for providing mixed physical-virtual interaction on desktop surfaces have been proposed for decades	background	2K_dev_1356
though no such systems have achieved widespread use	background	2K_dev_1356
	background	2K_dev_1356
	finding	2K_dev_1356
demonstrating their imminent feasibility	finding	2K_dev_1356
	finding	2K_dev_1356
	mechanism	2K_dev_1356
In this paper	method	2K_dev_1356
we use an elicitation study and interviews to synthesize a list of ten interactive behaviors that desk-bound	method	2K_dev_1356
digital interfaces should implement to support responsive cohabitation with physical objects As a proof of concept	method	2K_dev_1356
we implemented these interactive behaviors in a working augmented desk system	method	2K_dev_1356
One major factor contributing to this lack of acceptance may be that these systems are not designed for the variety and complexity of actual work surfaces	purpose	2K_dev_1356
which are often in flux and cluttered with physical objects	purpose	2K_dev_1356
	purpose	2K_dev_1356
Given a bipartite graph of users and the products that they review	background	2K_dev_1357
or followers and followees	background	2K_dev_1357
how can we detect fake reviews or follows ? Existing fraud detection methods ( spectral	background	2K_dev_1357
etc	background	2K_dev_1357
) try to identify dense subgraphs of nodes that are sparsely connected to the remaining graph	background	2K_dev_1357
Fraudsters can evade these methods using camouflage	background	2K_dev_1357
by adding reviews or follows with honest targets so that they look normal	background	2K_dev_1357
Even worse	background	2K_dev_1357
some fraudsters use hijacked accounts from honest users	background	2K_dev_1357
and then the camouflage is indeed organic	background	2K_dev_1357
show that FRAUDAR outperforms the top competitor in accuracy of detecting both camouflaged and non-camouflaged fraud FRAUDAR successfully detected a subgraph of more than 4	finding	2K_dev_1357
000 detected accounts	finding	2K_dev_1357
of which a majority had tweets showing that they used follower-buying services	finding	2K_dev_1357
	finding	2K_dev_1357
We propose FRAUDAR	mechanism	2K_dev_1357
an algorithm that ( a ) is camouflage resistant	mechanism	2K_dev_1357
( b ) provides upper bounds on the effectiveness of fraudsters	mechanism	2K_dev_1357
and ( c ) is effective in real-world data	mechanism	2K_dev_1357
	mechanism	2K_dev_1357
Experimental results under various attacks Additionally	method	2K_dev_1357
in real-world experiments with a Twitter follower -- followee graph of 1	method	2K_dev_1357
47 billion edges	method	2K_dev_1357
	method	2K_dev_1357
Our focus is to spot fraudsters in the presence of camouflage or hijacked accounts	purpose	2K_dev_1357
	background	2K_dev_1358
show that our approach is capable of handling model and data scales which are several orders of magnitude larger than existing correlation results	finding	2K_dev_1358
without sacrificing modeling quality by providing competitive or superior performance in document classification and retrieval	finding	2K_dev_1358
In this paper	mechanism	2K_dev_1358
we propose a new model through the closeness between the topic vectors	mechanism	2K_dev_1358
Our method enables efficient inference in the low-dimensional embedding space	mechanism	2K_dev_1358
reducing previous cubic or quadratic time complexity to linear w	mechanism	2K_dev_1358
r	mechanism	2K_dev_1358
t the topic size	mechanism	2K_dev_1358
We further speedup variational inference with a fast sampler to exploit sparsity of topic occurrence	mechanism	2K_dev_1358
	mechanism	2K_dev_1358
Extensive experiments	method	2K_dev_1358
Correlated topic modeling has been limited to small model and problem sizes due to their high computational cost and poor scaling which learns compact topic embeddings and captures topic correlations	purpose	2K_dev_1358
	background	2K_dev_1359
	finding	2K_dev_1359
	mechanism	2K_dev_1359
	method	2K_dev_1359
	purpose	2K_dev_1359
Intelligent personalization systems are becoming increasingly reliant on contextually-relevant devices and services	background	2K_dev_1360
such as those available within modern IoT deployments	background	2K_dev_1360
An IoT context may emerge -- -or become pervasive -- -when the intelligent system generates knowledge from dialogue-based interactions with the end-user ; the context is strengthened even further by incorporating state representations about the environment ( e	background	2K_dev_1360
g	background	2K_dev_1360
	background	2K_dev_1360
generated from wireless sensor data ) into the knowledge graph	background	2K_dev_1360
This is crucial for pervasive applications like digital assistance in IoT	background	2K_dev_1360
where context-aware systems need to adapt quickly : activities like leaving work home-bound	background	2K_dev_1360
driving to the grocery store	background	2K_dev_1360
arriving at home	background	2K_dev_1360
and walking the dog	background	2K_dev_1360
for example	background	2K_dev_1360
can occur in a relatively short period of time -- -during which an intelligent assistant must be able to support user requests in a consistent and coherent manner	background	2K_dev_1360
Given that computational ontologies can serve as semantic models for heterogeneous data	background	2K_dev_1360
they are becoming increasingly viable for reasoning across different IoT contexts	background	2K_dev_1360
This involves : ( a ) federation and dynamic pruning of multiple modular ontologies	background	2K_dev_1360
ideally	background	2K_dev_1360
to comprehensively capture only the knowledge that will facilitate execution of a multi-context task ; ( b ) fast consistency-checking and ontology-based inferences	background	2K_dev_1360
aided by rules-based execution environments that can evaluate/transform ambient wireless sensor network ( WSN ) data	background	2K_dev_1360
in real-time ; and ( c ) run-time execution of ontology-based control procedures	background	2K_dev_1360
through rule-engine actuation commands sent across the WSN The approach we describe is also partially based on the Ubiquitous Personal Assistant ( UPA ) project	background	2K_dev_1360
Bosch Research 's largest research initiative worldwide	background	2K_dev_1360
Preliminary results are also discussed	finding	2K_dev_1360
In this poster	mechanism	2K_dev_1360
we illustrate how a multi-context knowledge base can be structured on the basis of modular ontologies and integrated with a distributed rules-based inference engine in multiple smart-building environments	mechanism	2K_dev_1360
This work is conducted through the partnership of Bosch Research Pittsburgh and Carnegie Mellon University ( CMU )	method	2K_dev_1360
and is in partial satisfaction of CMU 's Bosch Energy Research Network ( BERN ) grant	method	2K_dev_1360
awarded for developments in intelligent building solutions	method	2K_dev_1360
	method	2K_dev_1360
Only by realizing these functionalities may intelligent systems be capable of reasoning over device properties	purpose	2K_dev_1360
system states	purpose	2K_dev_1360
and user activities	purpose	2K_dev_1360
while appropriately delegating commands to other intelligent agents or other relevant IoT services in order to enable scalable contextual reasoning for intelligent assistance	purpose	2K_dev_1360
	purpose	2K_dev_1360
Audio transcription is an important task for making content accessible to people who are deaf or hard of hearing	background	2K_dev_1361
Much of the transcription work is increasingly done by crowd workers	background	2K_dev_1361
people online who pick up the work as it becomes available often in small bits at a time Whereas work typically provides a ladder for skill development -- a series of opportunities to acquire new skills that lead to advancement -- crowd transcription work generally does not	background	2K_dev_1361
Our research demonstrates a new way for workers on crowd platforms to align their work and skill development with the accessibility domain while they work	background	2K_dev_1361
	background	2K_dev_1361
We show that Scopist can distinguish touch-typing from stenotyping with 94 % accuracy	finding	2K_dev_1361
we created Scopist	mechanism	2K_dev_1361
a JavaScript application for learning an efficient text-entry method known as stenotype while doing audio transcription tasks	mechanism	2K_dev_1361
Scopist facilitates on-the-job learning to prepare crowd workers for remote	mechanism	2K_dev_1361
real-time captioning by supporting both touch-typing and chording Real-time captioning is a difficult skill to master but is important for making live events accessible	mechanism	2K_dev_1361
	mechanism	2K_dev_1361
We conducted 3 crowd studies of Scopist focusing on Scopist 's performance and support for learning	method	2K_dev_1361
	method	2K_dev_1361
To demonstrate how crowd work might create a skill ladder	purpose	2K_dev_1361
Situational awareness involves the timely acquisition of knowledge about real-world events	background	2K_dev_1362
distillation of those events into higher-level conceptual constructs	background	2K_dev_1362
and their synthesis into a coherent context-sensitive view	background	2K_dev_1362
	background	2K_dev_1362
	finding	2K_dev_1362
We explore how convergent trends in video sensing	mechanism	2K_dev_1362
crowd sourcing and edge computing can be harnessed to create a shared real-time information system	mechanism	2K_dev_1362
	method	2K_dev_1362
for situational awareness in vehicular systems that span driverless and drivered vehicles	purpose	2K_dev_1362
	purpose	2K_dev_1362
	background	2K_dev_1363
	finding	2K_dev_1363
	mechanism	2K_dev_1363
	method	2K_dev_1363
	purpose	2K_dev_1363
Social media has become a popular and important tool for human communication	background	2K_dev_1364
However	background	2K_dev_1364
due to this popularity	background	2K_dev_1364
spam and the distribution of malicious content by computer-controlled users	background	2K_dev_1364
known as bots	background	2K_dev_1364
has become a widespread problem	background	2K_dev_1364
At the same time	background	2K_dev_1364
when users use social media	background	2K_dev_1364
they generate valuable data that can be used to understand the patterns of human communication	background	2K_dev_1364
	background	2K_dev_1364
is characterized by following four patterns : ( i ) heavy-tails	finding	2K_dev_1364
( ii ) periodic-spikes	finding	2K_dev_1364
( iii ) correlation between consecutive values	finding	2K_dev_1364
and ( iv ) bimodallity	finding	2K_dev_1364
Our experiments show that Act-M provides a more accurate fit to the data than existing models for human dynamics	finding	2K_dev_1364
Additionally	finding	2K_dev_1364
when detecting bots	finding	2K_dev_1364
Act-M provided a precision higher than 93 % and 77 % with a sensitivity of 70 % for the Twitter and Reddit datasets	finding	2K_dev_1364
respectively	finding	2K_dev_1364
	finding	2K_dev_1364
As our second contribution	mechanism	2K_dev_1364
we propose a mathematical model named Act-M ( Activity Model ) We show that Act-M can accurately from social media users Finally	mechanism	2K_dev_1364
we use Act-M to develop a method	mechanism	2K_dev_1364
The first contribution of this article is showing that the distribution of inter-arrival times ( IATs ) between postings We validate Act-M using data from over 55 million postings from four social media services : Reddit	method	2K_dev_1364
Twitter	method	2K_dev_1364
Stack-Overflow	method	2K_dev_1364
and Hacker-News	method	2K_dev_1364
	method	2K_dev_1364
In this article	purpose	2K_dev_1364
we focus on the following important question : Can we identify and use patterns of human communication to decide whether a human or a bot controls a user ? fit the distribution of IATs that detects if users are bots based only on the timing of their postings	purpose	2K_dev_1364
	purpose	2K_dev_1364
	background	2K_dev_1365
demonstrate that our approach significantly outperforms the compared baselines	finding	2K_dev_1365
In this work	mechanism	2K_dev_1365
we introduce Video Question Answering in the temporal domain We present an encoderdecoder approach using Recurrent Neural Networks to learn the temporal structures of videos and introduce a dual-channel ranking loss to answer multiple-choice questions	mechanism	2K_dev_1365
In addition	mechanism	2K_dev_1365
390	mechanism	2K_dev_1365
744 corresponding questions are generated from annotations	mechanism	2K_dev_1365
	mechanism	2K_dev_1365
We explore approaches for finer understanding of video content using the question form of fill-in-the-blank	method	2K_dev_1365
and collect our Video Context QA dataset consisting of 109	method	2K_dev_1365
895 video clips with a total duration of more than 1000 h from existing TACoS	method	2K_dev_1365
MPII-MD and MEDTest 14 datasets	method	2K_dev_1365
Extensive experiments	method	2K_dev_1365
to infer the past	purpose	2K_dev_1365
describe the present and predict the future	purpose	2K_dev_1365
	background	2K_dev_1366
validates the accuracy of sentence and attribute generation	finding	2K_dev_1366
We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures With differentiable approximation to discrete text samples	mechanism	2K_dev_1366
explicit constraints on independent attribute controls	mechanism	2K_dev_1366
and efficient collaborative learning of generator and discriminators	mechanism	2K_dev_1366
our model learns highly interpretable representations from even only word annotations	mechanism	2K_dev_1366
and produces realistic sentences with desired attributes	mechanism	2K_dev_1366
	mechanism	2K_dev_1366
Quantitative evaluation	method	2K_dev_1366
Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain	purpose	2K_dev_1366
This paper aims at generating plausible natural language sentences	purpose	2K_dev_1366
whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics	purpose	2K_dev_1366
	purpose	2K_dev_1366
Nuclear organization has an important role in determining genome function ; however	background	2K_dev_1367
it is not clear how spatiotemporal organization of the genome relates to functionality	background	2K_dev_1367
We anticipate the general applicability and scalability of our method will enhance causative analyses between gene function and compartmentalization in a high-throughput manner	background	2K_dev_1367
was successful at labeling 9 different loci in HCT116 cells with up to 20 % efficiency These loci included both nuclear speckle-associated	finding	2K_dev_1367
euchromatin regions and nuclear lamina-associated	finding	2K_dev_1367
heterochromatin regions	finding	2K_dev_1367
	finding	2K_dev_1367
Here	mechanism	2K_dev_1367
we report an efficient and scalable method named SHACKTeR ( Short Homology and CRISPR/Cas9-mediated Knock-in of a TetO Repeat Compared to alternatives	mechanism	2K_dev_1367
our method does not require a nearby repetitive sequence and it requires only two modifications to the genome : CRISPR/Cas9-mediated knock-in of an optimized TetO repeat and its visualization by TetR-EGFP expression	mechanism	2K_dev_1367
Our simplified knock-in protocol	mechanism	2K_dev_1367
utilizing short homology arms integrated by PCR	mechanism	2K_dev_1367
	method	2K_dev_1367
To elucidate this relationship	purpose	2K_dev_1367
a high-throughput method for tracking any locus of interest is desirable	purpose	2K_dev_1367
for live cell imaging of specific chromosomal regions	purpose	2K_dev_1367
	purpose	2K_dev_1367
Robust hand detection and classification is one of the most crucial pre-processing steps to support human computer interaction	background	2K_dev_1368
driver behavior monitoring	background	2K_dev_1368
virtual reality	background	2K_dev_1368
etc	background	2K_dev_1368
	background	2K_dev_1368
The experimental results show that our proposed MS-FRCN approach consistently achieves the state-of-the-art hand detection results	finding	2K_dev_1368
i	finding	2K_dev_1368
e	finding	2K_dev_1368
Average Precision ( AP ) / Average Recall ( AR ) of 95	finding	2K_dev_1368
1 % / 94	finding	2K_dev_1368
5 % at level 1 and 86	finding	2K_dev_1368
0 % / 83	finding	2K_dev_1368
4 % at level 2	finding	2K_dev_1368
on the VIVA challenge In addition	finding	2K_dev_1368
the proposed method achieves the state-of-the-art results for left/right hand and driver/passenger classification tasks on the VIVA database with a significant improvement on AP/AR of ~7 % and ~13 % for both classification tasks	finding	2K_dev_1368
respectively The hand detection performance of MS-RFCN reaches to 75	finding	2K_dev_1368
1 % of AP and 77	finding	2K_dev_1368
8 % of AR on Oxford database	finding	2K_dev_1368
	finding	2K_dev_1368
This work presents a novel approach named Multiple Scale Region-based Fully Convolutional Networks ( MSRFCN ) In this approach	mechanism	2K_dev_1368
the whole image is passed through the proposed fully convolutional network to compute score maps Those score maps with their position-sensitive properties can help to efficiently address a dilemma between translation-invariance in classification and detection	mechanism	2K_dev_1368
	mechanism	2K_dev_1368
The method is evaluated on the challenging hand databases	method	2K_dev_1368
i	method	2K_dev_1368
e	method	2K_dev_1368
the Vision for Intelligent Vehicles and Applications ( VIVA ) Challenge	method	2K_dev_1368
Oxford hand dataset and compared against various recent hand detection methods	method	2K_dev_1368
This problem	purpose	2K_dev_1368
however	purpose	2K_dev_1368
is very challenging due to numerous variations of hand images in real-world scenarios	purpose	2K_dev_1368
to robustly detect and classify human hand regions under various challenging conditions	purpose	2K_dev_1368
e	purpose	2K_dev_1368
g	purpose	2K_dev_1368
occlusions	purpose	2K_dev_1368
illumination	purpose	2K_dev_1368
low-resolutions	purpose	2K_dev_1368
Abstract Server-side variability the idea that the same job can take longer to run on one server than another due to server-dependent factors isan increasingly important concern in many queueing systems	background	2K_dev_1369
One strategy for overcoming server-side variability to achieve low response time is redundancy	background	2K_dev_1369
under which jobs create copies of themselves and send these copies to multiple different servers	background	2K_dev_1369
waiting for only one copy to complete service	background	2K_dev_1369
Most of the existing theoretical work on redundancy has focused on developing bounds	background	2K_dev_1369
approximations	background	2K_dev_1369
and exact analysis to study the response time gains offered by redundancy	background	2K_dev_1369
shows that FCFS can be unfair in that it can hurt non-redundant jobs	finding	2K_dev_1369
which is provably fair and also achieves excellent overall mean response time	finding	2K_dev_1369
We develop new exact analysis under First-Come First-Served ( FCFS ) scheduling for a general type of system structure ; We then introduce the Least Redundant First ( LRF ) scheduling policy	mechanism	2K_dev_1369
which we prove is optimal with respect to overall system response time	mechanism	2K_dev_1369
but which can be unfair in that it can hurt the jobs that become redundant	mechanism	2K_dev_1369
Finally	mechanism	2K_dev_1369
we introduce the Primaries First ( PF ) scheduling policy	mechanism	2K_dev_1369
our analysis	method	2K_dev_1369
However	purpose	2K_dev_1369
response time is not the only important metric in redundancy systems : in addition to providing low overall response time	purpose	2K_dev_1369
the system should also be fair in the sense that no job class should have a worse mean response time in the system with redundancy than it did in the system before redundancy is allowed In this paper we use scheduling to address the simultaneous goals of ( 1 ) achieving low response time and ( 2 ) maintaining fairness across job classes	purpose	2K_dev_1369
for per-class response time	purpose	2K_dev_1369
	background	2K_dev_1370
	finding	2K_dev_1370
	mechanism	2K_dev_1370
	method	2K_dev_1370
	purpose	2K_dev_1370
Generative Adversarial Networks ( GANs ) have recently achieved significant improvement on paired/unpaired image-to-image translation	background	2K_dev_1371
such as photo $ \rightarrow $ sketch and artist painting style transfer	background	2K_dev_1371
	background	2K_dev_1371
show considerable performance gain by our contrast-GAN over other conditional GANs Quantitative results further demonstrate the superiority of our model on generating manipulated results with high visual fidelity and reasonable object semantics	finding	2K_dev_1371
we introduce a contrasting GAN ( contrast-GAN ) with a novel adversarial contrasting objective	mechanism	2K_dev_1371
Instead of directly making the synthesized samples close to target data as previous GANs did	mechanism	2K_dev_1371
our adversarial contrasting objective optimizes over the distance comparisons between samples	mechanism	2K_dev_1371
that is	mechanism	2K_dev_1371
enforcing the manipulated data be semantically closer to the real data with target category than the input data Equipped with the new contrasting objective	mechanism	2K_dev_1371
a novel mask-conditional contrast-GAN architecture is proposed to enable disentangle image background with object semantic changes	mechanism	2K_dev_1371
Experiments on several semantic manipulation tasks on ImageNet and MSCOCO dataset	method	2K_dev_1371
However	purpose	2K_dev_1371
existing models can only be capable of transferring the low-level information ( e	purpose	2K_dev_1371
g	purpose	2K_dev_1371
color or texture changes )	purpose	2K_dev_1371
but fail to edit high-level semantic meanings ( e	purpose	2K_dev_1371
g	purpose	2K_dev_1371
	purpose	2K_dev_1371
geometric structure or content ) of objects	purpose	2K_dev_1371
On the other hand	purpose	2K_dev_1371
while some researches can synthesize compelling real-world images given a class label or caption	purpose	2K_dev_1371
they can not condition on arbitrary shapes or structures	purpose	2K_dev_1371
which largely limits their application scenarios and interpretive capability of model results In this work	purpose	2K_dev_1371
we focus on a more challenging semantic manipulation task	purpose	2K_dev_1371
which aims to modify the semantic meaning of an object while preserving its own characteristics ( e	purpose	2K_dev_1371
g	purpose	2K_dev_1371
viewpoints and shapes )	purpose	2K_dev_1371
such as cow $ \rightarrow $ sheep	purpose	2K_dev_1371
motor $ \rightarrow $ bicycle	purpose	2K_dev_1371
cat $ \rightarrow $ dog	purpose	2K_dev_1371
To tackle such large semantic changes	purpose	2K_dev_1371
The influence of motor cortex on muscles during different behaviors is incompletely understood	background	2K_dev_1372
	background	2K_dev_1372
	finding	2K_dev_1372
	mechanism	2K_dev_1372
	method	2K_dev_1372
In this issue of Neuron	purpose	2K_dev_1372
Miri etal	purpose	2K_dev_1372
( 2017 ) show that the population activity patterns produced by motor cortex during different behaviors determine the selective routing of signals along different pathways between motor cortex and muscles	purpose	2K_dev_1372
Future frame prediction in videos is a promising avenue for unsupervised video representation learning	background	2K_dev_1373
Video frames are naturally generated by the inherent pixel flows from preceding frames based on the appearance and motion dynamics in the video	background	2K_dev_1373
	background	2K_dev_1373
demonstrate that the proposed dual motion GAN significantly outperforms state-of-the-art approaches on synthesizing new video frames and predicting future flows	finding	2K_dev_1373
Our model generalizes well across diverse visual scenes and shows superiority in unsupervised video representation learning	finding	2K_dev_1373
In this paper	mechanism	2K_dev_1373
we develop a dual motion Generative Adversarial Net ( GAN ) architecture	mechanism	2K_dev_1373
which learns to explicitly enforce future-frame predictions to be consistent with the pixel-wise flows in the video through a dual-learning mechanism The primal future-frame prediction and dual future-flow prediction form a closed loop	mechanism	2K_dev_1373
generating informative feedback signals to each other for better video prediction	mechanism	2K_dev_1373
To make both synthesized future frames and flows indistinguishable from reality	mechanism	2K_dev_1373
a dual adversarial training method is proposed to ensure that the future-flow prediction is able to help infer realistic future-frames	mechanism	2K_dev_1373
while the future-frame prediction in turn leads to realistic optical flows Our dual motion GAN also handles natural motion uncertainty in different pixel locations with a new probabilistic motion encoder	mechanism	2K_dev_1373
which is based on variational	mechanism	2K_dev_1373
Extensive experiments	method	2K_dev_1373
However	purpose	2K_dev_1373
existing methods focus on directly hallucinating pixel values	purpose	2K_dev_1373
resulting in blurry predictions	purpose	2K_dev_1373
	purpose	2K_dev_1373
	background	2K_dev_1374
We surprisingly find that the evolution patterns of real social groups goes far beyond the classic dynamic models like SI and SIR	finding	2K_dev_1374
For example	finding	2K_dev_1374
we observe both diffusion and non-diffusion mechanism in the group joining process	finding	2K_dev_1374
and power-law decay in group quitting process	finding	2K_dev_1374
rather than exponential decay as expected in SIR model	finding	2K_dev_1374
Therefore	mechanism	2K_dev_1374
we propose a new model come N go	mechanism	2K_dev_1374
a concise yet flexible dynamic model Our model has the following advantages : ( a ) Unification power : it generalizes earlier theoretical models and different joining and quitting mechanisms we find from observation	mechanism	2K_dev_1374
( b ) Succinctness and interpretability : it contains only six parameters with clear physical meanings ( c ) Accuracy : it can capture various kinds of group evolution patterns preciously	mechanism	2K_dev_1374
and the goodness of fit increases by 58 % over baseline	mechanism	2K_dev_1374
( d ) Usefulness : it can be used in multiple application scenarios	mechanism	2K_dev_1374
such as forecasting and pattern discovery Furthermore	mechanism	2K_dev_1374
our model can provide insights about different evolution patterns of social groups	mechanism	2K_dev_1374
and we also find that group structure and its evolution has notable relations with temporal patterns of group evolution	mechanism	2K_dev_1374
In this article	method	2K_dev_1374
we examine temporal evolution patterns of more than 100 thousands social groups with more than 10 million users	method	2K_dev_1374
	method	2K_dev_1374
How do social groups	purpose	2K_dev_1374
such as Facebook groups and Wechat groups	purpose	2K_dev_1374
dynamically evolve over time ? How do people join the social groups	purpose	2K_dev_1374
uniformly or with burst ? What is the pattern of people quitting from groups ? Is there a simple universal model to depict the come-and-go patterns of various groups ? for group evolution	purpose	2K_dev_1374
	purpose	2K_dev_1374
Computer vision based technologies have seen widespread adoption over the recent years	background	2K_dev_1375
This use is not limited to the rapid adoption of facial recognition technology but extends to facial expression recognition	background	2K_dev_1375
scene recognition and more	background	2K_dev_1375
	background	2K_dev_1375
	finding	2K_dev_1375
In this paper we introduce a novel distributed privacy infrastructure for the Internet-of-Things and discuss in particular how it can help The infrastructure	mechanism	2K_dev_1375
	mechanism	2K_dev_1375
supports the automated discovery of IoT resources and the selective notification of users This includes the presence of computer vision applications that collect data about users	mechanism	2K_dev_1375
In particular	mechanism	2K_dev_1375
we describe an implementation of functionality that helps users discover nearby cameras and choose whether or not they want their faces to be denatured in the video streams	mechanism	2K_dev_1375
	mechanism	2K_dev_1375
which has undergone early deployment and evaluation on two campuses	method	2K_dev_1375
These developments raise privacy concerns and call for novel solutions to ensure adequate user awareness	purpose	2K_dev_1375
and ideally	purpose	2K_dev_1375
control over the resulting collection and use of potentially sensitive data	purpose	2K_dev_1375
While cameras have become ubiquitous	purpose	2K_dev_1375
most of the time users are not even aware of their presence	purpose	2K_dev_1375
enhance user 's awareness of and control over the collection and use of video data about them	purpose	2K_dev_1375
	purpose	2K_dev_1375
Information cascades are ubiquitous in both physical society and online social media	background	2K_dev_1376
taking on large variations in structures	background	2K_dev_1376
dynamics and semantics	background	2K_dev_1376
Our discoveries also provide a foundation for the microscopic mechanisms for information spreading	background	2K_dev_1376
potentially leading to implications for cascade prediction and outlier detection	background	2K_dev_1376
We find that the structural complexity of information cascades is far beyond the previous conjectures We find that bimodal law governs majority of the metrics	finding	2K_dev_1376
information flows in cascades have four directions	finding	2K_dev_1376
and the self-loop number and average activity of cascades follows power law and finally uncover some notable implications of structural patterns in information cascades	finding	2K_dev_1376
We first propose a ten-dimensional metric	mechanism	2K_dev_1376
reflecting cascade size	mechanism	2K_dev_1376
silhouette	mechanism	2K_dev_1376
direction and activity aspects	mechanism	2K_dev_1376
	mechanism	2K_dev_1376
Here we explore a large-scale dataset including $ 432 $ million information cascades with explicit records of spreading traces	method	2K_dev_1376
spreading behaviors	method	2K_dev_1376
information content as well as user profiles We then analyze the high-order structural patterns of information cascades Finally	method	2K_dev_1376
we evaluate to what extent the structural features of information cascades can explain its dynamic patterns and semantics	method	2K_dev_1376
	method	2K_dev_1376
Although the dynamics and semantics of information cascades have been studied	purpose	2K_dev_1376
the structural patterns and their correlations with dynamics and semantics are largely unknown to quantify the structural characteristics of information cascades	purpose	2K_dev_1376
Extreme Classification comprises multi-class or multi-label prediction where there is a large number of classes	background	2K_dev_1377
and is increasingly relevant to many real-world applications such as text and image tagging	background	2K_dev_1377
our proposed method achieves accuracy competitive to the state-of-the-art while reducing the training time from days to tens of minutes compared with existing parallel or sparse methods on a cluster of 100 cores	finding	2K_dev_1377
	finding	2K_dev_1377
In this work	mechanism	2K_dev_1377
we extend PD-Sparse	mechanism	2K_dev_1377
By introducing separable loss functions	mechanism	2K_dev_1377
we can scale out the training	mechanism	2K_dev_1377
with network communication and space efficiency comparable to those in one-versus-all approaches while maintaining an overall complexity sub-linear in the number of classes	mechanism	2K_dev_1377
	mechanism	2K_dev_1377
On several large-scale benchmarks	method	2K_dev_1377
In this setting	purpose	2K_dev_1377
standard classification methods	purpose	2K_dev_1377
with complexity linear in the number of classes	purpose	2K_dev_1377
become intractable	purpose	2K_dev_1377
while enforcing structural constraints among classes ( such as low-rank or tree-structure ) to reduce complexity often sacrifices accuracy for efficiency	purpose	2K_dev_1377
The recent PD-Sparse method addresses this via an algorithm that is sub-linear in the number of variables	purpose	2K_dev_1377
by exploiting primal-dual sparsity inherent in a specific loss function	purpose	2K_dev_1377
namely the max-margin loss to be efficiently parallelized in large-scale distributed settings	purpose	2K_dev_1377
Time-limited promotions that exploit consumers ' sense of urgency to boost sales account for billions of dollars in consumer spending each year	background	2K_dev_1378
	background	2K_dev_1378
and show that RUSH ! provides higher expected value than various baselines that do not jointly model time and category information	finding	2K_dev_1378
	finding	2K_dev_1378
Specifically	mechanism	2K_dev_1378
we use large-scale anonymized transaction records	mechanism	2K_dev_1378
based on which we generate data-driven	mechanism	2K_dev_1378
personalized coupons	mechanism	2K_dev_1378
Our proposed model RUSH ( 1 ) predicts { both the time and category } of the next event ; ( 2 ) captures correlations between purchases in different categories ( such as shopping triggering dining purchases ) ; ( 3 ) incorporates temporal dynamics of purchase behavior ( such as increased spending on weekends ) ; ( 4 ) is composed of additive factors that are easily interpretable ; and finally ( 5 ) scales linearly to millions of transactions	mechanism	2K_dev_1378
	mechanism	2K_dev_1378
We design a cost-benefit framework that facilitates systematic evaluation in terms of our application	method	2K_dev_1378
However	purpose	2K_dev_1378
it is challenging to discover the right timing and duration of a promotion to increase its chances of being redeemed	purpose	2K_dev_1378
In this work	purpose	2K_dev_1378
we consider the problem of delivering time-limited discount coupons	purpose	2K_dev_1378
where we partner with a large national bank functioning as a commission-based third-party coupon provider to model consumer spending and forecast future purchases	purpose	2K_dev_1378
How do people make friends dynamically in social networks ? What are the temporal patterns for an individual increasing its social connectivity ? What are the basic mechanisms governing the formation of these temporal patterns ? No matter cyber or physical social systems	background	2K_dev_1379
their structure and dynamics are mainly driven by the connectivity dynamics of each individual	background	2K_dev_1379
Our model and discoveries provide a foundation for the microscopic mechanisms of network growth dynamics	background	2K_dev_1379
potentially leading to implications for prediction	background	2K_dev_1379
clustering and outlier detection on human dynamics	background	2K_dev_1379
	background	2K_dev_1379
We uncover a wide range of long-term power law growth and short-term bursty growth for the social connectivity of different users	finding	2K_dev_1379
We propose three key ingredients	finding	2K_dev_1379
namely average-effect	finding	2K_dev_1379
multiscale-effect and correlation-effect	finding	2K_dev_1379
which govern the observed growth patterns at microscopic level	finding	2K_dev_1379
we discover statistical regularities underlying the empirical growth dynamics	finding	2K_dev_1379
	finding	2K_dev_1379
As a result	mechanism	2K_dev_1379
we propose the long short memory process incorporating these ingredients	mechanism	2K_dev_1379
demonstrating that it successfully reproduces the complex growth patterns observed in the empirical data	mechanism	2K_dev_1379
We examine the detailed growth process of `` WeChat ''	method	2K_dev_1379
the largest online social network in China	method	2K_dev_1379
with 300 million users and 4	method	2K_dev_1379
75 billion links spanning two years	method	2K_dev_1379
By analyzing modeling parameters	method	2K_dev_1379
However	purpose	2K_dev_1379
due to the lack of empirical data	purpose	2K_dev_1379
little is known about the empirical dynamic patterns of social connectivity at microscopic level	purpose	2K_dev_1379
let alone the regularities or models governing these microscopic dynamics	purpose	2K_dev_1379
	purpose	2K_dev_1379
With the pervasiveness of mobile technology and location-based computing	background	2K_dev_1380
new forms of smart urban transportation	background	2K_dev_1380
such as Uber & Lyft	background	2K_dev_1380
have become increasingly popular	background	2K_dev_1380
These new forms of urban infrastructure can influence individuals ' movement frictions and patterns	background	2K_dev_1380
in turn influencing local consumption patterns and the economic performance of local businesses	background	2K_dev_1380
	background	2K_dev_1380
	finding	2K_dev_1380
in this paper	mechanism	2K_dev_1380
we utilize a novel dataset and econometric analysis methods	mechanism	2K_dev_1380
a quasi-experimental examination	method	2K_dev_1380
To gain insights about future impact of urban transportation changes to present of how the emerging growth of peer-to-peer car sharing services may have affected local consumer mobility and consumption patterns	purpose	2K_dev_1380
This generalizes a prior decomposition result for an M/M/k/staggeredM/M/k/staggered-setup	background	2K_dev_1381
	background	2K_dev_1381
We show that	finding	2K_dev_1381
the response time of an M/G/k/staggeredM/G/k/staggered-setup approximately decomposes into the sum of the response time for an M/G/kM/G/k and the setup time	finding	2K_dev_1381
where the approximation is nearly exact	finding	2K_dev_1381
	mechanism	2K_dev_1381
for exponentially distributed setup times	method	2K_dev_1381
We consider the M/G/k/staggeredM/G/k/staggered-setup	purpose	2K_dev_1381
where idle servers are turned off to save cost	purpose	2K_dev_1381
necessitating a setup time for turning a server back on ; however	purpose	2K_dev_1381
at most one server may be in setup mode at any time	purpose	2K_dev_1381
	purpose	2K_dev_1381
Quickly converting speech to text allows deaf and hard of hearing people to interactively follow along with live speech Doing so reliably requires a combination of perception	background	2K_dev_1382
understanding	background	2K_dev_1382
and speed that neither humans nor machines possess alone Scribe illustrates the broad potential for deeply interleaving human labor and machine intelligence to provide intelligent interactive services that neither can currently achieve alone	background	2K_dev_1382
	finding	2K_dev_1382
In this article	mechanism	2K_dev_1382
we discuss how our Scribe system combines human labor and machine intelligence in real time	mechanism	2K_dev_1382
Scribe integrates automated assistance in two ways	mechanism	2K_dev_1382
First	mechanism	2K_dev_1382
its user interface directs workers to different portions of the audio stream	mechanism	2K_dev_1382
slows down the portion they are asked to type	mechanism	2K_dev_1382
and adaptively determines segment length based on typing speed	mechanism	2K_dev_1382
Second	mechanism	2K_dev_1382
it automatically merges the partial input of multiple workers into a single transcript using a custom version of multiple-sequence alignment	mechanism	2K_dev_1382
	mechanism	2K_dev_1382
	method	2K_dev_1382
to reliably convert speech to text with less than 4s latency	purpose	2K_dev_1382
To achieve this speed while maintaining high accuracy	purpose	2K_dev_1382
	background	2K_dev_1383
The results demonstrate the effectiveness of our proposed model	finding	2K_dev_1383
M & M TGM not only outperforms prior state-of-the-art methods but also achieves better generalization ability	finding	2K_dev_1383
In this paper	mechanism	2K_dev_1383
we propose an unified caption framework	mechanism	2K_dev_1383
M & M TGM	mechanism	2K_dev_1383
which mines multimodal topics in unsupervised fashion from data and guides the caption decoder with these topics	mechanism	2K_dev_1383
Compared to pre-defined topics	mechanism	2K_dev_1383
the mined multimodal topics are more semantically and visually coherent and can reflect the topic distribution of videos better	mechanism	2K_dev_1383
We formulate the topic-aware caption generation as a multi-task learning problem	mechanism	2K_dev_1383
in which we add a parallel task	mechanism	2K_dev_1383
topic prediction	mechanism	2K_dev_1383
in addition to the caption task	mechanism	2K_dev_1383
For the topic prediction task	mechanism	2K_dev_1383
we use the mined topics as the teacher to train a student topic prediction model	mechanism	2K_dev_1383
which learns to predict the latent topics from multimodal contents of videos	mechanism	2K_dev_1383
The topic prediction provides intermediate supervision to the learning process	mechanism	2K_dev_1383
As for the caption task	mechanism	2K_dev_1383
we propose a novel topic-aware decoder to generate more accurate and detailed video descriptions with the guidance from latent topics	mechanism	2K_dev_1383
The entire learning procedure is end-to-end and it optimizes both tasks simultaneously	mechanism	2K_dev_1383
from extensive experiments conducted on the MSR-VTT and Youtube2Text datasets on multiple evaluation metrics and on both benchmark datasets	method	2K_dev_1383
	method	2K_dev_1383
The topic diversity of open-domain videos leads to various vocabularies and linguistic expressions in describing video contents	purpose	2K_dev_1383
and therefore	purpose	2K_dev_1383
makes the video captioning task even more challenging	purpose	2K_dev_1383
Data association	background	2K_dev_1384
which could be categorized into offline approaches and the online counterparts	background	2K_dev_1384
is a crucial part of a multi-object tracker in the tracking-by-detection framework	background	2K_dev_1384
	background	2K_dev_1384
results show that our approach achieves the state-of-the-art performance on challenging datasets	finding	2K_dev_1384
	finding	2K_dev_1384
In this paper	mechanism	2K_dev_1384
we propose a mixed style tracker	mechanism	2K_dev_1384
which is not only as efficient as the online tracker but also aware of future observations in offline setting	mechanism	2K_dev_1384
We start from a Markov Decision Process ( MDP ) online tracker and design a parallelized apprenticeship learning algorithm to learn both the reward function and transition policy in MDP	mechanism	2K_dev_1384
By proposing a rewind to track strategy to generate backward tracklets	mechanism	2K_dev_1384
future detections in offline data are efficiently utilized to obtain a more stable similarity measurement for association	mechanism	2K_dev_1384
Experiment	method	2K_dev_1384
On the one hand	purpose	2K_dev_1384
classical offline data association methods exploit all the video data and have high computation cost	purpose	2K_dev_1384
which makes them unscalable to long-term offline video data	purpose	2K_dev_1384
On the other hand	purpose	2K_dev_1384
online approaches have much lower computation cost	purpose	2K_dev_1384
but they suffer from ID-switches and tracklet drifting problem when directly applied to offline data as they are only aware of past observations	purpose	2K_dev_1384
	purpose	2K_dev_1384
	background	2K_dev_1385
demonstrate the effectiveness of proposed framework	finding	2K_dev_1385
	finding	2K_dev_1385
we propose a unified SED detection framework which divides events into two categories	mechanism	2K_dev_1385
i	mechanism	2K_dev_1385
e	mechanism	2K_dev_1385
	mechanism	2K_dev_1385
short-term events and long-duration events The former can be represented as a kind of snapshots of static key-poses and embodies an inner-dependencies	mechanism	2K_dev_1385
while the latter contains complex interactions between pedestrians	mechanism	2K_dev_1385
and shows obvious inter-dependencies and temporal context	mechanism	2K_dev_1385
For short-term event	mechanism	2K_dev_1385
a novel cascade Convolutional Neural Network ( CNN ) -HsNet is first constructed to detect the pedestrian	mechanism	2K_dev_1385
and then the corresponding events are classified	mechanism	2K_dev_1385
For long-duration event	mechanism	2K_dev_1385
Dense Trajectory ( DT ) and Improved Dense Trajectory ( IDT ) are first applied to explore the temporal features of the events respectively	mechanism	2K_dev_1385
and subsequently	mechanism	2K_dev_1385
Fisher Vector ( FV ) coding is adopted to encode raw features and linear SVM classifiers are learned to predict	mechanism	2K_dev_1385
	mechanism	2K_dev_1385
Finally	method	2K_dev_1385
a heuristic fusion scheme is used to obtain the results In addition	method	2K_dev_1385
a new large-scale pedestrian dataset	method	2K_dev_1385
named SED-PD	method	2K_dev_1385
is built for evaluation	method	2K_dev_1385
Comprehensive experiments on TRECVID SEDtest datasets	method	2K_dev_1385
As an important branch of multimedia content analysis	purpose	2K_dev_1385
Surveillance Event Detection ( SED ) is still a quite challenging task due to high abstraction and complexity such as occlusions	purpose	2K_dev_1385
cluttered backgrounds and viewpoint changes etc	purpose	2K_dev_1385
To address the problem	purpose	2K_dev_1385
	purpose	2K_dev_1385
Genome-wide association studies have discovered a large number of genetic variants associated with complex diseases such as Alzheimers disease	background	2K_dev_1386
	background	2K_dev_1386
we demonstrate that BTAM significantly improves the statistical power over forward three-way association mapping that finds genotypes associated with both transcripts and phenotypes and genotype-phenotype association mapping and report top 10 genotype-transcript-phenotype associations	finding	2K_dev_1386
In this paper	mechanism	2K_dev_1386
we present a novel approach called Backward Three-way Association Mapping ( BTAM ) Assuming that genotypes affect transcript levels	mechanism	2K_dev_1386
which in turn affect phenotypes	mechanism	2K_dev_1386
we first find transcripts associated with the phenotypes	mechanism	2K_dev_1386
and then find genotypes associated with the chosen transcripts	mechanism	2K_dev_1386
The backward ordering of association mappings allows us to avoid a large number of association testings between all genotypes and all transcripts	mechanism	2K_dev_1386
making it possible to identify three-way associations with a small computational cost	mechanism	2K_dev_1386
In our simulation study	method	2K_dev_1386
Furthermore	method	2K_dev_1386
we apply BTAM on an Alzheimers disease dataset	method	2K_dev_1386
However	purpose	2K_dev_1386
the genetic background of such diseases is largely unknown due to the complex mechanisms underlying genetic effects on traits	purpose	2K_dev_1386
as well as a small sample size ( e	purpose	2K_dev_1386
g	purpose	2K_dev_1386
	purpose	2K_dev_1386
1000 ) and a large number of genetic variants ( e	purpose	2K_dev_1386
g	purpose	2K_dev_1386
	purpose	2K_dev_1386
1 million ) Fortunately	purpose	2K_dev_1386
datasets that contain genotypes	purpose	2K_dev_1386
transcripts	purpose	2K_dev_1386
and phenotypes are becoming more readily available	purpose	2K_dev_1386
creating new opportunities for detecting disease-associated genetic variants for detecting three-way associations among genotypes	purpose	2K_dev_1386
transcripts	purpose	2K_dev_1386
and phenotypes	purpose	2K_dev_1386
	purpose	2K_dev_1386
The Next-Generation Airborne Collision Avoidance System ACASi ? X is intended to be installed on all large aircraft to give advice to pilots and prevent mid-air collisions with other aircraft	background	2K_dev_1387
It is currently being developed by the Federal Aviation Administration FAA	background	2K_dev_1387
Our approach is general and could also be used to identify unsafe advice issued by other collision avoidance systems or confirm their safety	background	2K_dev_1387
	finding	2K_dev_1387
In this paper we determine the geometric configurations under a precise set of assumptions and formally verify these configurations using hybrid systems theorem proving techniques	mechanism	2K_dev_1387
We conduct an initial examination of the current version of the real ACAS X system and discuss some cases where our safety theorem conflicts with the actual advisory given by that version	mechanism	2K_dev_1387
demonstrating how formal	mechanism	2K_dev_1387
hybrid approaches are helping ensure the safety of ACAS X	mechanism	2K_dev_1387
	method	2K_dev_1387
under which the advice given by ACAS X is safe	purpose	2K_dev_1387
Recently	background	2K_dev_1388
to solve large-scale lasso and group lasso problems	background	2K_dev_1388
screening rules have been developed	background	2K_dev_1388
the goal of which is to reduce the problem size by efficiently discarding zero coefficients using simple rules independently of the others	background	2K_dev_1388
	background	2K_dev_1388
we demonstrate the efficiency of our screening rules	finding	2K_dev_1388
In this paper	mechanism	2K_dev_1388
we develop screening rules for overlapping group lasso we take into account overlapping groups only if they are inclusive of the group being tested	mechanism	2K_dev_1388
and then we derive screening rules	mechanism	2K_dev_1388
adopting the dual polytope projection approach This strategy allows us to screen each group independently of each other	mechanism	2K_dev_1388
In our experiments	method	2K_dev_1388
on various datasets	method	2K_dev_1388
	method	2K_dev_1388
However	purpose	2K_dev_1388
screening for overlapping group lasso remains an open challenge because the overlaps between groups make it infeasible to test each group independently To address the challenge arising from groups with overlaps	purpose	2K_dev_1388
	purpose	2K_dev_1388
Facility location and committee selection are classic embodiments of this problem	background	2K_dev_1389
	background	2K_dev_1389
demonstrate the viability of this approach and the value of such optimized mechanisms vis-a-vis mechanisms derived through worst-case analysis	finding	2K_dev_1389
	finding	2K_dev_1389
We propose a class of percentile mechanisms	mechanism	2K_dev_1389
a form of generalized median mechanisms	mechanism	2K_dev_1389
that are strategy-proof	mechanism	2K_dev_1389
and for L1 and L2 cost models More importantly	mechanism	2K_dev_1389
we propose a sample-based framework	mechanism	2K_dev_1389
while maintaining strategy-proofness	mechanism	2K_dev_1389
	mechanism	2K_dev_1389
Our empirical investigations	method	2K_dev_1389
using social cost and maximum load as objectives	method	2K_dev_1389
	method	2K_dev_1389
We consider the mechanism design problem for agents with single-peaked preferences over multi-dimensional domains when multiple alternatives can be chosen derive worst-case approximation ratios for social cost and maximum load for optimizing the choice of percentiles relative to any prior distribution over preferences	purpose	2K_dev_1389
	background	2K_dev_1390
	finding	2K_dev_1390
using first and second authentication processes and a handoff from the first process to the second process	mechanism	2K_dev_1390
In one embodiment	mechanism	2K_dev_1390
the first authentication process is a stronger process performed at the outset of a session	mechanism	2K_dev_1390
and the second authentication process is a weaker process iteratively performed during the session	mechanism	2K_dev_1390
The stronger authentication process may require cooperation from the user	mechanism	2K_dev_1390
while the weaker authentication process is preferably one that requires little or no user cooperation	mechanism	2K_dev_1390
In other embodiments	mechanism	2K_dev_1390
a strong authentication process may be iteratively performed during the session	mechanism	2K_dev_1390
	method	2K_dev_1390
Controlling a registered-user session of a registered user on a device	purpose	2K_dev_1390
Social choice theory provides insights into a variety of collective decision making settings	background	2K_dev_1391
	background	2K_dev_1391
	finding	2K_dev_1391
In this paper we model the problem via Markov decision processes ( MDP )	mechanism	2K_dev_1391
where the states of the MDP coincide with preference profiles and a ( deterministic	mechanism	2K_dev_1391
stationary ) policy corresponds to a social choice function We can therefore employ the axioms studied in the social choice literature as guidelines in the design of socially desirable policies	mechanism	2K_dev_1391
We present tractable algorithms that compute optimal policies under different prominent social choice constraints	mechanism	2K_dev_1391
Our machinery relies on techniques for exploiting symmetries and isomorphisms between MDPs	mechanism	2K_dev_1391
	method	2K_dev_1391
but nowadays some of its tenets are challenged by internet environments	purpose	2K_dev_1391
which call for dynamic decision making under constantly changing preferences	purpose	2K_dev_1391
	purpose	2K_dev_1391
While the analysis of unlabeled networks has been studied extensively in the past	background	2K_dev_1392
finding patterns in different kinds of labeled graphs is still an open challenge	background	2K_dev_1392
	background	2K_dev_1392
We show that Com $ $ ^2 $ $ 2 spots intuitive patterns regarding edge labels that carry temporal or other discrete information	finding	2K_dev_1392
Our findings include large `` star '' -like patterns	finding	2K_dev_1392
near-bipartite cores	finding	2K_dev_1392
as well as tiny groups ( five users )	finding	2K_dev_1392
calling each other hundreds of times within a few days	finding	2K_dev_1392
We also show that we are able to automatically identify competing airline companies	finding	2K_dev_1392
We propose Com $ $ ^2 $ $ 2	mechanism	2K_dev_1392
a novel	mechanism	2K_dev_1392
fast and incremental tensor analysis approach The method is ( a ) scalable	mechanism	2K_dev_1392
being linear on the input size	mechanism	2K_dev_1392
( b ) general	mechanism	2K_dev_1392
( c ) needs no user-defined parameters and ( d ) effective	mechanism	2K_dev_1392
returning results that agree with intuition	mechanism	2K_dev_1392
	mechanism	2K_dev_1392
We apply our method to real datasets	method	2K_dev_1392
including a phone call network	method	2K_dev_1392
a computer-traffic network and a flight information network	method	2K_dev_1392
The phone call network consists of 4 million mobile users	method	2K_dev_1392
with 51 million edges ( phone calls )	method	2K_dev_1392
over 14 days	method	2K_dev_1392
while the flights dataset consists of 7733 airports and 5995 airline companies flying 67	method	2K_dev_1392
663 different routes	method	2K_dev_1392
Given a large edge-labeled network	purpose	2K_dev_1392
e	purpose	2K_dev_1392
g	purpose	2K_dev_1392
	purpose	2K_dev_1392
a time-evolving network	purpose	2K_dev_1392
how can we find interesting patterns ? which can discover communities appearing over subsets of the labels	purpose	2K_dev_1392
	purpose	2K_dev_1392
The Pitman-Yor process provides an elegant way to cluster data that exhibit power law behavior	background	2K_dev_1393
where the number of clusters is unknown or unbounded	background	2K_dev_1393
	background	2K_dev_1393
We show that our method scales well with increasing data while avoiding any degradation in estimate quality	finding	2K_dev_1393
	finding	2K_dev_1393
In this paper we present new auxiliary-variable representations for the Pitman-Yor process and a special case of the hierarchical Pitman-Yor process that allows us	mechanism	2K_dev_1393
	method	2K_dev_1393
Unfortunately	purpose	2K_dev_1393
inference in Pitman-Yor process-based models is typically slow and does not scale well with dataset size	purpose	2K_dev_1393
to develop parallel inference algorithms that distribute inference both on the data space and the model space	purpose	2K_dev_1393
	purpose	2K_dev_1393
	background	2K_dev_1394
We show that OpenEval is able to respond to the queries within a limited amount of time while also achieving high F1 score In addition	finding	2K_dev_1394
we show that the accuracy of responses provided by OpenEval is increased as more time is given for evaluation	finding	2K_dev_1394
that illustrate the effectiveness of our approach compared to related techniques	finding	2K_dev_1394
We introduce OpenEval	mechanism	2K_dev_1394
a which uses information on the web that are stated as multiargument predicate instances ( e	mechanism	2K_dev_1394
g	mechanism	2K_dev_1394
	mechanism	2K_dev_1394
DrugHasSideEffect ( Aspirin	mechanism	2K_dev_1394
GI Bleeding ) ) )	mechanism	2K_dev_1394
OpenEval gets a small number of instances of a predicate as seed positive examples and automatically learns how to evaluate the truth of a new predicate instance by querying the web and processing the retrieved unstructured web pages	mechanism	2K_dev_1394
	mechanism	2K_dev_1394
We have extensively tested our model and shown empirical results	method	2K_dev_1394
In this paper	purpose	2K_dev_1394
we investigate information validation tasks that are initiated as queries from either automated agents or humans new online information validation technique	purpose	2K_dev_1394
to automatically evaluate the truth of queries	purpose	2K_dev_1394
How can we correlate the neural activity in the human brain as it responds to typed words	background	2K_dev_1395
with properties of these terms ( like edible	background	2K_dev_1395
fits in hand ) ? In short	background	2K_dev_1395
we want to find latent variables	background	2K_dev_1395
that jointly explain both the brain activity	background	2K_dev_1395
as well as the behavioral responses	background	2K_dev_1395
This is one of many settings of the Coupled Matrix-Tensor Factorization ( CMTF ) problem	background	2K_dev_1395
	background	2K_dev_1395
by up to 200	finding	2K_dev_1395
along with an up to 65 fold increase in sparsity	finding	2K_dev_1395
with comparable accuracy to the baseline	finding	2K_dev_1395
TURBO-SMT is able to find meaningful latent variables	finding	2K_dev_1395
as well as to predict brain activity with competitive accuracy	finding	2K_dev_1395
	finding	2K_dev_1395
We introduce TURBO-SMT	mechanism	2K_dev_1395
a meta-method : it boosts the performance of any CMTF algorithm	mechanism	2K_dev_1395
	mechanism	2K_dev_1395
We apply TURBO-SMT to BRAINQ	method	2K_dev_1395
a dataset consisting of a ( nouns	method	2K_dev_1395
brain voxels	method	2K_dev_1395
human subjects ) tensor and a ( nouns	method	2K_dev_1395
properties ) matrix	method	2K_dev_1395
with coupling along the nouns dimension	method	2K_dev_1395
	method	2K_dev_1395
Can we accelerate any CMTF solver	purpose	2K_dev_1395
so that it runs within a few minutes instead of tens of hours to a day	purpose	2K_dev_1395
while maintaining good accuracy ? capable of doing exactly that	purpose	2K_dev_1395
The typical approach thus far is to use tensors or dynamical systems	background	2K_dev_1396
	background	2K_dev_1396
EEG-MINE ( a ) can successfully reconstruct the signals with high accuracy ; ( b ) can spot surprising patterns within seizure EEG signals ; and ( c ) may provide early warning of epileptic seizures	finding	2K_dev_1396
	finding	2K_dev_1396
Here	mechanism	2K_dev_1396
we present EEG-MINE	mechanism	2K_dev_1396
a nonlinear	mechanism	2K_dev_1396
chaos-based `` gray box model ''	mechanism	2K_dev_1396
that blends domain knowledge with data observations	mechanism	2K_dev_1396
When applied to numerous	method	2K_dev_1396
real EEG sequences	method	2K_dev_1396
	method	2K_dev_1396
Given electroencephalogram time series data from patients with epilepsy	purpose	2K_dev_1396
can we find patterns and regularities ?	purpose	2K_dev_1396
	background	2K_dev_1397
	finding	2K_dev_1397
	mechanism	2K_dev_1397
	method	2K_dev_1397
	purpose	2K_dev_1397
Live music performance with computers has motivated many research projects in science	background	2K_dev_1398
engineering	background	2K_dev_1398
and the arts	background	2K_dev_1398
We conclude with directions for future work	background	2K_dev_1398
	background	2K_dev_1398
	finding	2K_dev_1398
outline our efforts to establish a new direction	mechanism	2K_dev_1398
Human-Computer Music Performance ( HCMP )	mechanism	2K_dev_1398
as a framework for a variety of coordinated studies	mechanism	2K_dev_1398
Our work in this area spans performance analysis	mechanism	2K_dev_1398
synchronization techniques	mechanism	2K_dev_1398
and interactive performance systems	mechanism	2K_dev_1398
	mechanism	2K_dev_1398
We review the development of techniques for live music performance and	method	2K_dev_1398
In spite of decades of work	purpose	2K_dev_1398
it is surprising that there is not more technology for	purpose	2K_dev_1398
and a better understanding of the computer as music performer	purpose	2K_dev_1398
Our goal is to enable musicians to ncorporate computers into performances easily and effectively through a better understanding of requirements	purpose	2K_dev_1398
new techniques	purpose	2K_dev_1398
and practical	purpose	2K_dev_1398
performance-worthy implementations	purpose	2K_dev_1398
Matching function binaries -- the process of identifying similar functions among binary executables -- is a challenge that underlies many security applications such as malware analysis and patch-based exploit generation	background	2K_dev_1399
Recent work tries to establish semantic similarity based on static analysis methods	background	2K_dev_1399
BLEX outperforms BinDiff by up to 3	finding	2K_dev_1399
5 times in correctly identifying similar functions BLEX also outperforms BinDiff if the binaries have been compiled by different compilers Averaged over all indexed functions	finding	2K_dev_1399
our search engine ranks the correct matches among the top ten results 77 % of the time	finding	2K_dev_1399
	finding	2K_dev_1399
In this work	mechanism	2K_dev_1399
we propose blanket execution	mechanism	2K_dev_1399
a novel that achieves complete coverage by overriding the intended program logic	mechanism	2K_dev_1399
Blanket execution collects the side effects of functions during execution under a controlled randomized environment	mechanism	2K_dev_1399
Two functions are deemed similar	mechanism	2K_dev_1399
if their corresponding side effects	mechanism	2K_dev_1399
as observed under the same environment	mechanism	2K_dev_1399
are similar too	mechanism	2K_dev_1399
We implement our blanket execution technique in a system called BLEX	mechanism	2K_dev_1399
Using the functionality in BLEX	mechanism	2K_dev_1399
we have also built a binary search engine	mechanism	2K_dev_1399
We evaluate BLEX rigorously against the state of the art binary comparison tool BinDiff	method	2K_dev_1399
When comparing optimized and un-optimized executables from the popular GNU coreutils package	method	2K_dev_1399
	method	2K_dev_1399
Unfortunately	purpose	2K_dev_1399
these methods do not perform well if the compared binaries are produced by different compiler toolchains or optimization levels	purpose	2K_dev_1399
dynamic equivalence testing primitive that identifies similar functions across optimization boundaries	purpose	2K_dev_1399
	purpose	2K_dev_1399
Complex systems are designed using the model-based design paradigm in which mathematical models of systems are created and checked against specifications	background	2K_dev_1400
Cyber-physical systems ( CPS ) are complex systems in which the physical environment is sensed and controlled by computational or cyber elements possibly distributed over communication networks	background	2K_dev_1400
Various aspects of CPS design such as physical dynamics	background	2K_dev_1400
software	background	2K_dev_1400
control	background	2K_dev_1400
and communication networking must interoperate correctly for correct functioning of the systems	background	2K_dev_1400
Modeling formalisms	background	2K_dev_1400
analysis techniques and tools for designing these different aspects have evolved ind ependently	background	2K_dev_1400
and remain dissimilar and disparate	background	2K_dev_1400
There is no unifying formalism in which one can model all these aspects equally well	background	2K_dev_1400
In current practice	background	2K_dev_1400
there is no principled approach that deals with this modeling heterogeneity within a formal framework	background	2K_dev_1400
Composition of analysis results	finding	2K_dev_1400
this thesis develops a framework based on behavioral semantics Heterogeneity arising from the different interacting aspects of CPS design must be addressed in order to enable system-level verification We develop behavioral semantics to address heterogeneity in a general yet formal manner	mechanism	2K_dev_1400
Our framework makes no assumptions about the specifics of any particular formalism	mechanism	2K_dev_1400
therefore it readily supports various formalisms	mechanism	2K_dev_1400
techniques and tools	mechanism	2K_dev_1400
Models can be analyzed independently in isolation	mechanism	2K_dev_1400
supporting separation of concerns	mechanism	2K_dev_1400
Mappings across heterogeneous semantic domains enable associations between analysis results	mechanism	2K_dev_1400
Interdependencies across different models and specifications can be formally represented as constraints over parameters and verification can be carried out in a semantically consistent manner	mechanism	2K_dev_1400
is supported both hierarchically across different levels of abstraction and structurally into interacting component models at a given level of abstraction	method	2K_dev_1400
The theoretical concepts developed in the thesis are illustrated using a case study on the hierarchical heterogeneous verification of an automotive intersection collision avoidance system	method	2K_dev_1400
	method	2K_dev_1400
Therefore	purpose	2K_dev_1400
model-based design of CPS must make use of a collection of models in several different formalisms and use respective analysis methods and tools together to ensure correct system design	purpose	2K_dev_1400
To enable doing this in a formal manner for multi-model verification of cyber-physical systems	purpose	2K_dev_1400
	background	2K_dev_1401
	finding	2K_dev_1401
	mechanism	2K_dev_1401
	method	2K_dev_1401
	purpose	2K_dev_1401
Randomly mutating well-formed program inputs or simply fuzzing	background	2K_dev_1402
is a highly effective and widely used strategy to find bugs in software	background	2K_dev_1402
Other than showing fuzzers find bugs	background	2K_dev_1402
there has been little systematic effort in understanding the science of how to fuzz properly	background	2K_dev_1402
Overall	finding	2K_dev_1402
we find 240 bugs in 8 applications and show that the choice of algorithm can greatly increase the number of bugs found We also show that current seed selection strategies as found in Peach may fare no better than picking seeds at random	finding	2K_dev_1402
We make our data set and code publicly available	finding	2K_dev_1402
We design six different algorithms using over 650 CPU days on Amazon Elastic Compute Cloud ( EC2 )	mechanism	2K_dev_1402
and evaluate to provide ground truth data	method	2K_dev_1402
	method	2K_dev_1402
In this paper	purpose	2K_dev_1402
we focus on how to mathematically formulate and reason about one critical aspect in fuzzing : how best to pick seed files to maximize the total number of bugs found during a fuzz campaign	purpose	2K_dev_1402
A reliable and accurate biometric identification system must be able to distinguish individuals even in situations where their biometric signatures are very similar	background	2K_dev_1403
	background	2K_dev_1403
indicate that both our proposed approaches achieve high identification rates and are hence quite promising at distinguishing twins	finding	2K_dev_1403
	finding	2K_dev_1403
proposes two novel methods using ( 1 ) facial aging features and ( 2 ) asymmetry decomposition features	mechanism	2K_dev_1403
Facial aging features are extracted using Gabor filters from regions of the face that typically exhibit wrinkles and laugh lines	mechanism	2K_dev_1403
while Facial asymmetry decomposition based features are obtained by projecting the difference between the two left sides ( consisting of the left half of the face and its mirror ) and two right sides ( consisting of the right half of the face and its mirror ) of a face onto a subspace	mechanism	2K_dev_1403
Feature vectors obtained using these methods were used for classification HighlightsThe proposal of two novel approaches to distinguishing identical twins	mechanism	2K_dev_1403
Facial aging and intrinsic facial symmetry features are sued	mechanism	2K_dev_1403
A thorough evaluation on a challenging database	mechanism	2K_dev_1403
The summarizing of existing techniques and the results obtained by them	mechanism	2K_dev_1403
Experiments conducted on images of five types of twins from the University of Notre Dame ND-Twins database	method	2K_dev_1403
However	purpose	2K_dev_1403
the strong similarity in the facial appearance of twins has complicated facial feature based recognition and has even compromised commercial face recognition systems	purpose	2K_dev_1403
This paper addresses the above problem and to distinguish identical twins	purpose	2K_dev_1403
Function identification is a fundamental challenge in reverse engineering and binary program analysis	background	2K_dev_1404
For instance	background	2K_dev_1404
binary rewriting and control flow integrity rely on accurate function detection and identification in binaries	background	2K_dev_1404
we found that BYTE-WEIGHT missed 44	finding	2K_dev_1404
621 functions in comparison with the 266	finding	2K_dev_1404
672 functions missed by the industry-leading tool IDA	finding	2K_dev_1404
Furthermore	finding	2K_dev_1404
while IDA misidentified 459	finding	2K_dev_1404
247 functions	finding	2K_dev_1404
BYTEWEIGHT misidentified only 43	finding	2K_dev_1404
992 functions	finding	2K_dev_1404
In this paper	mechanism	2K_dev_1404
we propose BYTEWEIGHT	mechanism	2K_dev_1404
a new algorithm Our approach automatically learns key features for recognizing functions and can therefore easily be adapted to different platforms	mechanism	2K_dev_1404
new compilers	mechanism	2K_dev_1404
and new optimizations	mechanism	2K_dev_1404
We evaluated our tool against three well-known tools that feature function identification : IDA	method	2K_dev_1404
BAP	method	2K_dev_1404
and Dyninst	method	2K_dev_1404
Our data set consists of 2	method	2K_dev_1404
200 binaries created with three different compilers	method	2K_dev_1404
with four different optimization levels	method	2K_dev_1404
and across two different operating systems	method	2K_dev_1404
In our experiments with 2	method	2K_dev_1404
200 binaries	method	2K_dev_1404
Although many binary program analyses assume functions can be identified a priori	purpose	2K_dev_1404
identifying functions in stripped binaries remains a challenge	purpose	2K_dev_1404
automatic function identification	purpose	2K_dev_1404
	background	2K_dev_1405
we demonstrate that contextual supervision improves significantly over a reasonable baseline and existing unsupervised methods for source separation and show that recovery of the signal components depends only on cross-correlation between features for different signals	finding	2K_dev_1405
not on correlations between features for the same signal	finding	2K_dev_1405
	finding	2K_dev_1405
We propose a new framework that lies between the fully supervised and unsupervised setting	mechanism	2K_dev_1405
Instead of supervision	mechanism	2K_dev_1405
we provide input features for each source signal and use convex methods Contextually supervised source separation is a natural fit for domains with large amounts of data but no explicit supervision ; our motivating application is energy disaggregation of hourly smart meter data ( the separation of whole-home power signals into different energy uses )	mechanism	2K_dev_1405
Here contextual supervision allows us for thousands homes	mechanism	2K_dev_1405
a task previously impossible due to the need for specialized data collection hardware	mechanism	2K_dev_1405
	mechanism	2K_dev_1405
On smaller datasets which include labels	method	2K_dev_1405
Finally	method	2K_dev_1405
we analyze the case of l2 loss theoretically	method	2K_dev_1405
for single-channel source separation to estimate the correlations between these features and the unobserved signal decomposition	purpose	2K_dev_1405
to provide itemized energy usage	purpose	2K_dev_1405
Computing equilibria of games is a central task in computer science	background	2K_dev_1406
A large number of results are known for Nash equilibrium ( NE )	background	2K_dev_1406
	background	2K_dev_1406
	finding	2K_dev_1406
	mechanism	2K_dev_1406
showing that the problem is in P	mechanism	2K_dev_1406
We then design a spatial branch -- and -- bound algorithm to find an SNE	mechanism	2K_dev_1406
	mechanism	2K_dev_1406
and we experimentally evaluate the algorithm	method	2K_dev_1406
However	purpose	2K_dev_1406
these can be adopted only when coalitions are not an issue	purpose	2K_dev_1406
When instead agents can form coalitions	purpose	2K_dev_1406
NE is inadequate and an appropriate solution concept is strong Nash equilibrium ( SNE )	purpose	2K_dev_1406
Few computational results are known about SNE	purpose	2K_dev_1406
In this paper	purpose	2K_dev_1406
we first study the problem of verifying whether a strategy profile is an SNE	purpose	2K_dev_1406
	background	2K_dev_1407
where we show performance comparable to state of the art detector-based methods	finding	2K_dev_1407
We present a model that localizes objects via unsupervised tracking while learning a representation of each object	mechanism	2K_dev_1407
avoiding the need for pre-built detectors	mechanism	2K_dev_1407
Our model uses a dependent Dirichlet process mixture to capture the uncertainty in the number and appearance of objects and requires only spatial and color video data that can be efficiently extracted via frame differencing	mechanism	2K_dev_1407
We give two inference algorithms for use in both online and offline settings	mechanism	2K_dev_1407
and use them to perform accurate detection-free tracking on multiple real videos	mechanism	2K_dev_1407
	mechanism	2K_dev_1407
We demonstrate our method in difficult detection scenarios involving occlusions and appearance shifts	method	2K_dev_1407
on videos containing a large number of objects	method	2K_dev_1407
and on a recent human-tracking benchmark	method	2K_dev_1407
This paper explores how to find	purpose	2K_dev_1407
track	purpose	2K_dev_1407
and learn models of arbitrary objects in a video without a predefined method for object detection	purpose	2K_dev_1407
Given the re-broadcasts ( i	background	2K_dev_1408
e	background	2K_dev_1408
retweets ) of posts in Twitter	background	2K_dev_1408
how can we spot fake from genuine user reactions ? What will be the tell-tale sign the connectivity of retweeters	background	2K_dev_1408
their relative timing	background	2K_dev_1408
or something else ? High retweet activity indicates influential users	background	2K_dev_1408
and can be monetized	background	2K_dev_1408
Hence	background	2K_dev_1408
there are strong incentives for fraudulent users to artificially boost their retweets ' volume	background	2K_dev_1408
	background	2K_dev_1408
Our main contribu- tions are : ( a ) the discovery of patterns that fraudulent activity seems to follow ( the `` triangles `` a nd `` homogeneity '' patterns	finding	2K_dev_1408
the formation of micro-clusters in appropriate feature spaces ) ; and	finding	2K_dev_1408
( b ) `` RTGen ''	mechanism	2K_dev_1408
a realistic generator that mimics the behaviors of both honest and fraud- ulent users	mechanism	2K_dev_1408
	mechanism	2K_dev_1408
We present experiments on a dataset of more than 6 million retweets crawled from Twitter	method	2K_dev_1408
Here	purpose	2K_dev_1408
we explore the identifi- cation of fraudulent and genuine retweet threads	purpose	2K_dev_1408
Safety critical systems often have shutdown mechanisms to bring the system to a safe state in the event of a malfunction	background	2K_dev_1409
shows that using a rate-limited ride-through bound permits a tighter safety limit on speed than a xed threshold without creating false alarm shutdowns resulted in im- proved detection of speed limit violations and shorter shutdown stopping distances without needing to increase the false alarm shutdown rate	finding	2K_dev_1409
We ex- amine the use of ride-through	mechanism	2K_dev_1409
a technique by allowing small transient violations of safety rules Adding state machines to select speci c safety bounds based on vehicle state accommodates expected control system transients	mechanism	2K_dev_1409
An illustrative example of enforcing a speed limit for an autonomous vehicle Testing these principles on an autonomous utility vehicle	method	2K_dev_1409
to reduce the frequency of safety shutdowns	purpose	2K_dev_1409
	background	2K_dev_1410
	finding	2K_dev_1410
	mechanism	2K_dev_1410
	method	2K_dev_1410
	purpose	2K_dev_1410
	background	2K_dev_1411
Empirical results demonstrate the effectiveness of our proposed approach	finding	2K_dev_1411
	finding	2K_dev_1411
In this paper	mechanism	2K_dev_1411
we propose sparse output coding	mechanism	2K_dev_1411
a principled way by turning high-cardinality multi-class categorization into a bit-by-bit decoding problem	mechanism	2K_dev_1411
Specifically	mechanism	2K_dev_1411
sparse output coding is composed of two steps : efficient coding matrix learning with scalability to thousands of classes	mechanism	2K_dev_1411
and probabilistic decoding	mechanism	2K_dev_1411
	mechanism	2K_dev_1411
on object recognition and scene classification	method	2K_dev_1411
Many vision tasks require a multi-class classifier to discriminate multiple categories	purpose	2K_dev_1411
on the order of hundreds or thousands for large-scale multi-class classification	purpose	2K_dev_1411
	purpose	2K_dev_1411
	background	2K_dev_1412
	finding	2K_dev_1412
	mechanism	2K_dev_1412
	method	2K_dev_1412
	purpose	2K_dev_1412
Given a multimillion-node social network	background	2K_dev_1413
how can we sum- marize connectivity pattern from the data	background	2K_dev_1413
and how can we find unex- pected user behavior ?	background	2K_dev_1413
We discover that ( a ) the lockstep behavior on the graph shapes dense `` block '' in its adjacency matrix and creates `` ray '' in spectral subspaces	finding	2K_dev_1413
and ( b ) partially overlapping of the behavior shapes `` staircase '' in the matrix and creates `` pearl '' in the subspaces	finding	2K_dev_1413
We demonstrate that our approach is effective	finding	2K_dev_1413
The second contribution is that we provide a fast algorithm	mechanism	2K_dev_1413
using the discovery as a guide for practi- tioners	mechanism	2K_dev_1413
	mechanism	2K_dev_1413
Our first contribution is that we study strange patterns on the adjacency matrix and in the spectral subspaces with respect to several flavors of lockstep	method	2K_dev_1413
on both synthetic and real data	method	2K_dev_1413
	method	2K_dev_1413
In this paper we study a complete graph from a large who-follows-whom network and spot lockstep behavior that large groups of followers connect to the same groups of followees	purpose	2K_dev_1413
to detect users who offer the lockstep behavior	purpose	2K_dev_1413
	purpose	2K_dev_1413
	background	2K_dev_1414
our model can be used to effectively explore a citation network and provide meaningful explanations for links while still maintaining competitive citation prediction performance	finding	2K_dev_1414
	finding	2K_dev_1414
In this paper	mechanism	2K_dev_1414
we present a novel model that integrates the merits of content and citation analyses into a single probabilistic framework	mechanism	2K_dev_1414
	mechanism	2K_dev_1414
We demonstrate our model on three real-world citation networks	method	2K_dev_1414
Compared with existing baselines	method	2K_dev_1414
Out of the many potential factors that determine which links form in a document citation network	purpose	2K_dev_1414
two in particular are of high importance : first	purpose	2K_dev_1414
a document may be cited based on its subject matterthis can be modeled by analyzing document content ; second	purpose	2K_dev_1414
a document may be cited based on which other documents have previously cited itthis can be modeled by analyzing citation structure	purpose	2K_dev_1414
Both factors are important for users to make informed decisions and choose appropriate citations as the network grows	purpose	2K_dev_1414
	purpose	2K_dev_1414
	background	2K_dev_1415
	finding	2K_dev_1415
	mechanism	2K_dev_1415
	method	2K_dev_1415
	purpose	2K_dev_1415
Automatically recognizing a large number of action categories from videos is of significant importance for video understanding	background	2K_dev_1416
	background	2K_dev_1416
validate the superiority of our method over fully-supervised approaches using few positive exemplars	finding	2K_dev_1416
we propose to perform action recognition when no positive exemplars of that class are provided	mechanism	2K_dev_1416
which is often known as the zero-shot learning	mechanism	2K_dev_1416
Different from other zero-shot learning approaches	mechanism	2K_dev_1416
which exploit attributes as the intermediate layer for the knowledge transfer	mechanism	2K_dev_1416
our main contribution is SIR	mechanism	2K_dev_1416
which directly leverages the semantic inter-class relationships between the known and unknown actions followed by label transfer learning	mechanism	2K_dev_1416
The inter-class semantic relationships are automatically measured by continuous word vectors	mechanism	2K_dev_1416
which learned by the skip-gram model using the large-scale text corpus	mechanism	2K_dev_1416
	mechanism	2K_dev_1416
Extensive experiments on the UCF101 dataset	method	2K_dev_1416
Most existing works focused on the design of more discriminative feature representation	purpose	2K_dev_1416
and have achieved promising results when the positive samples are enough	purpose	2K_dev_1416
However	purpose	2K_dev_1416
very limited efforts were spent on recognizing a novel action without any positive exemplars	purpose	2K_dev_1416
which is often the case in the real settings due to the large amount of action classes and the users ' queries dramatic variations	purpose	2K_dev_1416
To address this issue	purpose	2K_dev_1416
	purpose	2K_dev_1416
	background	2K_dev_1417
	finding	2K_dev_1417
	mechanism	2K_dev_1417
	method	2K_dev_1417
	purpose	2K_dev_1417
With the goal of improving the quality of life for people suffering from various motor control disorders	background	2K_dev_1418
brain-machine interfaces provide direct neural control of prosthetic devices by translating neural signals into control signals	background	2K_dev_1418
These systems act by reading motor intent signals directly from the brain and using them to control	background	2K_dev_1418
for example	background	2K_dev_1418
the movement of a cursor on a computer screen	background	2K_dev_1418
Over the past two decades	background	2K_dev_1418
much attention has been devoted to the decoding problem : how should recorded neural activity be translated into the movement of the cursor ? These results have implications for understanding how motor neurons are recruited to perform various tasks	background	2K_dev_1418
and may lend insight into the brain 's ability to conceptualize artificial systems	background	2K_dev_1418
	background	2K_dev_1418
This framework leads to new interpretations of why certain types of decoders have been shown to perform better than others	finding	2K_dev_1418
Here we recast the decoder design problem from a physical control system perspective	mechanism	2K_dev_1418
and	mechanism	2K_dev_1418
	method	2K_dev_1418
Most approaches have focused on this problem from an estimation standpoint	purpose	2K_dev_1418
i	purpose	2K_dev_1418
e	purpose	2K_dev_1418
	purpose	2K_dev_1418
decoders are designed to return the best estimate of motor intent possible	purpose	2K_dev_1418
under various sets of assumptions about how the recorded neural signals represent motor intent	purpose	2K_dev_1418
investigate how various classes of decoders lead to different types of physical systems for the subject to control	purpose	2K_dev_1418
	background	2K_dev_1419
	finding	2K_dev_1419
We propose a novel method The proposed method considers positive	mechanism	2K_dev_1419
implicit	mechanism	2K_dev_1419
and negative information of all users in a network based on belief propagation to predict trust relationships of a target user	mechanism	2K_dev_1419
	mechanism	2K_dev_1419
	method	2K_dev_1419
to predict accurately trust relationships of a target user even if he/she does not have much interaction information	purpose	2K_dev_1419
	purpose	2K_dev_1419
	background	2K_dev_1420
	finding	2K_dev_1420
	mechanism	2K_dev_1420
	method	2K_dev_1420
	purpose	2K_dev_1420
Given the retweeting activity for the posts of several Twitter users	background	2K_dev_1421
how can we distinguish organic activity from spammy retweets by paid followers to boost a post 's appearance of popularity ? More gen- erally	background	2K_dev_1421
given groups of observations	background	2K_dev_1421
can we spot strange groups ?	background	2K_dev_1421
Our method achieves a 97 % accuracy on a real dataset of 12 million retweets crawled from Twitter	finding	2K_dev_1421
Here	mechanism	2K_dev_1421
we propose : ( A ) ND-Sync	mechanism	2K_dev_1421
an efficient method	mechanism	2K_dev_1421
and ( B ) a set of carefully designed features ND-Sync is effec- tive in spotting retweet fraudsters	mechanism	2K_dev_1421
robust to different types of abnormal activity	mechanism	2K_dev_1421
and adaptable as it can easily incorporate additional features	mechanism	2K_dev_1421
	method	2K_dev_1421
Our main intuition is that organic behavior has more variability	purpose	2K_dev_1421
while fraud- ulent behavior	purpose	2K_dev_1421
like retweets by botnet members	purpose	2K_dev_1421
is more synchronized	purpose	2K_dev_1421
We refer to the detection of such synchronized observations as the Syn- chonization Fraud problem	purpose	2K_dev_1421
and we study a specific instance of it	purpose	2K_dev_1421
Retweet Fraud Detection	purpose	2K_dev_1421
manifested in Twitter	purpose	2K_dev_1421
for detecting group fraud for characterizing retweet threads	purpose	2K_dev_1421
	purpose	2K_dev_1421
	background	2K_dev_1422
	finding	2K_dev_1422
is represented in image data In one embodiment	mechanism	2K_dev_1422
age-estimation techniques involves combining a Contourlet Appearance Model ( CAM ) for facial-age feature extraction and Support Vector Regression ( SVR ) for learning aging rules	mechanism	2K_dev_1422
In a particular example	method	2K_dev_1422
characteristics of input facial images are converted to feature vectors by CAM	method	2K_dev_1422
then these feature vectors are analyzed by an aging-mechanism-based classifier to estimate whether the images represent faces of younger or older people prior to age-estimation	method	2K_dev_1422
the aging-mechanism-based classifier being generated in one embodiment by running Support Vector Machines ( SVM ) on training images	method	2K_dev_1422
In an exemplary binary youth/adult classifier	method	2K_dev_1422
faces classified as adults are passed to an adult age-estimation function and the others are passed to a youth age-estimation function	method	2K_dev_1422
	method	2K_dev_1422
Age-estimation of a face of an individual in order to improve the accuracy of age-estimation over the current techniques	purpose	2K_dev_1422
Refactoring of code is a common device in software engineering	background	2K_dev_1423
As cyber-physical systems CPS become ever more complex	background	2K_dev_1423
similar engineering practices become more common in CPS development	background	2K_dev_1423
Proper safe developments of CPS designs are accompanied by a proof of correctness	background	2K_dev_1423
	background	2K_dev_1423
For some of these we can give strong results that they are correct	finding	2K_dev_1423
	finding	2K_dev_1423
we develop proof-aware refactorings for CPS	mechanism	2K_dev_1423
That is	mechanism	2K_dev_1423
we study model transformations on CPS and show how they correspond to relations on correctness proofs	mechanism	2K_dev_1423
As the main technical device	mechanism	2K_dev_1423
we show how the impact of model transformations on correctness can be characterized by different notions of refinement in differential dynamic logic Furthermore	mechanism	2K_dev_1423
we demonstrate the application of refinements on a series of safety-preserving and liveness-preserving refactorings	mechanism	2K_dev_1423
	mechanism	2K_dev_1423
by proving on a meta-level Where this is impossible	method	2K_dev_1423
we construct proof obligations for showing that the refactoring respects the refinement relation	method	2K_dev_1423
Since the inherent complexities of CPS practically mandate iterative development	purpose	2K_dev_1423
frequent changes of models are standard practice	purpose	2K_dev_1423
but require reverification of the resulting models after every change	purpose	2K_dev_1423
To overcome this issue	purpose	2K_dev_1423
	purpose	2K_dev_1423
Most work building on the Stackelberg security games model assumes that the attacker can perfectly observe the defender 's randomized assignment of resources to targets	background	2K_dev_1424
implies that	background	2K_dev_1424
in some realistic situations	background	2K_dev_1424
limited surveillance may not need to be explicitly addressed	background	2K_dev_1424
	background	2K_dev_1424
that in zero-sum security games	finding	2K_dev_1424
lazy defenders	finding	2K_dev_1424
who simply keep optimizing against perfectly informed attackers	finding	2K_dev_1424
are almost optimal against diligent attackers	finding	2K_dev_1424
who go to the effort of gathering a reasonable number of observations	finding	2K_dev_1424
This result	finding	2K_dev_1424
	mechanism	2K_dev_1424
We analytically demonstrate	method	2K_dev_1424
This assumption has been challenged by recent papers	purpose	2K_dev_1424
which designed tailor-made algorithms that compute optimal defender strategies for security games with limited surveillance	purpose	2K_dev_1424
Motivated by the success of CNNs in object recognition on images	background	2K_dev_1425
researchers are striving to develop CNN equivalents for learning video features	background	2K_dev_1425
	background	2K_dev_1425
results show competitive performance	finding	2K_dev_1425
	finding	2K_dev_1425
Therefore	mechanism	2K_dev_1425
we propose to leverage effective techniques from both data-driven and data-independent approaches to improve action recognition system	mechanism	2K_dev_1425
Our contribution is three-fold	mechanism	2K_dev_1425
First	mechanism	2K_dev_1425
we explicitly show that local handcrafted features and CNNs share the same convolution-pooling network structure	mechanism	2K_dev_1425
Second	mechanism	2K_dev_1425
we propose to use independent subspace analysis ( ISA ) to learn descriptors for state-of-the-art handcrafted features	mechanism	2K_dev_1425
Third	mechanism	2K_dev_1425
we enhance ISA with two new improvements	mechanism	2K_dev_1425
which make our learned descriptors significantly outperform the handcrafted ones	mechanism	2K_dev_1425
	mechanism	2K_dev_1425
Experimental on standard action recognition benchmarks	method	2K_dev_1425
However	purpose	2K_dev_1425
learning video features globally has proven to be quite a challenge due to the difficulty of getting enough labels	purpose	2K_dev_1425
processing large-scale video data	purpose	2K_dev_1425
and representing motion information	purpose	2K_dev_1425
	purpose	2K_dev_1425
	background	2K_dev_1426
	finding	2K_dev_1426
	mechanism	2K_dev_1426
	method	2K_dev_1426
	purpose	2K_dev_1426
	background	2K_dev_1427
	finding	2K_dev_1427
Methods and software A supply and demand balancing scheme is used across a network of agents to facilitate agreement on the optimal incremental price for energy provision in an electric power network subject to the constraint that the total generation in the electric power network matches the total network demand A multi-step optimization approach is provided that incorporates inter-temporal constraints	mechanism	2K_dev_1427
allowing for optimal integration of flexible power loads and power storage entities and taking into account power generation ramp rate constraints at individual generation entities The approach is extended to cope with line flow constraints imposed by the physical system topology and transmission line limits/capacities	mechanism	2K_dev_1427
	mechanism	2K_dev_1427
	method	2K_dev_1427
for managing electric power networks in a distributed manner	purpose	2K_dev_1427
	purpose	2K_dev_1427
	background	2K_dev_1428
	finding	2K_dev_1428
	mechanism	2K_dev_1428
	method	2K_dev_1428
	purpose	2K_dev_1428
Designers of human computation systms often face the need to aggregate noisy information provided by multiple people	background	2K_dev_1429
Our short-term goal is to motivate the design of better human computation systems ; our long-term goal is to spark an interaction between researchers in ( computational ) social choice and human computation	background	2K_dev_1429
	background	2K_dev_1429
Our empirical conclusions show that noisy human voting can differ from what popular theoretical models would predict	finding	2K_dev_1429
	mechanism	2K_dev_1429
We conduct extensive experiments on Amazon Mechanical Turk	method	2K_dev_1429
While voting is often used for this purpose	purpose	2K_dev_1429
the choice of voting method is typically not principled to better understand how different voting rules perform in practice	purpose	2K_dev_1429
The Poisson distribution has been widely studied and used for modeling univariate count-valued data	background	2K_dev_1430
Multivariate generalizations of the Poisson distribution that permit dependencies	background	2K_dev_1430
however	background	2K_dev_1430
have been far less popular	background	2K_dev_1430
Finally	background	2K_dev_1430
we suggest new research directions as explored in the subsequent discussion section	background	2K_dev_1430
	background	2K_dev_1430
These empirical experiments develop intuition about the comparative advantages and disadvantages of each class of multivariate distribution that was derived from the Poisson	finding	2K_dev_1430
	mechanism	2K_dev_1430
compare the models in terms of interpretability and theory Then	method	2K_dev_1430
we empirically compare multiple models from each class on three real-world datasets that have varying data characteristics from different domains	method	2K_dev_1430
namely traffic accident data	method	2K_dev_1430
biological next generation sequencing data	method	2K_dev_1430
and text data	method	2K_dev_1430
	method	2K_dev_1430
Yet	purpose	2K_dev_1430
real-world high-dimensional count-valued data found in word counts	purpose	2K_dev_1430
genomics	purpose	2K_dev_1430
and crime statistics	purpose	2K_dev_1430
for example	purpose	2K_dev_1430
exhibit rich dependencies	purpose	2K_dev_1430
and motivate the need for multivariate distributions that can appropriately model this data	purpose	2K_dev_1430
We review multivariate distributions derived from the univariate Poisson	purpose	2K_dev_1430
categorizing these models into three main classes : 1 ) where the marginal distributions are Poisson	purpose	2K_dev_1430
2 ) where the joint distribution is a mixture of independent multivariate Poisson distributions	purpose	2K_dev_1430
and 3 ) where the node-conditional distributions are derived from the Poisson	purpose	2K_dev_1430
We discuss the development of multiple instances of these classes and	purpose	2K_dev_1430
	background	2K_dev_1431
	finding	2K_dev_1431
	mechanism	2K_dev_1431
	method	2K_dev_1431
	purpose	2K_dev_1431
More generally	background	2K_dev_1432
the approach could be used to identify malleable components of cognitive functions	background	2K_dev_1432
such as spatial reasoning or executive functions	background	2K_dev_1432
we find that the component models provide both better predictions and better explanations than the faculty models	finding	2K_dev_1432
Weak model variations tend to improve generalization across students	finding	2K_dev_1432
but hurt generalization across items and make a sacrifice to explanatory power	finding	2K_dev_1432
	finding	2K_dev_1432
we develop statistical models of them These models use latent variables Strong versions of these models provide a common explanation for the variance in task difficulty and transfer	mechanism	2K_dev_1432
Weak versions decouple difficulty and transfer explanations by describing task difficulty with parameters for each unique task	mechanism	2K_dev_1432
	mechanism	2K_dev_1432
We analyze naturally occurring datasets from student use of educational technologies We contrast a faculty theory of broad transfer with a component theory of more constrained transfer We evaluate these models in terms of both their prediction accuracy on held-out data and their power in explaining task difficulty and learning transfer	method	2K_dev_1432
In comparisons across eight datasets	method	2K_dev_1432
to explore a long-standing question of the scope of transfer of learning To test these theories to represent mental functions that are changed while learning to cause a reduction in error rates for new tasks	purpose	2K_dev_1432
Current methods for depression assessment depend almost entirely on clinical interview or self-report ratings	background	2K_dev_1433
These findings suggest that automatic detection of depression from behavioral indicators is feasible and that multimodal measures afford most powerful detection	background	2K_dev_1433
Accuracy ( remitted versus depressed ) for facial movement dynamics was higher than that for head movement dynamics ; and each was substantially higher than that for vocal prosody	finding	2K_dev_1433
Accuracy for all three modalities together reached 88	finding	2K_dev_1433
93 %	finding	2K_dev_1433
exceeding that for any single modality or pair of modalities	finding	2K_dev_1433
	finding	2K_dev_1433
	mechanism	2K_dev_1433
We compared a clinical interview of depression severity with automatic measurement in 48 participants undergoing treatment for depression	method	2K_dev_1433
Interviews were obtained at 7-week intervals on up to four occasions	method	2K_dev_1433
Following standard cut-offs	method	2K_dev_1433
participants at each session were classified as remitted	method	2K_dev_1433
intermediate	method	2K_dev_1433
or depressed Logistic regression classifiers using leave-one-out validation were compared for facial movement dynamics	method	2K_dev_1433
head movement dynamics	method	2K_dev_1433
and vocal prosody individually and in combination	method	2K_dev_1433
	method	2K_dev_1433
Such measures lack systematic and efficient ways of incorporating behavioral observations that are strong indicators of psychological disorder	purpose	2K_dev_1433
	background	2K_dev_1434
In high-multiplicity events	finding	2K_dev_1434
a long-range ( |__| > 2 )	finding	2K_dev_1434
near-side ( __0 ) structure emerges in the two-particle __-__ correlation functions	finding	2K_dev_1434
The magnitude of the correlation exhibits a pronounced maximum in the range 1 < p_ { T } < 2	finding	2K_dev_1434
0__GeV/c and an approximately linear increase with the charged particle multiplicity	finding	2K_dev_1434
with an overall correlation strength similar to that found in earlier pp data at sqrt [ s ] 0	finding	2K_dev_1434
The present measurement extends the study of near-side long-range correlations up to charged particle multiplicities N_ { ch } _180	finding	2K_dev_1434
a region so far unexplored in pp collisions	finding	2K_dev_1434
	mechanism	2K_dev_1434
The data were taken with the CMS detector at the LHC and correspond to an integrated luminosity of about 270__nb^ { -1 }	method	2K_dev_1434
The correlations are studied over a broad range of pseudorapidity ( |_| < 2	method	2K_dev_1434
4 ) and over the full azimuth ( _ ) as a function of charged particle multiplicity and transverse momentum ( p_ { T } The observed long-range correlations are compared to those seen in pp	method	2K_dev_1434
pPb	method	2K_dev_1434
and PbPb collisions at lower collision energies	method	2K_dev_1434
Results on two-particle angular correlations for charged particles produced in pp collisions at a center-of-mass energy of 13TeV are presented	purpose	2K_dev_1434
	purpose	2K_dev_1434
	background	2K_dev_1435
	finding	2K_dev_1435
	mechanism	2K_dev_1435
	method	2K_dev_1435
	purpose	2K_dev_1435
	background	2K_dev_1436
	finding	2K_dev_1436
	mechanism	2K_dev_1436
	method	2K_dev_1436
	purpose	2K_dev_1436
	background	2K_dev_1437
	finding	2K_dev_1437
	mechanism	2K_dev_1437
	method	2K_dev_1437
	purpose	2K_dev_1437
This is in contrast to a main path analysis of conflict from 1957-1971 where ideas did n't persist in that multiple paths existed and died or emerged reflecting lack of scientific coherence ( Carley	background	2K_dev_1438
Hummon	background	2K_dev_1438
and Harty	background	2K_dev_1438
1993 )	background	2K_dev_1438
More recent intrastate studies that focused on inequalities emerged from interstate studies on the democracy of peace earlier on the path	background	2K_dev_1438
2 ) Recent research on the path focused on forecasting conflict	background	2K_dev_1438
which depends on well-developed metrics and theories to model	background	2K_dev_1438
These datasets appear to be important in the development of conflict research	background	2K_dev_1438
allowing for cross-case comparisons	background	2K_dev_1438
and comparisons to previous works	background	2K_dev_1438
	background	2K_dev_1438
Out of this vast dataset	finding	2K_dev_1438
49 academic works were highlighted by the CPA suggesting a coherent field of inquiry ; which means that researchers in the field acknowledge seminal contributions and share a common knowledge base	finding	2K_dev_1438
did not form their own CP A single path formed	finding	2K_dev_1438
meaning that there was a cohesive set of ideas that built upon previous research	finding	2K_dev_1438
The critical path consisted of a number of key features : 1 ) Concepts that built throughout include the notion that resource availability drives conflict	finding	2K_dev_1438
which emerged in the 1960s-1990s and continued on until 2011	finding	2K_dev_1438
Publically available conflict datasets developed early on helped shape the operationalization of conflict	finding	2K_dev_1438
In fact	finding	2K_dev_1438
94 % of the works on the CP that analyzed data either relied on publically available datasets	finding	2K_dev_1438
or they generated a dataset and made it public	finding	2K_dev_1438
	mechanism	2K_dev_1438
We inductively tested in an analysis of published research involving `` conflict '' in the Web of Science ( WoS ) over a 66-year period ( 1945-2011 )	method	2K_dev_1438
We created a citation network that linked the 62504 WoS records and their cited literature	method	2K_dev_1438
We performed a critical path analysis ( CPA )	method	2K_dev_1438
a specialized social network analysis on this citation network ( ~1	method	2K_dev_1438
5 million works )	method	2K_dev_1438
Other conflict concepts that were also analyzed-such as interpersonal conflict or conflict among pharmaceuticals	method	2K_dev_1438
for example	method	2K_dev_1438
3 ) We used keyword analysis to independently	method	2K_dev_1438
if a coherent field of inquiry in human conflict research emerged to highlight the main contributions in conflict research and to test if research on conflict has in fact evolved to represent a coherent field of inquiry	purpose	2K_dev_1438
show how the CP was topically linked ( i	purpose	2K_dev_1438
e	purpose	2K_dev_1438
	purpose	2K_dev_1438
through democracy	purpose	2K_dev_1438
modeling	purpose	2K_dev_1438
resources	purpose	2K_dev_1438
and geography )	purpose	2K_dev_1438
	purpose	2K_dev_1438
	background	2K_dev_1439
	finding	2K_dev_1439
	mechanism	2K_dev_1439
	method	2K_dev_1439
	purpose	2K_dev_1439
The core premise of evidence-based medicine is that clinical decisions are informed by the peer-reviewed literature and discuss the implication of this form of bias as it pertains to evidence-based medicine	background	2K_dev_1440
	background	2K_dev_1440
We found that the distribution of these 108 articles among the 26 journals to be non-random ( p < 0	finding	2K_dev_1440
01 )	finding	2K_dev_1440
with 75 of the 108 published articles ( 69 % ) appearing in 6 of the 26 journals ( 25 % )	finding	2K_dev_1440
Moreover	finding	2K_dev_1440
certain journals were likely to publish a large number of articles from the same medical academic genealogy ( authors with shared training history and/or mentor ) We term the tendency of certain types of articles to be published in select journals 'journal bias '	finding	2K_dev_1440
	mechanism	2K_dev_1440
We performed an exhaustive search that identified articles exploring the question of whether survival benefit was associated with maximal high-grade glioma ( HGG ) resection	method	2K_dev_1440
To extract meaningful conclusions from this literature	purpose	2K_dev_1440
one must first understand the various forms of biases inherent within the process of peer review	purpose	2K_dev_1440
and analysed this literature for patterns of publication	purpose	2K_dev_1440
	purpose	2K_dev_1440
Fluorescence microscopy is one of the most important tools in cell biology research because it provides spatial and temporal information to investigate regulatory systems inside cells This technique can generate data in the form of signal intensities at thousands of positions resolved inside individual live cells	background	2K_dev_1441
However	background	2K_dev_1441
given extensive cell-to-cell variation	background	2K_dev_1441
these data can not be readily assembled into three- or four-dimensional maps of protein concentration that can be compared across different cells and conditions	background	2K_dev_1441
showed that the primary effect of costimulation blockade was to decrease recruitment of the activator of actin nucleation WAVE2 ( Wiskott-Aldrich syndrome protein family verprolin-homologous protein 2 ) and the actin-severing protein cofilin to F-actin	finding	2K_dev_1441
Reconstitution of WAVE2 and cofilin activity restored the defect in actin signaling dynamics caused by costimulation blockade	finding	2K_dev_1441
Thus	finding	2K_dev_1441
we have developed and validated an approach to quantify protein distributions in time and space for the analysis of complex regulatory systems	finding	2K_dev_1441
	finding	2K_dev_1441
We have developed a method and applied it Antigen recognition in T cells by the T cell receptor ( TCR ) is amplified by engagement of the costimulatory receptor CD28	mechanism	2K_dev_1441
We imaged actin and eight core actin regulators to generate over a thousand movies of T cells under conditions in which CD28 was either engaged or blocked in the context of a strong TCR signal	mechanism	2K_dev_1441
	mechanism	2K_dev_1441
Our computational analysis	method	2K_dev_1441
to enable comparison of imaging data from many cells to investigate actin dynamics in T cell activation	purpose	2K_dev_1441
	purpose	2K_dev_1441
One goal of human genetics is to understand the genetic basis of disease	background	2K_dev_1442
a challenge for diseases of complex inheritance because risk alleles are few relative to the vast set of benign variants	background	2K_dev_1442
Risk variants are often sought by association studies in which allele frequencies in case subjects are contrasted with those from population-based samples used as control subjects	background	2K_dev_1442
If such a resource were to exist	background	2K_dev_1442
it would yield ample savings and would facilitate the effective use of data repositories by removing administrative and technical barriers	background	2K_dev_1442
These results highlight how UNICORN can enable reliable	background	2K_dev_1442
powerful	background	2K_dev_1442
and convenient genetic association analyses without access to the individual-level data	background	2K_dev_1442
showing how it controls 0 positives	finding	2K_dev_1442
provides power similar to that achieved when all control data are directly accessible	finding	2K_dev_1442
and enhances power when control data are limiting or even imperfectly matched ancestrally	finding	2K_dev_1442
We call this concept the Universal Control Repository Network ( UNICORN )	mechanism	2K_dev_1442
a means Our approach to UNICORN uses existing genetic resources and various statistical tools to analyze these data	mechanism	2K_dev_1442
including hierarchical clustering with spectral analysis of ancestry ; and empirical Bayesian analysis along with Gaussian spatial processes to estimate ancestry-specific allele frequencies	mechanism	2K_dev_1442
We demonstrate our approach using tens of thousands of control subjects from studies of Crohn disease	method	2K_dev_1442
	method	2K_dev_1442
In an ideal world we would know population-level allele frequencies	purpose	2K_dev_1442
releasing researchers to focus on case subjects	purpose	2K_dev_1442
We argue this ideal is possible	purpose	2K_dev_1442
at least theoretically	purpose	2K_dev_1442
and we outline a path to achieving it in reality	purpose	2K_dev_1442
to perform association analyses without necessitating direct access to individual-level control data	purpose	2K_dev_1442
	purpose	2K_dev_1442
	background	2K_dev_1443
indicate that SMs reveal more PTSD symptoms to the VH than they report on the Post Deployment Health Assessment Pre/Post deployment facial expression analysis indicated more sad expressions and few happy expressions at post deployment	finding	2K_dev_1443
	finding	2K_dev_1443
SimSensei is a Virtual Human ( VH ) interviewing platform that uses off-the-shelf sensors ( i	mechanism	2K_dev_1443
e	mechanism	2K_dev_1443
	mechanism	2K_dev_1443
webcams	mechanism	2K_dev_1443
Microsoft Kinect and a microphone ) to capture and interpret real-time audiovisual behavioral signals from users interacting with the VH system	mechanism	2K_dev_1443
The system was specifically designed for clinical interviewing and health care support by providing a face-to-face interaction between a user and a VH that can automatically react to the inferred state of the user through analysis of behavioral signals gleaned from the user 's facial expressions	mechanism	2K_dev_1443
body gestures and vocal parameters	mechanism	2K_dev_1443
Akin to how non-verbal behavioral signals have an impact on human-to-human interaction and communication	mechanism	2K_dev_1443
	mechanism	2K_dev_1443
Results from of sample of service members ( SMs ) who were interviewed before and after a deployment to Afghanistan	method	2K_dev_1443
SimSensei aims to capture and infer user state from signals generated from user non-verbal communication to improve engagement between a VH and a user and to quantify user state from the data captured across a 20 minute interview	purpose	2K_dev_1443
	purpose	2K_dev_1443
Multifunctional polymer-based composites have been widely used in various research and industrial applications	background	2K_dev_1444
such as flexible and stretchable electronics and sensors and sensor-integrated smart structures This work may provide rational methods for the fabrication of aligned composites	background	2K_dev_1444
With the increase of the volume fraction of the SNP	finding	2K_dev_1444
the aligned SNP/PDMS composites exhibited a higher tensile strength and a lower ultimate strain	finding	2K_dev_1444
In addition	finding	2K_dev_1444
the composites with aligned SNP showed a lower percolation threshold and a higher electrical conductivity compared with those with randomly dispersed SNP However	finding	2K_dev_1444
when the concentration of the SNP reached a certain level ( 40 vol	finding	2K_dev_1444
% )	finding	2K_dev_1444
the anisotropy of the effective material property became less noticeable than that of the lower concentration ( 20 vol	finding	2K_dev_1444
% ) composites due to the change of the microstructure of the particles caused by the coalescence of the particles at a high concentration	finding	2K_dev_1444
	mechanism	2K_dev_1444
	method	2K_dev_1444
This study investigates the influence of particle coalescence on the mechanical and electrical properties of spherical nickel powder ( SNP ) /polydimethylsiloxane ( PDMS ) composites in which SNP was aligned using an external magnetic field	purpose	2K_dev_1444
	background	2K_dev_1445
This material exhibits a unique combination of high dielectric constant	finding	2K_dev_1445
low stiffness	finding	2K_dev_1445
and large strain limit ( ca	finding	2K_dev_1445
600 % strain )	finding	2K_dev_1445
and strong agreement with predictions from effective medium theory is found	finding	2K_dev_1445
	finding	2K_dev_1445
by embedding liquid-metal inclusions in an elastomer matrix	mechanism	2K_dev_1445
	mechanism	2K_dev_1445
The elasticity	method	2K_dev_1445
electrostatics	method	2K_dev_1445
and electromechanical coupling of the composite are investigated	method	2K_dev_1445
	method	2K_dev_1445
An all-soft-matter composite with exceptional electro-elasto properties is demonstrated	purpose	2K_dev_1445
Maximum-a-Posteriori ( MAP ) inference lies at the heart of Graphical Models and Structured Prediction	background	2K_dev_1446
Despite the intractability of exact MAP inference	background	2K_dev_1446
approximate methods based on LP relaxations have exhibited superior performance across a wide range of applications	background	2K_dev_1446
	background	2K_dev_1446
In this paper	mechanism	2K_dev_1446
we introduce an effective MAP inference method for problems with large output domains	mechanism	2K_dev_1446
The method builds upon alternating minimization of an Augmented Lagrangian that exploits the sparsity of messages through greedy optimization techniques	mechanism	2K_dev_1446
A key feature of our greedy approach is to introduce variables in an on-demand manner with a pre-built data structure over local factors	mechanism	2K_dev_1446
In addition	mechanism	2K_dev_1446
we introduce a variant of GDMM for binary MAP inference problems with a large number of factors	mechanism	2K_dev_1446
	mechanism	2K_dev_1446
Empirically	method	2K_dev_1446
Yet for problems involving large output domains ( i	purpose	2K_dev_1446
e	purpose	2K_dev_1446
	purpose	2K_dev_1446
the state space for each variable is large )	purpose	2K_dev_1446
standard LP relaxations can easily give rise to a large number of variables and constraints which are beyond the limit of existing optimization algorithms	purpose	2K_dev_1446
	purpose	2K_dev_1446
Recent studies have shown that brain-machine interfaces ( BMIs ) offer great potential for restoring upper limb function	background	2K_dev_1447
	background	2K_dev_1447
	finding	2K_dev_1447
We describe a method of shared control where the user controls a prosthetic arm using a BMI and receives assistance with positioning the hand when it approaches an object	mechanism	2K_dev_1447
	method	2K_dev_1447
However	purpose	2K_dev_1447
grasping objects is a complicated task and the signals extracted from the brain may not always be capable of driving these movements reliably	purpose	2K_dev_1447
Vision-guided robotic assistance is one possible way to improve BMI performance	purpose	2K_dev_1447
	purpose	2K_dev_1447
Complex networks have been shown to exhibit universal properties	background	2K_dev_1448
with one of the most consistent patterns being the scale-free degree distribution	background	2K_dev_1448
We find that this relationship follows a power-law in real networks within the range 2 r d	finding	2K_dev_1448
where d is the effective diameter of the network	finding	2K_dev_1448
that is	finding	2K_dev_1448
the 90-th percentile distance	finding	2K_dev_1448
We provide theoretical justification for this pattern we show the pervasiveness of the power-hop	finding	2K_dev_1448
	finding	2K_dev_1448
by identifying another power-law pattern that describes the relationship between the fractions of node pairs C ( r ) within r hops and the hop count r	mechanism	2K_dev_1448
This scale-free distribution is pervasive and describes a large variety of networks	mechanism	2K_dev_1448
ranging from social and urban to technological and biological networks	mechanism	2K_dev_1448
In particular	mechanism	2K_dev_1448
inspired by the definition of the fractal correlation dimension D2 on a point-set	mechanism	2K_dev_1448
we consider the hop-count r to be the underlying distance metric between two vertices of the network	mechanism	2K_dev_1448
and we examine the scaling of C ( r ) with r	mechanism	2K_dev_1448
We term this relationship as power-hop and the corresponding power-law exponent as power-hop exponent h	mechanism	2K_dev_1448
	mechanism	2K_dev_1448
under successful existing network models	method	2K_dev_1448
while we analyze a large set of real and synthetic network datasets and	method	2K_dev_1448
but are there regularities obeyed by the r-hop neighborhood in real networks ? We answer this question	purpose	2K_dev_1448
Eumelanins are extended heterogeneous biopolymers composed of molecular subunits with ambiguous macromolecular topology	background	2K_dev_1449
which suggests that natural eumelanin pigments contain indole-based tetramers that are arranged into porphyrin-like domains	finding	2K_dev_1449
suggest that sodium ions undergo occupancy-dependent stepwise insertion into the core of porphyrin-like tetramers in natural eumelanins at discrete potentials	finding	2K_dev_1449
	finding	2K_dev_1449
Here	mechanism	2K_dev_1449
an electrochemical fingerprinting technique is described	mechanism	2K_dev_1449
	mechanism	2K_dev_1449
Spectroscopy and density functional theory calculations	method	2K_dev_1449
	purpose	2K_dev_1449
High throughput screening determines the effects of many conditions on a given biological target	background	2K_dev_1450
Currently	background	2K_dev_1450
to estimate the effects of those conditions on other targets requires either strong modeling assumptions ( e	background	2K_dev_1450
g	background	2K_dev_1450
similarities among targets ) or separate screens	background	2K_dev_1450
The results represent the first practical demonstration of the utility of active learning-driven biological experimentation in which the set of possible phenotypes is unknown in advance	background	2K_dev_1450
	background	2K_dev_1450
this learner accurately learned the effects of 48 chemical compounds on the subcellular localization of 48 proteins while performing only 29 % of all possible experiments	finding	2K_dev_1450
We have previously described an active machine learning algorithm that can iteratively choose small sets of experiments to learn models of multiple effects	mechanism	2K_dev_1450
	mechanism	2K_dev_1450
We now show that	method	2K_dev_1450
with no prior knowledge and with liquid handling robotics and automated microscopy under its control	method	2K_dev_1450
Ideally	purpose	2K_dev_1450
data-driven experimentation could be used to learn accurate models for many conditions and targets without doing all possible experiments	purpose	2K_dev_1450
Despite the enormous medical impact of cancers and intensive study of their biology	background	2K_dev_1451
detailed characterization of tumor growth and development remains elusive	background	2K_dev_1451
This difficulty occurs in large part because of enormous heterogeneity in the molecular mechanisms of cancer progression	background	2K_dev_1451
both tumor-to-tumor and cell-to-cell in single tumors Advances in genomic technologies	background	2K_dev_1451
especially at the single-cell level	background	2K_dev_1451
are improving the situation	background	2K_dev_1451
but these approaches are held back by limitations of the biotechnologies for gathering genomic data from heterogeneous cell populations and the computational methods for making sense of those data	background	2K_dev_1451
One popular way to gain the advantages of whole-genome methods without the cost of single-cell genomics has been the use of computational deconvolution ( unmixing ) methods to reconstruct clonal heterogeneity from bulk genomic data	background	2K_dev_1451
a key step in the process of accurately deconvolving tumor genomic data and inferring clonal heterogeneity from bulk data	background	2K_dev_1451
	background	2K_dev_1451
that this new method substantially improves our ability to resolve discrete tumor subgroups	finding	2K_dev_1451
	finding	2K_dev_1451
Here	mechanism	2K_dev_1451
we present a new method by better identifying subspaces corresponding to tumors produced from mixtures of distinct combinations of clonal subpopulations We develop a nonparametric clustering method based on medoidshift clustering for identifying subgroups of tumors expected to correspond to distinct trajectories of evolutionary progression	mechanism	2K_dev_1451
	mechanism	2K_dev_1451
We show on synthetic and real tumor copy-number data	method	2K_dev_1451
These methods	purpose	2K_dev_1451
too	purpose	2K_dev_1451
are limited by the difficulty of inferring genomic profiles of rare or subtly varying clonal subpopulations from bulk data	purpose	2K_dev_1451
a problem that can be computationally reduced to that of reconstructing the geometry of point clouds of tumor samples in a genome space to improve that reconstruction	purpose	2K_dev_1451
	background	2K_dev_1452
	finding	2K_dev_1452
	mechanism	2K_dev_1452
	method	2K_dev_1452
	purpose	2K_dev_1452
In eukaryotic cells	background	2K_dev_1453
mitochondria form a dynamic interconnected network to respond to changing needs at different subcellular locations	background	2K_dev_1453
We found that stationary and moving mitochondria underwent fusion and fission regularly but followed different spatial distribution patterns and exhibited different morphology Disruption of inner membrane fusion by knockdown of dOpa1	finding	2K_dev_1453
Drosophila Optic Atrophy 1	finding	2K_dev_1453
not only increased the spatial density of stationary and moving mitochondria but also changed their spatial distributions and morphology differentially	finding	2K_dev_1453
Knockdown of dOpa1 also impaired axonal transport of mitochondria	finding	2K_dev_1453
But the changed spatial distributions of mitochondria resulted primarily from disruption of inner membrane fusion because knockdown of Milton	finding	2K_dev_1453
a mitochondrial kinesin-1 adapter	finding	2K_dev_1453
caused similar transport velocity impairment but different spatial distributions	finding	2K_dev_1453
Together	finding	2K_dev_1453
our data reveals that stationary mitochondria within the axon interconnect with moving mitochondria through fusion and fission and that local inner membrane fusion between individual mitochondria mediates their global distribution	finding	2K_dev_1453
	finding	2K_dev_1453
	mechanism	2K_dev_1453
we developed high-resolution computational image analysis techniques	mechanism	2K_dev_1453
to examine the relations between mitochondrial fusion/fission and spatial distribution within the axon of Drosophila larval neurons	method	2K_dev_1453
	method	2K_dev_1453
A fundamental yet unanswered question regarding this network is whether	purpose	2K_dev_1453
and if so how	purpose	2K_dev_1453
local fusion and fission of individual mitochondria affect their global distribution	purpose	2K_dev_1453
To address this question	purpose	2K_dev_1453
Bayesian theory has provided a compelling conceptualization for perceptual inference in the brain	background	2K_dev_1454
Central to Bayesian inference is the notion of statistical priors	background	2K_dev_1454
To understand the neural mechanisms of Bayesian inference	background	2K_dev_1454
we need to understand the neural representation of statistical regularities in the natural environment	background	2K_dev_1454
They also suggest that the Boltzmann machine can be a viable model for conceptualizing computations in the visual cortex and	background	2K_dev_1454
as such	background	2K_dev_1454
can be used to predict neural circuits in the visual cortex from natural scene statistics	background	2K_dev_1454
	background	2K_dev_1454
	finding	2K_dev_1454
and found that the units in the model exhibited cooperative and competitive interactions	finding	2K_dev_1454
forming a `` disparity association field ''	finding	2K_dev_1454
analogous to the contour association field	finding	2K_dev_1454
The cooperative and competitive interactions in the disparity association field are consistent with constraints of computational models for stereo matching	finding	2K_dev_1454
and found the results to be consistent with neurophysiological data in terms of the functional connectivity measurements between disparity-tuned neurons in the macaque primary visual cortex	finding	2K_dev_1454
These findings demonstrate that there is a relationship between the functional connectivity observed in the visual cortex and the statistics of natural scenes	finding	2K_dev_1454
	finding	2K_dev_1454
We applied a Boltzmann machine model	mechanism	2K_dev_1454
In addition	method	2K_dev_1454
we simulated neurophysiological experiments on the model	method	2K_dev_1454
	method	2K_dev_1454
In this paper	purpose	2K_dev_1454
we investigated empirically how statistical regularities in natural 3D scenes are represented in the functional connectivity of disparity-tuned neurons in the primary visual cortex of primates	purpose	2K_dev_1454
to learn from 3D natural scenes	purpose	2K_dev_1454
Between postnatal days 14 and 18	finding	2K_dev_1455
synapse density significantly increases most in superficial layers	finding	2K_dev_1455
and synapse length increases in L3 and L5B	finding	2K_dev_1455
Removal of all but a single whisker row for 24 h led to an apparent increase in synapse density in L2 and a decrease in L6	finding	2K_dev_1455
and a significant increase in length in L3	finding	2K_dev_1455
showed that mEPSC frequency nearly doubled in the whisker-spared column	finding	2K_dev_1455
a difference that was highly significant	finding	2K_dev_1455
	finding	2K_dev_1455
Here we adapt an electron microscopy technique that selectively labels synapses	mechanism	2K_dev_1455
in combination with a machine-learning algorithm for semiautomated synapse detection	mechanism	2K_dev_1455
	mechanism	2K_dev_1455
Synapse density and length were compared across development and during whisker-evoked plasticity	method	2K_dev_1455
Targeted electrophysiological analysis of changes in miniature EPSC and IPSC properties in L2 pyramidal neurons	method	2K_dev_1455
Without this comprehensive approach	purpose	2K_dev_1455
a full understanding of how cortical circuits adapt during learning or altered sensory input will be impossible to perform an unbiased analysis of developmental and experience-dependent changes in synaptic properties across an entire cortical column in mice	purpose	2K_dev_1455
	purpose	2K_dev_1455
In this paradigm	background	2K_dev_1456
mothers and infants play normally for 2 minutes ( Play ) followed by 2 minutes in which the mothers remain unresponsive ( Still Face )	background	2K_dev_1456
and then two minutes in which they resume normal behavior ( Reunion )	background	2K_dev_1456
Together	background	2K_dev_1456
these findings suggest that angular displacement	background	2K_dev_1456
angular velocity and their coordination between mothers and infants are strongly related to age-appropriate emotion challenge	background	2K_dev_1456
Attention to head movement can deepen our understanding of emotion communication	background	2K_dev_1456
	background	2K_dev_1456
In male but not female infants	finding	2K_dev_1456
angular displacement increased from Play to Still-Face and decreased from Still Face to Reunion	finding	2K_dev_1456
Infant angular velocity was higher during Still-Face than Reunion with no differences between male and female infants Windowed cross-correlation suggested changes in how infant and mother head movements are associated	finding	2K_dev_1456
revealing dramatic changes in direction of association	finding	2K_dev_1456
Coordination between mother and infant head movement velocity was greater during Play compared with Reunion	finding	2K_dev_1456
	finding	2K_dev_1456
	mechanism	2K_dev_1456
Participants were 42 ethnically diverse 4-month-old infants and their mothers	method	2K_dev_1456
Mother and infant angular displacement and angular velocity were measured using the CSIRO head tracker	method	2K_dev_1456
	method	2K_dev_1456
We investigated the dynamics of head movement in mothers and infants during an age-appropriate	purpose	2K_dev_1456
well-validated emotion induction	purpose	2K_dev_1456
the Still Face paradigm	purpose	2K_dev_1456
	purpose	2K_dev_1456
	background	2K_dev_1457
	finding	2K_dev_1457
	mechanism	2K_dev_1457
	method	2K_dev_1457
	purpose	2K_dev_1457
Characterizing the spatial distribution of proteins directly from microscopy images is a difficult problem with numerous applications in cell biology ( e	background	2K_dev_1458
g	background	2K_dev_1458
identifying motor-related proteins ) and clinical research ( e	background	2K_dev_1458
g	background	2K_dev_1458
identification of cancer biomarkers )	background	2K_dev_1458
Such models are expected to be valuable for representing and summarizing each pattern and for constructing systems biology simulations of cell behaviors	background	2K_dev_1458
We were able to show that these patterns could be distinguished from each other with high accuracy	finding	2K_dev_1458
and we were able to assign to one of these subclasses hundreds of proteins whose subcellular localization had not previously been well defined	finding	2K_dev_1458
	finding	2K_dev_1458
Here we describe the design of a system We constructed the system using confocal immunofluorescence microscopy images from the Human Protein Atlas project for 11 punctate proteins in three cultured cell lines These proteins have previously been characterized as being primarily located in punctate structures	mechanism	2K_dev_1458
but their images had all been annotated by visual examination as being simply `` vesicular '' In addition to providing these novel annotations	mechanism	2K_dev_1458
we built a generative approach to	mechanism	2K_dev_1458
	method	2K_dev_1458
that provides automated analysis of punctate protein patterns in microscope images	purpose	2K_dev_1458
including quantification of their relationships to microtubules	purpose	2K_dev_1458
modeling of punctate distributions that captures the essential characteristics of the distinct patterns	purpose	2K_dev_1458
	purpose	2K_dev_1458
	background	2K_dev_1459
show moderate volumetric resistivity ( as low as _ 0 0	finding	2K_dev_1459
03 /m ) through the thickness and no conductivity between adjacent traces	finding	2K_dev_1459
Functionality is demonstrated	finding	2K_dev_1459
These films are composed of polydimethylsiloxane ( PDMS ) embedded with vertically aligned columns of ferromagnetic Ag-Ni microparticles	mechanism	2K_dev_1459
The microparticles are magnetically aligned and support electrical conductivity only through the thickness ( z-axis ) of the elastomer film	mechanism	2K_dev_1459
	mechanism	2K_dev_1459
We introduce a method for sealing liquid metal ( LM ) circuits with soft anisotropic conductors that prevent leaking	purpose	2K_dev_1459
while simultaneously allowing for electrical contact with skin and surface mounted electronics	purpose	2K_dev_1459
	purpose	2K_dev_1459
This lack of consistency will affect future research on the clinical significance of snoring	background	2K_dev_1460
	background	2K_dev_1460
The chest audio picked up the highest number of snore events of the different snore sensors	finding	2K_dev_1460
: overhead audio ( 0	finding	2K_dev_1460
78	finding	2K_dev_1460
0	finding	2K_dev_1460
98 )	finding	2K_dev_1460
cannula ( 0	finding	2K_dev_1460
55	finding	2K_dev_1460
0	finding	2K_dev_1460
67 ) and piezoelectric sensor ( 0	finding	2K_dev_1460
78	finding	2K_dev_1460
0	finding	2K_dev_1460
92 )	finding	2K_dev_1460
respectively	finding	2K_dev_1460
The chest audio was capable of detecting snore events with lower volume and higher fundamental frequency than the other sensors	finding	2K_dev_1460
The 200 Hz sampling rate of the cannula and piezoelectric sensor was one of their limitations for detecting snore events	finding	2K_dev_1460
The different snore sensors do not measure snore events in the same manner Standardization of objective snore measurements is therefore needed	finding	2K_dev_1460
Based on this paper	finding	2K_dev_1460
snore measurements should be audio-based and the use of the cannula as a snore sensor be discontinued	finding	2K_dev_1460
but the piezoelectric sensor could possibly be modified for improvement	finding	2K_dev_1460
	finding	2K_dev_1460
	mechanism	2K_dev_1460
Ten subjects reporting habitual snoring were included in the study	method	2K_dev_1460
performed at Landspitali-University Hospital	method	2K_dev_1460
Iceland	method	2K_dev_1460
Snoring was assessed by listening to the air medium microphone located on a patient 's chest	method	2K_dev_1460
compared to listening to two overhead air medium microphones ( stereo ) and manual scoring of a piezoelectric sensor and nasal cannula vibrations The sensitivity and positive predictive value of scoring snore events from the different sensors was compared to the chest audio	method	2K_dev_1460
The objective of this study was to compare to each other the methods currently recommended by the American Academy of Sleep Medicine ( AASM ) to measure snoring : an acoustic sensor	purpose	2K_dev_1460
a piezoelectric sensor and a nasal pressure transducer ( cannula )	purpose	2K_dev_1460
	purpose	2K_dev_1460
	background	2K_dev_1461
	finding	2K_dev_1461
	mechanism	2K_dev_1461
	method	2K_dev_1461
	purpose	2K_dev_1461
Games for health ( G4H ) aim to improve health outcomes and encourage behavior change While existing theoretical frameworks describe features of both games and health interventions	background	2K_dev_1462
We discuss how this work can be applied to provide conceptual tools	background	2K_dev_1462
improve the G4H design process	background	2K_dev_1462
and guide approaches to encoding G4H-related data for large-scale empirical analysis	background	2K_dev_1462
	background	2K_dev_1462
We found evidence of conceptual differences suggesting that a G4H perspective is not simply the sum of game and health perspectives At the same time	finding	2K_dev_1462
we found evidence of convergence in stakeholder views	finding	2K_dev_1462
including areas where game experts provided insights about health and vice versa	finding	2K_dev_1462
	mechanism	2K_dev_1462
We recruited 18 experts from the fields of game design	method	2K_dev_1462
behavioral health	method	2K_dev_1462
and games for health	method	2K_dev_1462
and prompted them with 16 sample games	method	2K_dev_1462
Applying methods including open card sorting and triading	method	2K_dev_1462
we elicited themes and features ( e	method	2K_dev_1462
g	method	2K_dev_1462
	method	2K_dev_1462
real-world interaction	method	2K_dev_1462
game mechanics ) around G4H	method	2K_dev_1462
there has been limited systematic investigation into how disciplinary and interdisciplinary stakeholders understand design features in G4H	purpose	2K_dev_1462
	purpose	2K_dev_1462
Both the occurrence and intensity of facial expressions are critical to what the face reveals	background	2K_dev_1463
While much progress has been made towards the automatic detection of facial expression occurrence	background	2K_dev_1463
controversy exists about how to estimate expression intensity	background	2K_dev_1463
The most straight-forward approach is to train multiclass or regression models using intensity ground truth	background	2K_dev_1463
However	background	2K_dev_1463
collecting intensity ground truth is even more time consuming and expensive than collecting binary ground truth	background	2K_dev_1463
	background	2K_dev_1463
However	finding	2K_dev_1463
if they do so	finding	2K_dev_1463
high reliability with expert human coders can be achieved	finding	2K_dev_1463
Intensity-trained multiclass and regression models outperformed binary-trained classifier decision values on smile intensity estimation Multiclass models even outperformed binary-trained classifiers	finding	2K_dev_1463
	mechanism	2K_dev_1463
across multiple databases and methods for feature extraction and dimensionality reduction	method	2K_dev_1463
on smile occurrence detection	method	2K_dev_1463
	method	2K_dev_1463
As a shortcut	purpose	2K_dev_1463
some researchers have proposed using the decision values of binary-trained maximum margin classifiers as a proxy for expression intensity	purpose	2K_dev_1463
We provide empirical evidence that this heuristic is flawed in practice as well as in theory Unfortunately	purpose	2K_dev_1463
there are no shortcuts when it comes to estimating smile intensity : researchers must take the time to collect and train on intensity ground truth	purpose	2K_dev_1463
	purpose	2K_dev_1463
	background	2K_dev_1464
	finding	2K_dev_1464
	mechanism	2K_dev_1464
	method	2K_dev_1464
	purpose	2K_dev_1464
	background	2K_dev_1465
	finding	2K_dev_1465
	mechanism	2K_dev_1465
	method	2K_dev_1465
	purpose	2K_dev_1465
Laser photocoagulation is a mainstay or adjuvant treatment for a variety of common retinal diseases	background	2K_dev_1466
	finding	2K_dev_1466
The authors introduce an automated laser photocoagulation system for intraocular surgery	mechanism	2K_dev_1466
based on a novel handheld instrument	mechanism	2K_dev_1466
	method	2K_dev_1466
Automated laser photocoagulation during intraocular surgery has not yet been established	purpose	2K_dev_1466
The goals of the system are to enhance accuracy and efficiency and improve safety	purpose	2K_dev_1466
	purpose	2K_dev_1466
As sampling-based motion planners become faster	background	2K_dev_1467
they can be re-executed more frequently by a robot during task execution to react to uncertainty in robot motion	background	2K_dev_1467
obstacle motion	background	2K_dev_1467
sensing noise	background	2K_dev_1467
and uncertainty in the robot 's kinematic model	background	2K_dev_1467
	background	2K_dev_1467
We show that	finding	2K_dev_1467
as parallel computation power increases	finding	2K_dev_1467
HFR offers asymptotic optimality for these objectives during each period for goal-oriented problems	finding	2K_dev_1467
We then demonstrate the effectiveness of HFR	finding	2K_dev_1467
	mechanism	2K_dev_1467
where	mechanism	2K_dev_1467
during each period	mechanism	2K_dev_1467
fast sampling-based motion planners are executed in parallel as the robot simultaneously executes the first action of the best motion plan from the previous period	mechanism	2K_dev_1467
We consider discrete-time systems with stochastic nonlinear ( but linearizable ) dynamics and observation models with noise drawn from zero mean Gaussian distributions	mechanism	2K_dev_1467
	mechanism	2K_dev_1467
for holonomic and nonholonomic robots including car-like vehicles and steerable medical needles	method	2K_dev_1467
We investigate and analyze high-frequency replanning ( HFR ) The objective is to maximize the probability of success ( i	purpose	2K_dev_1467
e	purpose	2K_dev_1467
	purpose	2K_dev_1467
avoid collision with obstacles and reach the goal ) or to minimize path length subject to a lower bound on the probability of success	purpose	2K_dev_1467
	purpose	2K_dev_1467
Nationally sponsored cancer-care quality-improvement efforts have been deployed in community health centers to increase breast	background	2K_dev_1468
cervical	background	2K_dev_1468
and colorectal cancer-screening rates among vulnerable populations Despite several immediate and short-term gains	background	2K_dev_1468
screening rates remain below national benchmark objectives	background	2K_dev_1468
Overall improvement has been both difficult to sustain over time in some organizational settings and/or challenging to diffuse to other settings as repeatable best practices	background	2K_dev_1468
Reasons for this include facility-level changes	background	2K_dev_1468
which typically occur in dynamic organizational environments that are complex	background	2K_dev_1468
adaptive	background	2K_dev_1468
and unpredictable	background	2K_dev_1468
	background	2K_dev_1468
	finding	2K_dev_1468
	mechanism	2K_dev_1468
This study applies a computational-modeling approach	method	2K_dev_1468
combining principles of health-services research	method	2K_dev_1468
health informatics	method	2K_dev_1468
network theory	method	2K_dev_1468
and systems science	method	2K_dev_1468
	method	2K_dev_1468
This study seeks to understand the factors that shape community health center facility-level cancer-screening performance over time	purpose	2K_dev_1468
	purpose	2K_dev_1468
Management decisions underpinning availability of ecosystem services and the organisms that provide them in agroecosystems	background	2K_dev_1469
such as pollinators and pollination services	background	2K_dev_1469
have emerged as a foremost consideration for both conservation and crop production goals	background	2K_dev_1469
There is growing evidence that innovative management practices can support diverse pollinators and increase crop pollination	background	2K_dev_1469
	background	2K_dev_1469
The results demonstrated that 17 % of growers adopted combinations of bees ( e	finding	2K_dev_1469
g	finding	2K_dev_1469
honey bees	finding	2K_dev_1469
Apis mellifera	finding	2K_dev_1469
with other species )	finding	2K_dev_1469
representing an innovation in use by early adopters ; 49 % of growers adopted flowering cover crops	finding	2K_dev_1469
an innovation in use by the early majority 55 % of growers retained permanent habitat for pollinators	finding	2K_dev_1469
an innovation in use by the late majority	finding	2K_dev_1469
Not all growers adopted innovative practices	finding	2K_dev_1469
We found that growers ' personal experience with potential benefits and concerns related to the management practices had significant positive and negative relationships	finding	2K_dev_1469
respectively	finding	2K_dev_1469
with adoption of all three innovations	finding	2K_dev_1469
The influence of these communication links likely has different levels of importance	finding	2K_dev_1469
depending on the stage of the adoption that a practice is experiencing in the agricultural community Social learning was positively associated with adopting the use of combinations of bees	finding	2K_dev_1469
highlighting the potentially critical roles of peer-to-peer networks and social learning in supporting early stages of adoption of innovations Engaging with grower networks and understanding grower experience with benefits and concerns associated with innovative practices is needed to inform outreach	finding	2K_dev_1469
extension	finding	2K_dev_1469
and policy efforts designed to stimulate management innovations in agroecosystems	finding	2K_dev_1469
	mechanism	2K_dev_1469
This study investigated pollination management practices and related knowledge systems in a major crop producing region of southwest Michigan in the United States	method	2K_dev_1469
where 367 growers were surveyed to evaluate adoption of three innovative practices that are at various stages of adoption	method	2K_dev_1469
	method	2K_dev_1469
However	purpose	2K_dev_1469
there is also considerable debate regarding factors that support adoption of these innovative practices	purpose	2K_dev_1469
The goals of this quantitative	purpose	2K_dev_1469
social survey were to investigate grower experience with concerns and benefits associated with each practice	purpose	2K_dev_1469
as well as the influence of grower networks	purpose	2K_dev_1469
which are comprised of contacts that reflect potential pathways for social and technical learning	purpose	2K_dev_1469
	purpose	2K_dev_1469
	background	2K_dev_1470
	finding	2K_dev_1470
	mechanism	2K_dev_1470
	method	2K_dev_1470
	purpose	2K_dev_1470
Robust	background	2K_dev_1471
efficient	background	2K_dev_1471
and low-cost networks are advantageous in both biological and engineered systems	background	2K_dev_1471
During neural network development in the brain	background	2K_dev_1471
synapses are massively over-produced and then pruned-back over time	background	2K_dev_1471
This strategy is not commonly used when designing engineered networks	background	2K_dev_1471
since adding connections that will soon be removed is considered wasteful	background	2K_dev_1471
	background	2K_dev_1471
and found that the rate is decreasing over time	finding	2K_dev_1471
and show that decreasing rates lead to more robust and efficient networks compared to other rates	finding	2K_dev_1471
Thus	finding	2K_dev_1471
inspiration from neural network formation suggests effective ways to design distributed networks across several domains	finding	2K_dev_1471
We also present an application of this strategy	mechanism	2K_dev_1471
We first used high-throughput image analysis techniques to quantify the rate of pruning in the mammalian neocortex across a broad developmental time window Based on these results	method	2K_dev_1471
we analyzed a model of computational routing networks using both theoretical analysis and simulations	method	2K_dev_1471
Here	purpose	2K_dev_1471
we show that for large distributed routing networks	purpose	2K_dev_1471
network function is markedly enhanced by hyper-connectivity followed by aggressive pruning and that the global rate of pruning	purpose	2K_dev_1471
a developmental parameter not previously studied by experimentalists	purpose	2K_dev_1471
plays a critical role in optimizing network structure	purpose	2K_dev_1471
to improve the distributed design of airline networks	purpose	2K_dev_1471
	purpose	2K_dev_1471
There are likely marked differences in endotracheal intubation ( ETI ) techniques between novice and experienced providers	background	2K_dev_1472
	background	2K_dev_1472
	finding	2K_dev_1472
	mechanism	2K_dev_1472
We performed a proof of concept study	method	2K_dev_1472
to determine if portable motion technology could identify the motion components of ETI between novice and experienced providers	purpose	2K_dev_1472
On average	background	2K_dev_1473
two thousand residents in the United States experience a stroke every day	background	2K_dev_1473
These circumstances account for $ 28 billion direct costs annually and given the latest predictions	background	2K_dev_1473
these costs will more than triple by 2030	background	2K_dev_1473
	background	2K_dev_1473
offered positive indications towards this concept	finding	2K_dev_1473
In our research	mechanism	2K_dev_1473
we propose a portfolio of serious games Our system provides a collection of mini games based on rehabilitation exercises used in conventional physical therapy	mechanism	2K_dev_1473
monitors the patient 's performance while exercising and provides clinicians with an interface to personalize the training	mechanism	2K_dev_1473
The clinician can set the current state of rehabilitation and change the playable games over time to drive diversification	mechanism	2K_dev_1473
	mechanism	2K_dev_1473
While the system still has to be evaluated	method	2K_dev_1473
an early stage case study with one patient	method	2K_dev_1473
for home-based stroke rehabilitation The objective of the game approach is to enrich the training experience and establish a higher level of compliance to prescribed exercises	purpose	2K_dev_1473
while maintaining a supportive training environment as found in common therapy sessions	purpose	2K_dev_1473
Analogous to genomic sequence alignment	background	2K_dev_1474
biological network alignment identifies conserved regions between networks of different species	background	2K_dev_1474
Then	background	2K_dev_1474
function can be transferred from well- to poorly-annotated species between aligned network regions	background	2K_dev_1474
Network alignment typically encompasses two algorithmic components : node cost function ( NCF )	background	2K_dev_1474
which measures similarities between nodes in different networks	background	2K_dev_1474
and alignment strategy ( AS )	background	2K_dev_1474
which uses these similarities to rapidly identify high-scoring alignments	background	2K_dev_1474
Different methods use both different NCFs and different ASs	background	2K_dev_1474
Thus	background	2K_dev_1474
it is unclear whether the superiority of a method comes from its NCF	background	2K_dev_1474
its AS	background	2K_dev_1474
or both	background	2K_dev_1474
We already showed on state-of-the-art methods	background	2K_dev_1474
MI-GRAAL and IsoRankN	background	2K_dev_1474
that combining NCF of one method and AS of another method can give a new superior method	background	2K_dev_1474
Existing methods determine this parameter more-less arbitrarily	background	2K_dev_1474
which could affect alignment quality	background	2K_dev_1474
Existing methods assume that the larger the neighborhood size	background	2K_dev_1474
the better	background	2K_dev_1474
	background	2K_dev_1474
	finding	2K_dev_1474
GHOST	mechanism	2K_dev_1474
by mixing-and-matching the methods ' NCFs and ASs	mechanism	2K_dev_1474
	method	2K_dev_1474
Here	purpose	2K_dev_1474
we evaluate MI-GRAAL against a newer approach to potentially further improve alignment quality	purpose	2K_dev_1474
While doing so	purpose	2K_dev_1474
we approach important questions that have not been asked systematically thus far	purpose	2K_dev_1474
First	purpose	2K_dev_1474
we ask how much of the NCF information should come from protein sequence data compared to network topology data	purpose	2K_dev_1474
Second	purpose	2K_dev_1474
when topological information is used in NCF	purpose	2K_dev_1474
we ask how large the size of the neighborhoods of the compared nodes should be	purpose	2K_dev_1474
	purpose	2K_dev_1474
Platinum ( Pt ) drugs are the most potent and commonly used anti-cancer chemotherapeutics	background	2K_dev_1475
Nanoformulation of Pt drugs has the potential to improve the delivery to tumors and reduce toxic side effects	background	2K_dev_1475
	background	2K_dev_1475
This treatment can significantly reduce the toxicities of DACHPt/HANP in liver	finding	2K_dev_1475
spleen	finding	2K_dev_1475
and	finding	2K_dev_1475
interestingly	finding	2K_dev_1475
kidney Intralipid can decrease Pt accumulation in the liver	finding	2K_dev_1475
spleen	finding	2K_dev_1475
and kidney by 20	finding	2K_dev_1475
4 %	finding	2K_dev_1475
42	finding	2K_dev_1475
5 %	finding	2K_dev_1475
and 31	finding	2K_dev_1475
2 % at 24-hr post nanodrug administration	finding	2K_dev_1475
respectively	finding	2K_dev_1475
The bioavailability of DACHPt/HANP increases by 18	finding	2K_dev_1475
7 % and 9	finding	2K_dev_1475
4 % during the first 5 and 24 hr	finding	2K_dev_1475
respectively	finding	2K_dev_1475
	finding	2K_dev_1475
	method	2K_dev_1475
A major challenge for translating nanodrugs to clinical settings is their rapid clearance by the reticuloendothelial system ( RES )	purpose	2K_dev_1475
hence increasing toxicities on off-target organs and reducing efficacy	purpose	2K_dev_1475
	purpose	2K_dev_1475
In studying the strength and specificity of interaction between members of two protein families	background	2K_dev_1476
key questions center on which pairs of possible partners actually interact	background	2K_dev_1476
how well they interact	background	2K_dev_1476
and why they interact while others do not	background	2K_dev_1476
	background	2K_dev_1476
We demonstrate the effectiveness of our approach in analyzing and predicting interactions between a set of 82 PDZ recognition modules against a panel of 217 possible peptide partners	finding	2K_dev_1476
Our predicted _G values are highly predictive of the experimentally measured ones reaching correlation coefficients of 0	finding	2K_dev_1476
69 in 10-fold cross-validation and 0	finding	2K_dev_1476
63 in leave-one-PDZ-out cross-validation	finding	2K_dev_1476
Furthermore	finding	2K_dev_1476
the model serves as a compact representation of amino acid constraints underlying the interactions	finding	2K_dev_1476
enabling protein-level _G predictions to be naturally understood in terms of residue-level constraints Finally	finding	2K_dev_1476
the model DgSpi readily enables the design of new interacting partners	finding	2K_dev_1476
and we demonstrate that designed ligands are novel and diverse	finding	2K_dev_1476
	finding	2K_dev_1476
We develop here a method	mechanism	2K_dev_1476
DgSpi ( data-driven graphical models of specificity in protein : protein interactions )	mechanism	2K_dev_1476
based on data from MacBeath and colleagues	method	2K_dev_1476
The advent of large-scale experimental studies of interactions between members of a target family and a diverse set of possible interaction partners offers the opportunity to address these questions	purpose	2K_dev_1476
for learning and using graphical models that explicitly represent the amino acid basis for interaction specificity ( why ) and extend earlier classification-oriented approaches ( which ) to predict the _G of binding ( how well )	purpose	2K_dev_1476
	purpose	2K_dev_1476
	background	2K_dev_1477
	finding	2K_dev_1477
	mechanism	2K_dev_1477
	method	2K_dev_1477
	purpose	2K_dev_1477
It is often assumed that central pattern generators	background	2K_dev_1478
which generate rhythmic patterns without rhythmic inputs	background	2K_dev_1478
play a key role in the spinal control of human locomotion suggest feedback integration to be functionally more important than central pattern generation in human locomotion across behaviours	background	2K_dev_1478
In addition	background	2K_dev_1478
the proposed control architecture may serve as a guide in the search for the neurophysiological origin and circuitry of spinal control in humans	background	2K_dev_1478
	background	2K_dev_1478
The results	finding	2K_dev_1478
We propose a neural control model in which the spinal control generates muscle stimulations mainly through integrated reflex pathways with no central pattern generator Using a physics-based neuromuscular human model	mechanism	2K_dev_1478
we show that this control network is sufficient including walking and running	mechanism	2K_dev_1478
acceleration and deceleration	mechanism	2K_dev_1478
slope and stair negotiation	mechanism	2K_dev_1478
turning	mechanism	2K_dev_1478
and deliberate obstacle avoidance	mechanism	2K_dev_1478
	method	2K_dev_1478
to compose steady and transitional 3-D locomotion behaviours	purpose	2K_dev_1478
	background	2K_dev_1479
Given the selected threshold	finding	2K_dev_1479
The average error and execution time are reduced by 63	finding	2K_dev_1479
6 % and 28	finding	2K_dev_1479
5 %	finding	2K_dev_1479
respectively	finding	2K_dev_1479
compared to the unaided trials	finding	2K_dev_1479
Finally	finding	2K_dev_1479
the automated laser photocoagulation was demonstrated also in an eye phantom	finding	2K_dev_1479
including compensation for the eye movement	finding	2K_dev_1479
This paper presents a technique using a handheld micromanipulator known as Micron	mechanism	2K_dev_1479
The novel handheld manipulator enables the automated scanning of a laser probe within a cylinder of 4 mm long and 4 mm in diameter	mechanism	2K_dev_1479
For the automation	mechanism	2K_dev_1479
the surface of the retina is reconstructed using a stereomicroscope	mechanism	2K_dev_1479
and then preplanned targets are placed on the surface	mechanism	2K_dev_1479
The laser probe is precisely located on the target via visual servoing of the aiming beam	mechanism	2K_dev_1479
while maintaining a specific distance above the surface	mechanism	2K_dev_1479
In addition	mechanism	2K_dev_1479
the system is capable of tracking the surface of the eye in order to compensate for any eye movement introduced during the operation	mechanism	2K_dev_1479
	mechanism	2K_dev_1479
We compared the performance of the automated scanning using various control thresholds	method	2K_dev_1479
in order to find the most effective threshold in terms of accuracy and speed we conducted the handheld operation above a fixed target surface	method	2K_dev_1479
	method	2K_dev_1479
for automated intraocular laser surgery	purpose	2K_dev_1479
Many organisms move using traveling waves of body undulation	background	2K_dev_1480
and most work has focused on single-plane undulations in fluids A seemingly complex mode of snake locomotion	background	2K_dev_1480
sidewinding	background	2K_dev_1480
can be described by the superposition of two waves : horizontal and vertical body waves with a phase difference of 90	background	2K_dev_1480
Our study reveals the utility of templates in understanding the control of biological movement as well as in developing control schemes for limbless robots	background	2K_dev_1480
	background	2K_dev_1480
suggested that during differential turning the animals imposed an amplitude modulation in the horizontal wave whereas in reversal turning they shifted the phase of the vertical wave by 180 revealed a third turning mode	finding	2K_dev_1480
frequency turning	finding	2K_dev_1480
not observed in biological snakes	finding	2K_dev_1480
which produced large ( 127 ) in-place turns The two-wave system thus functions as a template ( a targeted motor pattern ) that enables complex behaviors in a high-degree-of-freedom system to emerge from relatively simple modulations to a basic pattern	finding	2K_dev_1480
	finding	2K_dev_1480
We tested these mechanisms using a multimodule snake robot as a physical model	mechanism	2K_dev_1480
successfully generating differential and reversal turning with performance comparable to that of the organisms	mechanism	2K_dev_1480
	mechanism	2K_dev_1480
Sidewinder rattlesnakes used two distinct turning methods	method	2K_dev_1480
which we term differential turning ( 26 change in orientation per wave cycle ) and reversal turning ( 89 )	method	2K_dev_1480
Observations of the snakes Further manipulations of the two-wave system	method	2K_dev_1480
Less attention has been paid to multiplane undulations	purpose	2K_dev_1480
which are particularly important in terrestrial environments where vertical undulations can regulate substrate contact	purpose	2K_dev_1480
We demonstrate that the high maneuverability displayed by sidewinder rattlesnakes ( Crotalus cerastes ) emerges from the animal 's ability to independently modulate these waves	purpose	2K_dev_1480
	purpose	2K_dev_1480
The assessment of jaundice in outpatient neonates is problematic	background	2K_dev_1481
Visual assessment is inaccurate	background	2K_dev_1481
and more exact methodologies are cumbersome and/or expensive	background	2K_dev_1481
	finding	2K_dev_1481
	mechanism	2K_dev_1481
using a smartphone application called BiliCam	method	2K_dev_1481
	method	2K_dev_1481
Our goal in this study was to assess the accuracy of a technology based on the analysis of digital images of newborns obtained	purpose	2K_dev_1481
Gene therapies have emerged as a promising treatment for congestive heart failure Prior work on controlling the movement of Cerberus required accurate knowledge of device geometry	background	2K_dev_1482
	background	2K_dev_1482
The presented auto-calibration routine is able to identify the shape of the device to within 0	finding	2K_dev_1482
5 mm and 0	finding	2K_dev_1482
9	finding	2K_dev_1482
	finding	2K_dev_1482
we developed Cerberus	mechanism	2K_dev_1482
a minimally invasive parallel wire robot	mechanism	2K_dev_1482
this paper presents work on developing an auto-calibration procedure using force sensors to move injector	mechanism	2K_dev_1482
	mechanism	2K_dev_1482
	method	2K_dev_1482
	purpose	2K_dev_1482
yet they lack a method for minimally invasive	purpose	2K_dev_1482
uniform delivery	purpose	2K_dev_1482
To address this need for cardiac interventions	purpose	2K_dev_1482
In order to determine the geometry of the device in vivo to measure the geometry of the robot	purpose	2K_dev_1482
Recent studies implicate chromatin modifiers in autism spectrum disorder ( ASD ) through the identification of recurrent de novo loss of function mutations in affected individuals	background	2K_dev_1483
	background	2K_dev_1483
CHD8 targets are strongly enriched for other ASD risk genes in both human and mouse neurodevelopment	finding	2K_dev_1483
and converge in ASD-associated co-expression networks in human midfetal cortex CHD8 knockdown in hNSCs results in dysregulation of ASD risk genes directly targeted by CHD8	finding	2K_dev_1483
Integration of CHD8-binding data into ASD risk models improves detection of risk genes These results suggest loss of CHD8 contributes to ASD by perturbing an ancient gene regulatory network during human brain development	finding	2K_dev_1483
	finding	2K_dev_1483
	mechanism	2K_dev_1483
we identify genes targeted by CHD8	method	2K_dev_1483
a chromodomain helicase strongly associated with ASD	method	2K_dev_1483
in human midfetal brain	method	2K_dev_1483
human neural stem cells ( hNSCs ) and embryonic mouse cortex	method	2K_dev_1483
	method	2K_dev_1483
ASD risk genes are co-expressed in human midfetal cortex	purpose	2K_dev_1483
suggesting that ASD risk genes converge in specific regulatory networks during neurodevelopment	purpose	2K_dev_1483
To elucidate such networks	purpose	2K_dev_1483
	background	2K_dev_1484
	finding	2K_dev_1484
	mechanism	2K_dev_1484
	method	2K_dev_1484
	purpose	2K_dev_1484
	background	2K_dev_1485
participants recommended 18 new features ( 29 % of comments )	finding	2K_dev_1485
identified 15 software errors ( 23 % of comments ) and 29 user interface errors ( 47 % of comments )	finding	2K_dev_1485
	finding	2K_dev_1485
	mechanism	2K_dev_1485
Seven subjects participated in laboratory-based usability sessions to evaluate the physical design	method	2K_dev_1485
appearance	method	2K_dev_1485
functionality and perceived ease of use of a multi-user telehealth kiosk prototype	method	2K_dev_1485
During usability testing	method	2K_dev_1485
The overall purpose of this study was to learn how community-dwelling older adults would interact with our prototype multi-user telehealth kiosk and their views about its usability	purpose	2K_dev_1485
	purpose	2K_dev_1485
The quantitative relationship between presynaptic calcium influx and transmitter release critically depends on the spatial coupling of presynaptic calcium channels to synaptic vesicles	background	2K_dev_1486
When there is a close association between calcium channels and synaptic vesicles	background	2K_dev_1486
the flux through a single open calcium channel may be sufficient to trigger transmitter release	background	2K_dev_1486
	background	2K_dev_1486
Furthermore	finding	2K_dev_1486
calcium ion flux through this channel has a low probability of triggering synaptic vesicle fusion ( _6 % )	finding	2K_dev_1486
even when multiple channels open in a single active zone	finding	2K_dev_1486
These mechanisms work to control the rare triggering of vesicle fusion in the frog neuromuscular junction from each of the tens of thousands of individual release sites at this large model synapse	finding	2K_dev_1486
	finding	2K_dev_1486
	mechanism	2K_dev_1486
Here we used a combination of pharmacological calcium channel block	method	2K_dev_1486
high-resolution calcium imaging	method	2K_dev_1486
postsynaptic recording	method	2K_dev_1486
and 3D Monte Carlo reaction-diffusion simulations in the adult frog neuromuscular junction	method	2K_dev_1486
	method	2K_dev_1486
With increasing spatial distance	purpose	2K_dev_1486
however	purpose	2K_dev_1486
a larger number of open calcium channels might be required to contribute sufficient calcium ions to trigger vesicle fusion	purpose	2K_dev_1486
to show that release of individual synaptic vesicles is predominately triggered by calcium ions entering the nerve terminal through the nearest open calcium channel	purpose	2K_dev_1486
	purpose	2K_dev_1486
Undirected graphical models are important in a number of modern applications that involve exploring or exploiting dependency structures underlying the data	background	2K_dev_1487
For example	background	2K_dev_1487
they are often used to explore complex systems where connections between entities are not well understood	background	2K_dev_1487
such as in functional brain networks or genetic networks	background	2K_dev_1487
	background	2K_dev_1487
demonstrate the effectiveness of the method under various conditions We provide illustrative applications to uncovering gene regulatory networks	finding	2K_dev_1487
and uncovering brain connectivity graph from Finally	finding	2K_dev_1487
we provide sufficient conditions under which the 1 graphical structure can be recovered correctly	finding	2K_dev_1487
	finding	2K_dev_1487
In this paper	mechanism	2K_dev_1487
we propose a new principled framework The structure of a graph is inferred through estimation of non-zero partial canonical correlation between nodes	mechanism	2K_dev_1487
Under a Gaussian model	mechanism	2K_dev_1487
this strategy is equivalent to estimating conditional independencies between random vectors represented by the nodes and it generalizes the classical problem of covariance selection ( Dempster	mechanism	2K_dev_1487
1972 ) We relate the problem of estimating non-zero partial canonical correlations to maximizing a penalized Gaussian likelihood objective and develop a method that efficiently maximizes this objective	mechanism	2K_dev_1487
	mechanism	2K_dev_1487
Extensive simulation studies from gene and protein profiles positron emission tomography data	method	2K_dev_1487
	method	2K_dev_1487
Existing methods for estimating structure of undirected graphical models focus on scenarios where each node represents a scalar random variable	purpose	2K_dev_1487
such as a binary neural activation state or a continuous mRNA abundance measurement	purpose	2K_dev_1487
even though in many real world problems	purpose	2K_dev_1487
nodes can represent multivariate variables with much richer meanings	purpose	2K_dev_1487
such as whole images	purpose	2K_dev_1487
text documents	purpose	2K_dev_1487
or multi-view feature vectors	purpose	2K_dev_1487
for estimating the structure of undirected graphical models from such multivariate ( or multi-attribute ) nodal data	purpose	2K_dev_1487
	background	2K_dev_1488
	finding	2K_dev_1488
	mechanism	2K_dev_1488
	method	2K_dev_1488
	purpose	2K_dev_1488
Individuals who exhibit large-magnitude blood pressure ( BP ) reactions to acute psychological stressors are at risk for hypertension and premature death by cardiovascular disease	background	2K_dev_1489
	background	2K_dev_1489
providing novel evidence for a candidate neurophysiological source of stress-related cardiovascular risk	finding	2K_dev_1489
	finding	2K_dev_1489
	mechanism	2K_dev_1489
	method	2K_dev_1489
This study tested whether a multivariate pattern of stressor-evoked brain activity could reliably predict individual differences in BP reactivity	purpose	2K_dev_1489
Of course	background	2K_dev_1490
for testing the significance of an additional variable between two nested linear models	background	2K_dev_1490
one typically uses the chi-squared test	background	2K_dev_1490
comparing the drop in residual sum of squares ( RSS ) to a [ Formula : see text ] distribution	background	2K_dev_1490
	background	2K_dev_1490
show that when the 1 model is linear	finding	2K_dev_1490
this statistic has an Exp ( 1 ) asymptotic distribution under the null hypothesis ( the null being that all truly active variables are contained in the current lasso model )	finding	2K_dev_1490
	finding	2K_dev_1490
We propose a simple test statistic based on lasso fitted values	mechanism	2K_dev_1490
called the covariance test statistic	mechanism	2K_dev_1490
and Our proof of this result for the special case of the first predictor to enter the model ( i	mechanism	2K_dev_1490
e	mechanism	2K_dev_1490
	mechanism	2K_dev_1490
testing for a single significant predictor variable against the global null ) requires only weak assumptions on the predictor matrix X	mechanism	2K_dev_1490
On the other hand	mechanism	2K_dev_1490
our proof for a general step in the lasso path places further technical assumptions on X and the generative model	mechanism	2K_dev_1490
but still allows for the important high-dimensional case p > n	mechanism	2K_dev_1490
and does not necessarily require that the current lasso model achieves perfect recovery of the truly active variables	mechanism	2K_dev_1490
as it must	mechanism	2K_dev_1490
since the lasso builds an adaptive sequence of linear models as the tuning parameter _ decreases	mechanism	2K_dev_1490
In this analysis	mechanism	2K_dev_1490
shrinkage plays a key role : though additional variables are chosen adaptively	mechanism	2K_dev_1490
the coefficients of lasso active variables are shrunken due to the [ Formula : see text ] penalty	mechanism	2K_dev_1490
Therefore	mechanism	2K_dev_1490
the test statistic ( which is based on lasso fitted values ) is in a sense balanced by these two opposing properties-adaptivity and shrinkage-and its null distribution is tractable and asymptotically Exp ( 1 )	mechanism	2K_dev_1490
	method	2K_dev_1490
In the sparse linear regression setting	purpose	2K_dev_1490
we consider testing the significance of the predictor variable that enters the current lasso model	purpose	2K_dev_1490
in the sequence of models visited along the lasso solution path	purpose	2K_dev_1490
But when this additional variable is not fixed	purpose	2K_dev_1490
and has been chosen adaptively or greedily	purpose	2K_dev_1490
this test is no longer appropriate : adaptivity makes the drop in RSS stochastically much larger than [ Formula : see text ] under the null hypothesis	purpose	2K_dev_1490
Our analysis explicitly accounts for adaptivity	purpose	2K_dev_1490
Recently there has been substantial interest in spectral methods for learning dynamical systems	background	2K_dev_1491
These methods are popular since they often offer a good tradeoff between computational and statistical efficiency	background	2K_dev_1491
the correctness of these instances follows directly from our general analysis	finding	2K_dev_1491
we present a new view of dynamical system learning : we show how to learn dynamical systems by solving a sequence of ordinary supervised learning problems	mechanism	2K_dev_1491
thereby allowing users to incorporate prior knowledge via standard techniques such as L1 regularization Many existing spectral methods are special cases of this new framework	mechanism	2K_dev_1491
using linear regression as the supervised learner	mechanism	2K_dev_1491
	mechanism	2K_dev_1491
We demonstrate the effectiveness of our framework by showing examples where nonlinear regression or lasso let us learn better state representations than plain linear regression does ;	method	2K_dev_1491
Unfortunately	purpose	2K_dev_1491
they can be difficult to use and extend in practice : e	purpose	2K_dev_1491
g	purpose	2K_dev_1491
	purpose	2K_dev_1491
they can make it difficult to incorporate prior information such as sparsity or structure	purpose	2K_dev_1491
To address this problem	purpose	2K_dev_1491
While studies show that autism is highly heritable	background	2K_dev_1492
the nature of the genetic basis of this disorder remains illusive	background	2K_dev_1492
The proposed modeling framework can be naturally extended to incorporate additional structural information concerning the dependence between genes	background	2K_dev_1492
	background	2K_dev_1492
the proposed algorithm successfully identified 333 genes that plausibly affect autism risk	finding	2K_dev_1492
Based on the idea that highly correlated genes are functionally interrelated and more likely to affect risk	mechanism	2K_dev_1492
we develop a novel statistical tool by combining the genetic association scores with gene co-expression in specific brain regions and periods of development	mechanism	2K_dev_1492
The gene dependence network is estimated using a novel partial neighborhood selection ( PNS ) algorithm	mechanism	2K_dev_1492
where node specific properties are incorporated into network estimation for improved statistical and computational efficiency Then we adopt a hidden Markov random field ( HMRF ) model to combine the estimated network and the genetic association scores in a systematic manner	mechanism	2K_dev_1492
Using currently available genetic association data from whole exome sequencing studies and brain gene expression levels	method	2K_dev_1492
to find more potentially autism risk genes	purpose	2K_dev_1492
	background	2K_dev_1493
	finding	2K_dev_1493
	mechanism	2K_dev_1493
	method	2K_dev_1493
	purpose	2K_dev_1493
Reconstructing regulatory and signaling response networks is one of the major goals of systems biology	background	2K_dev_1494
	background	2K_dev_1494
Our multi-task learning method was able to identify known and novel factors and genes	finding	2K_dev_1494
improving upon prior methods that model each condition independently	finding	2K_dev_1494
The MT-SDREM networks were also better at identifying proteins whose removal affects viral load indicating that joint learning can still lead to accurate	finding	2K_dev_1494
condition-specific	finding	2K_dev_1494
networks	finding	2K_dev_1494
Supporting website with MT-SDREM implementation : http : //sb	finding	2K_dev_1494
cs	finding	2K_dev_1494
cmu	finding	2K_dev_1494
edu/mtsdrem	finding	2K_dev_1494
	finding	2K_dev_1494
we developed MT-SDREM	mechanism	2K_dev_1494
a multi-task learning method which jointly models networks for several related conditions	mechanism	2K_dev_1494
In MT-SDREM	mechanism	2K_dev_1494
parameters are jointly constrained across the networks while still allowing for condition-specific pathways and regulation	mechanism	2K_dev_1494
	mechanism	2K_dev_1494
We applied MT-SDREM to reconstruct dynamic human response networks for three flu strains : H1N1	method	2K_dev_1494
H5N1 and H3N2	method	2K_dev_1494
	method	2K_dev_1494
While several successful methods have been suggested for this task	purpose	2K_dev_1494
some integrating large and diverse datasets	purpose	2K_dev_1494
these methods have so far been applied to reconstruct a single response network at a time	purpose	2K_dev_1494
even when studying and modeling related conditions	purpose	2K_dev_1494
To improve network reconstruction We formulate the multi-task learning problem and discuss methods for optimizing the joint target function	purpose	2K_dev_1494
	purpose	2K_dev_1494
Methods to assess individual facial actions have potential to shed light on important behavioral phenomena ranging from emotion and social interaction to psychological disorders and health	background	2K_dev_1495
However	background	2K_dev_1495
manual coding of such actions is labor intensive and requires extensive training	background	2K_dev_1495
To date	background	2K_dev_1495
establishing reliable automated coding of unscripted facial actions has been a daunting challenge impeding development of psychological theories and applications requiring facial expression assessment These findings suggest automated FACS coding has progressed sufficiently to be applied to observational research in emotion and related areas of study	background	2K_dev_1495
	background	2K_dev_1495
Automated coding showed very strong reliability for the proportion of time that each AU occurred ( mean intraclass correlation 0 0	finding	2K_dev_1495
89 )	finding	2K_dev_1495
and the more stringent criterion of frame-by-frame reliability was moderate to strong ( mean Matthew 's correlation 0 0	finding	2K_dev_1495
61 )	finding	2K_dev_1495
With few exceptions	finding	2K_dev_1495
differences in AU detection related to gender	finding	2K_dev_1495
ethnicity	finding	2K_dev_1495
pose	finding	2K_dev_1495
and average pixel intensity were small	finding	2K_dev_1495
Fewer than 6 % of frames could be coded manually but not automatically	finding	2K_dev_1495
	finding	2K_dev_1495
We report a major advance in automated coding of spontaneous facial actions during an unscripted social interaction involving three strangers For each participant ( n 0 80	mechanism	2K_dev_1495
47 % women	mechanism	2K_dev_1495
15 % Nonwhite )	mechanism	2K_dev_1495
25 facial action units ( AUs ) were manually coded from video using the Facial Action Coding System	mechanism	2K_dev_1495
Twelve AUs occurred more than 3 % of the time and were processed using automated FACS coding	mechanism	2K_dev_1495
	method	2K_dev_1495
It is therefore essential that automated coding systems be developed with enough precision and robustness to ease the burden of manual coding in challenging data involving variation in participant gender	purpose	2K_dev_1495
ethnicity	purpose	2K_dev_1495
head pose	purpose	2K_dev_1495
speech	purpose	2K_dev_1495
and occlusion	purpose	2K_dev_1495
	purpose	2K_dev_1495
	background	2K_dev_1496
	finding	2K_dev_1496
	mechanism	2K_dev_1496
	method	2K_dev_1496
	purpose	2K_dev_1496
Autism is a psychiatric/neurological condition in which alterations in social interaction ( among other symptoms ) are diagnosed by behavioral psychiatric methods	background	2K_dev_1497
The approach is based on previous advances in fMRI analysis methods that permit ( a ) the identification of a concept	background	2K_dev_1497
such as the thought of a physical object	background	2K_dev_1497
from its fMRI pattern	background	2K_dev_1497
and ( b ) the ability to assess the semantic content of a concept from its fMRI pattern The findings suggest that psychiatric alterations of thought can begin to be biologically understood by assessing the form and content of the altered thought 's underlying brain activation patterns	background	2K_dev_1497
One prominent neural representation factor that emerged ( manifested mainly in posterior midline regions ) was related to self-representation	finding	2K_dev_1497
but this factor was present only for the control participants	finding	2K_dev_1497
and was near-absent in the autism group Moreover	finding	2K_dev_1497
machine learning algorithms classified individuals as autistic or control with 97 % accuracy from their fMRI neurocognitive markers	finding	2K_dev_1497
and machine learning methods	mechanism	2K_dev_1497
These factor analysis were applied to the fMRI activation patterns of 17 adults with high-functioning autism and matched controls	method	2K_dev_1497
scanned while thinking about 16 social interactions	method	2K_dev_1497
The main goal of this study was to determine how the neural representations and meanings of social concepts ( such as to insult ) are altered in autism	purpose	2K_dev_1497
A second goal was to determine whether these alterations can serve as neurocognitive markers of autism	purpose	2K_dev_1497
	purpose	2K_dev_1497
Given a simple noun such as apple	background	2K_dev_1498
and a question such as `` Is it edible ?	background	2K_dev_1498
'' what processes take place in the human brain ?	background	2K_dev_1498
even though originating from the field of neuroscience to provide neuroscientific insights toward a better understanding of the way that neurons interact with each other	background	2K_dev_1498
GeBM produces brain activity patterns that are strikingly similar to the real ones	finding	2K_dev_1498
where the inferred functional connectivity is able as well as detect regularities and outliers in multisubject brain activity measurements	finding	2K_dev_1498
	finding	2K_dev_1498
In this work	mechanism	2K_dev_1498
we present a simple	mechanism	2K_dev_1498
novel good-enough brain model	mechanism	2K_dev_1498
or GeBM in short	mechanism	2K_dev_1498
and a novel algorithm Sparse-SysId	mechanism	2K_dev_1498
which are Moreover	mechanism	2K_dev_1498
GeBM is able to simulate basic psychological phenomena such as habituation and priming ( whose definition we provide in the main text )	mechanism	2K_dev_1498
	mechanism	2K_dev_1498
We evaluate GeBM by using real brain data	method	2K_dev_1498
More specifically	purpose	2K_dev_1498
given the stimulus	purpose	2K_dev_1498
what are the interactions between ( groups of ) neurons ( also known as functional connectivity ) and how can we automatically infer those interactions	purpose	2K_dev_1498
given measurements of the brain activity ? Furthermore	purpose	2K_dev_1498
how does this connectivity differ across different human subjects ? we show that this problem	purpose	2K_dev_1498
can benefit from big data techniques ; able to effectively model the dynamics of the neuron interactions and infer the functional connectivity	purpose	2K_dev_1498
	purpose	2K_dev_1498
Story understanding involves many perceptual and cognitive subprocesses	background	2K_dev_1499
from perceiving individual words	background	2K_dev_1499
to parsing sentences	background	2K_dev_1499
to understanding the relationships among the story characters Additionally	background	2K_dev_1499
this approach is promising for studying individual differences : it can be used to create single subject maps that may potentially be used to measure reading comprehension and diagnose reading disorders	background	2K_dev_1499
with 74 % accuracy	finding	2K_dev_1499
	finding	2K_dev_1499
We present an integrated computational model of reading that incorporates these and additional subprocesses	mechanism	2K_dev_1499
simultaneously discovering their fMRI signatures Our model predicts the fMRI activity associated with reading arbitrary text passages	mechanism	2K_dev_1499
well enough This approach is the first to ranging from visual word properties to the mention of different story characters and different actions they perform We construct brain representation maps that replicate many results from a wide range of classical studies that focus each on one aspect of language processing and offer new insights on which type of information is processed by different areas involved in language processing	mechanism	2K_dev_1499
	mechanism	2K_dev_1499
	method	2K_dev_1499
to distinguish which of two story segments is being read simultaneously track diverse reading subprocesses during complex story processing and predict the detailed neural representation of diverse story features	purpose	2K_dev_1499
	background	2K_dev_1500
the manipulator tolerates side load up to 0	finding	2K_dev_1500
25 N while tracking a sinusoidal target trajectory with less than 20 _m error	finding	2K_dev_1500
Physiological hand tremor is reduced by about 90 % in a pointing task	finding	2K_dev_1500
and error less than 25 _m is achieved in handheld circle-tracing	finding	2K_dev_1500
	finding	2K_dev_1500
This paper presents the design and actuation of a six-degree-of-freedom ( 6-DOF ) manipulator for a handheld instrument	mechanism	2K_dev_1500
known as `` Micron	mechanism	2K_dev_1500
'' The design incorporates a Gough-Stewart platform based on piezoelectric linear motor	mechanism	2K_dev_1500
with a specified minimum workspace of a cylinder 4 mm long and 4 mm in diameter at the end-effector	mechanism	2K_dev_1500
Given the stall force of the motors and the loading typically encountered in vitreoretinal microsurgery	mechanism	2K_dev_1500
the dimensions of the manipulator are optimized to tolerate a transverse load of 0	mechanism	2K_dev_1500
2 N on a remote center of motion near the midpoint of the tool shaft	mechanism	2K_dev_1500
The optimization yields a base diameter of 23 mm and a height of 37 mm The fully handheld instrument includes a custom-built optical tracking system for control feedback	mechanism	2K_dev_1500
and an ergonomic housing to serve as a handle	mechanism	2K_dev_1500
	mechanism	2K_dev_1500
The manipulation performance was investigated in both clamped and handheld conditions In positioning experiments with varying side loads	method	2K_dev_1500
which performs active tremor compensation during microsurgery	purpose	2K_dev_1500
	purpose	2K_dev_1500
In studying the strength and specificity of interaction between members of two protein families	background	2K_dev_1501
The advent of large-scale experimental studies of interactions between members of a target family and a diverse set of possible interaction partners offers the opportunity to address these questions	background	2K_dev_1501
	background	2K_dev_1501
We demonstrate the effectiveness of our approach in analyzing and predicting interactions between a set of 82 PDZ recognition modules	finding	2K_dev_1501
against a panel of 217 possible peptide partners Our predicted _G values are highly predictive of the experimentally measured ones	finding	2K_dev_1501
reaching correlation coefficients of 0	finding	2K_dev_1501
69 in 10-fold cross-validation and 0	finding	2K_dev_1501
63 in leave-one-PDZ-out cross-validation	finding	2K_dev_1501
Furthermore	finding	2K_dev_1501
the model serves as a compact representation of amino acid constraints underlying the interactions	finding	2K_dev_1501
enabling protein-level _G predictions to be naturally understood in terms of residue-level constraints	finding	2K_dev_1501
Finally	finding	2K_dev_1501
as a generative model	finding	2K_dev_1501
DgSpi readily enables the design of new interacting partners	finding	2K_dev_1501
and we demonstrate that designed ligands are novel and diverse	finding	2K_dev_1501
	finding	2K_dev_1501
We develop here a method	mechanism	2K_dev_1501
DgSpi ( Data-driven Graphical models of Specificity in Protein : protein Interactions )	mechanism	2K_dev_1501
	method	2K_dev_1501
based on data from MacBeath and colleagues	method	2K_dev_1501
	method	2K_dev_1501
key questions center on which pairs of possible partners actually interact	purpose	2K_dev_1501
how well they interact	purpose	2K_dev_1501
and why they interact while others do not	purpose	2K_dev_1501
for learning and using graphical models that explicitly represent the amino acid basis for interaction specificity ( why ) and extend earlier classification-oriented approaches ( which ) to predict the _G of binding ( how well	purpose	2K_dev_1501
Computer-mediated communication is driving fundamental changes in the nature of written language	background	2K_dev_1502
	background	2K_dev_1502
The results of this analysis offer support for prior arguments that focus on geographical proximity and population size	finding	2K_dev_1502
However	finding	2K_dev_1502
demographic similarity - especially with regard to race - plays an even more central role	finding	2K_dev_1502
as cities with similar racial demographics are far more likely to share linguistic influence Rather than moving towards a single unified `` netspeak '' dialect	finding	2K_dev_1502
language evolution in computer-mediated communication reproduces existing fault lines in spoken American English	finding	2K_dev_1502
	finding	2K_dev_1502
Using a latent vector autoregressive model to aggregate across thousands of words Our model is robust to unpredictable changes in Twitter 's sampling rate	mechanism	2K_dev_1502
and provides a probabilistic characterization of the relationship of macro-scale linguistic influence to a set of demographic and geographic predictors	mechanism	2K_dev_1502
	mechanism	2K_dev_1502
by statistical analysis of a dataset comprising 107 million Twitter messages ( authored by 2	method	2K_dev_1502
7 million unique user accounts )	method	2K_dev_1502
	method	2K_dev_1502
We investigate these changes we identify high-level patterns in diffusion of linguistic change over the United States	purpose	2K_dev_1502
	purpose	2K_dev_1502
Many statistical methods gain robustness and flexibility by sacrificing convenient computational structures	background	2K_dev_1503
Though this paper focuses on the problem of graph estimation	background	2K_dev_1503
the proposed methodology is widely applicable to other problems with similar structures	background	2K_dev_1503
	background	2K_dev_1503
We also report results	finding	2K_dev_1503
We explain how novel computational techniques In particular	mechanism	2K_dev_1503
we propose a nonparanormal neighborhood pursuit algorithm with theoretical guarantees	mechanism	2K_dev_1503
Moreover	mechanism	2K_dev_1503
we provide an alternative view under a smoothing optimization framework	mechanism	2K_dev_1503
	mechanism	2K_dev_1503
thorough experimental on text	method	2K_dev_1503
stock	method	2K_dev_1503
and genomic datasets	method	2K_dev_1503
	method	2K_dev_1503
In this paper	purpose	2K_dev_1503
we illustrate this fundamental tradeoff by studying a semi-parametric graph estimation problem in high dimensions	purpose	2K_dev_1503
help to solve this type of problem to estimate high dimensional semiparametric graphical models to analyze the tradeoff between computational efficiency and statistical error	purpose	2K_dev_1503
While only recently developed	background	2K_dev_1504
the ability to profile expression data in single cells ( scRNA-Seq ) has already led to several important studies and findings	background	2K_dev_1504
However	background	2K_dev_1504
this technology has also raised several new computational challenges	background	2K_dev_1504
Such database queries ( which can be performed using our web server ) will enable researchers to better characterize cells when analyzing heterogeneous scRNA-Seq samples	background	2K_dev_1504
	background	2K_dev_1504
We show that the NN method improves upon prior methods in both	finding	2K_dev_1504
the ability to correctly group cells in experiments not used in the training and the ability to correctly infer cell type or state by querying a database of tens of thousands of single cell profiles	finding	2K_dev_1504
we develop and test a method based on neural networks ( NN )	mechanism	2K_dev_1504
and used these to obtain a reduced dimension representation of the single cell expression data	mechanism	2K_dev_1504
We tested various NN architectures	method	2K_dev_1504
some of which incorporate prior biological knowledge	method	2K_dev_1504
These include questions about the best methods for clustering scRNA-Seq data	purpose	2K_dev_1504
how to identify unique group of cells in such experiments	purpose	2K_dev_1504
and how to determine the state or function of specific cells based on their expression profile	purpose	2K_dev_1504
To address these issues for the analysis and retrieval of single cell RNA-Seq data	purpose	2K_dev_1504
	purpose	2K_dev_1504
Limbless organisms such as snakes can navigate nearly all terrain	background	2K_dev_1505
In particular	background	2K_dev_1505
desert-dwelling sidewinder rattlesnakes ( Crotalus cerastes ) operate effectively on inclined granular media ( such as sand dunes ) that induce failure in field-tested limbless robots through slipping and pitching	background	2K_dev_1505
Together	background	2K_dev_1505
these three approaches demonstrate how sidewinding with contact-length control mitigates failure on granular media	background	2K_dev_1505
	background	2K_dev_1505
reveal that as granular incline angle increases	finding	2K_dev_1505
sidewinder rattlesnakes increase the length of their body in contact with the sand demonstrate that granular yield stresses decrease with increasing incline angle	finding	2K_dev_1505
	finding	2K_dev_1505
Implementing this strategy in a physical robot model of the snake	mechanism	2K_dev_1505
Our laboratory experiments Plate drag experiments	method	2K_dev_1505
enables the device to ascend sandy slopes close to the angle of maximum slope stability	purpose	2K_dev_1505
	purpose	2K_dev_1505
Whole-exome sequencing ( WES ) studies have demonstrated the contribution of de novo loss-of-function single-nucleotide variants ( SNVs ) to autism spectrum disorder ( ASD )	background	2K_dev_1506
	background	2K_dev_1506
we demonstrate that de novo frameshift indels contribute to ASD risk ( OR 0 1	finding	2K_dev_1506
6 ; 95 % CI 0 1	finding	2K_dev_1506
0-2	finding	2K_dev_1506
7 ; p 0 0	finding	2K_dev_1506
03 )	finding	2K_dev_1506
are more common in female probands ( p 0 0	finding	2K_dev_1506
02 )	finding	2K_dev_1506
are enriched among genes encoding FMRP targets ( p 0 6 _ 10 ( -9 ) )	finding	2K_dev_1506
and arise predominantly on the paternal chromosome ( p < 0	finding	2K_dev_1506
001 ) On the basis of mutation rates in probands versus unaffected siblings	finding	2K_dev_1506
we conclude that de novo frameshift indels contribute to risk in approximately 3 % of individuals with ASD	finding	2K_dev_1506
we uncover two ASD-associated genes : KMT2E ( MLL5 )	finding	2K_dev_1506
a chromatin regulator	finding	2K_dev_1506
and RIMS1	finding	2K_dev_1506
a regulator of synaptic vesicle release	finding	2K_dev_1506
	mechanism	2K_dev_1506
By applying a robust indel detection method to WES data from 787 ASD families ( 2963 individuals )	method	2K_dev_1506
Finally	method	2K_dev_1506
by observing clustering of mutations in unrelated probands	method	2K_dev_1506
	method	2K_dev_1506
However	purpose	2K_dev_1506
challenges in the reliable detection of de novo insertions and deletions ( indels ) have limited inclusion of these variants in prior analyses	purpose	2K_dev_1506
	purpose	2K_dev_1506
Fluctuations in the growth rate of a bacterial culture during unbalanced growth are generally considered undesirable in quantitative studies of bacterial Our method has implications for both basic understanding of bacterial physiology and for the classification of bacterial strains	background	2K_dev_1507
	finding	2K_dev_1507
Here	mechanism	2K_dev_1507
we present a method '' by time-frequency analysis of unbalanced growth curves measured with high temporal resolution	mechanism	2K_dev_1507
The signatures are then applied to differentiate amongst different bacterial strains or the same strain under different growth conditions	mechanism	2K_dev_1507
and to identify the essential architecture of the gene network underlying the observed growth dynamics	mechanism	2K_dev_1507
	mechanism	2K_dev_1507
	method	2K_dev_1507
Under well-controlled experimental conditions	purpose	2K_dev_1507
however	purpose	2K_dev_1507
these fluctuations are not random but instead reflect the interplay between intra-cellular networks underlying bacterial growth and the growth environment	purpose	2K_dev_1507
Therefore	purpose	2K_dev_1507
these fluctuations could be considered quantitative phenotypes of the bacteria under a specific growth condition to identify `` phenotypic signatures	purpose	2K_dev_1507
Spontaneously arising ( de novo ) mutations have an important role in medical genetics	background	2K_dev_1508
For diseases with extensive locus heterogeneity	background	2K_dev_1508
such as autism spectrum disorders ( ASDs )	background	2K_dev_1508
the signal from de novo mutations is distributed across many genes	background	2K_dev_1508
suggesting that the role of de novo mutations in ASDs might reside in fundamental neurodevelopmental processes	background	2K_dev_1508
whereas we affirmed a significant role for loss-of-function mutations	finding	2K_dev_1508
we found no excess of de novo loss-of-function mutations in cases with IQ above 100 We also used our model to identify _1	finding	2K_dev_1508
000 genes that are significantly lacking in functional coding variation in non-ASD samples and are enriched for de novo loss-of-function mutations identified in ASD cases	finding	2K_dev_1508
	finding	2K_dev_1508
Here we provide a statistical framework for the analysis of excesses in de novo mutation per gene and gene set by calibrating a model of de novo mutation	mechanism	2K_dev_1508
	mechanism	2K_dev_1508
We applied this framework to de novo mutations collected from 1078 ASD family trios	method	2K_dev_1508
and	method	2K_dev_1508
	method	2K_dev_1508
making it difficult to distinguish disease-relevant mutations from background variation	purpose	2K_dev_1508
	purpose	2K_dev_1508
Influence maximization in social networks has been widely studied motivated by applications like spread of ideas or innovations in a network and viral marketing of products	background	2K_dev_1509
Current studies focus almost exclusively on unsigned social networks containing only positive relationships ( e	background	2K_dev_1509
g	background	2K_dev_1509
friend or trust ) between users	background	2K_dev_1509
	background	2K_dev_1509
We prove that the influence function of the PRIM problem under the IC-P model is monotonic and submodular Thus	finding	2K_dev_1509
a greedy algorithm can be used to achieve an approximation ratio of 1-1/e for solving the PRIM problem in signed social networks	finding	2K_dev_1509
validate that our approximation algorithm for solving the PRIM problem outperforms state-of-the-art methods	finding	2K_dev_1509
Thus	mechanism	2K_dev_1509
in this paper	mechanism	2K_dev_1509
we propose the polarity-related influence maximization ( PRIM ) problem	mechanism	2K_dev_1509
we first extend the standard Independent Cascade ( IC ) model to the signed social networks and propose a Polarity-related Independent Cascade ( named IC-P ) diffusion model	mechanism	2K_dev_1509
	mechanism	2K_dev_1509
Experimental results on two signed social network datasets	method	2K_dev_1509
Epinions and Slashdot	method	2K_dev_1509
Influence maximization in signed social networks containing both positive relationships and negative relationships ( e	purpose	2K_dev_1509
g	purpose	2K_dev_1509
foe or distrust ) between users is still a challenging problem that has not been studied	purpose	2K_dev_1509
which aims to find the seed node set with maximum positive influence or maximum negative influence in signed social networks	purpose	2K_dev_1509
To address the PRIM problem	purpose	2K_dev_1509
The HMT3522 progression series of human breast cells have been used to discover how tissue architecture	background	2K_dev_1510
microenvironment and signaling molecules affect breast cell growth and behaviors	background	2K_dev_1510
	background	2K_dev_1510
We found that different breast cell states contain distinct gene networks	finding	2K_dev_1510
The network specific to non-malignant HMT3522-S1 cells is dominated by genes involved in normal processes	finding	2K_dev_1510
whereas the T4-2-specific network is enriched with cancer-related genes The networks specific to various conditions of the reverted T4-2 cells are enriched with pathways suggestive of compensatory effects	finding	2K_dev_1510
showed that aberrant expression values of certain hubs in the identified networks are associated with poor clinical outcomes	finding	2K_dev_1510
Thus	finding	2K_dev_1510
analysis of various reversion conditions ( including non-reverted ) of HMT3522 cells using Treegl can be a good model system to study drug effects on breast cancer	finding	2K_dev_1510
	finding	2K_dev_1510
We employed a `` pan-cell-state '' strategy	mechanism	2K_dev_1510
and analyzed jointly microarray profiles obtained from different state-specific cell populations from this progression and reversion model of the breast cells using a tree-lineage multi-network inference algorithm	mechanism	2K_dev_1510
Treegl	mechanism	2K_dev_1510
	mechanism	2K_dev_1510
consistent with clinical data showing patient resistance to anticancer drugs	method	2K_dev_1510
We validated the findings using an external dataset	method	2K_dev_1510
and	method	2K_dev_1510
However	purpose	2K_dev_1510
much remains to be elucidated about malignant and phenotypic reversion behaviors of the HMT3522-T4-2 cells of this series	purpose	2K_dev_1510
	purpose	2K_dev_1510
	background	2K_dev_1511
	finding	2K_dev_1511
	mechanism	2K_dev_1511
	method	2K_dev_1511
	purpose	2K_dev_1511
A key component of genetic architecture is the allelic spectrum influencing trait variability	background	2K_dev_1512
For autism spectrum disorder ( herein termed autism )	background	2K_dev_1512
the nature of the allelic spectrum is uncertain	background	2K_dev_1512
Individual risk-associated genes have been identified from rare variation	background	2K_dev_1512
especially de novo mutations From this evidence	background	2K_dev_1512
one might conclude that rare variation dominates the allelic spectrum in autism	background	2K_dev_1512
we reach several conclusions about autism 's genetic architecture : its narrow-sense heritability is _52	finding	2K_dev_1512
4 %	finding	2K_dev_1512
with most due to common variation	finding	2K_dev_1512
and rare de novo mutations contribute substantially to individual liability	finding	2K_dev_1512
yet their contribution to variance in liability	finding	2K_dev_1512
2	finding	2K_dev_1512
6 %	finding	2K_dev_1512
is modest compared to that for heritable variation	finding	2K_dev_1512
	finding	2K_dev_1512
	mechanism	2K_dev_1512
new methods that distinguish total narrow-sense heritability from that due to common variation	mechanism	2K_dev_1512
Using a unique epidemiological sample from Sweden and synthesis of results from other studies	method	2K_dev_1512
	method	2K_dev_1512
yet recent studies show that common variation	purpose	2K_dev_1512
individually of small effect	purpose	2K_dev_1512
has substantial impact en masse	purpose	2K_dev_1512
At issue is how much of an impact relative to rare variation this common variation has	purpose	2K_dev_1512
	purpose	2K_dev_1512
In effort to improve thermal control in minimally invasive cryosurgery	background	2K_dev_1513
the concept of a miniature	background	2K_dev_1513
wireless	background	2K_dev_1513
implantable sensing unit has been developed recently The sensing unit integrates a wireless power delivery mechanism	background	2K_dev_1513
wireless communication means	background	2K_dev_1513
and a sensing core-the subject matter of the current study	background	2K_dev_1513
The senor has shown to operate between -180C and room temperature	finding	2K_dev_1513
to consume power of less than 1 _W	finding	2K_dev_1513
and to have an uncertainty range of 1	finding	2K_dev_1513
4C and non-linearity of 1	finding	2K_dev_1513
1 %	finding	2K_dev_1513
Results of this study suggest that the sensing core is ready to be integrated in the sensing unit	finding	2K_dev_1513
where system integration is the subject matter of a parallel effort	finding	2K_dev_1513
	finding	2K_dev_1513
The current study presents a CMOS ultra-miniature PTAT temperature sensing core and For this purpose	mechanism	2K_dev_1513
a 100 _m _ 400 _m sensing core prototype has been fabricated using a 130 nm CMOS process	mechanism	2K_dev_1513
	mechanism	2K_dev_1513
	method	2K_dev_1513
focuses on design principles	purpose	2K_dev_1513
fabrication of a proof-of-concept	purpose	2K_dev_1513
and characterization in a cryogenic environment	purpose	2K_dev_1513
	purpose	2K_dev_1513
Stochastic models are increasingly used to study the behaviour of biochemical systems	background	2K_dev_1514
While the structure of such models is often readily available from first principles	background	2K_dev_1514
unknown quantitative features of the model are incorporated into the model as parameters	background	2K_dev_1514
	background	2K_dev_1514
demonstrate its effectiveness	finding	2K_dev_1514
We present a new parameter discovery algorithm that uses simulated annealing	mechanism	2K_dev_1514
sequential hypothesis testing	mechanism	2K_dev_1514
and statistical model checking We apply our technique to a model of glucose and insulin metabolism used for in-silico validation of artificial pancreata and	mechanism	2K_dev_1514
by developing parallel CUDA-based implementation for parameter synthesis in this model	method	2K_dev_1514
	method	2K_dev_1514
Algorithmic discovery of parameter values from experimentally observed facts remains a challenge for the computational systems biology community	purpose	2K_dev_1514
to learn the parameters in a stochastic model	purpose	2K_dev_1514
Discovering the transcriptional regulatory architecture of the metabolism has been an important topic to understand the implications of transcriptional fluctuations on metabolism	background	2K_dev_1515
The reporter algorithm ( RA ) was proposed to determine the hot spots in metabolic networks	background	2K_dev_1515
around which transcriptional regulation is focused owing to a disease or a genetic perturbation	background	2K_dev_1515
Using a z-score-based scoring scheme	background	2K_dev_1515
RA calculates the average statistical change in the expression levels of genes that are neighbors to a target metabolite in the metabolic network	background	2K_dev_1515
The RA approach has been used in numerous studies to analyze cellular responses to the downstream genetic changes	background	2K_dev_1515
	background	2K_dev_1515
We show that MIRA 's results are biologically sound	finding	2K_dev_1515
empirically significant and more reliable than RA	finding	2K_dev_1515
	finding	2K_dev_1515
In this article	mechanism	2K_dev_1515
we propose a mutual information-based multivariate reporter algorithm MIRA MIRA is a multivariate and combinatorial algorithm that calculates the aggregate transcriptional response around a metabolite using mutual information	mechanism	2K_dev_1515
	method	2K_dev_1515
with the goal of eliminating the following problems in detecting reporter metabolites : ( i ) conventional statistical methods suffer from small sample sizes	purpose	2K_dev_1515
( ii ) as z-score ranges from minus to plus infinity	purpose	2K_dev_1515
calculating average scores can lead to canceling out opposite effects and ( iii ) analyzing genes one by one	purpose	2K_dev_1515
then aggregating results can lead to information loss	purpose	2K_dev_1515
	purpose	2K_dev_1515
Discovering the transcriptional regulatory architecture of the metabolism has been an important topic to understand the implications of transcriptional fluctuations on metabolism	background	2K_dev_1516
The reporter algorithm ( RA ) was proposed to determine the hot spots in metabolic networks	background	2K_dev_1516
around which transcriptional regulation is focused owing to a disease or a genetic perturbation Using a z-score-based scoring scheme	background	2K_dev_1516
RA calculates the average statistical change in the expression levels of genes that are neighbors to a target metabolite in the metabolic network	background	2K_dev_1516
The RA approach has been used in numerous studies to analyze cellular responses to the downstream genetic changes	background	2K_dev_1516
	background	2K_dev_1516
We show that MIRA 's results are biologically sound	finding	2K_dev_1516
empirically significant and more reliable than RA	finding	2K_dev_1516
In this article	mechanism	2K_dev_1516
we propose a mutual information-based multivariate reporter algorithm ( MIRA ) with the goal of eliminating the following problems in detecting reporter metabolites : MIRA is a multivariate and combinatorial algorithm that calculates the aggregate transcriptional response around a metabolite using mutual information	mechanism	2K_dev_1516
	mechanism	2K_dev_1516
	method	2K_dev_1516
i ) conventional statistical methods suffer from small sample sizes	purpose	2K_dev_1516
( ii ) as z-score ranges from minus to plus infinity	purpose	2K_dev_1516
calculating average scores can lead to canceling out opposite effects and ( iii ) analyzing genes one by one	purpose	2K_dev_1516
then aggregating results can lead to information loss	purpose	2K_dev_1516
	purpose	2K_dev_1516
The vast bacteriophage population harbors an immense reservoir of genetic information	background	2K_dev_1517
Almost 2000 phage genomes have been sequenced from phages infecting hosts in the phylum Actinobacteria	background	2K_dev_1517
and	background	2K_dev_1517
and Jasmine is the first sequenced podovirus of an actinobacterial host	finding	2K_dev_1517
and can be grouped into 10 clusters according to their nucleotide diversity	finding	2K_dev_1517
and two singletons each with no close relatives	finding	2K_dev_1517
However	finding	2K_dev_1517
the clusters/singletons appear to be genomically well separated from each other	finding	2K_dev_1517
and relatively few genes are shared between clusters	finding	2K_dev_1517
Genome size varies from among the smallest of siphoviral phages ( 15319 bp ) to over 70 kbp	finding	2K_dev_1517
and G+C contents range from 45-68 %	finding	2K_dev_1517
compared to 63	finding	2K_dev_1517
4 % for the host genome	finding	2K_dev_1517
Although temperate phages are common among other actinobacterial hosts	finding	2K_dev_1517
these Arthrobacter phages are primarily lytic	finding	2K_dev_1517
and only the singleton Galaxy is likely temperate	finding	2K_dev_1517
	mechanism	2K_dev_1517
These phages include representatives of all three virion morphologies	method	2K_dev_1517
The phages also span considerable sequence diversity	method	2K_dev_1517
	method	2K_dev_1517
analysis of these genomes reveals substantial diversity	purpose	2K_dev_1517
pervasive mosaicism	purpose	2K_dev_1517
and novel mechanisms for phage replication and lysogeny	purpose	2K_dev_1517
Here	purpose	2K_dev_1517
we describe the isolation and genomic characterization of 46 phages from environmental samples at various geographic locations in the U	purpose	2K_dev_1517
S	purpose	2K_dev_1517
infecting a single Arthrobacter sp	purpose	2K_dev_1517
strain	purpose	2K_dev_1517
	purpose	2K_dev_1517
With the continuous improvement in genotyping and molecular phenotyping technology and the decreasing typing cost	background	2K_dev_1518
it is expected that in a few years	background	2K_dev_1518
more and more clinical studies of complex diseases will recruit thousands of individuals for pan-omic genetic association analyses	background	2K_dev_1518
	background	2K_dev_1518
report some interesting findings	finding	2K_dev_1518
GenAMap is available from http : //sailing	finding	2K_dev_1518
cs	finding	2K_dev_1518
cmu	finding	2K_dev_1518
edu/genamap	finding	2K_dev_1518
	finding	2K_dev_1518
We present GenAMap	mechanism	2K_dev_1518
an interactive analytics software platform that 1 ) automates the execution of principled machine learning methods that	mechanism	2K_dev_1518
and 2 ) provides new visualization tools specifically designed Algorithmically	mechanism	2K_dev_1518
GenAMap is based on a new paradigm for GWAS and PheWAS analysis	mechanism	2K_dev_1518
termed structured association mapping	mechanism	2K_dev_1518
which leverages various structures in the omic data	mechanism	2K_dev_1518
We demonstrate the function of GenAMap via a case study of the Brem and Kruglyak yeast dataset	method	2K_dev_1518
and then apply it on a comprehensive eQTL analysis of the NIH heterogeneous stock mice dataset and	method	2K_dev_1518
Hence	purpose	2K_dev_1518
there is a great need for algorithms and software tools that could scale up to the whole omic level	purpose	2K_dev_1518
integrate different omic data	purpose	2K_dev_1518
leverage rich structure information	purpose	2K_dev_1518
and be easily accessible to non-technical users detect genome- and phenome-wide associations among genotypes	purpose	2K_dev_1518
gene expression data	purpose	2K_dev_1518
and clinical or other macroscopic traits to aid in the exploration of association mapping results	purpose	2K_dev_1518
	purpose	2K_dev_1518
	background	2K_dev_1519
	finding	2K_dev_1519
	mechanism	2K_dev_1519
	method	2K_dev_1519
	purpose	2K_dev_1519
	background	2K_dev_1520
	finding	2K_dev_1520
	mechanism	2K_dev_1520
	method	2K_dev_1520
	purpose	2K_dev_1520
Vitreoretinal microsurgery requires precise hand-eye coordination to manipulate delicate structures within the eye on the order of tens of microns To achieve these tasks	background	2K_dev_1521
surgeons use tools of diameter 0	background	2K_dev_1521
9 mm or less to access the eye 's interior structures	background	2K_dev_1521
	background	2K_dev_1521
This approach resulted in a 42 % reduction in the mean force and 52 % reduction in maximum force during peeling tasks	finding	2K_dev_1521
	finding	2K_dev_1521
we present the implementation of hybrid position/force control operating in the sub-tactile force range for a handheld robotic system	mechanism	2K_dev_1521
	method	2K_dev_1521
The level of force required during these manipulations is often below the human tactile threshold	purpose	2K_dev_1521
requiring the surgeon to rely on subtle visual cues or to apply larger forces above the tactile threshold for feedback	purpose	2K_dev_1521
However	purpose	2K_dev_1521
both of these methods can lead to tissue damage	purpose	2K_dev_1521
Excursions can be made into tissues which are not felt by the surgeon	purpose	2K_dev_1521
while larger forces have a higher chance of damaging tissue within the eye	purpose	2K_dev_1521
To prevent damage to the retina and other anatomy	purpose	2K_dev_1521
	purpose	2K_dev_1521
	background	2K_dev_1522
	finding	2K_dev_1522
	mechanism	2K_dev_1522
	method	2K_dev_1522
	purpose	2K_dev_1522
Overview	background	2K_dev_1523
The Centers for Disease Control and Prevention ( CDC ) health-related quality of life ( HRQoL ) indicators are widely used in the general population to determine the burden of disease	background	2K_dev_1523
identify health needs	background	2K_dev_1523
and direct public health policy	background	2K_dev_1523
These indicators also allow the burden of illness to be compared across different diseases	background	2K_dev_1523
Although Lyme disease has recently been acknowledged as a major health threat in the USA with more than 300000 new cases per year	background	2K_dev_1523
no comprehensive assessment of the health burden of this tickborne disease is available	background	2K_dev_1523
The heavy burden of illness associated with CLD highlights the need for earlier diagnosis and innovative treatment approaches that may reduce the burden of illness and concomitant costs posed by this illness	background	2K_dev_1523
	background	2K_dev_1523
Results	finding	2K_dev_1523
Compared to the general population and patients with other chronic diseases reviewed here	finding	2K_dev_1523
patients with CLD reported significantly lower health quality status	finding	2K_dev_1523
more bad mental and physical health days	finding	2K_dev_1523
a significant symptom disease burden	finding	2K_dev_1523
and greater activity limitations	finding	2K_dev_1523
They also reported impairment in their ability to work	finding	2K_dev_1523
increased utilization of healthcare services	finding	2K_dev_1523
and greater out of pocket medical costs	finding	2K_dev_1523
Conclusions	finding	2K_dev_1523
CLD patients have significantly impaired HRQoL and greater healthcare utilization compared to the general population and patients with other chronic diseases	finding	2K_dev_1523
	finding	2K_dev_1523
	mechanism	2K_dev_1523
This study assesses the HRQoL of patients with chronic Lyme disease ( CLD ) and compares the severity of CLD to other chronic conditions	method	2K_dev_1523
Methods	method	2K_dev_1523
Of 5357 subjects who responded to an online survey	method	2K_dev_1523
3090 were selected for the study	method	2K_dev_1523
Respondents were characterized as having CLD if they were clinically diagnosed with Lyme disease and had persisting symptoms lasting more than 6 months following antibiotic treatment	method	2K_dev_1523
HRQoL of CLD patients was assessed using the CDC 9-item metric	method	2K_dev_1523
The HRQoL analysis for CLD was compared to published analyses for the general population and other chronic illnesses using standard statistical methods	method	2K_dev_1523
	method	2K_dev_1523
	purpose	2K_dev_1523
Performing micromanipulation and delicate operations in submillimeter workspaces is difficult because of destabilizing tremor and imprecise targeting	background	2K_dev_1524
Accurate micromanipulation is especially important for microsurgical procedures	background	2K_dev_1524
such as vitreoretinal surgery	background	2K_dev_1524
to maximize successful outcomes and minimize collateral damage	background	2K_dev_1524
	background	2K_dev_1524
We demonstrate that virtual fixtures significantly outperform tremor cancellation algorithms on a set of synthetic tracing tasks ( p < 0	finding	2K_dev_1524
05 )	finding	2K_dev_1524
virtual fixtures can significantly reduce both positioning error and forces applied to tissue ( p < 0	finding	2K_dev_1524
05 )	finding	2K_dev_1524
In this paper	mechanism	2K_dev_1524
we derive a virtual fixture framework for active handheld micromanipulators that is based on high-bandwidth position measurements rather than forces applied to a robot handle	mechanism	2K_dev_1524
For applicability in surgical environments	mechanism	2K_dev_1524
the fixtures are generated in real-time from microscope video during the procedure	mechanism	2K_dev_1524
Additionally	mechanism	2K_dev_1524
we develop motion scaling behavior around virtual fixtures as a simple and direct extension to the proposed framework	mechanism	2K_dev_1524
	mechanism	2K_dev_1524
In more medically relevant experiments of vein tracing and membrane peeling in eye phantoms	method	2K_dev_1524
Robotic aid combined with filtering techniques that suppress tremor frequency bands increases performance ; however	purpose	2K_dev_1524
if knowledge of the operator 's goals is available	purpose	2K_dev_1524
virtual fixtures have been shown to further improve performance	purpose	2K_dev_1524
	purpose	2K_dev_1524
Population stratification is an important task in genetic analyses	background	2K_dev_1525
It provides information about the ancestry of individuals and can be an important confounder in genome-wide association studies	background	2K_dev_1525
Public genotyping projects have made a large number of datasets available for study	background	2K_dev_1525
However	background	2K_dev_1525
practical constraints dictate that of a geographical/ethnic population	background	2K_dev_1525
only a small number of individuals are genotyped	background	2K_dev_1525
The resulting data are a sample from the entire population	background	2K_dev_1525
found that the accuracy of recovery of population structure is affected to a large extent by the sample used for analysis and how representative it is of the underlying populations	finding	2K_dev_1525
we show that sample selection bias can affect the results of population structure analyses	finding	2K_dev_1525
We demonstrate that such a correction is effective in practice	finding	2K_dev_1525
We develop a mathematical framework in models for population structure and also proposed a correction for sample selection bias using auxiliary information about the sample	mechanism	2K_dev_1525
	mechanism	2K_dev_1525
We examined two commonly used methods for analyses of such datasets	method	2K_dev_1525
ADMIXTURE and EIGENSOFT	method	2K_dev_1525
and Using simulated data and real genotype data from cattle using simulated and real data	method	2K_dev_1525
If the distribution of sample sizes is not representative of the populations being sampled	purpose	2K_dev_1525
the accuracy of population stratification analyses of the data could be affected	purpose	2K_dev_1525
We attempt to understand the effect of biased sampling on the accuracy of population structure analysis and individual ancestry recovery	purpose	2K_dev_1525
for sample selection bias	purpose	2K_dev_1525
Other identified temporal structures that were not highlighted in this paper may also be used to gain insights to possible novel mechanisms	background	2K_dev_1526
Importantly	background	2K_dev_1526
the Temp-O workflow is generic ; while we applied it on NSCLC	background	2K_dev_1526
it can be applied in other cancers and diseases	background	2K_dev_1526
Importantly	background	2K_dev_1526
the identified temporal structures are meaningful in the tumor progression of NSCLC as	background	2K_dev_1526
2 ) we showed that temporal structures are meaningful in the tumor progression of NSCLC	finding	2K_dev_1526
showed that differences in temporal network structures capture diverse mechanisms in NSCLC	finding	2K_dev_1526
Furthermore	finding	2K_dev_1526
results showed that structures are consistent and potentially biologically important as we observed that genes with similar protein names were captured in the same cliques for all cliques in all datasets	finding	2K_dev_1526
they agree with the molecular mechanism in the tumor progression or carcinogenesis of NSCLC	finding	2K_dev_1526
In particular	finding	2K_dev_1526
the identified major histocompatibility complex of class II temporal structures capture mechanisms concerning carcinogenesis ; the proteasome temporal structures capture mechanisms that are in early or late stages of lung cancer ; the ribosomal cliques capture the role of ribosome biosynthesis in cancer development and sustainment	finding	2K_dev_1526
we validated that temporal network structures identified proteins that are prognostic for overall survival in NSCLC adenocarcinoma	finding	2K_dev_1526
Our main contributions are 1 ) we proposed the Temporal-Omics ( Temp-O ) workflow using graph comparisons between multiple stage-specific graphs	mechanism	2K_dev_1526
and We used gene expression data from tumor samples across disease stages to model lung cancer progression	mechanism	2K_dev_1526
creating stage-specific tumor graphs	mechanism	2K_dev_1526
	mechanism	2K_dev_1526
Validating our findings in independent datasets Further	method	2K_dev_1526
on a large independent dataset	method	2K_dev_1526
Can we use graph mining algorithms to find patterns in tumor molecular mechanisms ? Can we model disease progression with multiple time-specific graph comparison algorithms ? In this paper	purpose	2K_dev_1526
we will focus on this area to model tumor progression in non-small cell lung cancer ( NSCLC )	purpose	2K_dev_1526
	background	2K_dev_1527
	finding	2K_dev_1527
	mechanism	2K_dev_1527
	method	2K_dev_1527
	purpose	2K_dev_1527
Matched field processing is a model-based framework for localizing targets in complex propagation environments	background	2K_dev_1528
In underwater acoustics	background	2K_dev_1528
it has been extensively studied for improving localization performance in multimodal and multipath media	background	2K_dev_1528
For guided wave structural health monitoring problems	background	2K_dev_1528
matched field processing has not been widely applied but is an attractive option for damage localization due to equally complex propagation environments	background	2K_dev_1528
and demonstrates its localization performance by distinguishing two nearby scatterers the data-driven matched field processing framework is shown to successfully localize two nearby scatterers with significantly smaller localization errors and finer resolutions	finding	2K_dev_1528
	finding	2K_dev_1528
this paper introduces data-driven matched field processing	mechanism	2K_dev_1528
a framework	mechanism	2K_dev_1528
and then use these models This paper presents the data-driven framework	mechanism	2K_dev_1528
analyzes its behavior under unmodeled multipath interference from experimental measurements of an aluminum plate	method	2K_dev_1528
Compared with delay-based models that are commonly used in structural health monitoring	method	2K_dev_1528
	method	2K_dev_1528
Although effective	purpose	2K_dev_1528
matched field processing is often challenging to implement because it requires accurate models of the propagation environment	purpose	2K_dev_1528
and the optimization methods used to generate these models are often unreliable and computationally expensive	purpose	2K_dev_1528
To address these obstacles to build models of multimodal propagation environments directly from measured data for localization	purpose	2K_dev_1528
	purpose	2K_dev_1528
	background	2K_dev_1529
	finding	2K_dev_1529
	mechanism	2K_dev_1529
	method	2K_dev_1529
	purpose	2K_dev_1529
Recent technological advances coupled with large sample sets have uncovered many factors underlying the genetic basis of traits and the predisposition to complex disease	background	2K_dev_1530
but much is left to discover	background	2K_dev_1530
A common thread to most genetic investigations is familial relationships	background	2K_dev_1530
Close relatives can be identified from family records	background	2K_dev_1530
and more distant relatives can be inferred from large panels of genetic markers Finally	background	2K_dev_1530
while our methods have been developed for refining genetic relationship matrices and improving estimates of heritability	background	2K_dev_1530
they have much broader potential application in statistics Most notably	background	2K_dev_1530
for error-in-variables random effects models and settings that require regularization of matrices with block or hierarchical structure	background	2K_dev_1530
we show that smoothing leads to better estimates of the relatedness amongst distantly related individuals	finding	2K_dev_1530
We illustrate our method We show that by using smoothed relationship matrices we can estimate heritability using population-based samples	finding	2K_dev_1530
	finding	2K_dev_1530
We propose a new method by exploiting the underlying structure due to hierarchical groupings of correlated individuals The approach	mechanism	2K_dev_1530
which we call Treelet Covariance Smoothing	mechanism	2K_dev_1530
employs a multiscale decomposition of covariance matrices to improve estimates of pairwise relationships	mechanism	2K_dev_1530
	mechanism	2K_dev_1530
On both simulated and real data with a large genome-wide association study and estimate the `` heritability '' of body mass index quite accurately	method	2K_dev_1530
Traditionally heritability	method	2K_dev_1530
defined as the fraction of the total trait variance attributable to additive genetic effects	method	2K_dev_1530
is estimated from samples of closely related individuals using random effects models	method	2K_dev_1530
	method	2K_dev_1530
Unfortunately these empirical estimates can be noisy	purpose	2K_dev_1530
especially regarding distant relatives	purpose	2K_dev_1530
for denoising genetically-inferred relationship matrices	purpose	2K_dev_1530
Good feature design is important to achieve effective image classification	background	2K_dev_1531
The feature design is applicable to different application domains	background	2K_dev_1531
Both experiments show promising performance improvements over the state-of-the-art	finding	2K_dev_1531
	finding	2K_dev_1531
This paper presents a novel feature design with two main contributions	mechanism	2K_dev_1531
First	mechanism	2K_dev_1531
prior to computing the feature descriptors	mechanism	2K_dev_1531
with learning-based filters Second	mechanism	2K_dev_1531
we propose with another set of learning-based filters In this way	mechanism	2K_dev_1531
while generic feature descriptors are used	mechanism	2K_dev_1531
data-adaptive information is integrated into the feature extraction process based on the optimization objective to enhance the discriminative power of feature descriptors	mechanism	2K_dev_1531
	mechanism	2K_dev_1531
and is evaluated on both lung tissue classification in high-resolution computed tomography ( HRCT ) images and apoptosis detection in time-lapse phase contrast microscopy image sequences	method	2K_dev_1531
we propose to transform the images to obtain more representative feature descriptors	purpose	2K_dev_1531
to transform the computed descriptors to further improve the classification accuracy	purpose	2K_dev_1531
	purpose	2K_dev_1531
	background	2K_dev_1532
	finding	2K_dev_1532
	mechanism	2K_dev_1532
	method	2K_dev_1532
	purpose	2K_dev_1532
	background	2K_dev_1533
The experimental results show that the proposed method is faster and requires smaller memory than the existing methods with little or no loss of accuracy	finding	2K_dev_1533
Exploiting the redundancy in a tensor representing the affinity between feature points	mechanism	2K_dev_1533
we approximate the affinity tensor with the linear combination of Kronecker products between bases and index tensors	mechanism	2K_dev_1533
The bases and index tensors are highly compressed representations of the approximated affinity tensor	mechanism	2K_dev_1533
requiring much smaller memory than in previous methods	mechanism	2K_dev_1533
which store the full affinity tensor	mechanism	2K_dev_1533
We compute the principal eigenvector of the approximated affinity tensor using the small bases and index tensors without explicitly storing the approximated tensor	mechanism	2K_dev_1533
To compensate for the loss of matching accuracy by the approximation	mechanism	2K_dev_1533
we also adopt and incorporate a marginalization scheme that maps a higher order tensor to matrix as well as a one-to-one mapping constraint into the eigenvector computation process	mechanism	2K_dev_1533
	mechanism	2K_dev_1533
	method	2K_dev_1533
This paper presents a fast and efficient computational approach to higher order spectral graph matching	purpose	2K_dev_1533
	purpose	2K_dev_1533
	background	2K_dev_1534
	finding	2K_dev_1534
	mechanism	2K_dev_1534
	method	2K_dev_1534
	purpose	2K_dev_1534
	background	2K_dev_1535
For the subject tested	finding	2K_dev_1535
the prototype is capable of generating an ankle range of motion of 27 ( 14 dorsiflexion and 13 plantarflexion )	finding	2K_dev_1535
The controllability of the system is The suitability of the proposed control strategy is	finding	2K_dev_1535
We describe the design and control of a wearable robotic device powered by pneumatic artificial muscle actuators The design is inspired by the biological musculoskeletal system of the human foot and lower leg	mechanism	2K_dev_1535
mimicking the morphology and the functionality of the biological muscle-tendon-ligament structure A key feature of the device is its soft structure that provides active assistance without restricting natural degrees of freedom at the ankle joint	mechanism	2K_dev_1535
Four pneumatic artificial muscles assist dorsiflexion and plantarflexion as well as inversion and eversion	mechanism	2K_dev_1535
The prototype is also equipped with various embedded sensors for gait pattern analysis	mechanism	2K_dev_1535
experimentally demonstrated using a linear time-invariant ( LTI ) controller	method	2K_dev_1535
The controller is found using an identified LTI model of the system	method	2K_dev_1535
resulting from the interaction of the soft orthotic device with a human leg	method	2K_dev_1535
and model-based classical control design techniques demonstrated with several angle-reference following experiments	method	2K_dev_1535
for use in ankle-foot rehabilitation	purpose	2K_dev_1535
Virus capsid assembly has been widely studied as a biophysical system	background	2K_dev_1536
both for its biological and medical significance and as an important model for complex self-assembly processes No current technology can monitor assembly in detail and what information we have on assembly kinetics comes exclusively from in vitro studies	background	2K_dev_1536
There are many differences between the intracellular environment and that of an in vitro assembly assay	background	2K_dev_1536
however	background	2K_dev_1536
that might be expected to alter assembly pathways These models may help us understand how complicated assembly systems may have evolved to function with high efficiency and fidelity in the densely crowded environment of the cell	background	2K_dev_1536
suggest a striking difference depending on whether or not a system uses nucleation-limited assembly	finding	2K_dev_1536
with crowding tending to promote off-pathway growth in a nonnucleation-limited model but often enhancing assembly efficiency at high crowding levels even while impeding it at lower crowding levels in a nucleation-limited model	finding	2K_dev_1536
	finding	2K_dev_1536
We combine prior particle simulation methods for estimating crowding effects with coarse-grained stochastic models of capsid assembly	mechanism	2K_dev_1536
using the crowding models to adjust kinetics of capsid simulations	mechanism	2K_dev_1536
Simulations	method	2K_dev_1536
Here	purpose	2K_dev_1536
we explore one specific feature characteristic of the intracellular environment and known to have large effects on macromolecular assembly processes : molecular crowding	purpose	2K_dev_1536
to examine possible effects of crowding on assembly pathways	purpose	2K_dev_1536
Computational cancer phylogenetics seeks to enumerate the temporal sequences of aberrations in tumor evolution	background	2K_dev_1537
thereby delineating the evolution of possible tumor progression pathways	background	2K_dev_1537
molecular subtypes	background	2K_dev_1537
and mechanisms of action	background	2K_dev_1537
We previously developed a pipeline for constructing phylogenies describing evolution between major recurring cell types computationally inferred from whole-genome tumor profiles	background	2K_dev_1537
We show which confirms its effectiveness for tumor phylogeny inference and suggests avenues for future advances	finding	2K_dev_1537
	finding	2K_dev_1537
Here	mechanism	2K_dev_1537
we present a novel hidden Markov model ( HMM ) scheme through joint segmentation and calling of multisample tumor data	mechanism	2K_dev_1537
Our method classifies sets of genome-wide DNA copy number measurements into a partitioning of samples into normal ( diploid ) or amplified at each probe It differs from other similar HMM methods in its design specifically for the needs of tumor phylogenetics	mechanism	2K_dev_1537
by seeking to identify robust markers of progression conserved across a set of copy number profiles	mechanism	2K_dev_1537
	mechanism	2K_dev_1537
an analysis of our method in comparison to other methods on both synthetic and real tumor data	method	2K_dev_1537
The accuracy and detail of the phylogenies	purpose	2K_dev_1537
however	purpose	2K_dev_1537
depend on the identification of accurate	purpose	2K_dev_1537
high-resolution molecular markers of progression	purpose	2K_dev_1537
i	purpose	2K_dev_1537
e	purpose	2K_dev_1537
	purpose	2K_dev_1537
reproducible regions of aberration that robustly differentiate different subtypes and stages of progression	purpose	2K_dev_1537
for the problem of inferring such phylogenetically significant markers	purpose	2K_dev_1537
In many behavioral domains	background	2K_dev_1538
such as facial expression and gesture	background	2K_dev_1538
sparse structure is prevalent As a consequence	background	2K_dev_1538
high-dimensional representations such as SIFT and Gabor features have been favored despite their much greater computational cost and potential loss of information	background	2K_dev_1538
	background	2K_dev_1538
KSS outperformed both sparse and non-sparse methods that utilize complex image features and their temporal extensions In the case of early facial event classification KSS had 10 % higher accuracy as measured by F1 score over kernel SVM methods	finding	2K_dev_1538
	finding	2K_dev_1538
We propose a Kernel Structured Sparsity ( KSS ) method We characterize spatio-temporal events as time-series of motion patterns and by utilizing time-series kernels we apply standard structured-sparse coding techniques to tackle this important problem	mechanism	2K_dev_1538
	mechanism	2K_dev_1538
We evaluated the KSS method using both gesture and facial expression datasets that include spontaneous behavior and differ in degree of difficulty and type of ground truth coding	method	2K_dev_1538
	method	2K_dev_1538
This sparsity would be well suited for event detection but for one problem	purpose	2K_dev_1538
Features typically are confounded by alignment error in space and time that can handle both the temporal alignment problem and the structured sparse reconstruction within a common framework	purpose	2K_dev_1538
and it can rely on simple features	purpose	2K_dev_1538
	purpose	2K_dev_1538
In contrast to previous systems in which the user interrogates an intermediate representation of visual information	background	2K_dev_1539
such as a tactile display representing a camera generated image	background	2K_dev_1539
a potentially useful feature for higher levels analysis of the visual scene	background	2K_dev_1539
	background	2K_dev_1539
have quantified the user 's ability to discriminate the angle of the edge	finding	2K_dev_1539
	finding	2K_dev_1539
We present a novel device mounted on the fingertip our device uses a fingertip-mounted camera and haptic stimulator to allow the user to feel visual features directly from the environment	mechanism	2K_dev_1539
Visual features ranging from simple intensity or oriented edges to more complex information identified automatically about objects in the environment may be translated in this manner into haptic stimulation of the finger	mechanism	2K_dev_1539
	mechanism	2K_dev_1539
Experiments using an initial prototype to trace a continuous straight edge	method	2K_dev_1539
for acquiring and transmitting visual information through haptic channels	purpose	2K_dev_1539
	purpose	2K_dev_1539
How can we correlate the neural activity in the human brain as it responds to typed words	background	2K_dev_1540
with properties of these terms ( like 'edible '	background	2K_dev_1540
'fits in hand ' ) ? In short	background	2K_dev_1540
we want to find latent variables	background	2K_dev_1540
that jointly explain both the brain activity	background	2K_dev_1540
as well as the behavioral responses	background	2K_dev_1540
This is one of many settings of the Coupled Matrix-Tensor Factorization ( CMTF ) problem	background	2K_dev_1540
TURBO-SMT is able to find meaningful latent variables	finding	2K_dev_1540
as well as to predict brain activity with competitive accuracy	finding	2K_dev_1540
	finding	2K_dev_1540
We introduce TURBO-SMT	mechanism	2K_dev_1540
a meta-method it boosts the performance of any CMTF algorithm	mechanism	2K_dev_1540
by up to 200_	mechanism	2K_dev_1540
along with an up to 65 fold increase in sparsity	mechanism	2K_dev_1540
with comparable accuracy to the baseline	mechanism	2K_dev_1540
	mechanism	2K_dev_1540
We apply TURBO-SMT to BRAINQ	method	2K_dev_1540
a dataset consisting of a ( nouns	method	2K_dev_1540
brain voxels	method	2K_dev_1540
human subjects ) tensor and a ( nouns	method	2K_dev_1540
properties ) matrix	method	2K_dev_1540
with coupling along the nouns dimension	method	2K_dev_1540
	method	2K_dev_1540
Can we accelerate any CMTF solver	purpose	2K_dev_1540
so that it runs within a few minutes instead of tens of hours to a day	purpose	2K_dev_1540
while maintaining good accuracy ? capable of doing exactly that :	purpose	2K_dev_1540
Our results significantly expand knowledge of eutherian genome evolution and will facilitate greater understanding of the role of chromosome rearrangements in adaptation	background	2K_dev_1541
speciation	background	2K_dev_1541
and the etiology of inherited and spontaneously occurring diseases	background	2K_dev_1541
	background	2K_dev_1541
The reconstructed chromosomes of the eutherian	finding	2K_dev_1541
boreoeutherian	finding	2K_dev_1541
and euarchontoglires ancestor each included > 80 % of the entire length of the human genome	finding	2K_dev_1541
whereas reconstructed chromosomes of the most recent common ancestor of simians	finding	2K_dev_1541
catarrhini	finding	2K_dev_1541
great apes	finding	2K_dev_1541
and humans and chimpanzees included > 90 % of human genome sequence	finding	2K_dev_1541
These high-coverage reconstructions permitted reliable identification of chromosomal rearrangements over _105 My of eutherian evolution Orangutan was found to have eight chromosomes that were completely conserved in homologous sequence order and orientation with the eutherian ancestor	finding	2K_dev_1541
the largest number for any species	finding	2K_dev_1541
Ruminant artiodactyls had the highest frequency of intrachromosomal rearrangements	finding	2K_dev_1541
and interchromosomal rearrangements dominated in murid rodents	finding	2K_dev_1541
A total of 162 chromosomal breakpoints in evolution of the eutherian ancestral genome to the human genome were identified ; however	finding	2K_dev_1541
the rate of rearrangements was significantly lower ( 0	finding	2K_dev_1541
80/My ) during the first _60 My of eutherian evolution	finding	2K_dev_1541
then increased to greater than 2	finding	2K_dev_1541
0/My along the five primate lineages studied	finding	2K_dev_1541
	finding	2K_dev_1541
Whole-genome assemblies of 19 placental mammals and two outgroup species were used we developed an algorithm ( DESCHRAMBLER ) that probabilistically determines the adjacencies of syntenic fragments using chromosome-scale and fragmented genome assemblies	mechanism	2K_dev_1541
	mechanism	2K_dev_1541
	method	2K_dev_1541
to reconstruct the order and orientation of syntenic fragments in chromosomes of the eutherian ancestor and six other descendant ancestors leading to human	purpose	2K_dev_1541
For ancestral chromosome reconstructions	purpose	2K_dev_1541
	background	2K_dev_1542
All added Ag was converted to Ag2S	finding	2K_dev_1542
regardless of the form of Ag added ( NP vs ionic )	finding	2K_dev_1542
Zn was transformed to three Zn-containing species	finding	2K_dev_1542
ZnS	finding	2K_dev_1542
Zn3 ( PO4 ) 2	finding	2K_dev_1542
and Zn associated Fe oxy/hydroxides	finding	2K_dev_1542
also regardless of the form of Zn added	finding	2K_dev_1542
Zn speciation was the same in the unamended control sludge	finding	2K_dev_1542
Ag2S persisted in all sludge treatments	finding	2K_dev_1542
Zn3 ( PO4 ) 2 persisted in sludge and biosolids	finding	2K_dev_1542
but the ratio of ZnS and Zn associated with Fe oxy/hydroxide depended on the redox state and water content of the biosolids	finding	2K_dev_1542
Limited differences in Zn and Ag speciation among NP-dosed	finding	2K_dev_1542
ion-dosed	finding	2K_dev_1542
and control biosolids indicate that these nanoparticles are transformed to similar chemical forms as bulk metals already entering the WWTP	finding	2K_dev_1542
	mechanism	2K_dev_1542
Here	method	2K_dev_1542
X-ray absorption spectroscopy ( XAS ) and supporting characterization methods are used to determine the chemical speciation of Ag and Zn in sludge from a pilot wastewater treatment plant ( WWTP ) that had received PVP coated 50 nm Ag NPs and 30 nm ZnO NPs	method	2K_dev_1542
dissolved metal ions	method	2K_dev_1542
or no added metal	method	2K_dev_1542
The effects of composting and lime and heat treatment on metal speciation in the resulting biosolids were also examined	method	2K_dev_1542
	method	2K_dev_1542
Chemical transformations of silver nanoparticles ( Ag NPs ) and zinc oxide nanoparticles ( ZnO NPs ) during wastewater treatment and sludge treatment must be characterized to accurately assess the risks that these nanomaterials pose from land application of biosolids	purpose	2K_dev_1542
	purpose	2K_dev_1542
	background	2K_dev_1543
	finding	2K_dev_1543
	mechanism	2K_dev_1543
	method	2K_dev_1543
	purpose	2K_dev_1543
	background	2K_dev_1544
	finding	2K_dev_1544
	mechanism	2K_dev_1544
	method	2K_dev_1544
	purpose	2K_dev_1544
With the introduction of next-generation sequencing ( NGS ) technologies	background	2K_dev_1545
we are facing an exponential increase in the amount of genomic sequence data	background	2K_dev_1545
The success of all medical and genetic applications of next-generation sequencing critically depends on the existence of computational techniques that can process and analyze the enormous amount of sequence data quickly and accurately	background	2K_dev_1545
	background	2K_dev_1545
we observed up to 19-fold speedup while still maintaining 100 % sensitivity and high comprehensiveness	finding	2K_dev_1545
	finding	2K_dev_1545
NGS	mechanism	2K_dev_1545
We propose a new algorithm	mechanism	2K_dev_1545
FastHASH which drastically improves the performance of the seed-and-extend type hash table based read mapping algorithms	mechanism	2K_dev_1545
while maintaining the high sensitivity and comprehensiveness of such methods FastHASH is a generic algorithm compatible with all seed-and-extend class read mapping algorithms	mechanism	2K_dev_1545
It introduces two main techniques	mechanism	2K_dev_1545
namely Adjacency Filtering	mechanism	2K_dev_1545
and Cheap K-mer Selection	mechanism	2K_dev_1545
We implemented FastHASH and merged it into the codebase of the popular read mapping program	mechanism	2K_dev_1545
mrFAST	mechanism	2K_dev_1545
	mechanism	2K_dev_1545
Depending on the edit distance cutoffs	method	2K_dev_1545
	method	2K_dev_1545
Unfortunately	purpose	2K_dev_1545
the current read mapping algorithms have difficulties in coping with the massive amounts of data generated by	purpose	2K_dev_1545
Most of the relevant prior works involve supervised learning frameworks ( e	background	2K_dev_1546
g	background	2K_dev_1546
	background	2K_dev_1546
Support Vector Machines )	background	2K_dev_1546
However	background	2K_dev_1546
in-home monitoring provides only coarse ground truth information about symptom occurrences	background	2K_dev_1546
making it very hard to adapt and train supervised learning classifiers for symptom detection	background	2K_dev_1546
	background	2K_dev_1546
We were able to detect subject specific symptoms ( e	finding	2K_dev_1546
g	finding	2K_dev_1546
dyskinesia ) that conformed with a daily log maintained by the patients	finding	2K_dev_1546
	finding	2K_dev_1546
to use a weakly supervised machine learning framework We address this challenge by formulating symptom detection under incomplete ground truth information as a multiple instance learning ( MIL ) problem	mechanism	2K_dev_1546
MIL is a weakly supervised learning framework that does not require exact instances of symptom occurrences for training ; rather	mechanism	2K_dev_1546
it learns from approximate time intervals within which a symptom might or might not have occurred on a given day Once trained	mechanism	2K_dev_1546
the MIL detector was able to spot symptom-prone time windows on other days and approximately localize the symptom instances	mechanism	2K_dev_1546
	mechanism	2K_dev_1546
We monitored two Parkinson 's disease ( PD ) patients	method	2K_dev_1546
each for four days with a set of five triaxial accelerometers and utilized a MIL algorithm based on axis parallel rectangle ( APR ) fitting in the feature space	method	2K_dev_1546
	method	2K_dev_1546
In this paper	purpose	2K_dev_1546
we propose for automatic detection of Parkinson 's Disease motor symptoms in daily living environments	purpose	2K_dev_1546
Our primary goal is to develop a monitoring system capable of being used outside of controlled laboratory settings	purpose	2K_dev_1546
Such a system would enable us to track medication cycles at home and provide valuable clinical feedback	purpose	2K_dev_1546
	purpose	2K_dev_1546
The proposed soft capsules could be used as minimally invasive tetherless medical devices with therapeutic capability for the next generation capsule endoscopy	background	2K_dev_1547
	background	2K_dev_1547
show that the drug release can be controlled by the frequency of the external magnetic pulse	finding	2K_dev_1547
to evaluate the magnetically actuated multimodal drug release capability	finding	2K_dev_1547
	finding	2K_dev_1547
In this paper	mechanism	2K_dev_1547
we present a magnetically actuated multimodal drug release mechanism using a tetherless soft capsule endoscope Because the designed capsule has a drug chamber between both magnetic heads	mechanism	2K_dev_1547
if it is compressed by the external magnetic field	mechanism	2K_dev_1547
the capsule could release a drug in a specific position locally	mechanism	2K_dev_1547
The capsule is designed to release a drug in two modes according to the situation	mechanism	2K_dev_1547
In the first mode	mechanism	2K_dev_1547
a small amount of drug is continuously released by a series of pulse type magnetic field ( 0	mechanism	2K_dev_1547
01-0	mechanism	2K_dev_1547
03 T )	mechanism	2K_dev_1547
In the second mode	mechanism	2K_dev_1547
about 800 mm ( 3 ) of drug is released by the external magnetic field of 0	mechanism	2K_dev_1547
07 T	mechanism	2K_dev_1547
which induces a stronger magnetic attraction than the critical force for capsule 's collapsing	mechanism	2K_dev_1547
As a result	mechanism	2K_dev_1547
a polymeric coating is formed around the capsule	mechanism	2K_dev_1547
The coated area is dependent on the drug viscosity	mechanism	2K_dev_1547
	mechanism	2K_dev_1547
The experimental results This paper presents simulations and various experiments	method	2K_dev_1547
for the treatment of gastric disease	purpose	2K_dev_1547
	purpose	2K_dev_1547
Recognizing facial action units ( AUs ) is important for situation analysis and automated video annotation	background	2K_dev_1548
Previous work has emphasized face tracking and registration and the choice of features classifiers	background	2K_dev_1548
Relatively neglected is the effect of imbalanced data for action unit detection	background	2K_dev_1548
Our findings suggest that skew is a critical factor in evaluating performance metrics	background	2K_dev_1548
	background	2K_dev_1548
With exception of area under the ROC curve	finding	2K_dev_1548
all were attenuated by skewed distributions	finding	2K_dev_1548
in many cases	finding	2K_dev_1548
dramatically so	finding	2K_dev_1548
While ROC was unaffected by skew	finding	2K_dev_1548
precision-recall curves suggest that ROC may mask poor performance	finding	2K_dev_1548
To avoid or minimize skew-biased estimates of performance	finding	2K_dev_1548
we recommend reporting skew-normalized scores along with the obtained ones	finding	2K_dev_1548
	finding	2K_dev_1548
	mechanism	2K_dev_1548
we conducted experiments using both simulated classifiers and three major databases that differ in size	method	2K_dev_1548
type of FACS coding	method	2K_dev_1548
and degree of skew We evaluated influence of skew on both threshold metrics ( Accuracy	method	2K_dev_1548
F-score	method	2K_dev_1548
Cohen 's kappa	method	2K_dev_1548
and Krippendorf 's alpha ) and rank metrics ( area under the receiver operating characteristic ( ROC ) curve and precision-recall curve )	method	2K_dev_1548
	method	2K_dev_1548
While the machine learning community has become aware of the problem of skewed data for training classifiers	purpose	2K_dev_1548
little attention has been paid to how skew may bias performance metrics	purpose	2K_dev_1548
To address this question	purpose	2K_dev_1548
	purpose	2K_dev_1548
	background	2K_dev_1549
demonstrating that the SSP model achieves faster algorithm convergence on several different ML problems	finding	2K_dev_1549
compared to fully-synchronous and asynchronous schemes	finding	2K_dev_1549
We propose a parameter server system for distributed ML	mechanism	2K_dev_1549
which follows a Stale Synchronous Parallel ( SSP ) model of computation that The parameter server provides an easy-to-use shared interface for read/write access to an ML model 's values ( parameters and variables )	mechanism	2K_dev_1549
and the SSP model allows distributed workers to read older	mechanism	2K_dev_1549
stale versions of these values from a local cache	mechanism	2K_dev_1549
instead of waiting to get them from a central storage	mechanism	2K_dev_1549
This significantly increases the proportion of time workers spend computing	mechanism	2K_dev_1549
as opposed to waiting	mechanism	2K_dev_1549
Furthermore	mechanism	2K_dev_1549
the SSP model ensures ML algorithm correctness by limiting the maximum age of the stale values	mechanism	2K_dev_1549
	mechanism	2K_dev_1549
We provide a proof of correctness under SSP	method	2K_dev_1549
as well as empirical results	method	2K_dev_1549
maximizes the time computational workers spend doing useful work on ML algorithms	purpose	2K_dev_1549
while still providing correctness guarantees	purpose	2K_dev_1549
	purpose	2K_dev_1549
	background	2K_dev_1550
	finding	2K_dev_1550
our method is several orders of magnitude faster	finding	2K_dev_1550
with competitive or improved accuracy for latent space recovery and link prediction	finding	2K_dev_1550
We propose a scalable approach With a succinct representation of networks as a bag of triangular motifs	mechanism	2K_dev_1550
a parsimonious statistical model	mechanism	2K_dev_1550
and an efficient stochastic variational inference algorithm	mechanism	2K_dev_1550
we are able to analyze real networks with over a million vertices and hundreds of latent roles on a single machine in a matter of hours	mechanism	2K_dev_1550
a setting that is out of reach for many existing methods	mechanism	2K_dev_1550
When compared to the state-of-the-art probabilistic approaches	method	2K_dev_1550
for making inference about latent spaces of large networks	purpose	2K_dev_1550
	purpose	2K_dev_1550
	background	2K_dev_1551
The performance of our method is investigated and illustrated	finding	2K_dev_1551
by bringing together two different nonparametric ideas : distribution free inference and nonparametric smoothing We start from the general conformal prediction approach and we use a kernel density estimator as a measure of agreement between a sample point and the underlying distribution	mechanism	2K_dev_1551
The resulting prediction set is shown to be closely related to plug-in density level sets with carefully chosen cut-off values	mechanism	2K_dev_1551
Under standard smoothness conditions	mechanism	2K_dev_1551
we get an asymptotic efficiency result that is near optimal for a wide range of function classes But the coverage is guaranteed whether or not the smoothness conditions hold and regardless of the sample size	mechanism	2K_dev_1551
through simulation studies in a real data example	method	2K_dev_1551
This paper introduces a new approach to prediction Specifically	purpose	2K_dev_1551
we consider the problem of constructing nonparametric tolerance/prediction sets	purpose	2K_dev_1551
	purpose	2K_dev_1551
Bevel-tipped flexible needles can be robotically steered to reach clinical targets along curvilinear paths in 3D	background	2K_dev_1552
	background	2K_dev_1552
demonstrate the performance of the proposed controller results also show the feasibility of this technique in 2D and 3D environments	finding	2K_dev_1552
This paper presents a control law A look-ahead proportional controller for position and orientation is presented	mechanism	2K_dev_1552
The look-ahead distance is a linear function of insertion speed	mechanism	2K_dev_1552
	mechanism	2K_dev_1552
Simulations in a 3D brain-like environment Experimental	method	2K_dev_1552
Manual needle insertion allows the clinician to control the insertion speed	purpose	2K_dev_1552
ensuring patient safety for automatic 3D steering of manually inserted flexible needles	purpose	2K_dev_1552
enabling path-following control	purpose	2K_dev_1552
	purpose	2K_dev_1552
Previous studies have examined the characteristics of physiological tremor under laboratory settings as well as different operating conditions	background	2K_dev_1553
However	background	2K_dev_1553
different test methods make the comparison of results across trials and conditions difficult	background	2K_dev_1553
	mechanism	2K_dev_1553
Two vitroretinal microsurgeons were evaluated while performing a pointing task with no entry-point constraint	method	2K_dev_1553
constrained by an artificial eye model	method	2K_dev_1553
and constrained by a rabbit eye in vivo	method	2K_dev_1553
A spectral analysis was also performed	method	2K_dev_1553
This paper presents the characterization and comparison of physiological tremor for pointing tasks in multiple environments	purpose	2K_dev_1553
as a baseline for performance evaluation of microsurgical robotics	purpose	2K_dev_1553
	purpose	2K_dev_1553
According to this hypothesis	background	2K_dev_1554
when symptoms are severe	background	2K_dev_1554
depressed participants withdraw from other people in order to protect themselves from anticipated rejection	background	2K_dev_1554
scorn	background	2K_dev_1554
and social exclusion	background	2K_dev_1554
As their symptoms fade	background	2K_dev_1554
participants send more signals indicating a willingness to affiliate	background	2K_dev_1554
suggests that automatic facial expression analysis may be ready for use in behavioral and clinical science	background	2K_dev_1554
Automatic and manual coding were highly consistent for FACS action units	finding	2K_dev_1554
and showed similar effects for change over time in depression severity	finding	2K_dev_1554
For both systems	finding	2K_dev_1554
when symptom severity was high	finding	2K_dev_1554
participants made more facial expressions associated with contempt	finding	2K_dev_1554
smiled less	finding	2K_dev_1554
and those smiles that occurred were more likely to be accompanied by facial actions associated with contempt	finding	2K_dev_1554
These results are consistent with the `` social risk hypothesis '' of depression	finding	2K_dev_1554
The finding that automatic facial expression analysis was both consistent with manual coding and produced the same pattern of depression effects	finding	2K_dev_1554
	mechanism	2K_dev_1554
Depressed participants were followed over the course of treatment and video recorded during a series of clinical interviews	method	2K_dev_1554
Facial expressions were analyzed from the video using both manual and automatic systems	method	2K_dev_1554
	method	2K_dev_1554
Investigated the relationship between change over time in severity of depression symptoms and facial expression	purpose	2K_dev_1554
	purpose	2K_dev_1554
	background	2K_dev_1555
	finding	2K_dev_1555
	mechanism	2K_dev_1555
	method	2K_dev_1555
	purpose	2K_dev_1555
G protein coupled receptors ( GPCRs ) are seven helical transmembrane proteins that function as signal transducers	background	2K_dev_1556
They bind ligands in their extracellular and transmembrane regions and activate cognate G proteins at their intracellular surface at the other side of the membrane	background	2K_dev_1556
The relay of allosteric communication between the ligand binding site and the distant G protein binding site is poorly understood	background	2K_dev_1556
	background	2K_dev_1556
The GREMLIN-predicted long-range interactions between amino acids were analyzed with respect to the seven GPCR structures that have been crystallized at the time this study was undertaken	finding	2K_dev_1556
In this study	mechanism	2K_dev_1556
GREMLIN 1	mechanism	2K_dev_1556
a recently developed method that identifies networks of co-evolving residues from multiple sequence alignments	mechanism	2K_dev_1556
was used	mechanism	2K_dev_1556
	method	2K_dev_1556
to identify those that may be involved in communicating the activation signal across the membrane	purpose	2K_dev_1556
	purpose	2K_dev_1556
	background	2K_dev_1557
	finding	2K_dev_1557
We describe an R package named huge which provides easy-to-use functions This package implements recent results in the literature	mechanism	2K_dev_1557
including Friedman et al	mechanism	2K_dev_1557
( 2007 )	mechanism	2K_dev_1557
Liu et al	mechanism	2K_dev_1557
( 2009	mechanism	2K_dev_1557
2012 ) and Liu et al	mechanism	2K_dev_1557
( 2010 ) Compared with the existing graph estimation package glasso	mechanism	2K_dev_1557
the huge package provides extra features : ( 1 ) instead of using Fortan	mechanism	2K_dev_1557
it is written in C	mechanism	2K_dev_1557
which makes the code more portable and easier to modify ; ( 2 ) besides fitting Gaussian graphical models	mechanism	2K_dev_1557
it also provides functions for fitting high dimensional semiparametric Gaussian copula models ; ( 3 ) more functions like data-dependent model selection	mechanism	2K_dev_1557
data generation and graph visualization ; ( 4 ) a minor convergence problem of the graphical lasso algorithm is corrected ; ( 5 ) the package allows the user to apply both lossless and lossy screening rules to scale up large-scale problems	mechanism	2K_dev_1557
making a tradeoff between computational and statistical efficiency	mechanism	2K_dev_1557
	mechanism	2K_dev_1557
	method	2K_dev_1557
for estimating high dimensional undirected graphs from data	purpose	2K_dev_1557
	purpose	2K_dev_1557
Previous works either study the group sparsity in the parametric setting ( e	background	2K_dev_1558
g	background	2K_dev_1558
	background	2K_dev_1558
group lasso )	background	2K_dev_1558
or address the problem in the nonparametric setting without exploiting the structural information ( e	background	2K_dev_1558
g	background	2K_dev_1558
	background	2K_dev_1558
sparse additive models )	background	2K_dev_1558
that GroupSpAM substantially outperforms the competing methods in terms of support recovery and prediction accuracy in additive models	finding	2K_dev_1558
and also conduct a comparative experiment on a real breast cancer dataset	finding	2K_dev_1558
	finding	2K_dev_1558
In this paper	mechanism	2K_dev_1558
we present a new method	mechanism	2K_dev_1558
called group sparse additive models ( GroupSpAM )	mechanism	2K_dev_1558
which can handle group sparsity in additive models	mechanism	2K_dev_1558
We generalize the _1/_2 norm to Hilbert spaces as the sparsity-inducing penalty in GroupSpAM	mechanism	2K_dev_1558
Moreover	mechanism	2K_dev_1558
we derive a novel thresholding condition for identifying the functional sparsity at the group level	mechanism	2K_dev_1558
and propose an efficient block coordinate descent algorithm for constructing the estimate	mechanism	2K_dev_1558
	mechanism	2K_dev_1558
We demonstrate by simulation	method	2K_dev_1558
We consider the problem of sparse variable selection in nonparametric additive models	purpose	2K_dev_1558
with the prior knowledge of the structure among the covariates to encourage those variables within a group to be selected jointly	purpose	2K_dev_1558
	background	2K_dev_1559
	finding	2K_dev_1559
an inexpensive pico-projector-based augmented reality ( AR ) display The system is designed for use with Micron	mechanism	2K_dev_1559
an active handheld surgical tool that cancels hand tremor of surgeons to improve microsurgical accuracy	mechanism	2K_dev_1559
Using the AR display	mechanism	2K_dev_1559
virtual cues can be injected into the microscope view Cues can be used to maintain high performance by helping the surgeon to avoid drifting out of the workspace of the instrument	mechanism	2K_dev_1559
Also	mechanism	2K_dev_1559
boundary information such as the view range of the cameras that record surgical procedures can be displayed to tell surgeons the operation area	mechanism	2K_dev_1559
Furthermore	mechanism	2K_dev_1559
numerical	mechanism	2K_dev_1559
textual	mechanism	2K_dev_1559
or graphical information can be displayed	mechanism	2K_dev_1559
showing such things as tool tip depth in the work space and on/off status of the canceling function of Micron	mechanism	2K_dev_1559
	mechanism	2K_dev_1559
	method	2K_dev_1559
This paper describes for a surgical microscope	purpose	2K_dev_1559
to track the movement of the tip of Micron	purpose	2K_dev_1559
show the desired position	purpose	2K_dev_1559
and indicate the position error	purpose	2K_dev_1559
	purpose	2K_dev_1559
	background	2K_dev_1560
	finding	2K_dev_1560
We propose a procedure that estimates the structure of a graphical model by minimizing the temporally smoothed L1 penalized regression	mechanism	2K_dev_1560
which allows jointly estimating the partition boundaries of the VCVS model and the coefficient of the sparse precision matrix on each block of the partition A highly scalable proximal gradient method is proposed to solve the resultant convex optimization problem ; and the conditions for sparsistent estimation and the convergence rate of both the partition boundaries and the network structure are established for the first time for such estimators	mechanism	2K_dev_1560
	mechanism	2K_dev_1560
	method	2K_dev_1560
We study the problem of estimating a temporally varying coefficient and varying structure ( VCVS ) graphical model underlying data collected over a period of time	purpose	2K_dev_1560
such as social states of interacting individuals or microarray expression profiles of gene networks	purpose	2K_dev_1560
as opposed to i	purpose	2K_dev_1560
i	purpose	2K_dev_1560
d	purpose	2K_dev_1560
data from an invariant model widely considered in current literature of structural estimation	purpose	2K_dev_1560
In particular	purpose	2K_dev_1560
we consider the scenario in which the model evolves in a piece-wise constant fashion	purpose	2K_dev_1560
	purpose	2K_dev_1560
Semantic grounding is the process of relating meaning to symbols ( e	background	2K_dev_1561
g	background	2K_dev_1561
	background	2K_dev_1561
words )	background	2K_dev_1561
It is the foundation for creating a representational symbolic system such as language	background	2K_dev_1561
Motor and a portion of somatosensory neurons were found to be involved in primarily sensorimotor mapping	finding	2K_dev_1561
while parietal and some somatosensory neurons were found to be involved in both sensorimotor and verb-category mapping	finding	2K_dev_1561
The time course of the spike activities and the selective tuning pattern of these neurons indicate that they belong to a large neural network used for semantic processing	finding	2K_dev_1561
	finding	2K_dev_1561
	mechanism	2K_dev_1561
These two mechanisms were investigated by examining neuronal-level spike ( i	method	2K_dev_1561
e	method	2K_dev_1561
neuronal action potential ) activities from the motor	method	2K_dev_1561
somatosensory and parietal areas in two human participants	method	2K_dev_1561
	method	2K_dev_1561
Semantic grounding for verb meaning is hypothesized to be achieved through two mechanisms : sensorimotor mapping	purpose	2K_dev_1561
i	purpose	2K_dev_1561
e	purpose	2K_dev_1561
	purpose	2K_dev_1561
directly encoding the sensorimotor experiences the verb describes	purpose	2K_dev_1561
and verb-category mapping	purpose	2K_dev_1561
i	purpose	2K_dev_1561
e	purpose	2K_dev_1561
	purpose	2K_dev_1561
encoding the abstract category a verb belongs to	purpose	2K_dev_1561
This study is the first step towards understanding how words are processed by neurons	purpose	2K_dev_1561
Present treatments for ventricular tachycardia have significant drawbacks	background	2K_dev_1562
	finding	2K_dev_1562
To ameliorate these drawbacks	mechanism	2K_dev_1562
it may be advantageous to employ an epicardial robotic walker with precise control of needle insertion depth	mechanism	2K_dev_1562
	method	2K_dev_1562
that performs mapping and ablation	purpose	2K_dev_1562
This paper examines the feasibility of such a system	purpose	2K_dev_1562
	purpose	2K_dev_1562
Cryo-electron tomography ( cryo-ET ) captures the 3Delectron density distribution of macromolecular complexes in close to native state	background	2K_dev_1563
With the rapid advance of cryo-ET acquisition technologies	background	2K_dev_1563
it is possible to generate large numbers ( > 100000 ) of subtomograms	background	2K_dev_1563
each containing a macromolecular complex	background	2K_dev_1563
Often	background	2K_dev_1563
these subtomograms represent a heterogeneous sample due to variations in the structure and composition of a complex insitu form or because particles are a mixture of different complexes	background	2K_dev_1563
In this case subtomograms must be classified	background	2K_dev_1563
	finding	2K_dev_1563
This paper introduces an open source software platform	mechanism	2K_dev_1563
TomoMiner	mechanism	2K_dev_1563
Its scalable and robust parallel processing allows efficient classification of tens to hundreds of thousands of subtomograms	mechanism	2K_dev_1563
In addition	mechanism	2K_dev_1563
TomoMiner provides a pre-configured TomoMinerCloud computing service permitting users without sufficient computing resources instant access to TomoMiners high-performance features	mechanism	2K_dev_1563
	method	2K_dev_1563
However	purpose	2K_dev_1563
classification of large numbers of subtomograms is a time-intensive task and often a limiting bottleneck	purpose	2K_dev_1563
for large-scale subtomogram classification	purpose	2K_dev_1563
template matching	purpose	2K_dev_1563
subtomogram averaging	purpose	2K_dev_1563
and alignment	purpose	2K_dev_1563
	background	2K_dev_1564
	finding	2K_dev_1564
	mechanism	2K_dev_1564
	method	2K_dev_1564
	purpose	2K_dev_1564
	background	2K_dev_1565
Our experiments demonstrate that our synthesis method is precise and efficient The implicit specification helped us find one concurrency bug previously missed when model-checking using an explicit	finding	2K_dev_1565
user-provided specification	finding	2K_dev_1565
observed that different synchronization placements are produced for our experiments	finding	2K_dev_1565
favoring a minimal number of synchronization operations or maximum concurrency	finding	2K_dev_1565
respectively	finding	2K_dev_1565
	finding	2K_dev_1565
We present a computer-aided programming approach The approach allows programmers to program assuming a friendly	mechanism	2K_dev_1565
non-preemptive scheduler	mechanism	2K_dev_1565
and our synthesis procedure inserts synchronization The correctness specification is implicit	mechanism	2K_dev_1565
inferred from the non-preemptive behavior	mechanism	2K_dev_1565
Let us consider sequences of calls that the program makes to an external interface	mechanism	2K_dev_1565
The specification requires that any such sequence produced under a preemptive scheduler should be included in the set of sequences produced under a non-preemptive scheduler	mechanism	2K_dev_1565
We guarantee that our synthesis does not introduce deadlocks and that the synchronization inserted is optimal w	mechanism	2K_dev_1565
r	mechanism	2K_dev_1565
t	mechanism	2K_dev_1565
a given objective function	mechanism	2K_dev_1565
The solution is based on a finitary abstraction	mechanism	2K_dev_1565
an algorithm for bounded language inclusion moduloan independence relation	mechanism	2K_dev_1565
and generation of a set of global constraints over synchronization placements	mechanism	2K_dev_1565
Each model of the global constraints set corresponds to a correctness-ensuring synchronization placement	mechanism	2K_dev_1565
The placement that is optimal w	mechanism	2K_dev_1565
r	mechanism	2K_dev_1565
t	mechanism	2K_dev_1565
the given objective function is chosen as the synchronization solution	mechanism	2K_dev_1565
	mechanism	2K_dev_1565
We apply the approach to device-driver programming	method	2K_dev_1565
where the driver threads call the software interface of the device and the API provided by the operating system	method	2K_dev_1565
We implemented objective functions for coarse-grained and fine-grained locking and	method	2K_dev_1565
to concurrency	purpose	2K_dev_1565
to ensure that the final program works even with a preemptive scheduler	purpose	2K_dev_1565
Macroautophagy is regarded as a nonspecific bulk degradation process of cytoplasmic material within the lysosome	background	2K_dev_1566
indicating stimulus-specific pathways in stress-induced macroautophagy	background	2K_dev_1566
Protein dynamics are linked to image-based models of autophagosome turnover	finding	2K_dev_1566
Depending on the inducing stimulus	finding	2K_dev_1566
protein as well as organelle turnover differ	finding	2K_dev_1566
Amino acid starvation-induced macroautophagy leads to selective degradation of proteins important for protein translation	finding	2K_dev_1566
Thus	finding	2K_dev_1566
protein dynamics reflect cellular conditions in the respective treatment	finding	2K_dev_1566
	mechanism	2K_dev_1566
In the present study we monitor protein turnover and degradation by global	method	2K_dev_1566
unbiased approaches relying on quantitative mass spectrometry-based proteomics	method	2K_dev_1566
Macroautophagy is induced by rapamycin treatment	method	2K_dev_1566
and by amino acid and glucose starvation in differentially	method	2K_dev_1566
metabolically labeled cells	method	2K_dev_1566
	method	2K_dev_1566
However	purpose	2K_dev_1566
the process has mainly been studied by nonspecific bulk degradation assays using radiolabeling	purpose	2K_dev_1566
	purpose	2K_dev_1566
	background	2K_dev_1567
	finding	2K_dev_1567
	mechanism	2K_dev_1567
	method	2K_dev_1567
	purpose	2K_dev_1567
	background	2K_dev_1568
	finding	2K_dev_1568
	mechanism	2K_dev_1568
	method	2K_dev_1568
	purpose	2K_dev_1568
	background	2K_dev_1569
to show the higher accuracy of the surface reconstruction as compared to standard stereo reconstruction	finding	2K_dev_1569
to show the increased surgical accuracy due to motion scaling are also carried out	finding	2K_dev_1569
	finding	2K_dev_1569
using an actively stabilized handheld robot	mechanism	2K_dev_1569
guided by monocular vision We employ a previously developed monocular camera based surface reconstruction method using automated laser beam scanning over the retina	mechanism	2K_dev_1569
We use the reconstructed plane to find a coordinate transform between the 2D image plane coordinate system and the global 3D frame Within a hemispherical region around the target	mechanism	2K_dev_1569
we use motion scaling for higher precision	mechanism	2K_dev_1569
The contribution of this work is the homography matrix estimation using monocular vision and application of the previously developed laser surface reconstruction to Micron guided vein cannulation	mechanism	2K_dev_1569
Experiments are conducted in a wet eye phantom Further	method	2K_dev_1569
experiments	method	2K_dev_1569
In this paper we describe work towards retinal vessel cannulation	purpose	2K_dev_1569
Neuromechanical simulations have been used to study the spinal control of human locomotion which involves complex mechanical dynamics So far	background	2K_dev_1570
most neuromechanical simulation studies have focused on demonstrating the capability of a proposed control model in generating normal walking	background	2K_dev_1570
As many of these models with competing control hypotheses can generate human-like normal walking behaviors	background	2K_dev_1570
a more in-depth evaluation is required	background	2K_dev_1570
A model that captures these selective amplifications would be able to explain both steady and reactive spinal control of human locomotion	background	2K_dev_1570
Neuromechanical simulations that investigate hypothesized control models are complementary to gait experiments in better understanding the control of human locomotion	background	2K_dev_1570
	background	2K_dev_1570
Remarkably similar response trends for the majority of investigated muscles and experimental conditions reinforce the plausibility of the reflex circuits of the model	finding	2K_dev_1570
However	finding	2K_dev_1570
the model 's responses lack in amplitude suggesting that in these cases the proposed reflex circuits need to be amplified by additional control structures such as location-specific cutaneous reflexes	finding	2K_dev_1570
	mechanism	2K_dev_1570
The immediate changes in muscle activations of the model are compared to those of humans across different gait phases and disturbance magnitudes	method	2K_dev_1570
for two experiments with whole body disturbances	method	2K_dev_1570
Here	purpose	2K_dev_1570
we conduct the more in-depth evaluation on a spinal-reflex-based control model using five representative gait disturbances	purpose	2K_dev_1570
ranging from electrical stimulation to mechanical perturbation at individual leg joints and at the whole body	purpose	2K_dev_1570
	purpose	2K_dev_1570
Palau has unique features advantageous for this study : due to its population history	background	2K_dev_1571
Palauans are substantially interrelated ; affected individuals often	background	2K_dev_1571
but not always	background	2K_dev_1571
cluster in families ; and we have essentially complete ascertainment of affected individuals	background	2K_dev_1571
	background	2K_dev_1571
This extensive sharing	finding	2K_dev_1571
typically identical by descent	finding	2K_dev_1571
was significantly greater in cases than population controls	finding	2K_dev_1571
even after controlling for relatedness	finding	2K_dev_1571
Several regions of the genome exhibited substantial excess of shared haplotypes for affected individuals	finding	2K_dev_1571
including 3p21	finding	2K_dev_1571
3p12	finding	2K_dev_1571
4q28	finding	2K_dev_1571
and 5q23-q31	finding	2K_dev_1571
Two of these regions	finding	2K_dev_1571
4q28 and 5q23-q31	finding	2K_dev_1571
showed significant linkage by traditional LOD score analysis and could harbor variants of more sizeable risk for psychosis or a multiplicity of risk variants	finding	2K_dev_1571
The pattern of haplotype sharing in 4q28 highlights PCDH10	finding	2K_dev_1571
encoding a cadherin-related neuronal receptor	finding	2K_dev_1571
as possibly involved in risk	finding	2K_dev_1571
	mechanism	2K_dev_1571
we genotyped DNA samples from 203 Palauan individuals diagnosed with psychotic disorders	method	2K_dev_1571
broadly defined	method	2K_dev_1571
and 125 control subjects using a genome-wide single nucleotide polymorphism array	method	2K_dev_1571
	method	2K_dev_1571
we evaluated long-shared haplotypes	method	2K_dev_1571
10 Mb	method	2K_dev_1571
identifying clusters of affected individuals who share such haplotypes	method	2K_dev_1571
	method	2K_dev_1571
To localize genetic variation affecting risk for psychotic disorders in the population of Palau To localize risk variants to genomic regions	purpose	2K_dev_1571
	background	2K_dev_1572
show the proposed method 's robustness to data noise and size	finding	2K_dev_1572
its ability to capture the 1 features of the data	finding	2K_dev_1572
and its capability of performing additional analytics Examples include shock equations	finding	2K_dev_1572
pattern formation	finding	2K_dev_1572
fluid flow and turbulence	finding	2K_dev_1572
and oscillatory convection	finding	2K_dev_1572
	finding	2K_dev_1572
This work develops a learning algorithm only using data	mechanism	2K_dev_1572
The algorithm uses sparse optimization The features are data driven in the sense that they are constructed using nonlinear algebraic equations on the spatial derivatives of the data	mechanism	2K_dev_1572
	mechanism	2K_dev_1572
Several numerical experiments	method	2K_dev_1572
We investigate the problem of learning an evolution equation directly from some given data	purpose	2K_dev_1572
to identify the terms in the underlying partial differential equations and to approximate the coefficients of the terms in order to perform feature selection and parameter estimation	purpose	2K_dev_1572
	purpose	2K_dev_1572
Three-dimensional live cell imaging of the interaction of T cells with antigen-presenting cells ( APCs ) visualizes the subcellular distributions of signaling intermediates during T cell activation at thousands of resolved positions within a cell	background	2K_dev_1573
These information-rich maps of local protein concentrations are a valuable resource in understanding T cell signaling	background	2K_dev_1573
	background	2K_dev_1573
	finding	2K_dev_1573
Here	mechanism	2K_dev_1573
we describe a protocol This protocol allows quantitative analysis of T cell signaling as it occurs inside live cells with resolution in time and space across thousands of cells	mechanism	2K_dev_1573
	mechanism	2K_dev_1573
	method	2K_dev_1573
for the efficient acquisition of such imaging data and their computational processing to create four-dimensional maps of local concentrations	purpose	2K_dev_1573
	purpose	2K_dev_1573
Quantitative image analysis procedures are necessary for the automated discovery of effects of drug treatment in large collections of fluorescent micrographs	background	2K_dev_1574
These results can function as a baseline for comparison to other protein organization modeling approaches in plant cells	background	2K_dev_1574
	background	2K_dev_1574
we report the dose dependent drug effects in the first high-content Arabidopsis thaliana drug screen of its kind	finding	2K_dev_1574
we generated a large collection of images of single plant cells after various drug treatments	mechanism	2K_dev_1574
For this	mechanism	2K_dev_1574
protoplasts were isolated from six transgenic lines of A	mechanism	2K_dev_1574
thaliana expressing fluorescently tagged proteins	mechanism	2K_dev_1574
Eight drugs at three concentrations were applied to protoplast cultures followed by automated image acquisition For image analysis	mechanism	2K_dev_1574
we developed a cell segmentation protocol for detecting drug effects using a Hough transform-based region of interest detector and a novel cross-channel texture feature descriptor	mechanism	2K_dev_1574
In order to determine treatment effects	mechanism	2K_dev_1574
we summarized differences between treated and untreated experiments with an L1 Cramr-von Mises statistic	mechanism	2K_dev_1574
	mechanism	2K_dev_1574
The distribution of these statistics across all pairs of treated and untreated replicates was compared to the variation within control replicates to determine the statistical significance of observed effects	method	2K_dev_1574
Using this pipeline	method	2K_dev_1574
	method	2K_dev_1574
When compared to their mammalian counterparts	purpose	2K_dev_1574
the effects of drug conditions on protein localization in plant species are poorly understood and underexplored	purpose	2K_dev_1574
To investigate this relationship	purpose	2K_dev_1574
Event discovery aims to discover a temporal segment of interest	background	2K_dev_1575
such as human behavior	background	2K_dev_1575
actions or activities	background	2K_dev_1575
Most approaches to event discovery within or between time series use supervised learning	background	2K_dev_1575
A potential solution to CED is searching over all possible pairs of segments	background	2K_dev_1575
which would incur a prohibitive quartic cost	background	2K_dev_1575
We consider extensions to video search and supervised event detection	background	2K_dev_1575
	background	2K_dev_1575
	finding	2K_dev_1575
In this paper	mechanism	2K_dev_1575
we propose an efficient branch-and-bound ( B & B ) framework that avoids exhaustive search while guaranteeing a globally optimal solution	mechanism	2K_dev_1575
To this end	mechanism	2K_dev_1575
we derive novel bounding functions for various commonality measures and provide extensions to multiple commonality discovery and accelerated search The B & B framework takes as input any multidimensional signal that can be quantified into histograms A generalization of the framework can be readily applied to discover events at the same or different times ( synchrony and event commonality	mechanism	2K_dev_1575
respectively )	mechanism	2K_dev_1575
The effectiveness of the B & B framework is evaluated in motion capture of deliberate behavior and in video of spontaneous facial behavior in diverse interpersonal contexts : interviews	method	2K_dev_1575
small groups of young adults	method	2K_dev_1575
and parent-infant face-to-face interaction	method	2K_dev_1575
This becomes problematic when some relevant event labels are unknown	purpose	2K_dev_1575
are difficult to detect	purpose	2K_dev_1575
or not all possible combinations of events have been anticipated To overcome these problems	purpose	2K_dev_1575
this paper explores Common Event Discovery ( CED )	purpose	2K_dev_1575
a new problem that aims to discover common events of variable-length segments in an unsupervised manner	purpose	2K_dev_1575
	purpose	2K_dev_1575
Recent research has uncovered an important These findings illustrate the importance of population-based reference cohorts for the interpretation of candidate pathogenic variants	background	2K_dev_1576
even for analyses of complex diseases and de novo variation	background	2K_dev_1576
	background	2K_dev_1576
	finding	2K_dev_1576
we found that _1/3 of de novo variants are independently present as standing variation in the Exome Aggregation Consortium 's cohort of 60706 adults	finding	2K_dev_1576
and these de novo variants do not contribute to neurodevelopmental risk	finding	2K_dev_1576
LoF-intolerant genes also carry a modest excess of inherited PTVs	finding	2K_dev_1576
although the strongest de novo-affected genes contribute little to this excess	finding	2K_dev_1576
thus suggesting that the excess of inherited risk resides in lower-penetrant genes	finding	2K_dev_1576
	finding	2K_dev_1576
	mechanism	2K_dev_1576
role for de novo variation in neurodevelopmental disorders	purpose	2K_dev_1576
to identify a subset of LoF-intolerant genes containing the observed signal of associated de novo protein-truncating variants ( PTVs ) in neurodevelopmental disorders	purpose	2K_dev_1576
	purpose	2K_dev_1576
	background	2K_dev_1577
	finding	2K_dev_1577
	mechanism	2K_dev_1577
	method	2K_dev_1577
	purpose	2K_dev_1577
	background	2K_dev_1578
	finding	2K_dev_1578
	mechanism	2K_dev_1578
	method	2K_dev_1578
	purpose	2K_dev_1578
Robust principal component analysis ( PCA ) is one of the most important dimension-reduction techniques for handling high-dimensional data with outliers	background	2K_dev_1579
	background	2K_dev_1579
illustrate the effectiveness and superiority of the proposed method	finding	2K_dev_1579
	finding	2K_dev_1579
Extensive experimental results on several benchmark data sets	method	2K_dev_1579
	background	2K_dev_1580
	finding	2K_dev_1580
	mechanism	2K_dev_1580
	method	2K_dev_1580
	purpose	2K_dev_1580
State estimation is the most critical capability for MAV ( Micro-Aerial Vehicle ) localization	background	2K_dev_1581
autonomous obstacle avoidance	background	2K_dev_1581
robust flight control and 3D environmental mapping There are three main challenges for MAV state estimation : ( 1 ) it can deal with aggressive 6 DOF ( Degree Of Freedom ) motion ; ( 2 ) it should be robust to intermittent GPS ( Global Positioning System ) ( even GPS-denied ) situations ; ( 3 ) it should work well both for low- and high-altitude flight	background	2K_dev_1581
	background	2K_dev_1581
Experimental results show the effectiveness of the proposed state estimation system	finding	2K_dev_1581
especially for the aggressive	finding	2K_dev_1581
intermittent GPS and high-altitude MAV flight	finding	2K_dev_1581
	finding	2K_dev_1581
In this paper	mechanism	2K_dev_1581
we present by fusing long-range stereo visual odometry	mechanism	2K_dev_1581
GPS	mechanism	2K_dev_1581
barometric and IMU ( Inertial Measurement Unit ) measurements The new estimation system has two main parts	mechanism	2K_dev_1581
a stochastic cloning EKF ( Extended Kalman Filter ) estimator that loosely	mechanism	2K_dev_1581
and is derived and discussed in detail	mechanism	2K_dev_1581
A long-range stereo visual odometry is proposed by using both multi-view stereo triangulation and a multi-view stereo inverse depth filter	mechanism	2K_dev_1581
The odometry takes the EKF information ( IMU integral ) for robust camera pose tracking and image feature matching	mechanism	2K_dev_1581
and the stereo odometry output serves as the relative measurements for the update of the state estimation	mechanism	2K_dev_1581
	mechanism	2K_dev_1581
on a benchmark dataset and our real flight dataset	method	2K_dev_1581
a state estimation technique fuses both absolute state measurements ( GPS	purpose	2K_dev_1581
barometer ) and the relative state measurements ( IMU	purpose	2K_dev_1581
visual odometry ) for high-altitude MAV odometry calculation	purpose	2K_dev_1581
Autonomous robots often rely on models of their sensing and actions for intelligent decision making	background	2K_dev_1582
shows that this approach significantly enhances the detection power of existing RIM-detection algorithms in high-dimensional spaces	finding	2K_dev_1582
To find inaccuracies tractably	mechanism	2K_dev_1582
the robot conducts an informed search through low-dimensional projections of execution data to find parametric Regions of Inaccurate Modeling ( RIMs )	mechanism	2K_dev_1582
	mechanism	2K_dev_1582
Empirical evidence from two robot domains	method	2K_dev_1582
However	purpose	2K_dev_1582
when operating in unconstrained environments	purpose	2K_dev_1582
the complexity of the world makes it infeasible to create models that are accurate in every situation This article addresses the problem of using potentially large and high-dimensional sets of robot execution data to detect situations in which a robot model is inaccurate-that is	purpose	2K_dev_1582
detecting context-dependent model inaccuracies in a high-dimensional context space	purpose	2K_dev_1582
	purpose	2K_dev_1582
	background	2K_dev_1583
	finding	2K_dev_1583
	mechanism	2K_dev_1583
	method	2K_dev_1583
	purpose	2K_dev_1583
Quantifying differences or similarities in connectomes has been a challenge due to the immense complexity of global brain networks	background	2K_dev_1584
This novel approach opens a new door for probing the influence of pathological	background	2K_dev_1584
genetic	background	2K_dev_1584
social	background	2K_dev_1584
or environmental factors on the unique configuration of the human connectome	background	2K_dev_1584
we show that the local connectome fingerprint is highly specific to an individual	finding	2K_dev_1584
allowing for an accurate self-versus-others classification that achieved 100 % accuracy across 17398 identification tests The estimated classification error was approximately one thousand times smaller than fingerprints derived from diffusivity-based measures or region-to-region connectivity patterns for repeat scans acquired within 3 months The local connectome fingerprint also revealed neuroplasticity within an individual reflected as a decreasing trend in self-similarity across time	finding	2K_dev_1584
whereas this change was not observed in the diffusivity measures	finding	2K_dev_1584
Moreover	finding	2K_dev_1584
the local connectome fingerprint can be used as a phenotypic marker	finding	2K_dev_1584
revealing 12	finding	2K_dev_1584
51 % similarity between monozygotic twins	finding	2K_dev_1584
5	finding	2K_dev_1584
14 % between dizygotic twins	finding	2K_dev_1584
and 4	finding	2K_dev_1584
51 % between none-twin siblings	finding	2K_dev_1584
relative to differences between unrelated subjects	finding	2K_dev_1584
	finding	2K_dev_1584
Here we introduce a noninvasive method that uses diffusion MRI to characterize whole-brain white matter architecture as a single local connectome fingerprint	mechanism	2K_dev_1584
In four independently acquired data sets with repeated scans ( total N 0 213 )	method	2K_dev_1584
	method	2K_dev_1584
that allows for a direct comparison between structural connectomes	purpose	2K_dev_1584
	purpose	2K_dev_1584
Clinical decision support tools ( DSTs ) are computational systems that aid healthcare decision-making	background	2K_dev_1585
While effective in labs	background	2K_dev_1585
almost all these systems failed when they moved into clinical practice	background	2K_dev_1585
Healthcare researchers speculated it is most likely due to a lack of user-centered HCI considerations in the design of these systems These findings suggest an alternative perspective to the traditional use models	background	2K_dev_1585
in which clinicians engage with DSTs at the point of making a decision	background	2K_dev_1585
We identify situations across patients ' healthcare trajectories when decision supports would help	background	2K_dev_1585
and we discuss new forms it might take in these situations	background	2K_dev_1585
Our findings reveal a lack of perceived need for and trust of machine intelligence	finding	2K_dev_1585
as well as many barriers to computer use at the point of clinical decision-making	finding	2K_dev_1585
	mechanism	2K_dev_1585
a field study investigating how clinicians make a heart pump implant decision	method	2K_dev_1585
This paper describes with a focus on how to best integrate an intelligent DST into their work process	purpose	2K_dev_1585
	purpose	2K_dev_1585
Death by suicide demonstrates profound personal suffering and societal failure	background	2K_dev_1586
The results provide insight into how advanced technology can be used for suicide assessment and prevention	background	2K_dev_1586
	background	2K_dev_1586
By combining linguistic and acoustic characteristics	finding	2K_dev_1586
subjects could be classified into one of the three groups with up to 85 % accuracy	finding	2K_dev_1586
	finding	2K_dev_1586
In this novel prospective	mechanism	2K_dev_1586
multimodal	mechanism	2K_dev_1586
multicenter	mechanism	2K_dev_1586
mixed demographic study	mechanism	2K_dev_1586
we used machine learning	mechanism	2K_dev_1586
Machine learning algorithms were used with the subjects ' words and vocal characteristics to classify 379 subjects recruited from two academic medical centers and a rural community hospital into one of three groups : suicidal	method	2K_dev_1586
mentally ill but not suicidal	method	2K_dev_1586
or controls	method	2K_dev_1586
	method	2K_dev_1586
While basic sciences provide the opportunity to understand biological markers related to suicide	purpose	2K_dev_1586
computer science provides opportunities to understand suicide thought markers	purpose	2K_dev_1586
to measure and fuse two classes of suicidal thought markers : verbal and nonverbal	purpose	2K_dev_1586
	purpose	2K_dev_1586
How neural stem cells generate the correct number and type of differentiated neurons in appropriate places remains an important question Although nervous systems are diverse across phyla	background	2K_dev_1587
in many taxa the larva forms an anterior concentration of serotonergic neurons	background	2K_dev_1587
or apical organ	background	2K_dev_1587
which are observed in a great diversity of metazoans This work explains how spatial patterning in the ectoderm controls progression of neurogenesis in addition to providing spatial cues for neuron location	background	2K_dev_1587
	background	2K_dev_1587
We show that neurogenesis in sea star larvae begins with soxc-expressing multipotent progenitors	finding	2K_dev_1587
These give rise to restricted progenitors that express lhx2/9 soxc- and lhx2/9-expressing cells can undergo both asymmetric divisions	finding	2K_dev_1587
allowing for progression towards a particular neural fate	finding	2K_dev_1587
and symmetric proliferative divisions We show that nested concentric domains of gene expression along the anterior-posterior ( AP ) axis	finding	2K_dev_1587
	finding	2K_dev_1587
control neurogenesis in the sea star larva by promoting particular division modes and progression towards becoming a neuron	finding	2K_dev_1587
Modification to the sizes of these AP territories provides a simple mechanism to explain the diversity of neuron number among apical organs	finding	2K_dev_1587
	finding	2K_dev_1587
	mechanism	2K_dev_1587
	method	2K_dev_1587
The sea star embryo initially has a pan-neurogenic ectoderm	purpose	2K_dev_1587
but the genetic mechanism that directs a subset of these cells to generate serotonergic neurons in a particular location is unresolved	purpose	2K_dev_1587
	purpose	2K_dev_1587
A fundamental problem in comparative genomics is to compute the distance between two genomes in terms of its higher level organization ( given by genes or syntenic blocks )	background	2K_dev_1588
For two genomes without duplicate genes	background	2K_dev_1588
we can easily define ( and almost always efficiently compute ) a variety of distance measures	background	2K_dev_1588
Of the many distance measures	background	2K_dev_1588
the breakpoint distance ( the number of nonconserved adjacencies ) was the first one to be studied and remains of significant interest because of its simplicity and model-free property	background	2K_dev_1588
The three breakpoint distance problems corresponding to the three formulations have been widely studied Although we provided last year a solution for the exemplar problem that runs very fast on full genomes	background	2K_dev_1588
we show that our algorithms run very fast ( in seconds ) on mammalian genomes and scale well beyond	finding	2K_dev_1588
We find that our algorithm for the `` any matching '' formulation significantly outperforms other methods in terms of accuracy while achieving nearly maximum coverage	finding	2K_dev_1588
	finding	2K_dev_1588
three formulations ( exemplar	mechanism	2K_dev_1588
maximum matching	mechanism	2K_dev_1588
and any matching ) have been proposed	mechanism	2K_dev_1588
In this article	mechanism	2K_dev_1588
we describe very fast	mechanism	2K_dev_1588
exact algorithms for these two problems Our algorithms rely on a compact integer-linear program that we further simplify by developing an algorithm to remove variables	mechanism	2K_dev_1588
based on new results on the structure of adjacencies and matchings	mechanism	2K_dev_1588
	mechanism	2K_dev_1588
Through extensive experiments using both simulations and biological data sets	method	2K_dev_1588
We also apply these algorithms ( as well as the classic orthology tool MSOAR ) to create orthology assignment	method	2K_dev_1588
then compare their quality in terms of both accuracy and coverage	method	2K_dev_1588
but the problem is NP-hard under most models when genomes contain duplicate genes	purpose	2K_dev_1588
To tackle duplicate genes	purpose	2K_dev_1588
all of which aim to build a matching between homologous genes so as to minimize some distance measure	purpose	2K_dev_1588
	purpose	2K_dev_1588
computing optimal solutions for the other two problems has remained challenging	purpose	2K_dev_1588
	purpose	2K_dev_1588
Over 100 genetic loci harbor schizophrenia-associated variants	background	2K_dev_1589
and highlight the utility of this resource for mechanistic interpretations of genetic liability for brain diseases	background	2K_dev_1589
_20 % of schizophrenia loci have variants that could contribute to altered gene expression and liability In five loci	finding	2K_dev_1589
only a single gene was involved : FURIN	finding	2K_dev_1589
TSNARE1	finding	2K_dev_1589
CNTN4	finding	2K_dev_1589
CLCN3 or SNAP91	finding	2K_dev_1589
changed neurodevelopment in zebrafish ; yielded abnormal migration Of 693 genes showing significant case-versus-control differential expression	finding	2K_dev_1589
their fold changes were 1	finding	2K_dev_1589
33	finding	2K_dev_1589
and an independent cohort yielded similar results Gene co-expression implicates a network relevant for schizophrenia	finding	2K_dev_1589
Our findings show that schizophrenia is polygenic	finding	2K_dev_1589
The CommonMind Consortium sequenced RNA from dorsolateral prefrontal cortex of people with schizophrenia ( N 0 258 ) and control subjects ( N 0 279 )	mechanism	2K_dev_1589
creating	mechanism	2K_dev_1589
Using this resource Altering expression of FURIN	method	2K_dev_1589
TSNARE1 or CNTN4 knockdown of FURIN in human neural progenitor cells	method	2K_dev_1589
yet how these variants confer liability is uncertain	purpose	2K_dev_1589
a resource of gene expression and its genetic regulation	purpose	2K_dev_1589
Genome-wide association studies have discovered a large number of genetic variants associated with complex diseases such as Alzheimer 's disease	background	2K_dev_1590
However	background	2K_dev_1590
the genetic background of such diseases is largely unknown due to the complex mechanisms underlying genetic effects on traits	background	2K_dev_1590
as well as a small sample size ( e	background	2K_dev_1590
g	background	2K_dev_1590
	background	2K_dev_1590
1000 ) and a large number of genetic variants ( e	background	2K_dev_1590
g	background	2K_dev_1590
	background	2K_dev_1590
1 million )	background	2K_dev_1590
	background	2K_dev_1590
we demonstrate that BTAM significantly improves the statistical power over `` forward '' three-way association mapping that finds genotypes associated with both transcripts and phenotypes and genotype-phenotype association mapping	finding	2K_dev_1590
and report top 10 genotype-transcript-phenotype associations	finding	2K_dev_1590
	finding	2K_dev_1590
In this paper	mechanism	2K_dev_1590
we present a novel approach called `` Backward Three-way Association Mapping '' ( BTAM Assuming that genotypes affect transcript levels	mechanism	2K_dev_1590
which in turn affect phenotypes	mechanism	2K_dev_1590
we first find transcripts associated with the phenotypes	mechanism	2K_dev_1590
and then find genotypes associated with the chosen transcripts	mechanism	2K_dev_1590
The backward ordering of association mappings allows us to avoid a large number of association testings between all genotypes and all transcripts	mechanism	2K_dev_1590
making it possible	mechanism	2K_dev_1590
In our simulation study	method	2K_dev_1590
Furthermore	method	2K_dev_1590
we apply BTAM on an Alzheimer 's disease dataset	method	2K_dev_1590
Fortunately	purpose	2K_dev_1590
datasets that contain genotypes	purpose	2K_dev_1590
transcripts	purpose	2K_dev_1590
and phenotypes are becoming more readily available	purpose	2K_dev_1590
creating new opportunities for detecting disease-associated genetic variants ) for detecting three-way associations among genotypes	purpose	2K_dev_1590
transcripts	purpose	2K_dev_1590
and phenotypes	purpose	2K_dev_1590
to identify three-way associations with a small computational cost	purpose	2K_dev_1590
Stable chronic functionality of intracortical probes is of utmost importance toward realizing clinical application of brain-machine interfaces	background	2K_dev_1591
Sustained immune response from the brain tissue to the neural probes is one of the major challenges that hinder stable chronic functionality	background	2K_dev_1591
There is a growing body of evidence in the literature that highly compliant neural probes with sub-cellular dimensions may significantly reduce the foreign-body response	background	2K_dev_1591
thereby enhancing long term stability of intracortical recordings	background	2K_dev_1591
thereby showing promise toward chronic applications	background	2K_dev_1591
To demonstrate the versatility of the process to show the co-delivery potential of the needles	finding	2K_dev_1591
Insertion of the needles without mechanical failure	finding	2K_dev_1591
and their subsequent dissolution are demonstrated	finding	2K_dev_1591
It is concluded that ultra-miniature	finding	2K_dev_1591
ultra-compliant probes and associated biodissolvable delivery needles can be successfully fabricated	finding	2K_dev_1591
and the use of the ultra-compliant meandered probes results in drastic reduction in strains imposed in the tissue as compared to stiff probes	finding	2K_dev_1591
	finding	2K_dev_1591
In this paper	mechanism	2K_dev_1591
we present design	mechanism	2K_dev_1591
fabrication	mechanism	2K_dev_1591
and in vitro evaluation of ultra-miniature ( 2	mechanism	2K_dev_1591
7_m x 10_m cross section )	mechanism	2K_dev_1591
ultra-compliant ( 1	mechanism	2K_dev_1591
4___10 ( -2 ) _N/_m in the axial direction	mechanism	2K_dev_1591
and 2	mechanism	2K_dev_1591
6___10 ( -5 ) _N/_m and 1	mechanism	2K_dev_1591
8___10 ( -6 ) _N/_m in the lateral directions ) neural probes and associated probe-encasing biodissolvable delivery needles toward addressing the aforementioned challenges	mechanism	2K_dev_1591
The high compliance of the probes is obtained by micron-scale cross-section and meandered shape of the parylene-C insulated platinum wiring Finite-element analysis is performed to compare the strains within the tissue during micromotion when using the ultra-compliant meandered probes with that when using stiff silicon probes	mechanism	2K_dev_1591
The standard batch microfabrication techniques are used for creating the probes	mechanism	2K_dev_1591
A dissolvable delivery needle that encases the probe facilitates failure-free insertion and precise placement of the ultra-compliant probes Upon completion of implantation	mechanism	2K_dev_1591
the needle gradually dissolves	mechanism	2K_dev_1591
leaving behind the ultra-compliant neural probe A spin-casting based micromolding approach is used for the fabrication of the needle	mechanism	2K_dev_1591
An automated insertion device is developed for repeatable and precise implantation of needle-encased probes into brain tissue	mechanism	2K_dev_1591
	mechanism	2K_dev_1591
	method	2K_dev_1591
needles from different biodissolvable materials	method	2K_dev_1591
as well as two-dimensional needle arrays with different geometries and dimensions	method	2K_dev_1591
are fabricated	method	2K_dev_1591
Further	method	2K_dev_1591
needles incorporating anti-inflammatory drugs are created	method	2K_dev_1591
Since the prevailing commercial probes are considerably larger than neurons and of high stiffness	purpose	2K_dev_1591
new approaches are needed for developing miniature probes with high compliance	purpose	2K_dev_1591
	purpose	2K_dev_1591
Automated machine-reading biocuration systems typically use sentence-by-sentence information extraction to construct meaning representations for use by curators	background	2K_dev_1592
This does not directly reflect the typical discourse structure used by scientists to construct an argument from the experimental data available within a article	background	2K_dev_1592
and is therefore less likely to correspond to representations typically used in biomedical informatics systems ( let alone to the mental models that scientists have ) Although preliminary	background	2K_dev_1592
these results support the notion that targeting information extraction methods to experimental results could provide accurate	background	2K_dev_1592
automated methods for biocuration	background	2K_dev_1592
We also suggest the need for finer-grained curation of experimental methods used when constructing molecular biology databases	background	2K_dev_1592
	background	2K_dev_1592
to obtain baseline F1 scores of 0	finding	2K_dev_1592
59 for MINT	finding	2K_dev_1592
0	finding	2K_dev_1592
71 for INTACT and 0	finding	2K_dev_1592
63 for Pathway Logic	finding	2K_dev_1592
	finding	2K_dev_1592
In this study	mechanism	2K_dev_1592
we develop Natural Language Processing methods In our domain of interest ( molecular biology studies of cancer signal transduction pathways )	mechanism	2K_dev_1592
individual articles may contain as many as 30 small-scale individual experiments describing a variety of findings	mechanism	2K_dev_1592
upon which authors base their overall research conclusions	mechanism	2K_dev_1592
Our system automatically classifies discourse segments in these texts into seven categories ( fact	mechanism	2K_dev_1592
hypothesis	mechanism	2K_dev_1592
problem	mechanism	2K_dev_1592
goal	mechanism	2K_dev_1592
method	mechanism	2K_dev_1592
result	mechanism	2K_dev_1592
implication ) with an F-score of 0	mechanism	2K_dev_1592
68	mechanism	2K_dev_1592
These segments describe the essential building blocks of scientific discourse to ( i ) provide context for each experiment	mechanism	2K_dev_1592
( ii ) report experimental details and ( iii ) explain the data 's meaning in context	mechanism	2K_dev_1592
	mechanism	2K_dev_1592
We evaluate our system on text passages from articles that were curated in molecular biology databases ( the Pathway Logic Datum repository	method	2K_dev_1592
the Molecular Interaction MINT and INTACT databases ) linking individual experiments in articles to the type of assay used ( coprecipitation	method	2K_dev_1592
phosphorylation	method	2K_dev_1592
translocation etc	method	2K_dev_1592
)	method	2K_dev_1592
We use supervised machine learning techniques on text passages containing unambiguous references to experiments	method	2K_dev_1592
to locate	purpose	2K_dev_1592
extract	purpose	2K_dev_1592
and classify the individual passages of text from articles ' Results sections that refer to experimental data	purpose	2K_dev_1592
	purpose	2K_dev_1592
	background	2K_dev_1593
We show that the stable phase is the one with the lower defect line tension	finding	2K_dev_1593
The strong and opposite monolayer curvatures present in junctions and edges enhance the mole fraction of negatively curved lipids in junctions and deplete it in edges	finding	2K_dev_1593
This lipid sorting affects the two line tensions and in turn the relative stability of the two phases	finding	2K_dev_1593
It also leads to a subtle entropic barrier for the transition between junction and edge that is absent in uniform membranes	finding	2K_dev_1593
We use a combination of coarse-grained molecular dynamics simulations and theoretical modeling These junctions are localized defect lines in which three bilayers merge in such a way that each bilayer shares one monolayer with one of the other two bilayers	mechanism	2K_dev_1593
The resulting local morphology is non-lamellar	mechanism	2K_dev_1593
resembling the threefold symmetric defect lines in inverse hexagonal phases	mechanism	2K_dev_1593
but it regularly occurs during membrane fission and fusion events	mechanism	2K_dev_1593
We realize a system of junctions by setting up a honeycomb lattice	mechanism	2K_dev_1593
which in its primitive cell contains two hexagons and four three-line junctions	mechanism	2K_dev_1593
permitting us to study their stability as well as their line tension We specifically consider the effects of lipid composition and intrinsic curvature in binary mixtures	mechanism	2K_dev_1593
which contain a fraction of negatively curved lipids in a curvature-neutral background phase	mechanism	2K_dev_1593
Three-junction stability results from a competition between the junction and an open edge	mechanism	2K_dev_1593
which arises if one of the three bilayers detaches from the other two	mechanism	2K_dev_1593
	method	2K_dev_1593
to examine three-junctions in mixed lipid bilayer membranes	purpose	2K_dev_1593
	purpose	2K_dev_1593
	background	2K_dev_1594
	finding	2K_dev_1594
	mechanism	2K_dev_1594
	method	2K_dev_1594
	purpose	2K_dev_1594
The paradigm of evidence-based medicine dictates that clinical practice should reflect the shifting landscape of the peer-reviewed literature	background	2K_dev_1595
	finding	2K_dev_1595
	mechanism	2K_dev_1595
	method	2K_dev_1595
Here	purpose	2K_dev_1595
we examined the extent to which this premise is fulfilled as it pertains to the surgical resection of high-grade gliomas ( HGGs )	purpose	2K_dev_1595
	background	2K_dev_1596
	finding	2K_dev_1596
	mechanism	2K_dev_1596
	method	2K_dev_1596
	purpose	2K_dev_1596
Aneuploidy and structural variations ( SVs ) generate cancer genomes containing a mixture of rearranged genomic segments with extensive somatic copy number alterations	background	2K_dev_1597
We demonstrate the accuracy of Weaver findingsfrom Our approach provides a more complete assessment of the complex genomic architectures inherent to many cancer genomes	finding	2K_dev_1597
Here	mechanism	2K_dev_1597
we introduce Weaver	mechanism	2K_dev_1597
an algorithm Weaver uses a Markov random field to estimate joint probabilities of allele-specific copy numbers of SVs and their inter-connectivity based on paired-end whole-genome sequencing data	mechanism	2K_dev_1597
Weaver also predicts the timing of SVs relative to chromosome amplifications	mechanism	2K_dev_1597
	mechanism	2K_dev_1597
using simulations and whole-genome optical mapping	method	2K_dev_1597
We apply Weaver to generate allele-specific copy numbers ofSVs for MCF-7 and HeLa cell lines and identify recurrent SV patterns in 44 TCGA ovarian cancer whole-genome sequencing datasets	method	2K_dev_1597
	method	2K_dev_1597
However	purpose	2K_dev_1597
existing methods can identify either SVs or allele-specific copy number alterations but not both simultaneously	purpose	2K_dev_1597
which provides a limited view of cancer genome structure for the quantification and analysis of allele-specific copy numbers of SVs	purpose	2K_dev_1597
	purpose	2K_dev_1597
Wearable activity trackers have become a viable business opportunity	background	2K_dev_1598
Nevertheless	background	2K_dev_1598
research has raised concerns over their potentially detrimental effects on wellbeing	background	2K_dev_1598
For example	background	2K_dev_1598
a recent study found that while counting steps with a pedometer increased steps taken throughout the day	background	2K_dev_1598
at the same time it decreased the enjoyment people derived from walking	background	2K_dev_1598
This poses a serious threat to the incorporation of healthy routines into everyday life	background	2K_dev_1598
	background	2K_dev_1598
	finding	2K_dev_1598
	mechanism	2K_dev_1598
	method	2K_dev_1598
Most studies aim at proving the effectiveness of activity trackers	purpose	2K_dev_1598
In contrast	purpose	2K_dev_1598
a wellbeing-oriented perspective calls for a deeper understanding of how trackers create and mediate meaningful experiences in everyday life	purpose	2K_dev_1598
	purpose	2K_dev_1598
Advances in fluorescence in situ hybridization ( FISH ) make it feasible to detect multiple copy-number changes in hundreds of cells of solid tumors	background	2K_dev_1599
Studies using FISH	background	2K_dev_1599
sequencing	background	2K_dev_1599
and other technologies have revealed substantial intra-tumor heterogeneity	background	2K_dev_1599
The evolution of subclones in tumors may be modeled by phylogenies Tumors often harbor aneuploid or polyploid cell populations	background	2K_dev_1599
	background	2K_dev_1599
Tests on simulated data show improved accuracy of the ploidy-based approach relative to prior ploidyless methods Tests on real data further demonstrate novel insights these methods offer into tumor progression processes Trees for DCIS samples are significantly less complex than trees for paired IDC samples Consensus graphs show substantial divergence among most paired samples from both sets	finding	2K_dev_1599
Low consensus between DCIS and IDC trees may help explain the difficulty in finding biomarkers that predict which DCIS cases are at most risk to progress to IDC	finding	2K_dev_1599
The FISHtrees software is available at ftp : //ftp	finding	2K_dev_1599
ncbi	finding	2K_dev_1599
nih	finding	2K_dev_1599
gov/pub/FISHtrees	finding	2K_dev_1599
We present FISHtrees 3	mechanism	2K_dev_1599
which implements a ploidy-based tree building method based on mixed integer linear programming ( MILP ) The ploidy-based modeling in FISHtrees includes a new formulation of the problem of merging trees for changes of a single gene into trees modeling changes in multiple genes and the ploidy	mechanism	2K_dev_1599
When multiple samples are collected from each patient	mechanism	2K_dev_1599
varying over time or tumor regions	mechanism	2K_dev_1599
it is useful to evaluate similarities in tumor progression among the samples Therefore	mechanism	2K_dev_1599
we further implemented in FISHtrees 3 a new method to build consensus graphs for multiple samples	mechanism	2K_dev_1599
	mechanism	2K_dev_1599
We validate FISHtrees 3 on a simulated data and on FISH data from paired cases of cervical primary and metastatic tumors and on paired breast ductal carcinoma in situ ( DCIS ) and invasive ductal carcinoma ( IDC )	method	2K_dev_1599
Using a FISH probe to estimate changes in ploidy can guide the creation of trees that model changes in ploidy and individual gene copy-number variations	purpose	2K_dev_1599
	purpose	2K_dev_1599
The recent proliferation of cryptomarkets and the associated emergence of a sub-field of research on the anonymous web have outpaced the development of an ethical consensus regarding research methods and dissemination amongst scholars working in this unique online space	background	2K_dev_1600
The peculiar characteristics of cryptomarket research	background	2K_dev_1600
which often involves encryption	background	2K_dev_1600
illegal activity	background	2K_dev_1600
large-scale data collection	background	2K_dev_1600
and geographical separation from research participants	background	2K_dev_1600
challenge conventional ethical frameworks	background	2K_dev_1600
A further complicating factor for reaching ethical consensus is the confluence of scholars drawn from a variety of academic disciplines	background	2K_dev_1600
each with their own particular norms	background	2K_dev_1600
practices and perspectives	background	2K_dev_1600
	background	2K_dev_1600
	finding	2K_dev_1600
	mechanism	2K_dev_1600
	method	2K_dev_1600
This paper is intended to stimulate awareness and debate	purpose	2K_dev_1600
and to prompt further reflection amongst scholars studying these fascinating online phenomena	purpose	2K_dev_1600
The paper explores tensions and addresses some of the more prominent and pressing ethical questions	purpose	2K_dev_1600
including public vs	purpose	2K_dev_1600
private online spaces	purpose	2K_dev_1600
anonymity	purpose	2K_dev_1600
data sharing and ownership	purpose	2K_dev_1600
risks and threats to research subjects and researchers	purpose	2K_dev_1600
Also discussed is how best to balance the potential harms of cryptomarket research against benefits to the public	purpose	2K_dev_1600
	purpose	2K_dev_1600
Efforts to model how signaling and regulatory networks work in cells have largely either not considered spatial organization or have used compartmental models with minimal spatial resolution Fluorescence microscopy provides the ability to monitor the spatiotemporal distribution of many molecules during signaling events	background	2K_dev_1601
	background	2K_dev_1601
	finding	2K_dev_1601
Here we present and methods	mechanism	2K_dev_1601
evaluate	method	2K_dev_1601
but as of yet no methods have been described for large scale image analysis to learn a complex protein regulatory network	purpose	2K_dev_1601
for identifying how changes in concentration in one cell region influence concentration of other proteins in other regions	purpose	2K_dev_1601
	purpose	2K_dev_1601
Within the last 20 years	background	2K_dev_1602
there has been an increasing interest in the computer vision community in automated facial image analysis algorithms	background	2K_dev_1602
This has been driven by applications in animation	background	2K_dev_1602
market research	background	2K_dev_1602
autonomous-driving	background	2K_dev_1602
surveillance	background	2K_dev_1602
and facial editing among others	background	2K_dev_1602
To date	background	2K_dev_1602
there exist several commercial packages for specific facial image analysis tasks such as facial expression recognition	background	2K_dev_1602
facial attribute analysis or face tracking relatively unexplored problem in facial image analysis	background	2K_dev_1602
	background	2K_dev_1602
IF achieved state-of-the-art results for emotion expression and action unit detection in three databases	finding	2K_dev_1602
FERA	finding	2K_dev_1602
CK+ and RU-FACS ; measured audience reaction to a talk given by one of the authors ; and discovered synchrony for smiling in videos of parent-infant interaction IF is free of charge for academic use at http : //www	finding	2K_dev_1602
humansensing	finding	2K_dev_1602
cs	finding	2K_dev_1602
cmu	finding	2K_dev_1602
edu/intraface/	finding	2K_dev_1602
This paper presents IntraFace ( IF )	mechanism	2K_dev_1602
a publicly-available software package In addition	mechanism	2K_dev_1602
IFincludes a newly develop technique for unsupervised synchrony detection a	mechanism	2K_dev_1602
In tests	method	2K_dev_1602
However	purpose	2K_dev_1602
free and easy-to-use software that incorporates all these functionalities is unavailable	purpose	2K_dev_1602
for automated facial feature tracking	purpose	2K_dev_1602
head pose estimation	purpose	2K_dev_1602
facial attribute recognition	purpose	2K_dev_1602
and facial expression analysis from video	purpose	2K_dev_1602
to discover correlated facial behavior between two or more persons	purpose	2K_dev_1602
	purpose	2K_dev_1602
The generativity and complexity of human thought stem in large part from the ability to represent relations among concepts and form propositions	background	2K_dev_1603
the classifiers were able to reliably identify the thematic role of an object from its associated fMRI activation pattern	finding	2K_dev_1603
classifiers reliably identified the thematic roles in the data of a left-out participant ( mean accuracy_=_	finding	2K_dev_1603
66 )	finding	2K_dev_1603
indicating that the neural representations of thematic roles were common across individuals	finding	2K_dev_1603
	finding	2K_dev_1603
	mechanism	2K_dev_1603
Machine-learning classifiers were trained on functional magnetic resonance imaging ( fMRI ) data evoked by a set of short videos that conveyed agent-verb-patient propositions	method	2K_dev_1603
When tested on a held-out video Moreover	method	2K_dev_1603
when trained on one subset of the study participants	method	2K_dev_1603
	method	2K_dev_1603
The current study reveals how a given object such as rabbit is neurally encoded differently and identifiably depending on whether it is an agent ( `` the rabbit punches the monkey '' ) or a patient ( `` the monkey punches the rabbit '' )	purpose	2K_dev_1603
	purpose	2K_dev_1603
Despite the widespread popularity of genome-wide association studies ( GWAS ) for genetic mapping of complex traits	background	2K_dev_1604
	background	2K_dev_1604
	finding	2K_dev_1604
In this work	mechanism	2K_dev_1604
we propose a new method that considers dynamic phenotypes measured at a sequence of time points	mechanism	2K_dev_1604
Our approach relies on the use of Time-Varying Group Sparse Additive Models ( TV-GroupSpAM ) for high-dimensional	mechanism	2K_dev_1604
functional regression	mechanism	2K_dev_1604
	mechanism	2K_dev_1604
	method	2K_dev_1604
most existing GWAS methodologies are still limited to the use of static phenotypes measured at a single time point	purpose	2K_dev_1604
for association mapping	purpose	2K_dev_1604
Because no assumptions are required about illumination or surface properties	background	2K_dev_1605
the method can be applied to a wide range of imaging conditions that include 2D video and uncalibrated multi-view video	background	2K_dev_1605
The software is available online at http : //zface	background	2K_dev_1605
org	background	2K_dev_1605
The method has been validated Experimental findings strongly support the validity of real-time	finding	2K_dev_1605
3D registration and reconstruction from 2D video	finding	2K_dev_1605
	finding	2K_dev_1605
we developed a 3D cascade regression approach in which facial landmarks remain invariant across pose over a range of approximately 60 degrees	mechanism	2K_dev_1605
From a single 2D image of a person 's face	mechanism	2K_dev_1605
a dense 3D shape is registered in real time for each frame	mechanism	2K_dev_1605
The algorithm utilizes a fast cascade regression framework trained on high-resolution 3D face-scans of posed and spontaneous emotion expression	mechanism	2K_dev_1605
The algorithm first estimates the location of a dense set of markers and their visibility	mechanism	2K_dev_1605
then reconstructs face shapes by fitting a part-based 3D model	mechanism	2K_dev_1605
	mechanism	2K_dev_1605
in a battery of experiments that evaluate its precision of 3D reconstruction and extension to multi-view reconstruction	method	2K_dev_1605
To enable real-time	purpose	2K_dev_1605
person-independent 3D registration from 2D video	purpose	2K_dev_1605
	purpose	2K_dev_1605
The environment of a living cell is vastly different from that of an in vitro reaction system	background	2K_dev_1606
an issue that presents great challenges to the use of in vitro models	background	2K_dev_1606
or computer simulations based on them	background	2K_dev_1606
for understanding biochemistry in vivo Virus capsids make an excellent model system for such questions because they typically have few distinct components	background	2K_dev_1606
making them amenable to in vitro and modeling studies	background	2K_dev_1606
yet their assembly can involve complex networks of possible reactions that can not be resolved in detail by any current experimental technology	background	2K_dev_1606
We previously fit kinetic simulation parameters to bulk in vitro assembly data to yield a close match between simulated and real data	background	2K_dev_1606
and then used the simulations to study features of assembly that can not be monitored experimentally	background	2K_dev_1606
The work demonstrates how computer simulations can help us understand how assembly might differ between the in vitro and in vivo environments and what features of the cellular environment account for these differences	background	2K_dev_1606
	background	2K_dev_1606
The resulting simulations exhibit surprising behavioral complexity	finding	2K_dev_1606
with distinct effects often acting synergistically to drive efficient assembly and alter pathways relative to the in vitro model	finding	2K_dev_1606
	finding	2K_dev_1606
computationally adding features of the cellular environment to the system	mechanism	2K_dev_1606
specifically the presence of nucleic acid about which many capsids assemble	mechanism	2K_dev_1606
The major challenge of such work is computational : simulating fine-scale assembly pathways on the scale and in the parameter domains of real viruses is far too computationally costly to allow for explicit models of nucleic acid interaction	mechanism	2K_dev_1606
We bypass that limitation by applying analytical models of nucleic acid effects to adjust kinetic rate parameters learned from in vitro data to see how these adjustments	mechanism	2K_dev_1606
singly or in combination	mechanism	2K_dev_1606
might affect fine-scale assembly progress	mechanism	2K_dev_1606
	method	2K_dev_1606
The present work seeks to project how assembly in these simulations fit to in vitro data would be altered by	purpose	2K_dev_1606
Establishing quantitative bounds on the execution cost of programs is essential in many areas of computer science such as complexity analysis	background	2K_dev_1607
compiler optimizations	background	2K_dev_1607
security and privacy	background	2K_dev_1607
Techniques based on program analysis	background	2K_dev_1607
type systems and abstract interpretation are well-studied	background	2K_dev_1607
	background	2K_dev_1607
We prove our type system sound We demonstrate the precision and generality of our technique	finding	2K_dev_1607
In this work	mechanism	2K_dev_1607
we propose a relational cost analysis technique by making use of relational properties of programs and inputs	mechanism	2K_dev_1607
We develop Rel Cost	mechanism	2K_dev_1607
a refinement type and effect system The key novelty of our technique is the combination of relational refinements with two modes of typing-relational typing for reasoning about similar computations/inputs and unary typing for reasoning about unrelated computations/inputs	mechanism	2K_dev_1607
This combination allows us to analyze the execution cost difference of two programs more precisely than a naive non-relational approach	mechanism	2K_dev_1607
	mechanism	2K_dev_1607
using a semantic model based on step-indexed unary and binary logical relations accounting for non-relational and relational reasoning principles with their respective costs	method	2K_dev_1607
through examples	method	2K_dev_1607
but methods for analyzing how the execution costs of two programs compare to each other have not received attention	purpose	2K_dev_1607
Naively combining the worst and best case execution costs of the two programs does not work well in many cases because such analysis forgets the similarities between the programs or the inputs	purpose	2K_dev_1607
that is capable of establishing precise bounds on the difference in the execution cost of two programs for a higher-order functional language with recursion and subtyping	purpose	2K_dev_1607
	purpose	2K_dev_1607
During human-robot collaboration	background	2K_dev_1608
a robot and a user must often complete a disjoint set of tasks that use an overlapping set of objects	background	2K_dev_1608
without using the same object simultaneously	background	2K_dev_1608
A key challenge is deciding what task the robot should perform next in order to facilitate fluent and efficient collaboration	background	2K_dev_1608
Most prior work does so by first predicting the human 's intended goal	background	2K_dev_1608
and then selecting actions given that goal	background	2K_dev_1608
However	background	2K_dev_1608
it is often difficult	background	2K_dev_1608
and sometimes impossible	background	2K_dev_1608
to infer the human 's exact goal in real time	background	2K_dev_1608
and this serial predict-then-act method is not adaptive to changes in human goals	background	2K_dev_1608
	background	2K_dev_1608
show that our POMDP model outperforms state of the art predict-then-act models by producing fewer human-robot collisions and less human idling time	finding	2K_dev_1608
	finding	2K_dev_1608
In this paper	mechanism	2K_dev_1608
we present a system We extend recent work utilizing Partially Observable Markov Decision Processes ( POMDPs ) for shared autonomy in order	mechanism	2K_dev_1608
We evaluate our system in a study with 28 participants	method	2K_dev_1608
and	method	2K_dev_1608
Our human-robot collaboration research aims to improve the fluency and efficiency of interactions between humans and robots when executing a set of tasks in a shared workspace	purpose	2K_dev_1608
for inferring a probability distribution over human goals	purpose	2K_dev_1608
and producing assistance actions given that distribution in real time	purpose	2K_dev_1608
The aim is to minimize the disruption caused by the nature of human-robot shared workspace	purpose	2K_dev_1608
to provide assistance without knowing the exact goal	purpose	2K_dev_1608
	purpose	2K_dev_1608
	background	2K_dev_1609
demonstrate successful data association results	finding	2K_dev_1609
We provide a novel incremental data association method to complement our previous work on acoustic structure from motion ( ASFM ) Given point features extracted from multiple overlapping sonar images	mechanism	2K_dev_1609
our algorithm automatically finds the correspondences between the features	mechanism	2K_dev_1609
Our data association method uses information about the geometric correlations of the entire set of landmarks to reject spurious measurements or 0 positives that might otherwise have been accepted For each new sonar measurement	mechanism	2K_dev_1609
the algorithm uses a gating procedure to narrow the landmark match search space	mechanism	2K_dev_1609
Using the pruned surviving candidate correspondences	mechanism	2K_dev_1609
we identify the correct hypothesis based on a posterior compatibility cost	mechanism	2K_dev_1609
penalizing for null matches to avoid all measurements being declared new landmarks Unlike other methods	mechanism	2K_dev_1609
ASFM does not require any planar scene assumptions and uses constraints from more than two images to increase accuracy in both mapping and localization	mechanism	2K_dev_1609
	mechanism	2K_dev_1609
We evaluate our algorithm in simulation and on real sonar images	method	2K_dev_1609
	method	2K_dev_1609
	purpose	2K_dev_1609
which recovers 3D scene structure from multiple 2D sonar images	purpose	2K_dev_1609
while at the same time localizing the sonar	purpose	2K_dev_1609
	purpose	2K_dev_1609
	background	2K_dev_1610
showing significantly longer flight distances over the current state of the art	finding	2K_dev_1610
	finding	2K_dev_1610
This paper demonstrates a method capable with a final position error of 27 m	mechanism	2K_dev_1610
0	mechanism	2K_dev_1610
012\ % of the distance traveled Our technique efficiently captures the full state dynamics of the air vehicle with semi-intermittent global corrections using LIDAR measurements matched against an a priori Digital Elevation Model ( DEM )	mechanism	2K_dev_1610
Using an error-state Kalman filter with IMU bias estimation	mechanism	2K_dev_1610
we are able to maintain a high-certainty state estimate	mechanism	2K_dev_1610
reducing the computation time to search over a global elevation map A sub region of the DEM is scanned with the latest LIDAR projection providing a correlation map of landscape symmetry	mechanism	2K_dev_1610
The optimal position is extracted from the correlation map to produce a position correction that is applied to the state estimate in the filter	mechanism	2K_dev_1610
This method provides a GPS-denied state estimate for long range drift-free navigation	mechanism	2K_dev_1610
We demonstrate this method on two flight data sets from a full-sized helicopter	method	2K_dev_1610
	method	2K_dev_1610
Despite significant progress in GPS-denied autonomous flight	purpose	2K_dev_1610
long-distance traversals ( > 100 km ) in the absence of GPS remain elusive	purpose	2K_dev_1610
of accurately estimating the aircraft state over a 218 km flight	purpose	2K_dev_1610
As robots aspire for long-term autonomous operations in complex dynamic environments	background	2K_dev_1611
the ability to reliably take mission-critical decisions in ambiguous situations becomes critical	background	2K_dev_1611
	finding	2K_dev_1611
and show that it effectively handles uncertain situations	finding	2K_dev_1611
	finding	2K_dev_1611
propose a generic framework	mechanism	2K_dev_1611
We present this in the context of vision-based autonomous MAV flight in outdoor natural environments	method	2K_dev_1611
This motivates the need to build systems that have situational awareness to assess how qualified they are at that moment to make a decision	purpose	2K_dev_1611
We call this self-evaluating capability as introspection In this paper	purpose	2K_dev_1611
we take a small step in this direction and for introspective behavior in perception systems	purpose	2K_dev_1611
Our goal is to learn a model to reliably predict failures in a given system	purpose	2K_dev_1611
with respect to a task	purpose	2K_dev_1611
directly from input sensor data	purpose	2K_dev_1611
	purpose	2K_dev_1611
The design of legged robots is often inspired by animals evolved to excel at different tasks	background	2K_dev_1612
However	background	2K_dev_1612
while mimicking morphological features seen in nature can be very powerful	background	2K_dev_1612
robots may need to perform motor tasks that their living counterparts do not	background	2K_dev_1612
In the absence of designs that can be mimicked	background	2K_dev_1612
an alternative is to resort to mathematical models that allow the relationship between a robot 's form and function to be explored	background	2K_dev_1612
	background	2K_dev_1612
Our model was successfully used to find optimized designs for legged robots performing tasks that include jumping	finding	2K_dev_1612
walking	finding	2K_dev_1612
and climbing up a step	finding	2K_dev_1612
Although our results are preliminary and our analysis makes a number of simplifying assumptions	finding	2K_dev_1612
our findings indicate that the cost function	finding	2K_dev_1612
the sum of squared joint torques over the duration of a task	finding	2K_dev_1612
varies substantially as the design parameters change	finding	2K_dev_1612
In this paper	mechanism	2K_dev_1612
we propose such a model such that a measure of performance is optimized The framework begins by planning trajectories for a simplified model consisting of the center of mass and feet	mechanism	2K_dev_1612
The framework then optimizes the length of each leg link while solving for associated full-body motions	mechanism	2K_dev_1612
	method	2K_dev_1612
to co-design the motion and leg configurations of a robot	purpose	2K_dev_1612
	background	2K_dev_1613
	finding	2K_dev_1613
We use the Bayes tree factorization thereby minimizing computation We use kernel density estimation which naturally encapsulates multi-hypothesis and non-Gaussian inference	mechanism	2K_dev_1613
A variety of new uncertainty models can now be directly applied in the factor graph	mechanism	2K_dev_1613
and have the solver recover a potentially multi modal posterior	mechanism	2K_dev_1613
For example	mechanism	2K_dev_1613
data association for loop closure proposals can be incorporated at inference time without further modifications to the factor graph	mechanism	2K_dev_1613
Our implementation of the presented algorithm is written entirely in the Julia language	mechanism	2K_dev_1613
exploiting high performance parallel computing	mechanism	2K_dev_1613
	mechanism	2K_dev_1613
We show a larger scale use case with the well known Victoria park mapping and localization data set inferring over uncertain loop closures	method	2K_dev_1613
	method	2K_dev_1613
We relax parametric inference to a non parametric representation towards more general solutions on factor graphs	purpose	2K_dev_1613
to maximally exploit structure in the joint posterior to represent a wider class of constraint beliefs	purpose	2K_dev_1613
This is the first amortized analysis	background	2K_dev_1614
that automatically derives polynomial bounds for higher-order functions and polynomial bounds that depend on user-defined inductive types	background	2K_dev_1614
	background	2K_dev_1614
The practicality of the analysis system is the system infers bounds on the number of queries that are sent by OCaml programs to DynamoDB	finding	2K_dev_1614
a commercial NoSQL cloud database service	finding	2K_dev_1614
	finding	2K_dev_1614
The system automatically derives worst-case resource bounds for higher-order polymorphic programs with user-defined inductive types	mechanism	2K_dev_1614
The technique is parametric in the resource and can derive bounds for time	mechanism	2K_dev_1614
memory allocations and energy usage The derived bounds are multivariate resource polynomials which are functions of different size parameters that depend on the standard OCaml types	mechanism	2K_dev_1614
Bound inference is fully automatic and reduced to a linear optimization problem that is passed to an off-the-shelf LP solver Technically	mechanism	2K_dev_1614
the analysis system is based on a novel multivariate automatic amortized resource analysis ( AARA ) It builds on existing work on linear AARA for higher-order programs with user-defined inductive types and on multivariate AARA for first-order programs with built-in lists and binary trees Moreover	mechanism	2K_dev_1614
the analysis handles a limited form of side effects and even outperforms the linear bound inference of previous systems At the same time	mechanism	2K_dev_1614
it preserves the expressivity and efficiency of existing AARA techniques	mechanism	2K_dev_1614
demonstrated with an implementation and integration with Inria 's OCaml compiler The implementation is used to automatically derive resource bounds for 411 functions and 6018 lines of code derived from OCaml libraries	method	2K_dev_1614
the CompCert compiler	method	2K_dev_1614
and implementations of textbook algorithms	method	2K_dev_1614
In a case study	method	2K_dev_1614
	method	2K_dev_1614
This article presents a resource analysis system for OCaml programs	purpose	2K_dev_1614
	purpose	2K_dev_1614
For robots with several degrees of freedom	background	2K_dev_1615
collision checks are computationally expensive and often dominate planning time	background	2K_dev_1615
	background	2K_dev_1615
demonstrate that POMP performs comparably with RRTConnect and LazyPRM for the first feasible path	finding	2K_dev_1615
and BIT { * } for anytime performance	finding	2K_dev_1615
both in terms of collision checks and total planning time	finding	2K_dev_1615
We present POMP ( Pareto Optimal Motion Planner )	mechanism	2K_dev_1615
an anytime algorithm We assume that the roadmaps we search over are embedded in a continuous ambient space	mechanism	2K_dev_1615
where nearby points tend to share the same collision state	mechanism	2K_dev_1615
This enables us to formulate a probabilistic model that computes the probability of unevaluated configurations being collision-free	mechanism	2K_dev_1615
We update the model over time as more checks are performed This model lets us define a weighting function for roadmap edges that is related to the probability of the edge being in collision Our approach is to trade off between these two weights	mechanism	2K_dev_1615
gradually prioritizing edge length over collision likelihood	mechanism	2K_dev_1615
We also show that this tradeoff is approximately equivalent to minimizing the expected path length	mechanism	2K_dev_1615
with a penalty of being in collision	mechanism	2K_dev_1615
	mechanism	2K_dev_1615
Our experiments	method	2K_dev_1615
for geometric path planning on roadmaps Our goal is to minimize the number of collision checks for obtaining the first feasible path and successively shorter feasible paths	purpose	2K_dev_1615
	background	2K_dev_1616
results obtained	finding	2K_dev_1616
We propose a submap-based technique Our approach relies on the use of probabilistic volumetric techniques to create submaps from multibeam sonar scans	mechanism	2K_dev_1616
as these offer increased outlier robustness	mechanism	2K_dev_1616
Special attention is paid to the problem of denoising/enhancing sonar data	mechanism	2K_dev_1616
Pairwise submap alignment constraints are used in a factor graph framework to correct for navigation drift and improve map accuracy	mechanism	2K_dev_1616
	mechanism	2K_dev_1616
We provide experimental from the inspection of the running gear and bulbous bow of a 600-foot	method	2K_dev_1616
Wright-class supply ship	method	2K_dev_1616
	method	2K_dev_1616
for mapping of underwater structures with complex geometries	purpose	2K_dev_1616
Inertial reorientation of airborne articulated bodies has been an active area of research in the robotics community	background	2K_dev_1617
as this behavior can help guide dynamic robots to a safe landing with minimal damage	background	2K_dev_1617
show that the DiverBot can execute one somersault without drift and multiple somersaults with minimal drift	finding	2K_dev_1617
	finding	2K_dev_1617
To this end	mechanism	2K_dev_1617
a planar three link robot	mechanism	2K_dev_1617
called DiverBot	mechanism	2K_dev_1617
is proposed By considering a gravity-free scenario	mechanism	2K_dev_1617
a local connection is obtained between joint angles and the body orientation	mechanism	2K_dev_1617
resulting in a reduction in the system dynamics	mechanism	2K_dev_1617
An optimal control policy applied on this reduced configuration space yielded diving maneuvers that are dynamically feasible	mechanism	2K_dev_1617
	mechanism	2K_dev_1617
Numerical results	method	2K_dev_1617
The main objective of this work is emulating the aggressive and large angle correction maneuvers	purpose	2K_dev_1617
like somersaults	purpose	2K_dev_1617
that are performed by human divers	purpose	2K_dev_1617
	purpose	2K_dev_1617
The challenge here is to have a signal and detection system that works from long range ( > 1000m ) amongst ground clutter during various seasonal conditions on passive imagery	background	2K_dev_1618
	background	2K_dev_1618
outperforms commonly used feature descriptors	finding	2K_dev_1618
Our system was capable of detecting the smoke cloud with both precision and recall rates greater than 0	finding	2K_dev_1618
95 from ranges between 1000m and 1500m	finding	2K_dev_1618
	finding	2K_dev_1618
We present a long-range visual signal detection system We use a smoke-grenade as a ground signal	mechanism	2K_dev_1618
which has the advantageous properties of being easy to carry by ground crews because of its light weight and small size	mechanism	2K_dev_1618
but when released has a long visual signaling range	mechanism	2K_dev_1618
We employ a camera system on the UAV with a visual texture feature extraction approach in a machine learning framework to classify image patches as `signal ' or `background '	mechanism	2K_dev_1618
We study conventional approaches and develop a visual feature descriptor that can better differentiate the appearance of the visual signal under varying conditions and	mechanism	2K_dev_1618
when used to train a random-forest classifier	mechanism	2K_dev_1618
Further	mechanism	2K_dev_1618
we develop a method by assessing the shape of the smoke signal	mechanism	2K_dev_1618
The system was rigorously and quantitatively evaluated on data collected from a camera mounted on a helicopter and flown towards a plume of signal smoke over a variety of seasons	method	2K_dev_1618
ground conditions	method	2K_dev_1618
weather conditions	method	2K_dev_1618
and environments We present a preliminary evaluation of the wind estimation in conditions with different wind intensities and orientations relative to the approach direction	method	2K_dev_1618
	method	2K_dev_1618
that is suitable for an unmanned aerial vehicle to find an optical signal released at a desired landing site for the purposes of cargo delivery or rescue situations where radio signals or other communication systems are not available or the wind conditions at the landing site need to be signaled	purpose	2K_dev_1618
to estimate wind orientation and approximate wind strength	purpose	2K_dev_1618
In a hierarchical motion planning system for urban autonomous driving	background	2K_dev_1619
it is a common practice to separate tactical reasoning from the lower-level trajectory planning	background	2K_dev_1619
	background	2K_dev_1619
The results demonstrate enhanced planning feasibility	finding	2K_dev_1619
coherency and scalability	finding	2K_dev_1619
We therefore propose a planning method that automatically discovers tactical maneuver patterns	mechanism	2K_dev_1619
and fuses pattern reasoning and sampling-based trajectory planning	mechanism	2K_dev_1619
	mechanism	2K_dev_1619
	method	2K_dev_1619
This separation makes it difficult to achieve robust maneuver-based tactical reasoning	purpose	2K_dev_1619
which is intrinsically linked to trajectory planning	purpose	2K_dev_1619
	purpose	2K_dev_1619
	background	2K_dev_1620
We validate the performance of the proposed approach	finding	2K_dev_1620
We extend the existing assignment and planning approaches for quadrotor teams to find minimal-time trajectories to enable team transition between non-rest initial and ending states while ensuring dynamic feasibility with respect to predefined kinematic	mechanism	2K_dev_1620
dynamic	mechanism	2K_dev_1620
and collision constraints This work also presents a method for safe splitting and merging of robot formations according to input specification	mechanism	2K_dev_1620
The proposed methodology is capable of generating dynamically feasible and safe plans for teams of quadrotors in real time	mechanism	2K_dev_1620
	mechanism	2K_dev_1620
through various trials and scenarios conducted in simulation	method	2K_dev_1620
We consider the problem of generating dynamically feasible and safe plans for teams of aerial robots ( quadrotors ) while holding a fixed relative formation as well as transitioning between a sequence of formations	purpose	2K_dev_1620
	purpose	2K_dev_1620
In many multi-robot applications such as target search	background	2K_dev_1621
environmental monitoring and reconnaissance	background	2K_dev_1621
the multi-robot system operates semi-autonomously	background	2K_dev_1621
but under the supervision of a remote human who monitors task progress	background	2K_dev_1621
In these applications	background	2K_dev_1621
each robot collects a large amount of task-specific data that must be sent to the human periodically to keep the human aware of task progress It is often the case that the human-robot communication links are extremely bandwidth constrained and/or have significantly higher latency than inter-robot communication links	background	2K_dev_1621
so it is impossible for all robots to send their task-specific data together Thus	background	2K_dev_1621
only a subset of robots	background	2K_dev_1621
which we call the knowledge leaders	background	2K_dev_1621
can send their data at a time	background	2K_dev_1621
	background	2K_dev_1621
We prove that the knowledge leader selection is a submodular function maximization problem under explicit conditions The effectiveness of our approach is demonstrated	finding	2K_dev_1621
and present a novel distributed submodular optimization algorithm that has the same approximation guarantees as the centralized greedy algorithm	mechanism	2K_dev_1621
	mechanism	2K_dev_1621
using numerical simulations	method	2K_dev_1621
In this paper	purpose	2K_dev_1621
we study the knowledge leader selection problem	purpose	2K_dev_1621
where the goal is to select a subset of robots with a given cardinality that transmits the most informative task-specific data for the human	purpose	2K_dev_1621
Formal constructive type theory has proved to be an effective language for mechanized proof	background	2K_dev_1622
By avoiding non-constructive principles	background	2K_dev_1622
such as the law of the excluded middle	background	2K_dev_1622
type theory admits sharper proofs and broader interpretations of results	background	2K_dev_1622
From a computer science perspective	background	2K_dev_1622
interest in type theory arises from its applications to programming languages	background	2K_dev_1622
Standard constructive type theories used in mechanization admit computational interpretations based on meta-mathematical normalization theorems	background	2K_dev_1622
These proofs are notoriously brittle ; any change to the theory potentially invalidates its computational meaning	background	2K_dev_1622
As a case in point	background	2K_dev_1622
Voevodsky 's univalence axiom raises questions about the computational meaning of proofs	background	2K_dev_1622
	background	2K_dev_1622
The main result is a canonicity theorem stating that closed programs of boolean type evaluate to 1 or 0	finding	2K_dev_1622
	finding	2K_dev_1622
by providing a direct	mechanism	2K_dev_1622
deterministic operational interpretation for a representative higher-dimensional dependent type theory with higher inductive types and an instance of univalence	mechanism	2K_dev_1622
Rather than being a formal type theory defined by rules	mechanism	2K_dev_1622
it is instead a computational type theory in the sense of Martin-Lof 's meaning explanations and of the NuPRL semantics	mechanism	2K_dev_1622
The definition of the type theory starts with programs ; types are specifications of program behavior	mechanism	2K_dev_1622
	method	2K_dev_1622
We consider the question : Can higher-dimensional type theory be construed as a programming language ? We answer this question affirmatively	purpose	2K_dev_1622
	background	2K_dev_1623
	finding	2K_dev_1623
	mechanism	2K_dev_1623
	method	2K_dev_1623
	purpose	2K_dev_1623
Planning in CPSs requires temporal reasoning to handle the dynamics of the environment	background	2K_dev_1624
including human behavior	background	2K_dev_1624
as well as temporal constraints on system goals and durations of actions that systems and human actors may take	background	2K_dev_1624
The discrete abstraction of time in a state space planning should have a time sampling parameter value that satisfies some relation to achieve a certain precision	background	2K_dev_1624
In particular	background	2K_dev_1624
the sampling period should be small enough to allow the dynamics of the problem domain to be modeled with sufficient precision	background	2K_dev_1624
Meanwhile	background	2K_dev_1624
in many cases	background	2K_dev_1624
events in the far future ( relative to the sampling period ) may be relevant to the decision making earlier in the planning timeline ; therefore	background	2K_dev_1624
a longer planning look-ahead horizon can yield a closer-to optimal plan	background	2K_dev_1624
We illustrate our approach	finding	2K_dev_1624
In this paper	mechanism	2K_dev_1624
we propose a multiscale temporal planning approach formulated as MDP planning	mechanism	2K_dev_1624
in a middleware used to monitor large sensor networks	method	2K_dev_1624
	method	2K_dev_1624
Unfortunately	purpose	2K_dev_1624
planning with a uniform fine-grained discrete abstraction of time and a long look-ahead horizon is typically computationally infeasible	purpose	2K_dev_1624
to preserve the required time fidelity of the problem domain and at the same time approximate a globally optimal plan	purpose	2K_dev_1624
	purpose	2K_dev_1624
Modern frameworks are required to be extendable as well as secure	background	2K_dev_1625
	background	2K_dev_1625
	finding	2K_dev_1625
In this poster we describe an approach that uses a combination of static analysis and run-time management	mechanism	2K_dev_1625
based on software architecture models	mechanism	2K_dev_1625
Static analysis identifies the architecture and communication patterns among the collection of apps on an Android device and which communications might be vulnerable to attack	mechanism	2K_dev_1625
Run-time mechanisms monitor these potentially vulnerable communication patterns	mechanism	2K_dev_1625
and adapt the system to either deny them	mechanism	2K_dev_1625
request explicit approval from the user	mechanism	2K_dev_1625
or allow then	mechanism	2K_dev_1625
	mechanism	2K_dev_1625
We implement a prototype of the approach for the Android platform	method	2K_dev_1625
	method	2K_dev_1625
However	purpose	2K_dev_1625
these two qualities are often at odds	purpose	2K_dev_1625
that can improve security while maintaining framework extendability	purpose	2K_dev_1625
	purpose	2K_dev_1625
The Android platform is designed to support mutually un-trusted third-party apps	background	2K_dev_1626
which run as isolated processes but may interact via platform-controlled mechanisms	background	2K_dev_1626
called Intents	background	2K_dev_1626
Interactions among third-party apps are intended and can contribute to a rich user experience	background	2K_dev_1626
for example	background	2K_dev_1626
the ability to share pictures from one app with another	background	2K_dev_1626
The Android platform presents an interesting point in a design space of module systems that is biased toward isolation	background	2K_dev_1626
extensibility	background	2K_dev_1626
and untrusted contributions	background	2K_dev_1626
The Intent mechanism essentially provides message channels among modules	background	2K_dev_1626
in which the set of message types is extensible However	background	2K_dev_1626
the module system has design limitations including the lack of consistent mechanisms to document message types	background	2K_dev_1626
very limited checking that a message conforms to its specifications	background	2K_dev_1626
the inability to explicitly declare dependencies on other modules	background	2K_dev_1626
and the lack of checks for backward compatibility as message types evolve over time	background	2K_dev_1626
Based on our results	background	2K_dev_1626
we outline further research questions and propose possible mitigation strategies	background	2K_dev_1626
	background	2K_dev_1626
Our findings suggest that design limitations do indeed cause development problems	finding	2K_dev_1626
	finding	2K_dev_1626
	mechanism	2K_dev_1626
we studied a broad corpus of apps and cross-validated our results against app documentation and Android support forums	method	2K_dev_1626
	method	2K_dev_1626
In order to understand the degree to which these design limitations result in real issues	purpose	2K_dev_1626
	purpose	2K_dev_1626
Many have argued that the current try/catch mechanism for handling exceptions in Java is flawed	background	2K_dev_1627
Some of these issues might be addressed by future tools which autocomplete more complete handlers	background	2K_dev_1627
	background	2K_dev_1627
We found that programmers handle exceptions locally in catch blocks much of the time	finding	2K_dev_1627
rather than propagating by throwing an Exception	finding	2K_dev_1627
Programmers make heavy use of actions like Log	finding	2K_dev_1627
Print	finding	2K_dev_1627
Return	finding	2K_dev_1627
or Throw in catch blocks	finding	2K_dev_1627
and also frequently copy code between handlers We found bad practices like empty catch blocks or catching Exception are indeed widespread	finding	2K_dev_1627
We discuss evidence that programmers may misjudge risk when catching Exception	finding	2K_dev_1627
and face a tension between handlers that directly address local program statement failure and handlers that consider the program-wide implications of an exception	finding	2K_dev_1627
	mechanism	2K_dev_1627
We used the Boa tool	method	2K_dev_1627
A major complaint is that programmers often write minimal and low quality handlers	purpose	2K_dev_1627
to examine a large number of Java projects on GitHub to provide empirical evidence about how programmers currently deal with exceptions	purpose	2K_dev_1627
	purpose	2K_dev_1627
The theorems are not specific to sequences and can be applied to other data types with different costs for operating on interior and leaf versions	background	2K_dev_1628
	background	2K_dev_1628
The key advantages of the present approach compared to current approaches is that our implementation requires no changes to existing programming languages	finding	2K_dev_1628
supports nested parallelism	finding	2K_dev_1628
and has well defined cost semantics	finding	2K_dev_1628
At the same time	finding	2K_dev_1628
it allows for functional implementations of algorithms such as depth-first search with the same asymptotic complexity as imperative implementations	finding	2K_dev_1628
	finding	2K_dev_1628
to develop a form of functional arrays ( sequences The key idea is to consider sequences with functional value semantics but nonfunctional cost semantics	mechanism	2K_dev_1628
Because the value semantics is functional	mechanism	2K_dev_1628
`` updating { '' } a sequence returns a new sequence	mechanism	2K_dev_1628
We allow operations on `` older { '' } sequences ( called interior sequences ) to be more expensive than operations on the `` most recent { '' } sequences ( called leaf sequences )	mechanism	2K_dev_1628
We embed sequences in a language supporting fork-join parallelism	mechanism	2K_dev_1628
Due to the parallelism	mechanism	2K_dev_1628
operations can be interleaved non-deterministically	mechanism	2K_dev_1628
and	mechanism	2K_dev_1628
in conjunction with the different cost for interior and leaf sequences	mechanism	2K_dev_1628
this can lead to non-deterministic costs for a program	mechanism	2K_dev_1628
Consequently the costs of programs can be difficult to analyze	mechanism	2K_dev_1628
The main result is the derivation of a deterministic cost dynamics which makes analyzing the costs easier	mechanism	2K_dev_1628
We present a wait-free concurrent implementation of sequences that requires constant work for accessing and updating leaf sequences	mechanism	2K_dev_1628
and logarithmic work for accessing and linear work for updating interior sequences	mechanism	2K_dev_1628
We sketch a proof of correctness for the sequence implementation	method	2K_dev_1628
	method	2K_dev_1628
The goal of this paper is ) that are as efficient as imperative arrays	purpose	2K_dev_1628
can be used in parallel	purpose	2K_dev_1628
and have well defined cost-semantics	purpose	2K_dev_1628
	purpose	2K_dev_1628
	background	2K_dev_1629
Precision for head pose and gaze averaged 4 degrees or less for pitch	finding	2K_dev_1629
yaw	finding	2K_dev_1629
and roll	finding	2K_dev_1629
The algorithm outperformed alternative methods in both datasets	finding	2K_dev_1629
	finding	2K_dev_1629
We propose a fast cascade regression based method that first estimates the location of a dense set of markers and their visibility	mechanism	2K_dev_1629
then reconstructs face shape by fitting a part-based 3D model	mechanism	2K_dev_1629
Next	mechanism	2K_dev_1629
the reconstructed 3D shape is used to estimate a canonical view of the eyes for 3D gaze estimation	mechanism	2K_dev_1629
The model operates in a feature space that naturally encodes local ordinal properties of pixel intensities leading to photometric invariant estimation of gaze	mechanism	2K_dev_1629
	mechanism	2K_dev_1629
To evaluate the algorithm in comparison with alternative approaches	method	2K_dev_1629
three publicly-available databases were used	method	2K_dev_1629
Boston University Head Tracking	method	2K_dev_1629
Multi-View Gaze and CAVE Gaze datasets	method	2K_dev_1629
	method	2K_dev_1629
Person-independent and pose-invariant estimation of eye-gaze is important for situation analysis and for automated video annotation	purpose	2K_dev_1629
	purpose	2K_dev_1629
Massive	background	2K_dev_1630
Open	background	2K_dev_1630
Online Courses ( MOOCs ) have been promoted as a means to revolutionize access to education	background	2K_dev_1630
	background	2K_dev_1630
We describe their motivations for participating as well as the challenges they encountered We also describe the importance of the face-to-face learning environment provided by the iLab as a source of community support	finding	2K_dev_1630
	mechanism	2K_dev_1630
	method	2K_dev_1630
In this paper	purpose	2K_dev_1630
we describe experiences with MOOCs for Liberian students who are connected to the iLab technology hub	purpose	2K_dev_1630
Massive online classes can benefit from peer interactions such as discussion	background	2K_dev_1631
critique	background	2K_dev_1631
or tutoring	background	2K_dev_1631
	background	2K_dev_1631
	finding	2K_dev_1631
This paper introduces an imprecise yet simple browser-based conversational turn detector for video conversations	mechanism	2K_dev_1631
Turns are detected without accessing video or audio data	mechanism	2K_dev_1631
	mechanism	2K_dev_1631
In a case study with 1027 students using Talkabout	method	2K_dev_1631
a video-based discussion system for online classes	method	2K_dev_1631
	method	2K_dev_1631
However	purpose	2K_dev_1631
to scaffold productive peer interactions	purpose	2K_dev_1631
systems must be able to detect student behavior in interactions at scale	purpose	2K_dev_1631
which is challenging when interactions occur over rich media like video	purpose	2K_dev_1631
We show how this turn detector can find dominance in video-based conversations	purpose	2K_dev_1631
we show how detected conversational turn behavior correlates with participants ' subjective experience in discussions and their final course grade	purpose	2K_dev_1631
	purpose	2K_dev_1631
Although xMOOCs are not designed to directly engage students via social media platforms	background	2K_dev_1632
some students in these courses join MOOC-associated Facebook groups	background	2K_dev_1632
These findings have implications for how MOOCs and social media platforms can support learners from non-English speaking contexts	background	2K_dev_1632
	background	2K_dev_1632
Results suggests that a non-trivial number of MOOC students engage in Facebook groups	finding	2K_dev_1632
that learners from a number of non-U	finding	2K_dev_1632
S	finding	2K_dev_1632
locations are disproportionately likely to participate in such groups	finding	2K_dev_1632
and that the groups display both location and language homophily	finding	2K_dev_1632
	finding	2K_dev_1632
	mechanism	2K_dev_1632
	method	2K_dev_1632
the geographic distribution of students in such groups as compared to the courses at large	method	2K_dev_1632
and the extent to which such groups are location and/or language homophilous	method	2K_dev_1632
	method	2K_dev_1632
This study explores the prevalence of Facebook groups associated with courses from MITx and HarvardX	purpose	2K_dev_1632
Massive Open Online Courses ( MOOCs ) provide an effective learning platform with various high-quality educational materials accessible to learners from all over the However	background	2K_dev_1633
current MOOCs lack personalized learning guidance and intelligent assessment for individuals	background	2K_dev_1633
	background	2K_dev_1633
show our approach significantly improves over previous vanilla BKT models on predicting students ' quiz performance	finding	2K_dev_1633
	finding	2K_dev_1633
This paper proposes to model both the hierarchical and the temporal properties of the knowledge states in order to improve the modeling accuracy	mechanism	2K_dev_1633
Based on the content organization characteristics on the Coursera MOOC platform	mechanism	2K_dev_1633
we provide a well-defined KC model	mechanism	2K_dev_1633
and develop Multi-Grained-BKT and Historical-BKT to capture the above features effectively	mechanism	2K_dev_1633
	mechanism	2K_dev_1633
Experiments on a Coursera course dataset	method	2K_dev_1633
Though a few recent attempts have been made to trace students ' knowledge states by adapting the popular Bayesian Knowledge Tracing ( BKT ) model	purpose	2K_dev_1633
they have largely ignored the rich structures and correlations among knowledge components ( KCs ) within a course	purpose	2K_dev_1633
	purpose	2K_dev_1633
	background	2K_dev_1634
	finding	2K_dev_1634
We present online algorithms The convex covering problem is defined as : min ( x is an element of R+ ) ( n ) f ( x ) s	mechanism	2K_dev_1634
t Ax > 0 1	mechanism	2K_dev_1634
where f : R-+ ( n ) - > R+ is a monotone convex function	mechanism	2K_dev_1634
and A is an m x n matrix with non-negative entries	mechanism	2K_dev_1634
In the online version	mechanism	2K_dev_1634
a new row of the constraint matrix	mechanism	2K_dev_1634
representing a new covering constraint	mechanism	2K_dev_1634
is revealed in each step and the algorithm is required to maintain a feasible and monotonically non-decreasing assignment x over time We also consider a convex packing problem defined as : max ( y is an element of R+ ) ( m ) Sigma ( m ) ( j-1 ) y ( j ) - g ( A ( T ) y )	mechanism	2K_dev_1634
where g : R-+ ( n ) - > R+ is a monotone convex function	mechanism	2K_dev_1634
In the online version	mechanism	2K_dev_1634
each variable y ( j ) arrives online and the algorithm must decide the value of y ( j ) on its arrival	mechanism	2K_dev_1634
This represents the Fenchel dual of the convex covering program	mechanism	2K_dev_1634
when g is the convex conjugate of f	mechanism	2K_dev_1634
We use a primal-dual approach to give online algorithms for these generic problems	mechanism	2K_dev_1634
and use them to simplify	mechanism	2K_dev_1634
unify	mechanism	2K_dev_1634
and improve upon previous results for several applications	mechanism	2K_dev_1634
	mechanism	2K_dev_1634
	method	2K_dev_1634
for covering and packing problems with ( non-linear ) convex objectives	purpose	2K_dev_1634
	purpose	2K_dev_1634
In their model	background	2K_dev_1635
the input data consists of ordered pairs ( x ( i )	background	2K_dev_1635
y ( i ) ) is an element of { [ } -1	background	2K_dev_1635
1 ] x { [ } -1	background	2K_dev_1635
1 ]	background	2K_dev_1635
i 0 1	background	2K_dev_1635
2	background	2K_dev_1635
	background	2K_dev_1635
	background	2K_dev_1635
	background	2K_dev_1635
	background	2K_dev_1635
N	background	2K_dev_1635
and there is an unknown degree-d polynomial p such that for all but rho fraction of the i	background	2K_dev_1635
we have vertical bar p ( x ( i ) ) - y ( i ) vertical bar < 0 delta	background	2K_dev_1635
	background	2K_dev_1635
Specifically	finding	2K_dev_1635
we show that there are polynomial-time algorithms in both settings that recover q up to l ( infinity ) error O ( delta ( 0	finding	2K_dev_1635
99 ) ) provided 1 ) rho < 0 c ( 1 ) / log d and delta > 0 1/ ( log d ) ( c )	finding	2K_dev_1635
or 2 ) rho < 0 c ( 1 ) / log d/log ( 2 ) d	finding	2K_dev_1635
and delta > 0 1/d ( c Here c is any constant and c ( 1 ) is a small enough constant depending on c	finding	2K_dev_1635
The number of points that suffices is N 0 ( O ) over tilde ( d ) in the trigonometric setting for random x ( i )	finding	2K_dev_1635
or arbitrary x ( i )	finding	2K_dev_1635
that are roughly equally spaced	finding	2K_dev_1635
or in the algebraic setting when the x ( i ) are chosen according to the Chebyshev distribution	finding	2K_dev_1635
and N 0 ( O ) over tilde ( d ( 2 ) ) in the algebraic setting with random ( or roughly equally spaced ) x ( i )	finding	2K_dev_1635
In particular	mechanism	2K_dev_1635
we study the model of Arora and Khot ( STOC 2002 )	mechanism	2K_dev_1635
who were motivated by applications in computer vision	mechanism	2K_dev_1635
Unlike Arora-Khot	mechanism	2K_dev_1635
we also study the trigonometric setting	mechanism	2K_dev_1635
where the input is from T x { [ } -1	mechanism	2K_dev_1635
11	mechanism	2K_dev_1635
where T is the unit circle	mechanism	2K_dev_1635
In both scenarios	mechanism	2K_dev_1635
the i corresponding to errors are chosen randomly	mechanism	2K_dev_1635
and for such i the errors in the y ( i ) can be arbitrary	mechanism	2K_dev_1635
The goal is to output a degree-d polynomial q such that parallel to p - q parallel to ( infinity ) is small ( for example	mechanism	2K_dev_1635
O ( delta ) Arora and Khot could achieve a polynomial-time algorithm only for rho 0 0	mechanism	2K_dev_1635
Daltrophe et al	mechanism	2K_dev_1635
observed that a simple median-based algorithm can correct errors if the desired accuracy delta is large enough	mechanism	2K_dev_1635
( Larger delta makes the output guarantee easier to achieve	mechanism	2K_dev_1635
which seems to typically outweigh the weaker input promise	mechanism	2K_dev_1635
) We dramatically expand the range of parameters for which recovery of q is possible in polynomial time	mechanism	2K_dev_1635
	mechanism	2K_dev_1635
	method	2K_dev_1635
We consider the robust curve fitting problem	purpose	2K_dev_1635
for both algebraic and Fourier ( trigonometric ) polynomials	purpose	2K_dev_1635
in the presence of outliers	purpose	2K_dev_1635
	purpose	2K_dev_1635
	background	2K_dev_1636
determine whether a ( T ) X and b ( T ) Y are uncorrelated for every a is an element of R-p	background	2K_dev_1636
b is an element of R-q or not	background	2K_dev_1636
Linear independence testing is a fundamental information-theoretic and statistical problem that can be posed as follows : given n points \ { ( X ( i ) ; Y-i ) \ } ( n ) ( i=1 ) from a p + q dimensional multivariate distribution where X-i is an element of R-p and Y-i is an element of R-q	background	2K_dev_1636
In summary	finding	2K_dev_1636
our results imply that n must be at least as large as root pq/parallel to Sigma ( XY ) parallel to ( 2 ) ( F ) for any procedure ( test ) to have non-trivial power	finding	2K_dev_1636
where Sigma ( XY ) is the cross- covariance matrix of X	finding	2K_dev_1636
Y	finding	2K_dev_1636
We also provide evidence that the lower bound is tight	finding	2K_dev_1636
( when p + q	mechanism	2K_dev_1636
n - > infinity	mechanism	2K_dev_1636
( p + q ) /n < 0 kappa < infinity	mechanism	2K_dev_1636
without sparsity assumptions )	mechanism	2K_dev_1636
	mechanism	2K_dev_1636
by connections to two-sample testing and regression when q 0 1	method	2K_dev_1636
	method	2K_dev_1636
We give minimax lower bound for this problem	purpose	2K_dev_1636
With the appearance of fraudsters in social network sites	background	2K_dev_1637
the importance of trust prediction has increased	background	2K_dev_1637
Most such methods use only explicit and implicit trust information ( e	background	2K_dev_1637
g	background	2K_dev_1637
	background	2K_dev_1637
if Smith likes several of Johnson 's reviews	background	2K_dev_1637
then Smith implicitly trusts Johnson )	background	2K_dev_1637
but they do not consider distrust	background	2K_dev_1637
	background	2K_dev_1637
confirm that PIN-TRUST is scalable and outperforms existing methods in terms of prediction accuracy	finding	2K_dev_1637
achieving up to 50	finding	2K_dev_1637
4 percentage relative improvement	finding	2K_dev_1637
	finding	2K_dev_1637
In this paper	mechanism	2K_dev_1637
we propose PIN-TRUST	mechanism	2K_dev_1637
a novel method The novelties of our method are the following : ( a ) it is carefully designed	mechanism	2K_dev_1637
to take into account positive	mechanism	2K_dev_1637
implicit	mechanism	2K_dev_1637
and negative information	mechanism	2K_dev_1637
( b ) it is scalable ( i	mechanism	2K_dev_1637
e	mechanism	2K_dev_1637
	mechanism	2K_dev_1637
linear on the input size )	mechanism	2K_dev_1637
( c ) most importantly	mechanism	2K_dev_1637
it is effective and accurate	mechanism	2K_dev_1637
	mechanism	2K_dev_1637
Our extensive experiments with a real dataset	method	2K_dev_1637
Epinions	method	2K_dev_1637
corn data	method	2K_dev_1637
of 100K nodes and 1M edges	method	2K_dev_1637
	method	2K_dev_1637
Given `` who-trusts/distrusts-whom { '' } information	purpose	2K_dev_1637
how can we propagate the trust and distrust ? to handle all three types of interaction information : explicit trust	purpose	2K_dev_1637
implicit trust	purpose	2K_dev_1637
and explicit distrust	purpose	2K_dev_1637
	purpose	2K_dev_1637
Recent work in dense monocular 3D reconstruction relies on dense pixel correspondences and assumes brightness constancy and saliency	background	2K_dev_1638
and thus are fundamentally unable to reconstruct low-textured or non-lambertian objects such as glass or metal	background	2K_dev_1638
Occlusion boundaries differ from texture in that each unique view generates a unique set of occlusions	background	2K_dev_1638
	background	2K_dev_1638
the points of our reconstructed edge cloud have an RMS error of 2	finding	2K_dev_1638
3 mm	finding	2K_dev_1638
	finding	2K_dev_1638
By detecting and solving for the depths of occlusion boundaries by compensating with an increasing number of unique views	mechanism	2K_dev_1638
	mechanism	2K_dev_1638
In a sequence containing the Stanford Bunny ( 8	method	2K_dev_1638
5 cm )	method	2K_dev_1638
we show how dense reconstructions of challenging objects can be integrated with existing monocular reconstruction algorithms	purpose	2K_dev_1638
Change introduces conflict into software ecosystems : breaking changes may ripple through the ecosystem and trigger rework for users of a package	background	2K_dev_1639
but often developers can invest additional effort or accept opportunity costs to alleviate or delay downstream costs Our results illustrate that there is a large design space in how to build an ecosystem	background	2K_dev_1639
its policies and its supporting infrastructure ; and there is value in making community values and accepted tradeoffs explicit and transparent in order to resolve conflicts and negotiate change-related costs	background	2K_dev_1639
	background	2K_dev_1639
We found that all three ecosystems differ substantially in their practices and expectations toward change and that those differences can be explained largely by different community values in each ecosystem	finding	2K_dev_1639
	finding	2K_dev_1639
	mechanism	2K_dev_1639
We performed a multiple case study of three software ecosystems with different tooling and philosophies toward change	method	2K_dev_1639
Eclipse	method	2K_dev_1639
R/CRAN	method	2K_dev_1639
and Node	method	2K_dev_1639
js/npm	method	2K_dev_1639
to understand how developers make decisions about change and change-related costs and what practices	purpose	2K_dev_1639
tooling	purpose	2K_dev_1639
and policies are used	purpose	2K_dev_1639
	purpose	2K_dev_1639
	background	2K_dev_1640
Our results show that These policies can generalize across interactions with different numbers of people and can handle various levels of sensing noise	finding	2K_dev_1640
	finding	2K_dev_1640
a new state representation that we designed for this problem	mechanism	2K_dev_1640
In this scenario	method	2K_dev_1640
we assume that the correct behavior for the robot should convey attentiveness to the focus of attention of the conversation	method	2K_dev_1640
Thus	method	2K_dev_1640
the robot should turn towards the speaker	method	2K_dev_1640
from tests in a simulated environment	method	2K_dev_1640
We explore online reinforcement learning techniques to find good policies to control the orientation of a mobile robot during social group conversations can be used to find good policies for the robot	purpose	2K_dev_1640
	purpose	2K_dev_1640
	background	2K_dev_1641
showed good performance in comparison to an existing people detection approach	finding	2K_dev_1641
The projected polygon step captures significantly more people in the scene ( 77\ % vs	finding	2K_dev_1641
80\ % ) and supports group clustering in dense	finding	2K_dev_1641
complex scenarios Examples are provided for group splitting and merging	finding	2K_dev_1641
dense crowds with obstructions	finding	2K_dev_1641
and cases where other approaches typically encounter difficulty	finding	2K_dev_1641
	finding	2K_dev_1641
We describe a method It incorporates social expectations and is inspired by human perceptual processes	mechanism	2K_dev_1641
The approach uses a single Kinect to cluster all moving objects into groups	mechanism	2K_dev_1641
applies a 2D polygon projection in obscured regions	mechanism	2K_dev_1641
and a group personal space modeled using asymmetric Gaussians in order to inhibit certain socially inappropriate robot paths	mechanism	2K_dev_1641
This approach trades off detection of individual people for higher coverage and lower cost	mechanism	2K_dev_1641
while preserving high speed processing	mechanism	2K_dev_1641
	mechanism	2K_dev_1641
A real-world evaluation of this approach	method	2K_dev_1641
for low-cost awareness of characteristics of dense	purpose	2K_dev_1641
moving crowds such as group formation	purpose	2K_dev_1641
personal space approximation	purpose	2K_dev_1641
and occlusion compensation for use in navigating through crowds	purpose	2K_dev_1641
Trajectory planning methods for on-road autonomous driving are commonly formulated to optimize a Single Objective calculated by accumulating Multiple Weighted Feature terms ( SOMWF )	background	2K_dev_1642
	background	2K_dev_1642
	finding	2K_dev_1642
This paper addresses this issue by proposing a framework with multiple tunable phases of planning	mechanism	2K_dev_1642
along with two novel techniques : Optimization-free trajectory smoothing/nudging	mechanism	2K_dev_1642
Sampling-based trajectory search with cascaded ranking	mechanism	2K_dev_1642
	method	2K_dev_1642
Such formulation typically suffers from the lack of planning tunability	purpose	2K_dev_1642
Two main causes are the lack of physical intuition and relative feature prioritization due to the complexity of SOMWF	purpose	2K_dev_1642
especially when the number of features is big	purpose	2K_dev_1642
	purpose	2K_dev_1642
Proactive latency-aware adaptation is an approach for self-adaptive systems that improves over reactive adaptation by considering both the current and anticipated adaptation needs of the system	background	2K_dev_1643
and taking into account the latency of adaptation tactics so that they can be started with the necessary lead time	background	2K_dev_1643
Making an adaptation decision with these characteristics requires solving an optimization problem to select the adaptation path that maximizes an objective function over a finite look-ahead horizon Since this is a problem of selecting adaptation actions in the context of the probabilistic behavior of the environment	background	2K_dev_1643
Markov decision processes ( MDP ) are a suitable approach	background	2K_dev_1643
However	background	2K_dev_1643
given all the possible interactions between the different and possibly concurrent adaptation tactics	background	2K_dev_1643
the system	background	2K_dev_1643
and the environment	background	2K_dev_1643
constructing the MDP is a complex task	background	2K_dev_1643
Probabilistic model checking can be used to deal with this problem since it takes as input a formal specification of the stochastic system	background	2K_dev_1643
which is internally translated into an MDP	background	2K_dev_1643
and solved	background	2K_dev_1643
	background	2K_dev_1643
results show that this approach reduces the adaptation decision time by an order of magnitude while producing the same results	finding	2K_dev_1643
	finding	2K_dev_1643
In this paper we present an approach by constructing most of the MDP offline	mechanism	2K_dev_1643
also using formal specification	mechanism	2K_dev_1643
At run time	mechanism	2K_dev_1643
the adaptation decision is made by solving the MDP through stochastic dynamic programming	mechanism	2K_dev_1643
weaving in the stochastic environment model as the solution is computed	mechanism	2K_dev_1643
	mechanism	2K_dev_1643
Our experimental compared to the probabilistic model checking approach	method	2K_dev_1643
	method	2K_dev_1643
One drawback of this solution is that the MDP has to be constructed every time an adaptation decision has to be made to incorporate the latest predictions of the environment behavior	purpose	2K_dev_1643
that eliminates that run-time overhead	purpose	2K_dev_1643
Such incentives are likely aligned with benefits to utilities and grid operators	background	2K_dev_1644
which might take the form of peak-shaving or ancillary services However	background	2K_dev_1644
private cost savings are not strictly aligned with public benefits related to the avoidance of health and environmental damages from power plant emissions	background	2K_dev_1644
	background	2K_dev_1644
We find that feasible strategies exist to simultaneously realize public and private benefits and that load shifting can result in substantial cost savings and avoided damages in some circumstances	finding	2K_dev_1644
Concerns over increased latency and bandwidth costs can be mitigated with modifications to the model	finding	2K_dev_1644
However	finding	2K_dev_1644
the level of realized savings is dependent upon the specifics of a particular network operator and electricity rate schedule	finding	2K_dev_1644
	finding	2K_dev_1644
	mechanism	2K_dev_1644
so we compare private cost minimization with a strategy that minimizes these externalities	method	2K_dev_1644
This paper assesses the potential cost-saving incentives for content distribution networks to shift traffic load among geographically distributed data centers in response to hourly variation in electricity prices	purpose	2K_dev_1644
Personal informatics systems are becoming increasing prevalent as their price	background	2K_dev_1645
form	background	2K_dev_1645
and ease of use improves	background	2K_dev_1645
Though these systems offer great potential value to users	background	2K_dev_1645
many systems are hampered by issues that limit their ability to foster engagement	background	2K_dev_1645
and people often abandon use of these systems without garnering meaningful outcomes	background	2K_dev_1645
While continued use of these systems is not necessary for all people	background	2K_dev_1645
there is an opportunity to better support people working towards achievement-based goals and discuss how these strategies could be used to foster engagement with PI systems	background	2K_dev_1645
	background	2K_dev_1645
	finding	2K_dev_1645
We then propose seven strategies for the design community to explore	mechanism	2K_dev_1645
	method	2K_dev_1645
In this paper	purpose	2K_dev_1645
we draw from the literature and our own prior Work to identify a number of problems that hinder engagement with achievement-based personal informatics systems-problems related to inadequate support for goal setting	purpose	2K_dev_1645
misalignment of user and system goals	purpose	2K_dev_1645
and the burden of system maintenance	purpose	2K_dev_1645
for mitigating these problems	purpose	2K_dev_1645
Machine learning improves mobile user experience	background	2K_dev_1646
Interestingly	background	2K_dev_1646
envisioning apps with adaptive interfaces that reduce navigation and selection effort is not standard UX practice	background	2K_dev_1646
When implementing an adaptive UI for our mobile transit app	background	2K_dev_1646
we encountered a number of problems	background	2K_dev_1646
	background	2K_dev_1646
extracted six design patterns where UI adaptation can improve in-app navigation	finding	2K_dev_1646
	finding	2K_dev_1646
Next	mechanism	2K_dev_1646
we designed an exemplar set of wireframes	mechanism	2K_dev_1646
illustrating how UX designers might annotate their interaction flows	mechanism	2K_dev_1646
we reviewed the interfaces of popular apps and	method	2K_dev_1646
Our original design did not log necessary information nor did it induce users to provide good labels	purpose	2K_dev_1646
On reflection	purpose	2K_dev_1646
we realized UX designers should identify and refine UI adaptions when sketching wireframes	purpose	2K_dev_1646
To advance on this insight to communicate planned adaptation and note the information ( logs and labels ) needed to make the desired inferences	purpose	2K_dev_1646
	purpose	2K_dev_1646
	background	2K_dev_1647
The results of both analyses support the attribution of the effect to the behavioral interpretation	finding	2K_dev_1647
suggests that more social oriented topics triggered richer discussion than more biopsychology oriented topics	finding	2K_dev_1647
	finding	2K_dev_1647
	mechanism	2K_dev_1647
we adopted two approaches	method	2K_dev_1647
First	method	2K_dev_1647
we used propensity score matching to pair students who exhibit a similar level of involvement in other course activities	method	2K_dev_1647
Second	method	2K_dev_1647
we explored individual variation in engagement in higher-order thinking behaviors across weeks	method	2K_dev_1647
A further analysis using LDA applied to course materials	method	2K_dev_1647
With the aim of better scaffolding discussion to improve learning in a MOOC context	purpose	2K_dev_1647
this work investigates what kinds of discussion behaviors contribute to learning	purpose	2K_dev_1647
We explored whether engaging in higher-order thinking behaviors results in more learning than paying general or focused attention to course materials	purpose	2K_dev_1647
In order to evaluate whether to attribute the effect to engagement in the associated behaviors versus persistent characteristics of the students	purpose	2K_dev_1647
Our previous work has demonstrated that players who perceive a game as more challenging are likely to perceive greater learning from that game { [ } 8 However	background	2K_dev_1648
this may not be the case for all sources of challenge	background	2K_dev_1648
Previously we had identified two primary types of errors in the learning game	background	2K_dev_1648
Quantum Spectre : Science Errors related to the game 's core educational content ; and Puzzle Errors related to rules of the game but not to science knowledge	background	2K_dev_1648
	background	2K_dev_1648
we found that students ' progress through the first zone of the game seemed to encounter a `` roadblock { '' } during gameplay	finding	2K_dev_1648
dropping out when they can not ( or do not want to ) progress further	finding	2K_dev_1648
These results demonstrate that modeling player behavior can be useful for both assessing learning and for designing complex problem solving content for learning environments	finding	2K_dev_1648
	finding	2K_dev_1648
	mechanism	2K_dev_1648
In this study of a Science learning game called Quantum Spectre	method	2K_dev_1648
Using this prior analysis	method	2K_dev_1648
alongside Survival Analysis techniques for analyzing time-series data and drop-out rates	method	2K_dev_1648
	method	2K_dev_1648
we explored players ' gameplay patterns to help us understand player dropout in Quantum Spectre	purpose	2K_dev_1648
	purpose	2K_dev_1648
Compressed sensing is a simple and efficient technique that has a number of applications in signal processing and machine learning	background	2K_dev_1649
In machine learning it provides answers to questions such as : `` under what conditions is the sparse representation of data efficient ? { '' } ; `` when is learning a large margin classifier directly on the compressed domain possible ? { '' } ; and `` why does a large margin classifier learn more effectively if the data is sparse ? { '' }	background	2K_dev_1649
	background	2K_dev_1649
and show for the high dimensional sparse signals	finding	2K_dev_1649
when the bounds are tight	finding	2K_dev_1649
directly learning in the compressed domain is possible	finding	2K_dev_1649
by leveraging compressed sensing from the learning perspective We show	mechanism	2K_dev_1649
for a full-rank signal	mechanism	2K_dev_1649
the high dimensional sparse representation of data is efficient because from the classifiers viewpoint such a representation is in fact a low dimensional problem	mechanism	2K_dev_1649
	mechanism	2K_dev_1649
We provide practical bounds on the linear classifier to investigate the relationship between the SVM classifier in the high dimensional and compressed domains	method	2K_dev_1649
This work tackles the problem of feature representation from the context of sparsity and affine rank minimization in order to provide answers to the aforementioned questions	purpose	2K_dev_1649
	purpose	2K_dev_1649
An important research problem in learning analytics is	background	2K_dev_1650
which suggests ways in which we might foster these social benefits through intervention	finding	2K_dev_1650
	finding	2K_dev_1650
we propose a pipeline that includes data infrastructure	mechanism	2K_dev_1650
learning analytics	mechanism	2K_dev_1650
and intervention	mechanism	2K_dev_1650
along with computational models for individual components	mechanism	2K_dev_1650
	mechanism	2K_dev_1650
Next	method	2K_dev_1650
we describe an example of applying this pipeline to real data in a case study	method	2K_dev_1650
whose goal is to investigate the positive effects that goal-setting students have on their peers	method	2K_dev_1650
	method	2K_dev_1650
to expedite the cycle of data leading to the analysis of student progress and the improvement of student support	purpose	2K_dev_1650
For this goal in the context of social learning	purpose	2K_dev_1650
	purpose	2K_dev_1650
Various trends are reshaping content delivery on the Internet : the explosive growth of traffic due to video	background	2K_dev_1651
users ' increasing expectations for higher quality of experience ( QoE )	background	2K_dev_1651
and the proliferation of server capacity from a variety of sources ( e	background	2K_dev_1651
g	background	2K_dev_1651
	background	2K_dev_1651
cloud computing services	background	2K_dev_1651
content provider-owned datacenters	background	2K_dev_1651
CDNs	background	2K_dev_1651
and ISP-owned CDNs )	background	2K_dev_1651
In order to meet the scale and quality demands imposed by users	background	2K_dev_1651
content providers have started to spread demand across multiple CDNs using a broker	background	2K_dev_1651
Brokers break many traditional CDN assumptions ( e	background	2K_dev_1651
g	background	2K_dev_1651
	background	2K_dev_1651
unexpected traffic skew and significant variance in demand over short timescales )	background	2K_dev_1651
we show the potential challenges and opportunities that brokers impart on content delivery	finding	2K_dev_1651
	finding	2K_dev_1651
through a redesigned broker-CDN interface	mechanism	2K_dev_1651
Through an analysis of data from a leading broker and a leading CDN	method	2K_dev_1651
	method	2K_dev_1651
We take the first steps towards improvement	purpose	2K_dev_1651
The core number of a node is the highest k-core in which the node participates	background	2K_dev_1652
Core numbers are useful in many graph mining tasks	background	2K_dev_1652
especially ones that involve finding communities of nodes	background	2K_dev_1652
influential spreaders and dense subgraphs	background	2K_dev_1652
Large graphs often do not fit on the memory of a single machine	background	2K_dev_1652
Existing external memory solutions do not give bounds on the required space	background	2K_dev_1652
	background	2K_dev_1652
demonstrate that Nimble Core gives space savings up to 60X	finding	2K_dev_1652
while accurately estimating core numbers with average relative error less than 2	finding	2K_dev_1652
3\ %	finding	2K_dev_1652
We propose Nimble Core	mechanism	2K_dev_1652
an iterative external-memory algorithm	mechanism	2K_dev_1652
which using O ( n log d ( max ) ) space	mechanism	2K_dev_1652
where n is the number of nodes and d ( max ) is the maximum node-degree in the graph	mechanism	2K_dev_1652
We also show that Core requires O ( n ) space for graphs with power-law degree distributions	mechanism	2K_dev_1652
Nimble Experiments on forty-eight large graphs from various domains	method	2K_dev_1652
We address the problem of estimating core numbers of nodes by reading edges of a large graph stored in external memory	purpose	2K_dev_1652
In practice	purpose	2K_dev_1652
existing solutions also do not scale with the size of the graph	purpose	2K_dev_1652
estimates core numbers of nodes	purpose	2K_dev_1652
Making effective problem selection decisions is a challenging Self-Regulated Learning skill Students need to learn effective problem-selection strategies but also develop the motivation to use them	background	2K_dev_1653
A mastery-approach orientation is generally associated with positive problem selection behaviors such as willingness to work on new materials Our experiment contributes to prior literature by demonstrating that with tutor features to foster a mastery-approach orientation	background	2K_dev_1653
shared control over problem selection can lead to significantly better learning outcomes than full system control	background	2K_dev_1653
	background	2K_dev_1653
The results show that shared control over problem selection accompanied by mastery-oriented features leads to significantly better learning outcomes	finding	2K_dev_1653
as compared to fully system-controlled problem selection	finding	2K_dev_1653
as well as better declarative knowledge of a key problem-selection strategy Nevertheless	finding	2K_dev_1653
there was no effect on future problem selection and future learning	finding	2K_dev_1653
	finding	2K_dev_1653
	mechanism	2K_dev_1653
We conducted a classroom experiment with 200 6th - 8th graders	method	2K_dev_1653
to investigate the effectiveness of shared control over problem selection with mastery-oriented features ( i	purpose	2K_dev_1653
e	purpose	2K_dev_1653
	purpose	2K_dev_1653
features that aim at fostering a mastery-approach orientation that simulates effective problem-selection behaviors ) on students ' domain-level learning outcomes	purpose	2K_dev_1653
problem-selection skills	purpose	2K_dev_1653
enjoyment	purpose	2K_dev_1653
future learning and future problem selection	purpose	2K_dev_1653
	purpose	2K_dev_1653
	background	2K_dev_1654
The results show that the metacognitive scaffolding facilitated tutor learning ( regardless of the presence of the cognitive scaffolding )	finding	2K_dev_1654
whereas cognitive scaffolding had virtually no effect The same pattern was confirmed	finding	2K_dev_1654
	mechanism	2K_dev_1654
We conducted a classroom study to test these hypotheses in the context of learning to solve equations by teaching a synthetic peer	method	2K_dev_1654
SimStudent	method	2K_dev_1654
by two additional datasets collected from two previous school studies we conducted	method	2K_dev_1654
	method	2K_dev_1654
In this paper we study the effect of adaptive scaffolding to learning by teaching We hypothesize that learning by teaching is facilitated if ( 1 ) students receive adaptive scaffolding on how to teach and how to prepare for teaching ( the metacognitive hypothesis )	purpose	2K_dev_1654
( 2 ) students receive adaptive scaffolding on how to solve problems ( the cognitive hypothesis )	purpose	2K_dev_1654
or ( 3 ) both ( the hybrid hypothesis )	purpose	2K_dev_1654
	purpose	2K_dev_1654
	background	2K_dev_1655
The results show that the proposed adaptive online course technology is robust enough to be used in actual classroom with mixed effect for learning	finding	2K_dev_1655
	mechanism	2K_dev_1655
we have developed an adaptive online course on the Open Learning Initiative ( OLI ) platform by integrating four new instances of cognitive tutors into an existing OLI course	mechanism	2K_dev_1655
Cognitive tutors were created with an innovative cognitive tutor authoring system called WATSON	mechanism	2K_dev_1655
To evaluate the effectiveness of the adaptive online course	method	2K_dev_1655
a quasi-experiment was conducted in a gateway course at Carnegie Mellon University	method	2K_dev_1655
We hypothesize that when cognitive tutors are integrated into online courseware	purpose	2K_dev_1655
the online courseware can provide a new type of adaptive instructions	purpose	2K_dev_1655
such as impasse-driven adaptive remediation and need-based assessments	purpose	2K_dev_1655
As a proof of concept	purpose	2K_dev_1655
Ambiguity arises in requirements when a statement is unintentionally or otherwise incomplete	background	2K_dev_1656
missing information	background	2K_dev_1656
or when a word or phrase has more than one possible meaning	background	2K_dev_1656
	background	2K_dev_1656
to yield a rank order of vague terms in both isolation and composition	finding	2K_dev_1656
to show how increases in vagueness will decrease users ' acceptance of privacy risk and thus decrease users ' willingness to share personal information	finding	2K_dev_1656
In this paper	mechanism	2K_dev_1656
we introduce a theory of vagueness for privacy policy statements based on a taxonomy of vague terms derived from an empirical content analysis of 15 privacy policies	mechanism	2K_dev_1656
	mechanism	2K_dev_1656
The taxonomy was evaluated in a paired comparison experiment and results were analyzed using the Bradley-Terry model We further provide empirical evidence based on factorial vignette surveys	method	2K_dev_1656
For web-based and mobile information systems	purpose	2K_dev_1656
ambiguity	purpose	2K_dev_1656
and vagueness in particular	purpose	2K_dev_1656
undermines the ability of organizations to align their privacy policies with their data practices	purpose	2K_dev_1656
which can confuse or mislead users thus leading to an increase in privacy risk	purpose	2K_dev_1656
The theory predicts how vague modifiers to information actions and information types can be composed to increase or decrease overall vagueness	purpose	2K_dev_1656
	purpose	2K_dev_1656
confidentiality of training data induced by releasing machine-learning models	background	2K_dev_1657
and has recently received increasing attention	background	2K_dev_1657
which	background	2K_dev_1657
to the best of our knowledge	background	2K_dev_1657
were not previously known	background	2K_dev_1657
	background	2K_dev_1657
Interestingly	finding	2K_dev_1657
we also discovered an intriguing phenomenon	finding	2K_dev_1657
which we call `` invertibility interference	finding	2K_dev_1657
{ '' } where a highly invertible model quickly becomes highly non-invertible by adding little noise	finding	2K_dev_1657
We show that even very restricted communication between layers could leak a significant amount of information Perhaps more importantly	finding	2K_dev_1657
our study also unveils unexpected computational power of these restricted communication channels	finding	2K_dev_1657
	finding	2K_dev_1657
Motivated by existing MI attacks and other previous attacks that turn out to be MI `` in disguise	mechanism	2K_dev_1657
{ '' } by presenting a game-based methodology Our methodology uncovers a number of subtle issues	mechanism	2K_dev_1657
and devising a rigorous game-based definition	mechanism	2K_dev_1657
analogous to those in cryptography	mechanism	2K_dev_1657
is an interesting avenue for future work	mechanism	2K_dev_1657
We describe methodologies for two types of attacks The first is for black-box attacks	mechanism	2K_dev_1657
which consider an adversary who infers sensitive values with only oracle access to a model	mechanism	2K_dev_1657
The second methodology targets the white-box scenario where an adversary has some additional knowledge about the structure of a model	mechanism	2K_dev_1657
For the restricted class of Boolean models and black-box attacks	mechanism	2K_dev_1657
we characterize model invertibility using the concept of influence from Boolean analysis in the noiseless case	mechanism	2K_dev_1657
and connect model invertibility with stable influence in the noisy case	mechanism	2K_dev_1657
For the white-box case	mechanism	2K_dev_1657
we consider a common phenomenon in machine-learning models where the model is a sequential composition of several sub-models	mechanism	2K_dev_1657
	mechanism	2K_dev_1657
quantitatively	method	2K_dev_1657
this paper initiates a formal study of MI attacks	purpose	2K_dev_1657
Social networking sites ( SNSs ) offer users a platform to build and maintain social connections	background	2K_dev_1658
Results show that women self-disclose more than men	finding	2K_dev_1658
People with a stronger desire to manage impressions self-disclose less Network size is negatively associated with self-disclosure	finding	2K_dev_1658
while tie strength and network density are positively associated	finding	2K_dev_1658
	finding	2K_dev_1658
This observational research develops a machine learning model and uses it Features include emotional valence	mechanism	2K_dev_1658
social distance between the poster and people mentioned in the post	mechanism	2K_dev_1658
the language similarity between the post and the community and post topic	mechanism	2K_dev_1658
To validate the model and advance our understanding about online self-disclosure	method	2K_dev_1658
we applied it to de-identified	method	2K_dev_1658
aggregated status updates from Facebook users	method	2K_dev_1658
	method	2K_dev_1658
Understanding when people feel comfortable sharing information about themselves on SNSs is critical to a good user experience	purpose	2K_dev_1658
because self-disclosure helps maintain friendships and increase relationship closeness to measure self-disclosure in SNSs to understand the contexts where it is higher or lower	purpose	2K_dev_1658
	purpose	2K_dev_1658
Anonymity online is important to people at times in their lives	background	2K_dev_1659
Anonymous communication applications such as Whisper and YikYak enable people to communicate with strangers anonymously through their smartphones Our results provide implications for how anonymity in mobile apps can encourage expressiveness and interaction among users	background	2K_dev_1659
	background	2K_dev_1659
People share various types of content that range from deep confessions and secrets to lighthearted jokes and momentary feelings	finding	2K_dev_1659
An important driver for participation and posting is to get social validation from others	finding	2K_dev_1659
even though they are anonymous strangers We also find that participants believe these anonymous apps allow more honesty	finding	2K_dev_1659
openness	finding	2K_dev_1659
and diversity of opinion than they can find elsewhere	finding	2K_dev_1659
	finding	2K_dev_1659
We present a typology of the content people share	mechanism	2K_dev_1659
and their motivations for participation in anonymous apps	mechanism	2K_dev_1659
	mechanism	2K_dev_1659
We report results from semi-structured interviews with 18 users of these apps	method	2K_dev_1659
The goal of our study was to identify why and how people use anonymous apps	purpose	2K_dev_1659
their perceptions of their audience and interactions on the apps	purpose	2K_dev_1659
and how these apps compare with other online social communities	purpose	2K_dev_1659
When health services involve long-term treatment over months or years	background	2K_dev_1660
providers have the ability	background	2K_dev_1660
not present in acute emergency care	background	2K_dev_1660
to collaboratively reflect on clients ' changing health data and adjust interventions	background	2K_dev_1660
Current literature shows a bias toward standardized records and routines in the implementation of health information technology	background	2K_dev_1660
a policy that may not be appropriate for long-term health services	background	2K_dev_1660
We discuss how the design of information systems should vary based on temporal factors	background	2K_dev_1660
	background	2K_dev_1660
Our fieldwork in this context complements and provides contrasts to previous CSCW studies performed in time-critical hospital settings	finding	2K_dev_1660
	finding	2K_dev_1660
	mechanism	2K_dev_1660
We define a temporal spectrum ranging from time-critical services that benefit from standardization to long-term services that require more flexibility	method	2K_dev_1660
We provide empirical evidence from fieldwork that we performed in organizations providing long-term behavioral and mental health services for children	method	2K_dev_1660
In this paper	purpose	2K_dev_1660
we discuss temporality as a factor in the design of health information technology	purpose	2K_dev_1660
	purpose	2K_dev_1660
Hackathons are events where people who are not normally collocated converge for a few days to write code together	background	2K_dev_1661
Hackathons	background	2K_dev_1661
it seems	background	2K_dev_1661
are everywhere Our findings have implications for technology support that needs to be in place for hackathons and for understanding the role of brief interludes of collocation in loosely-coupled	background	2K_dev_1661
geographically distributed work	background	2K_dev_1661
	background	2K_dev_1661
We present results that suggest the way that hackathon-style collocation advances technical work varies across technical domain	finding	2K_dev_1661
community structure	finding	2K_dev_1661
and expertise of participants	finding	2K_dev_1661
Building social ties	finding	2K_dev_1661
in contrast	finding	2K_dev_1661
seems relatively constant across hackathons	finding	2K_dev_1661
Results from different hackathon team formation strategies suggest a tradeoff between advancing technical work and building social ties	finding	2K_dev_1661
	finding	2K_dev_1661
	mechanism	2K_dev_1661
from a multiple-case study	method	2K_dev_1661
We know that long-term collocation helps advance technical work and facilitate enduring interpersonal relationships	purpose	2K_dev_1661
but can similar benefits come from brief	purpose	2K_dev_1661
hackathon-style collocation ? How do participants spend their time preparing	purpose	2K_dev_1661
working face-to-face	purpose	2K_dev_1661
and following through these brief encounters ? Do the activities participants select suggest a tradeoff between the social and technical benefits of collocation ?	purpose	2K_dev_1661
People are more creative at solving difficult design problems when they use relevant examples from outside of the problem 's domain as inspirations	background	2K_dev_1662
Crowd workers drawing inspirations from the distant domains produced more creative solutions to the original problem than did those who sought inspiration on their own	finding	2K_dev_1662
or drew inspiration from domains closer to or not sharing structural correspondence with the original problem	finding	2K_dev_1662
	finding	2K_dev_1662
In this paper	mechanism	2K_dev_1662
we demonstrate an approach in which non-experts identify domains that have the potential to yield useful and non-obvious inspirations for solutions	mechanism	2K_dev_1662
We report an empirical study demonstrating how crowds can generate domains of expertise and that showing people an abstract representation rather than the original problem helps them identify more distant domains	method	2K_dev_1662
	method	2K_dev_1662
However	purpose	2K_dev_1662
finding such `` outside-the-box { '' } inspirations is difficult	purpose	2K_dev_1662
particularly in large idea repositories such as the web	purpose	2K_dev_1662
because without guidance people select domains to search based on surface similarity to the problem 's domain	purpose	2K_dev_1662
	purpose	2K_dev_1662
Large graph datasets have caused renewed interest for graph partitioning	background	2K_dev_1663
	background	2K_dev_1663
	finding	2K_dev_1663
we introduce the idea of skew-resistant graph partitioning Skewresistant graph partitioning tries to mitigate skewness by taking the characteristics of both the target workload and the graph structure into consideration	mechanism	2K_dev_1663
	mechanism	2K_dev_1663
	method	2K_dev_1663
However	purpose	2K_dev_1663
existing well-studied graph partitioners often assume that vertices of the graph are always active during the computation	purpose	2K_dev_1663
which may lead to time-varying skewness for traversal-style graph workloads	purpose	2K_dev_1663
like Breadth First Search	purpose	2K_dev_1663
since they only explore part of the graph in each superstep	purpose	2K_dev_1663
Additionally	purpose	2K_dev_1663
existing solutions do not consider what vertices each partition will have ; as a result	purpose	2K_dev_1663
high-degree vertices may be concentrated into a few partitions	purpose	2K_dev_1663
causing imbalance	purpose	2K_dev_1663
Towards this	purpose	2K_dev_1663
where the objective is to create an initial partitioning that will `` hold well { '' } over time without suffering from skewness	purpose	2K_dev_1663
	purpose	2K_dev_1663
Current dialogue systems typically lack a variation of audio-visual feedback tokens	background	2K_dev_1664
Either they do not encompass feedback tokens at all	background	2K_dev_1664
or only support a limited set of stereotypical functions	background	2K_dev_1664
However	background	2K_dev_1664
this does not mirror the subtleties of spontaneous conversations	background	2K_dev_1664
	finding	2K_dev_1664
In this study	mechanism	2K_dev_1664
we devised an array of monomodal and multimodal binary comparison perception tests and experiments	mechanism	2K_dev_1664
This allowed us to investigate i ) which features ( amplitude	method	2K_dev_1664
frequency	method	2K_dev_1664
duration	method	2K_dev_1664
	method	2K_dev_1664
	method	2K_dev_1664
) of the visual feedback influences attentiveness perception ; ii ) whether visual or verbal backchannels are perceived to be more attentive iii ) whether the fusion of unimodal tokens with low perceived attentiveness increases the degree of perceived attentiveness compared to unimodal tokens with high perceived attentiveness taken alone ; iv ) the automatic ranking of audio-visual feedback token in terms of conveyed degree of attentiveness	method	2K_dev_1664
	method	2K_dev_1664
If we want to be able to build an artificial listener	purpose	2K_dev_1664
as a first step towards building an empathetic artificial agent	purpose	2K_dev_1664
we also need to be able to synthesize more subtle audio-visual feedback tokens	purpose	2K_dev_1664
to understand how different realisations of verbal and visual feedback tokens influence third-party perception of the degree of attentiveness	purpose	2K_dev_1664
	purpose	2K_dev_1664
A previous approach utilizes gaze duration and word rarity features to perform this detection	background	2K_dev_1665
However	background	2K_dev_1665
while this system can be used by trained users	background	2K_dev_1665
its performance is not sufficient during natural reading by untrained users	background	2K_dev_1665
	background	2K_dev_1665
The experimental results demonstrate that learning using SVMs and proposed eye movement features improves detection performance and that personalization further improves results	finding	2K_dev_1665
	finding	2K_dev_1665
This paper proposes a method by using eye-tracking features In this paper	mechanism	2K_dev_1665
we 1 ) apply support vector machines ( SVM ) with novel eye movement features that were not considered in the previous work and 2	mechanism	2K_dev_1665
) examine the effect of personalization	method	2K_dev_1665
as measured by F-measure	method	2K_dev_1665
to detect unknown words during natural reading of non-native language text	purpose	2K_dev_1665
Automatic emotion recognition plays a central role in the technologies underlying social robots	background	2K_dev_1666
affect-sensitive human computer interaction design and affect-aware tutors	background	2K_dev_1666
	background	2K_dev_1666
Finally	finding	2K_dev_1666
we present a detailed analysis of the most indicative behavioral cues for emotion recognition in children	finding	2K_dev_1666
In this paper	mechanism	2K_dev_1666
we introduce a newly collected multimodal emotion dataset of children between the ages of four and fourteen years old The dataset contains 1102 audio-visual clips annotated for 17 different emotional states : six basic emotions	mechanism	2K_dev_1666
neutral	mechanism	2K_dev_1666
valence and nine complex emotions including curiosity	mechanism	2K_dev_1666
uncertainty and frustration	mechanism	2K_dev_1666
	mechanism	2K_dev_1666
Our experiments compare unimodal and multimodal emotion recognition baseline models to enable future research on this topic	method	2K_dev_1666
	method	2K_dev_1666
Although there has been a considerable amount of research on automatic emotion recognition in adults	purpose	2K_dev_1666
emotion recognition in children has been understudied	purpose	2K_dev_1666
This problem is more challenging as children tend to fidget and move around more than adults	purpose	2K_dev_1666
leading to more self-occlusions and non-frontal head poses	purpose	2K_dev_1666
Also	purpose	2K_dev_1666
the lack of publicly available datasets for children with annotated emotion labels leads most researchers to focus on adults	purpose	2K_dev_1666
	purpose	2K_dev_1666
Cyber-attacks aimed at breaking into networks and bringing websites down appear to have become an every-day phenomenon	background	2K_dev_1667
	background	2K_dev_1667
	finding	2K_dev_1667
using which we summarize the major players and trends in DDoS cyber-attacks	finding	2K_dev_1667
We used DDoS attacks data shared by Arbor Networks	mechanism	2K_dev_1667
from June 2013 to Mar 2016	mechanism	2K_dev_1667
	mechanism	2K_dev_1667
We take a high-level view of attacks mostly considering aggregate country-to-country attacks	method	2K_dev_1667
but there is less clarity on where the attacks come from and who are the top targets	purpose	2K_dev_1667
to understand the cyber-attacks network	purpose	2K_dev_1667
Cyber-attacks are cheap	background	2K_dev_1668
easy to conduct and often pose little risk in terms of attribution	background	2K_dev_1668
but their impact could be lasting	background	2K_dev_1668
The low attribution is because tracing cyber-attacks is primitive in the current network architecture	background	2K_dev_1668
Moreover	background	2K_dev_1668
even when attribution is known	background	2K_dev_1668
the absence of enforcement provisions in international law makes cyber attacks tough to litigate	background	2K_dev_1668
and hence attribution is hardly a deterrent	background	2K_dev_1668
Rather than attributing attacks	background	2K_dev_1668
we can re-look at cyber-attacks as societal events associated with social	background	2K_dev_1668
political	background	2K_dev_1668
economic and cultural ( SPEC ) motivations	background	2K_dev_1668
Because it is possible to observe SPEC motives on the internet	background	2K_dev_1668
social media data could be valuable in understanding cyber attacks	background	2K_dev_1668
	background	2K_dev_1668
We find that	finding	2K_dev_1668
for some countries	finding	2K_dev_1668
the probability of attacks increases by up to 27\ % while experiencing negative sentiments from other nations	finding	2K_dev_1668
To verify our model	finding	2K_dev_1668
	finding	2K_dev_1668
b ) Using cyber-attacks trend and sentiments trend	mechanism	2K_dev_1668
we build a decision tree model to find attacks that could be related to extreme sentiments	mechanism	2K_dev_1668
	mechanism	2K_dev_1668
In this research	method	2K_dev_1668
we use sentiment in Twitter posts	method	2K_dev_1668
and Arbor Networks data we describe three examples in which cyber-attacks follow increased tension between nations	method	2K_dev_1668
as perceived in social media	method	2K_dev_1668
	method	2K_dev_1668
to observe country-to-country perceptions to build ground truth of country-to-country DDoS cyber-attacks	purpose	2K_dev_1668
Using this dataset	purpose	2K_dev_1668
this research makes three important contributions : a ) We evaluate the impact of heightened sentiments towards a country on the trend of cyber-attacks received by the country	purpose	2K_dev_1668
	purpose	2K_dev_1668
Increasing proliferation of mobile and online social networking platforms have given us unprecedented opportunity to observe and study social interactions at a fine temporal scale	background	2K_dev_1669
A collection of all such social interactions among a group of individuals ( or agents ) observed over an interval of time is referred to as a temporally-detailed ( TD ) social network	background	2K_dev_1669
A TD social network opens up the opportunity to explore TD questions on the underlying social system	background	2K_dev_1669
e	background	2K_dev_1669
g	background	2K_dev_1669
	background	2K_dev_1669
`` How is the betweenness centrality of an individual changing with time ? { '' } To this end	background	2K_dev_1669
related work has proposed temporal extensions of centrality metrics ( e	background	2K_dev_1669
g	background	2K_dev_1669
	background	2K_dev_1669
betweenness and closeness )	background	2K_dev_1669
	background	2K_dev_1669
We prove the correctness and completeness of our algorithm	finding	2K_dev_1669
shows that the proposed algorithm out performs the alternatives by a wide margin	finding	2K_dev_1669
	finding	2K_dev_1669
To this end	mechanism	2K_dev_1669
we propose a novel computational paradigm called epoch-point based techniques Using the concept of epoch-points	mechanism	2K_dev_1669
we develop a novel algorithm for computing shortest path based centrality metric such as betweenness on a TD social network	mechanism	2K_dev_1669
	mechanism	2K_dev_1669
Our experimental analysis	method	2K_dev_1669
However	purpose	2K_dev_1669
scalable computation of these metrics for long time-intervals is challenging	purpose	2K_dev_1669
This is due to the non-stationary ranking of shortest paths ( the underlying structure of betweenness and closeness ) between a pair of nodes which violates the assumptions of classical dynamic programming based techniques	purpose	2K_dev_1669
for addressing the non-stationarity challenge of TD social networks	purpose	2K_dev_1669
	purpose	2K_dev_1669
Software architects inhabit a complex	background	2K_dev_1670
rapidly evolving technological landscape	background	2K_dev_1670
These must be overcome by future research in order to make our vision of curated knowledge bases a reality	background	2K_dev_1670
	background	2K_dev_1670
We report in this paper on the initial results of using supervised machine learning to assist with knowledge base curation	finding	2K_dev_1670
Our results show immense promise in recommending Web pages that are highly relevant to curators	finding	2K_dev_1670
We also describe the major obstacles	finding	2K_dev_1670
both practical and scientific	finding	2K_dev_1670
that our work has uncovered	finding	2K_dev_1670
	finding	2K_dev_1670
we envisage an ecosystem of curated	mechanism	2K_dev_1670
automatically updated knowledge bases These knowledge bases would emulate engineering handbooks that are commonly found in other engineering disciplines As a first step towards this vision	mechanism	2K_dev_1670
we have built a curated knowledge base for comparing distributed databases based on a semantically defined feature taxonomy	mechanism	2K_dev_1670
	mechanism	2K_dev_1670
	method	2K_dev_1670
An ever growing collection of competing architecturally significant technologies	purpose	2K_dev_1670
ranging from distributed databases to middleware and cloud platforms	purpose	2K_dev_1670
makes rigorously comparing alternatives and selecting appropriate solutions a daunting engineering task	purpose	2K_dev_1670
To address this problem that enable straightforward and streamlined technical comparisons of related products	purpose	2K_dev_1670
	purpose	2K_dev_1670
Large-scale deep learning requires huge computational resources to train a multi-layer neural network	background	2K_dev_1671
Recent systems propose using 100s to 1000s of machines to train networks with tens of layers and billions of connections	background	2K_dev_1671
We show that GeePS enables a state-of-the-art single-node GPU implementation to scale well	finding	2K_dev_1671
such as to 13 times the number of training images processed per second on 16 machines ( relative to the original optimized single-node code )	finding	2K_dev_1671
Moreover	finding	2K_dev_1671
GeePS achieves a higher training throughput with just four GPU machines than that a state-of-the-art CPU-only system achieves with 108 machines	finding	2K_dev_1671
	finding	2K_dev_1671
This paper describes a new parameter server	mechanism	2K_dev_1671
called GeePS overcoming these obstacles	mechanism	2K_dev_1671
	mechanism	2K_dev_1671
	method	2K_dev_1671
While the computation involved can be done more efficiently on GPUs than on more traditional CPU cores	purpose	2K_dev_1671
training such networks on a single GPU is too slow and training on distributed GPUs can be inefficient	purpose	2K_dev_1671
due to data movement overheads	purpose	2K_dev_1671
GPU stalls	purpose	2K_dev_1671
and limited GPU memory	purpose	2K_dev_1671
that supports scalable deep learning across GPUs distributed among multiple machines	purpose	2K_dev_1671
	purpose	2K_dev_1671
Machine learning ( ML ) algorithms are commonly applied to big data	background	2K_dev_1672
using distributed systems that partition the data across machines and allow each machine to read and update all ML model parameters - a strategy known as data parallelism	background	2K_dev_1672
An alternative and complimentary strategy	background	2K_dev_1672
model parallelism	background	2K_dev_1672
partitions the model parameters for non-shared parallel access and updates	background	2K_dev_1672
and may periodically repartition the parameters to facilitate communication	background	2K_dev_1672
Model parallelism is motivated by two challenges that data-parallelism does not usually address : ( 1 ) parameters may be dependent	background	2K_dev_1672
thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure ; ( 2 ) model parameters converge at different rates	background	2K_dev_1672
thus a small subset of parameters can bottleneck ML algorithm completion	background	2K_dev_1672
	background	2K_dev_1672
we show that SchMP programs running on STRADS outperform non-model-parallel ML implementations : for example	finding	2K_dev_1672
SchMP LDA and SchMP Lasso respectively achieve 10x and 5x faster convergence than recent	finding	2K_dev_1672
well-established baselines	finding	2K_dev_1672
	finding	2K_dev_1672
We propose scheduled model parallelism ( SchMP )	mechanism	2K_dev_1672
a programming approach by efficiently scheduling parameter updates	mechanism	2K_dev_1672
taking into account parameter dependencies and uneven convergence	mechanism	2K_dev_1672
To support SchMP at scale	mechanism	2K_dev_1672
we develop a distributed framework STRADS which optimizes the throughput of SchMP programs	mechanism	2K_dev_1672
and benchmark four common ML applications written as SchMP programs : LDA topic modeling	mechanism	2K_dev_1672
matrix factorization	mechanism	2K_dev_1672
sparse least-squares ( Lasso ) regression and sparse logistic regression By improving ML progress per iteration through SchMP programming whilst improving iteration throughput through STRADS	mechanism	2K_dev_1672
	method	2K_dev_1672
that improves ML algorithm convergence speed	purpose	2K_dev_1672
Today 's cellular core	background	2K_dev_1673
which connects the radio access network to the Internet	background	2K_dev_1673
relies on fixed hardware appliances placed at a few dedicated locations and uses relatively static routing policies	background	2K_dev_1673
As such	background	2K_dev_1673
today 's core design has key limitations-it induces inefficient provisioning tradeoffs and is poorly equipped to handle overload	background	2K_dev_1673
failure scenarios	background	2K_dev_1673
and diverse application requirements	background	2K_dev_1673
To address these limitations	background	2K_dev_1673
ongoing efforts envision `` clean slate { '' } solutions that depart from cellular standards and routing protocols ; e	background	2K_dev_1673
g	background	2K_dev_1673
	background	2K_dev_1673
via programmable switches at base stations and per-flow SDN-like orchestration	background	2K_dev_1673
	background	2K_dev_1673
show that KLEIN can scale to billions of devices and is close to optimal for wide variety of traffic and deployment parameters	finding	2K_dev_1673
	finding	2K_dev_1673
We propose KLEIN	mechanism	2K_dev_1673
a design that stays within the confines of current cellular standards and addresses the above limitations by combining network functions virtualization with smart resource management	mechanism	2K_dev_1673
We address key challenges w	mechanism	2K_dev_1673
r	mechanism	2K_dev_1673
t	mechanism	2K_dev_1673
scalability and responsiveness in realizing KLEIN via backwards-compatible orchestration mechanisms	mechanism	2K_dev_1673
	mechanism	2K_dev_1673
Our evaluations through data-driven simulations and real prototype experiments using OpenAirInterface	method	2K_dev_1673
The driving question of this work is to ask if a clean-slate redesign is necessary and if not	purpose	2K_dev_1673
how can we design a flexible cellular core that is minimally disruptive	purpose	2K_dev_1673
	purpose	2K_dev_1673
Mutual adaptation is critical for effective team collaboration	background	2K_dev_1674
	background	2K_dev_1674
indicate that the proposed formalism can significantly improve the effectiveness of human-robot teams	finding	2K_dev_1674
while human subject ratings on the robot performance and trust are comparable to those achieved by cross training	finding	2K_dev_1674
a state-ofthe-art human-robot team training practice	finding	2K_dev_1674
	finding	2K_dev_1674
This paper presents a formalism We propose the bounded-memory adaptation model ( BAM )	mechanism	2K_dev_1674
based on a bounded memory assumption	mechanism	2K_dev_1674
We integrate BAM into a partially observable stochastic model	mechanism	2K_dev_1674
When the human is adaptive	mechanism	2K_dev_1674
the robot will guide the human towards a new	mechanism	2K_dev_1674
optimal collaborative strategy unknown to the human in advance	mechanism	2K_dev_1674
When the human is not willing to change their strategy	mechanism	2K_dev_1674
the robot adapts to the human in order to retain human trust	mechanism	2K_dev_1674
	mechanism	2K_dev_1674
Human subject experiments	method	2K_dev_1674
for human-robot mutual adaptation in collaborative tasks	purpose	2K_dev_1674
which captures human adaptive behaviors which enables robot adaptation to the human	purpose	2K_dev_1674
	purpose	2K_dev_1674
This is the first demonstration that robot appearance affects people 's moral judgments about robots	background	2K_dev_1675
	background	2K_dev_1675
we found further evidence for a previously discovered Human-Robot ( HR ) asymmetry in moral judgments : Importantly	finding	2K_dev_1675
we found that people 's representation of the `` robot { '' } making these moral decisions appears to be one of a mechanical robot	finding	2K_dev_1675
people showed the HR asymmetry only when making judgments about a mechanical-looking robot	finding	2K_dev_1675
not a humanoid robot	finding	2K_dev_1675
	mechanism	2K_dev_1675
In three studies For when we manipulated the pictorial display of a verbally described robot	method	2K_dev_1675
	method	2K_dev_1675
that people blame robots more for inaction than action in a moral dilemma but blame humans more for action than inaction in the identical dilemma ( where inaction allows four persons to die and action sacrifices one to save the four )	purpose	2K_dev_1675
	purpose	2K_dev_1675
When interacting with robots deployed in the open world	background	2K_dev_1676
people may often attempt to engage with them in a playful manner or test their competencies	background	2K_dev_1676
and frame research directions and design implications for robots deployed in the wild	background	2K_dev_1676
	background	2K_dev_1676
We report on a pilot field-study We discuss early results from this initial study	finding	2K_dev_1676
	mechanism	2K_dev_1676
We have been studying the intentions of everyday users in their engagement with a long-lived robot system that provides directions within an office building	method	2K_dev_1676
exploring the use of direct queries to elicit the sincerity of user requests	method	2K_dev_1676
in terms of their actual need for directions	method	2K_dev_1676
	method	2K_dev_1676
Such engagements are often associated with language and behaviors that fall outside of designed task capabilities and can lead to interaction failures	purpose	2K_dev_1676
Detecting when users are driven by play and curiosity can help a robot to understand why some interactions are breaking down	purpose	2K_dev_1676
respond more appropriately by conveying its capabilities to its users	purpose	2K_dev_1676
and enhance perceptions of its situational awareness and social intelligence	purpose	2K_dev_1676
	purpose	2K_dev_1676
2D alignment of face images works well provided images are frontal or nearly so and pitch and yaw remain modest	background	2K_dev_1677
In spontaneous facial behavior	background	2K_dev_1677
these constraints often are violated by moderate to large head rotation	background	2K_dev_1677
3D alignment from 2D video has been proposed as a solution	background	2K_dev_1677
The results suggest that 3D alignment from 2D video is feasible on a wide range of face orientations	background	2K_dev_1677
Differences among methods are considered and suggest directions for further research	background	2K_dev_1677
We report results for four that provided necessary technical descriptions of their methods	finding	2K_dev_1677
The leading approach achieved prediction consistency error of 3	finding	2K_dev_1677
48\ %	finding	2K_dev_1677
Corresponding result for the lowest ranked approach was 5	finding	2K_dev_1677
9\ %	finding	2K_dev_1677
	finding	2K_dev_1677
The 3D Face Alignment in the Wild ( 3DFAW ) Challenge	mechanism	2K_dev_1677
presented for the first time	mechanism	2K_dev_1677
created an annotated corpus of over 23000 multi-view images from four sources together with 3D annotation	mechanism	2K_dev_1677
	mechanism	2K_dev_1677
made training and validation sets available to investigators	method	2K_dev_1677
and invited them to test their algorithms on an independent test-set	method	2K_dev_1677
Eight teams accepted the challenge and submitted test results	method	2K_dev_1677
	method	2K_dev_1677
A number of approaches have been explored	purpose	2K_dev_1677
but comparisons among them have been hampered by the lack of common test data	purpose	2K_dev_1677
To enable comparisons among alternative methods	purpose	2K_dev_1677
For each participating tracker	background	2K_dev_1678
a short description is provided in the Appendix	background	2K_dev_1678
	finding	2K_dev_1678
with a large number of trackers being published at major computer vision conferences and journals in the recent years	finding	2K_dev_1678
The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date	finding	2K_dev_1678
The VOT2016 goes beyond its predecessors by ( i ) introducing a new semi-automatic ground truth bounding box annotation methodology and ( ii ) extending the evaluation system with the no-reset experiment	mechanism	2K_dev_1678
	mechanism	2K_dev_1678
Results of 70 trackers are presented	method	2K_dev_1678
The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance	purpose	2K_dev_1678
	purpose	2K_dev_1678
Much robotics research has focused on intent-expressive ( legible ) motion	background	2K_dev_1679
	background	2K_dev_1679
that the produced motions are significantly more legible compared to those generated assuming an omniscient observer	finding	2K_dev_1679
	finding	2K_dev_1679
In this work	mechanism	2K_dev_1679
we free robots from this assumption and introduce the notion of an observer with a specific point of view into legibility optimization	mechanism	2K_dev_1679
In doing so	mechanism	2K_dev_1679
we account for two factors : ( 1 ) depth uncertainty induced by a particular viewpoint	mechanism	2K_dev_1679
and ( 2 ) occlusions along the motion	mechanism	2K_dev_1679
during which ( part of ) the robot is hidden behind some object	mechanism	2K_dev_1679
We propose viewpoint and occlusion models that enable autonomous generation of viewpoint-based legible motions	mechanism	2K_dev_1679
and	mechanism	2K_dev_1679
show through large-scale user studies	method	2K_dev_1679
However	purpose	2K_dev_1679
algorithms that can autonomously generate legible motion have implicitly made the strong assumption of an omniscient observer	purpose	2K_dev_1679
with access to the robot 's configuration as it changes across time	purpose	2K_dev_1679
In reality	purpose	2K_dev_1679
human observers have a particular viewpoint	purpose	2K_dev_1679
which biases the way they perceive the motion	purpose	2K_dev_1679
	purpose	2K_dev_1679
Nonverbal behaviors play an important role in communication for both humans and social robots	background	2K_dev_1680
However	background	2K_dev_1680
adding contextually appropriate animations by hand is time consuming and does not scale well	background	2K_dev_1680
Previous researchers have developed automated systems for inserting animations based on utterance text	background	2K_dev_1680
yet these systems lack human understanding of social context and are still being improved	background	2K_dev_1680
	background	2K_dev_1680
Results showed untrained workers are capable of providing reasonable labeling of semantic information and that emotional expressions derived from the labels were rated more highly than control videos	finding	2K_dev_1680
More study is needed to determine the effects of emphasis labels	finding	2K_dev_1680
	mechanism	2K_dev_1680
To test this approach	method	2K_dev_1680
untrained workers from Mechanical Turk labeled semantic information	method	2K_dev_1680
specifically emotion and emphasis	method	2K_dev_1680
for each utterance	method	2K_dev_1680
which was used to automatically add animations	method	2K_dev_1680
Videos of a robot performing the animated dialogue were rated by a second set of participants	method	2K_dev_1680
This work proposes a middle ground where untrained human workers label semantic information	purpose	2K_dev_1680
which is input to an automatic system to produce appropriate gestures	purpose	2K_dev_1680
	purpose	2K_dev_1680
Morphable face models are a powerful tool	background	2K_dev_1681
	background	2K_dev_1681
we show that our method generalizes to both webcam and high-quality camera images	finding	2K_dev_1681
and outperforms a state-of-the-art CNN method achieving a gaze estimation accuracy of 9	finding	2K_dev_1681
44 degrees in a challenging user-independent scenario	finding	2K_dev_1681
	finding	2K_dev_1681
We present a new multi-part model of the eye that includes a morphable model of the facial eye region	mechanism	2K_dev_1681
as well as an anatomy-based eyeball model	mechanism	2K_dev_1681
It is the first morphable model that accurately	mechanism	2K_dev_1681
since it was built from high-quality head scans	mechanism	2K_dev_1681
It is also the first	mechanism	2K_dev_1681
since we treat it as a separate part	mechanism	2K_dev_1681
To showcase our model we present a new method for illumination-and head-pose invariant gaze estimation from a single RGB image	mechanism	2K_dev_1681
We fit our model to an image through analysis-by-synthesis	mechanism	2K_dev_1681
solving for eye region shape	mechanism	2K_dev_1681
texture	mechanism	2K_dev_1681
eyeball pose	mechanism	2K_dev_1681
and illumination simultaneously	mechanism	2K_dev_1681
The fitted eyeball pose parameters are then used to estimate gaze direction	mechanism	2K_dev_1681
	mechanism	2K_dev_1681
Through evaluation on two standard datasets	method	2K_dev_1681
but have previously failed to model the eye accurately due to complexities in its material and motion captures eye region shape to allow independent eyeball movement	purpose	2K_dev_1681
Computer vision has a great potential to help our daily lives by searching for lost keys	background	2K_dev_1682
watering flowers or reminding us to take a pill To succeed with such tasks	background	2K_dev_1682
computer vision methods need to be trained from real and diverse examples of our daily dynamic scenes	background	2K_dev_1682
While most of such scenes are not particularly exciting	background	2K_dev_1682
they typically do not appear on YouTube	background	2K_dev_1682
in movies or TV broadcasts We believe that the realism	background	2K_dev_1682
diversity	background	2K_dev_1682
and casual nature of this dataset will present unique challenges and new opportunities for computer vision community	background	2K_dev_1682
	background	2K_dev_1682
provide baseline results for several tasks including action recognition and automatic description generation	finding	2K_dev_1682
	finding	2K_dev_1682
We propose a novel Hollywood in Homes approach Instead of shooting videos in the lab	mechanism	2K_dev_1682
we ensure diversity by distributing and crowdsourcing the whole process of video creation from script writing to video recording and annotation	mechanism	2K_dev_1682
Following this procedure we collect a new dataset	mechanism	2K_dev_1682
Charades	mechanism	2K_dev_1682
with hundreds of people recording videos in their own homes	mechanism	2K_dev_1682
acting out casual everyday activities	mechanism	2K_dev_1682
The dataset is composed of 9848 annotated videos with an average length of 30 s	mechanism	2K_dev_1682
showing activities of 267 people from three continents	mechanism	2K_dev_1682
Each video is annotated by multiple free-text descriptions	mechanism	2K_dev_1682
action labels	mechanism	2K_dev_1682
action intervals and classes of interacted objects	mechanism	2K_dev_1682
In total	mechanism	2K_dev_1682
Charades provides 27847 video descriptions	mechanism	2K_dev_1682
66500 temporally localized intervals for 157 action classes and 41104 labels for 46 object classes	mechanism	2K_dev_1682
	mechanism	2K_dev_1682
Using this rich data	method	2K_dev_1682
we evaluate and	method	2K_dev_1682
So how do we collect sufficiently many diverse but boring samples representing our lives ? to collect such data	purpose	2K_dev_1682
	purpose	2K_dev_1682
Previously	background	2K_dev_1683
even non-constructively	background	2K_dev_1683
the largest deletion fraction known to be correctable with positive rate was 1 - Theta ( 1/root k )	background	2K_dev_1683
and around 0	background	2K_dev_1683
17 for the binary case	background	2K_dev_1683
	background	2K_dev_1683
For any fixed k > 0 2	mechanism	2K_dev_1683
we construct a family of codes over alphabet of size k with positive rate	mechanism	2K_dev_1683
	mechanism	2K_dev_1683
	method	2K_dev_1683
We consider codes over fixed alphabets against worst case symbol deletions	purpose	2K_dev_1683
	purpose	2K_dev_1683
Current approaches in computer vision use category labels from datasets such as ImageNet to train ConvNets	background	2K_dev_1684
For example	background	2K_dev_1684
babies push objects	background	2K_dev_1684
poke them	background	2K_dev_1684
put them in their mouth and throw them to learn representations	background	2K_dev_1684
	background	2K_dev_1684
and show improvements compared to learning without external data	finding	2K_dev_1684
Finally	finding	2K_dev_1684
on the task of instance retrieval	finding	2K_dev_1684
our network outperforms the ImageNet network on recall @ 1 by 3\ %	finding	2K_dev_1684
Towards this goal	mechanism	2K_dev_1684
we build one of the first systems on a Baxter platform that pushes	mechanism	2K_dev_1684
pokes	mechanism	2K_dev_1684
grasps and observes objects in a tabletop environment It uses four different types of physical interactions to collect more than 130K datapoints	mechanism	2K_dev_1684
with each datapoint providing supervision to a shared ConvNet architecture allowing us to learn visual representations We show the quality of learned representations by observing neuron activations and performing nearest neighbor retrieval on this learned representation	mechanism	2K_dev_1684
Quantitatively	method	2K_dev_1684
we evaluate our learned ConvNet on image classification tasks	method	2K_dev_1684
What is the right supervisory signal to train visual representations ? However	purpose	2K_dev_1684
in case of biological agents	purpose	2K_dev_1684
visual representation learning does not require millions of semantic labels	purpose	2K_dev_1684
We argue that biological agents use physical interactions with the world to learn visual representations unlike current vision systems which just use passive observations ( images and videos downloaded from web )	purpose	2K_dev_1684
	purpose	2K_dev_1684
Discrete energy minimization is widely-used in computer vision and machine learning for problems such as MAP inference in graphical models The problem	background	2K_dev_1685
in general	background	2K_dev_1685
is notoriously intractable	background	2K_dev_1685
and finding the global optimal solution is known to be NP-hard This paper can help vision researchers to select an appropriate model for an application or guide them in designing new algorithms	background	2K_dev_1685
	background	2K_dev_1685
Specifically	finding	2K_dev_1685
we show that general energy minimization	finding	2K_dev_1685
even in the 2-label pairwise case	finding	2K_dev_1685
and planar energy minimization with three or more labels are exp-APX-complete	finding	2K_dev_1685
This finding rules out the existence of any approximation algorithm with a sub-exponential approximation ratio in the input size for these two problems	finding	2K_dev_1685
including constant factor approximations	finding	2K_dev_1685
Moreover	mechanism	2K_dev_1685
we collect and review the computational complexity of several subclass problems and arrange them on a complexity scale consisting of three major complexity classes - PO	mechanism	2K_dev_1685
APX	mechanism	2K_dev_1685
and exp-APX	mechanism	2K_dev_1685
corresponding to problems that are solvable	mechanism	2K_dev_1685
approximable	mechanism	2K_dev_1685
and inapproximable in polynomial time	mechanism	2K_dev_1685
Problems in the first two complexity classes can serve as alternative tractable formulations to the inapproximable ones	mechanism	2K_dev_1685
	mechanism	2K_dev_1685
	method	2K_dev_1685
However	purpose	2K_dev_1685
is it possible to approximate this problem with a reasonable ratio bound on the solution quality in polynomial time ? We show in this paper that the answer is no	purpose	2K_dev_1685
	purpose	2K_dev_1685
What happens if one pushes a cup sitting on a table toward the edge of the table ? How about pushing a desk against a wall ?	background	2K_dev_1686
show that the challenging task of predicting long-term movements of objects as their reaction to external forces is possible from a single image The code and dataset are available at : http : //allenai	finding	2K_dev_1686
org/plato/forces	finding	2K_dev_1686
	finding	2K_dev_1686
Doing so entails reasoning about scene geometry	mechanism	2K_dev_1686
objects	mechanism	2K_dev_1686
their attributes	mechanism	2K_dev_1686
and the physical rules that govern the movements of objects	mechanism	2K_dev_1686
We design a deep neural network model that learns long-term sequential dependencies of object movements while taking into account the geometry and appearance of the scene by combining Convolutional and Recurrent Neural Networks	mechanism	2K_dev_1686
Training our model requires a large-scale dataset of object movements caused by external forces	mechanism	2K_dev_1686
To build a dataset of forces in scenes	mechanism	2K_dev_1686
we reconstructed all images in SUN RGB-D dataset in a physics simulator to estimate the physical movements of objects caused by external forces applied to them Our Forces in Scenes ( ForScene ) dataset contains 65000 object movements in 3D which represent a variety of external forces applied to different types of objects	mechanism	2K_dev_1686
	mechanism	2K_dev_1686
Our experimental evaluations	method	2K_dev_1686
In this paper	purpose	2K_dev_1686
we study the problem of understanding the movements of objects as a result of applying external forces to them For a given force vector applied to a specific location in an image	purpose	2K_dev_1686
our goal is to predict long-term sequential movements caused by that force	purpose	2K_dev_1686
	purpose	2K_dev_1686
New IT functions have greatly increased the amount of in-car information delivered to drivers	background	2K_dev_1687
Although valuable	background	2K_dev_1687
that information can distract drivers when delivered during vehicle operation	background	2K_dev_1687
By inferring driver state from sensor data	background	2K_dev_1687
prior research has shown that it can accurately identify opportune moments to deliver information	background	2K_dev_1687
With these results	background	2K_dev_1687
researchers can then build information delivery systems that can deliver information to drivers both when they are interruptible and when they find the information valuable	background	2K_dev_1687
	background	2K_dev_1687
we identified driving situations when each of the in-car information items is highly valuable	finding	2K_dev_1687
and verified these situations Results from our study offer important insights for understanding the diversity of drivers ' experiences about the value of in-car information and the ability to determine situations in which this information is valuable to drivers	finding	2K_dev_1687
	mechanism	2K_dev_1687
To answer this question	method	2K_dev_1687
we conducted a series of surveys and interviews and compiled a list of representative in-car information items and context factors that affect the importance of these items By combining and exploring those context factors through a large online survey of drivers	method	2K_dev_1687
Lastly	method	2K_dev_1687
we examined what technology is available for detecting these driving situations	method	2K_dev_1687
and which situations require further advanced technologies for detection	method	2K_dev_1687
Now that we know when to best deliver information	purpose	2K_dev_1687
it raises the question : what information should we deliver at those interruptible moments ?	purpose	2K_dev_1687
In a given scene	background	2K_dev_1688
humans can easily predict a set of immediate future events that might happen	background	2K_dev_1688
However	background	2K_dev_1688
pixel-level anticipation in computer vision is difficult because machine learning struggles with the ambiguity in predicting the future	background	2K_dev_1688
We show that our method predicts events in a variety of scenes and can produce multiple different predictions for an ambiguous future	finding	2K_dev_1688
We also find that our method learns a representation that is applicable to semantic vision tasks	finding	2K_dev_1688
We propose a conditional variational autoencoder as a solution to this problem In this framework	mechanism	2K_dev_1688
direct inference from the image shapes the distribution of possible trajectories while latent variables encode information that is not available in the image	mechanism	2K_dev_1688
	mechanism	2K_dev_1688
	method	2K_dev_1688
In this paper	purpose	2K_dev_1688
we focus on predicting the dense trajectory of pixels in a scene-what will move in the scene	purpose	2K_dev_1688
where it will travel	purpose	2K_dev_1688
and how it will deform over the course of one second	purpose	2K_dev_1688
	purpose	2K_dev_1688
There is a growing interest in behavior based biometrics	background	2K_dev_1689
Although biometric data has considerable variations for an individual and may be faked	background	2K_dev_1689
yet the combination of such `weak experts ' can be rather strong	background	2K_dev_1689
A remotely detectable component is gaze direction estimation and thus	background	2K_dev_1689
eye movement patterns	background	2K_dev_1689
	background	2K_dev_1689
We show that it improves the precision of gaze direction estimation algorithms considerably	finding	2K_dev_1689
	finding	2K_dev_1689
Here	mechanism	2K_dev_1689
we present a novel personalization method which does not require a precise calibration setup	mechanism	2K_dev_1689
can be non-obtrusive	mechanism	2K_dev_1689
is fast and easy to use The method is convenient ; we exploit 3D face model reconstruction for the enrichment of a small number of collected data artificially	mechanism	2K_dev_1689
	mechanism	2K_dev_1689
	method	2K_dev_1689
for gaze estimation systems	purpose	2K_dev_1689
Software architecture modeling is important for analyzing system quality attributes	background	2K_dev_1690
particularly security	background	2K_dev_1690
However	background	2K_dev_1690
such analyses often assume that the architecture is completely known in advance	background	2K_dev_1690
In many modern domains	background	2K_dev_1690
especially those that use plugin-based frameworks	background	2K_dev_1690
it is not possible to have such a complete model because the software system continuously changes	background	2K_dev_1690
The Android mobile operating system is one such framework	background	2K_dev_1690
where users can install and uninstall apps at run time	background	2K_dev_1690
that indicates that the architecture can be amenable for use throughout the system 's lifetime	finding	2K_dev_1690
In this paper	mechanism	2K_dev_1690
we describe a formal architecture style We illustrate the use of the style with two security analyses : a predicate-based approach defined over architectural structure that can detect some common security vulnerabilities	mechanism	2K_dev_1690
and inter-app permission leakage determined by model checking We also show how the evolving architecture of an Android device can be obtained by analysis of the apps on a device	mechanism	2K_dev_1690
and	mechanism	2K_dev_1690
provide some performance evaluation	method	2K_dev_1690
We need ways to model and analyze such architectures that strike a balance between supporting the dynamism of the underlying platforms and enabling analysis	purpose	2K_dev_1690
particularly throughout a system 's lifetime	purpose	2K_dev_1690
that captures the modifiable architectures of Android systems	purpose	2K_dev_1690
and that supports security analysis as a system evolves	purpose	2K_dev_1690
Language usage behavior of users evolves over time	background	2K_dev_1691
as they interact on social media such as Twitter	background	2K_dev_1691
	background	2K_dev_1691
Our work is applicable in predicting activity and influence	finding	2K_dev_1691
interest evolution	finding	2K_dev_1691
job change and community change expected to happen to a user	finding	2K_dev_1691
in future	finding	2K_dev_1691
We propose Man-O-Meter	mechanism	2K_dev_1691
a framework We model the evolution using a combination of three dimensions : ( a ) time	mechanism	2K_dev_1691
( b ) content ( topics ) and ( c ) influence flow over social relationships We assert the goodness of our approach	mechanism	2K_dev_1691
by predicting ranks of experts	mechanism	2K_dev_1691
with respect to their influence in their respective expertise category	mechanism	2K_dev_1691
using the change in language used in time	mechanism	2K_dev_1691
	mechanism	2K_dev_1691
We apply our framework on 2	method	2K_dev_1691
273 influential microbloggers on Twitter	method	2K_dev_1691
across 62 categories	method	2K_dev_1691
spanning over 10 domains	method	2K_dev_1691
	method	2K_dev_1691
We study the evolution of language usage behavior of individuals	purpose	2K_dev_1691
across topics	purpose	2K_dev_1691
on microblogs	purpose	2K_dev_1691
to model such evolution	purpose	2K_dev_1691
	purpose	2K_dev_1691
Wicks et al	background	2K_dev_1692
conducted a number of ablation experiments on a population of worms in which one or more of the neurons in the TW circuit are surgically ablated ( removed )	background	2K_dev_1692
	background	2K_dev_1692
The Wicks et al	finding	2K_dev_1692
model has a number of parameters	finding	2K_dev_1692
and we demonstrate that the various TW responses and their probability of occurrence in a population of worms can be viewed as a problem of parameter uncertainty	finding	2K_dev_1692
The results we obtain are a significant extension of those of Wicks et al ( 1996 )	finding	2K_dev_1692
who equip their model with fixed parameter values that reproduce a single TW response	finding	2K_dev_1692
We show that our technique can be used to correctly estimate TW responseprobabilities for four of these ablation groups	finding	2K_dev_1692
We also use our technique to predict TW response behavior for two ablation groups not previously considered by Wicks et al	finding	2K_dev_1692
	finding	2K_dev_1692
of a ( nonlinear ODE ) model of a neural circuit in Caeorhabditis elegans ( C	mechanism	2K_dev_1692
elegans )	mechanism	2K_dev_1692
the common roundworm	mechanism	2K_dev_1692
Our approach to this problem rests on encoding each TW response as a hybrid automaton with parametric uncertainty	mechanism	2K_dev_1692
In contrast	mechanism	2K_dev_1692
our technique allow us to more thoroughly explore the models parameter space using statistical sampling theory	mechanism	2K_dev_1692
identifying in the process the distribution of TW responses	mechanism	2K_dev_1692
	mechanism	2K_dev_1692
a probabilistic reachability analysis In particular	method	2K_dev_1692
we consider Tap Withdrawal ( TW )	method	2K_dev_1692
a reflexive behavior exhibited by a C	method	2K_dev_1692
elegans worm in response to vibrating the surface on which it is moving Specially	method	2K_dev_1692
we perform boundedtime reachability analysis on the TW circuit model of Wicks et al	method	2K_dev_1692
( 1996 ) to estimate the probability of various TW responses We then perform probabilistic reachability analysis on these automata using a technique that combines a delta-decision procedure with statistical tests	method	2K_dev_1692
	method	2K_dev_1692
We present The neural circuit underlying this response is the subject of this investigation	purpose	2K_dev_1692
	purpose	2K_dev_1692
Problems of this nature arise in formal verification of continuous and hybrid dynamical systems	background	2K_dev_1693
where there is an increasing need for methods to expedite formal proofs	background	2K_dev_1693
we discuss and illustrate certain classes of problems where this relationship is interesting	background	2K_dev_1693
	background	2K_dev_1693
The relationship between increased deductive power and running time performance of the proof rules is far from obvious	finding	2K_dev_1693
	mechanism	2K_dev_1693
We study the trade-off between proof rule generality and practical performance and evaluate our theoretical observations on a set of benchmarks	method	2K_dev_1693
	method	2K_dev_1693
This paper studies sound proof rules for checking positive invariance of algebraic and semi-algebraic sets	purpose	2K_dev_1693
that is	purpose	2K_dev_1693
sets satisfying polynomial equalities and those satisfying finite boolean combinations of polynomial equalities and inequalities	purpose	2K_dev_1693
under the flow of polynomial ordinary differential equations	purpose	2K_dev_1693
	purpose	2K_dev_1693
Suppose you are a teacher	background	2K_dev_1694
and have to convey a set of object-property pairs ( 'lions eat meat ' )	background	2K_dev_1694
A good teacher will convey a lot of information	background	2K_dev_1694
with little effort on the student side	background	2K_dev_1694
What is the best and most intuitive way to convey this information to the student	background	2K_dev_1694
without the student being overwhelmed ?	background	2K_dev_1694
it is effective	finding	2K_dev_1694
achieving excellent results both with respect to our proposed metric	finding	2K_dev_1694
but also with respect to encoding length demonstrate the effectiveness of GROUPNTEACH	finding	2K_dev_1694
	finding	2K_dev_1694
We also design an algorithm	mechanism	2K_dev_1694
GROUPNTEACH	mechanism	2K_dev_1694
for this problem	mechanism	2K_dev_1694
Our proposed GROUPNTEACH is scalable ( near-linear in the dataset size ) ; and it is intuitive	mechanism	2K_dev_1694
conforming to wellknown educational principles	mechanism	2K_dev_1694
	mechanism	2K_dev_1694
on real data	method	2K_dev_1694
Experiments on real and synthetic datasets	method	2K_dev_1694
A related	purpose	2K_dev_1694
harder problem is : how can we assign a numerical score to each lesson plan ( i	purpose	2K_dev_1694
e	purpose	2K_dev_1694
	purpose	2K_dev_1694
way of conveying information ? Here	purpose	2K_dev_1694
we give a formal definition of this problem of forming learning units and we provide a metric for comparing different approaches based on information theory	purpose	2K_dev_1694
	purpose	2K_dev_1694
Recent research has improved our understanding of how to create strong	background	2K_dev_1695
memorable text passwords	background	2K_dev_1695
and suggest ways to ease password entry for mobile users	background	2K_dev_1695
We find that creating passwords on mobile devices takes significantly longer and is more error prone and frustrating	finding	2K_dev_1695
Passwords created on mobile devices are also weaker	finding	2K_dev_1695
but only against attackers who can make more than 10 ( 13 ) guesses	finding	2K_dev_1695
We find that the effects of password policies differ between the desktop and mobile environments	finding	2K_dev_1695
	finding	2K_dev_1695
	mechanism	2K_dev_1695
We compare the strength and usability of passwords created and used on mobile devices with those created and used on desktops and laptops	method	2K_dev_1695
while varying password policy requirements and input methods	method	2K_dev_1695
	method	2K_dev_1695
However	purpose	2K_dev_1695
this research has generally been in the context of desktops and laptops	purpose	2K_dev_1695
while users are increasingly creating and entering passwords on mobile devices	purpose	2K_dev_1695
In this paper we study whether recent password guidance carries over to the mobile setting	purpose	2K_dev_1695
	purpose	2K_dev_1695
Friendsourcing consists of broadcasting questions and help requests to friends on social networking sites	background	2K_dev_1696
Despite its potential value	background	2K_dev_1696
friendsourcing requests often fall on deaf ears	background	2K_dev_1696
One way to improve response rates and motivate friends to undertake more effortful tasks may be to offer extrinsic rewards	background	2K_dev_1696
such as money or a gift	background	2K_dev_1696
for responding to friendsourcing requests	background	2K_dev_1696
However	background	2K_dev_1696
past research suggests that these extrinsic rewards can have unintended consequences	background	2K_dev_1696
including undermining intrinsic motivations and undercutting the relationship between people	background	2K_dev_1696
Results indicate that large extrinsic rewards increase friends ' response rates without reducing the relationship strength between friends Additionally	finding	2K_dev_1696
the extrinsic rewards allow requesters to explain away the failure of friendsourcing requests and thus preserve their perceptions of relationship ties with friends	finding	2K_dev_1696
	finding	2K_dev_1696
	mechanism	2K_dev_1696
we conducted an experiment on a new friendsourcing platform - Mobilyzr	method	2K_dev_1696
To explore the effects of extrinsic reward on friends ' response rate and perceived relationship	purpose	2K_dev_1696
	purpose	2K_dev_1696
People accumulate huge assortments of a possessions	background	2K_dev_1697
but it is not yet clear how systems and system designers can help people make meaning from these large archives	background	2K_dev_1697
Early research in HCl has suggested that people generally appear to value their virtual things less than their material things	background	2K_dev_1697
but theory on material possessions does not entirely explain this difference	background	2K_dev_1697
We conclude with implication and strategies for aimed at supporting people in having more meaningful interactions and experiences with their virtual possessions	background	2K_dev_1697
	background	2K_dev_1697
Our study revealed insights about how materializing virtual possessions influences factors shaping how people draw on	finding	2K_dev_1697
understand	finding	2K_dev_1697
and value those possessions	finding	2K_dev_1697
	finding	2K_dev_1697
we designed a technology probe that selected snippets from old emails and mailed them as physical postcards to participating households The probe uncovered features of emails that trigger meaningful reflection	mechanism	2K_dev_1697
and how contextual information can help people engage in reminiscence	mechanism	2K_dev_1697
	mechanism	2K_dev_1697
	method	2K_dev_1697
To investigate if changes to the form and behavior of virtual things may surface valued elements of a virtual archive	purpose	2K_dev_1697
	purpose	2K_dev_1697
Timebanking is a growing type of peer-to-peer service exchange	background	2K_dev_1698
but is hampered by the effort of finding good transaction partners	background	2K_dev_1698
	background	2K_dev_1698
and shows that such an algorithm can retrieve matches that are subjectively better than matches based on matching the category of people 's historical offers or requests to the category of a current transaction request	finding	2K_dev_1698
	finding	2K_dev_1698
by using a Matching Algorithm for Service Transactions ( MAST )	mechanism	2K_dev_1698
MAST matches transaction partners in terms of similarity of interests and complementarity of abilities and needs	mechanism	2K_dev_1698
	mechanism	2K_dev_1698
We present an experiment involving data and participants from a real timebanking network	method	2K_dev_1698
that evaluates the acceptability of MAST	method	2K_dev_1698
	method	2K_dev_1698
We seek to reduce this effort	purpose	2K_dev_1698
From these findings we argue for the importance of extensions in supporting modularity	background	2K_dev_1699
community engagement	background	2K_dev_1699
and relatable prototyping materials in the iterative design of prosthetics	background	2K_dev_1699
We discuss materials that support on-the-spot design and iteration	finding	2K_dev_1699
dimensions along which in-person iteration is most important ( such as length and angle ) and the value of a supportive social network for users who prototype their own assistive technology	finding	2K_dev_1699
	mechanism	2K_dev_1699
a case study of three participants with upper-limb amputations working with researchers Our study made use of 3D printing and other playful and practical prototyping materials	method	2K_dev_1699
This paper presents to design prosthetic devices for specific tasks : playing the cello	purpose	2K_dev_1699
operating a hand-cycle	purpose	2K_dev_1699
and using a table knife	purpose	2K_dev_1699
Our goal was to identify requirements for a design process that can engage the assistive technology user in rapidly prototyping assistive devices that fill needs not easily met by traditional assistive technology	purpose	2K_dev_1699
	purpose	2K_dev_1699
Crowdsourcing offers a powerful new paradigm for online work However	background	2K_dev_1700
real world tasks are often interdependent	background	2K_dev_1700
requiring a big picture view of the difference pieces involved	background	2K_dev_1700
Existing crowdsourcing approaches that support such tasks - ranging fromWikipedia to flash teams-are bottlenecked by relying on a small number of individuals to maintain the big picture	background	2K_dev_1700
that may be informative for other systems aimed at supporting big picture thinking in small pieces	background	2K_dev_1700
	finding	2K_dev_1700
we instantiate the idea in a prototype system for accomplishing distributed information synthesis and We also contribute a set of design patterns	mechanism	2K_dev_1700
evaluate its output across a variety of topics	method	2K_dev_1700
	method	2K_dev_1700
In this paper	purpose	2K_dev_1700
we explore the idea that a computational system can scaffold an emerging interdependent	purpose	2K_dev_1700
big picture view entirely through the small contributions of individuals	purpose	2K_dev_1700
each of whom sees only a part of the whole	purpose	2K_dev_1700
To investigate the viability	purpose	2K_dev_1700
strengths	purpose	2K_dev_1700
and weaknesses of this approach	purpose	2K_dev_1700
More and more data nowadays exist in hierarchical formats such as JSON due to the increasing popularity of web applications and web services	background	2K_dev_1701
	background	2K_dev_1701
showed that our tool helped spreadsheet users complete data exploration tasks nearly two times faster than using Excel and even outperform programmers in most tasks	finding	2K_dev_1701
In this paper	mechanism	2K_dev_1701
we present a spreadsheet tool We introduce novel interaction techniques and algorithms using the data 's relative hierarchical relationships with the data in its adjacent columns Our tool leverages the data 's structural information	mechanism	2K_dev_1701
Our lab study	method	2K_dev_1701
While many end-user systems support getting hierarchical data from databases without programming	purpose	2K_dev_1701
they provide very little support for using hierarchical data beyond turning the data into a flat string or table for using and exploring hierarchical datasets to manipulate and visualize hierarchical data in a spreadsheet to support selecting	purpose	2K_dev_1701
grouping	purpose	2K_dev_1701
joining	purpose	2K_dev_1701
sorting and filtering hierarchical data in spreadsheets	purpose	2K_dev_1701
	background	2K_dev_1702
revealed that individuals who completed the same information processing task on a digital mobile device ( a tablet or laptop computer ) versus a non-digital platform ( a physical print-out ) exhibited a lower level of construal one prioritizing immediate	finding	2K_dev_1702
concrete details over abstract	finding	2K_dev_1702
decontextualized interpretations	finding	2K_dev_1702
This pattern emerged both in digital platform participants ' greater preference for concrete versus abstract descriptions of behaviors as well as superior performance on detail-focused items ( and inferior performance on inference-focused items ) on a reading comprehension assessment	finding	2K_dev_1702
found that the likelihood of correctly solving a problem-solving task requiring higher-level `` gist { '' } processing was : ( 1 ) higher for participants who processed the information for task on a non-digital versus digital platform and ( 2 ) heightened for digital platform participants who had first completed an activity activating an abstract mindset	finding	2K_dev_1702
	finding	2K_dev_1702
	mechanism	2K_dev_1702
Two initial randomized experiments A pair of final studies compared to ( equivalent ) performance levels exhibited by participants who had either completed no prior activity or completed an activity activating a concrete mindset	method	2K_dev_1702
	method	2K_dev_1702
The present research investigated whether digital and non-digital platforms activate differing default levels of cognitive construal	purpose	2K_dev_1702
	purpose	2K_dev_1702
Crowdsourced clustering approaches present a promising way to harness deep semantic knowledge for clustering complex information	background	2K_dev_1703
	finding	2K_dev_1703
We introduce Alloy	mechanism	2K_dev_1703
a hybrid approach that combines the richness of human judgments with the power of machine algorithms	mechanism	2K_dev_1703
Alloy through a new `` sample and search { '' } crowd pattern which changes the crowd 's task from classifying a fixed subset of items to actively sampling and querying the entire dataset	mechanism	2K_dev_1703
It also through a two phase process in which crowds provide examples To accomplish this	mechanism	2K_dev_1703
Alloy introduces a modular `` cast and gather { '' } approach which leverages a machine learning backbone	mechanism	2K_dev_1703
	method	2K_dev_1703
However	purpose	2K_dev_1703
existing approaches have difficulties supporting the global context needed for workers to generate meaningful categories	purpose	2K_dev_1703
and are costly because all items require human judgments supports greater global context improves efficiency to help a machine cluster the head of the distribution	purpose	2K_dev_1703
then classify low-confidence examples in the tail	purpose	2K_dev_1703
to stitch together different types of judgment tasks	purpose	2K_dev_1703
	purpose	2K_dev_1703
Although many users create predictable passwords	background	2K_dev_1704
the extent to which users realize these passwords are predictable is not well understood	background	2K_dev_1704
We conclude with design directions for helping users make better passwords	background	2K_dev_1704
	background	2K_dev_1704
Participants had serious misconceptions about the impact of basing passwords on common phrases and including digits and keyboard patterns in passwords	finding	2K_dev_1704
However	finding	2K_dev_1704
in most other cases	finding	2K_dev_1704
participants ' perceptions of what characteristics make a password secure were consistent with the performance of current password-cracking tools	finding	2K_dev_1704
We find large variance in participants ' understanding of how passwords may be attacked	finding	2K_dev_1704
potentially explaining why users nonetheless make predictable passwords	finding	2K_dev_1704
	finding	2K_dev_1704
	mechanism	2K_dev_1704
In this 165-participant online study	method	2K_dev_1704
we ask participants to rate the comparative security of carefully juxtaposed pairs of passwords	method	2K_dev_1704
as well as the security and memorability of both existing passwords and common password-creation strategies	method	2K_dev_1704
We investigate the relationship between users ' perceptions of the strength of specific passwords and their actual strength	purpose	2K_dev_1704
	purpose	2K_dev_1704
Stateless model checking is a powerful technique for testing concurrent programs	background	2K_dev_1705
but suffers from exponential state space explosion when the test input parameters are too large	background	2K_dev_1705
Several reduction techniques can mitigate this explosion	background	2K_dev_1705
but even after pruning equivalent interleavings	background	2K_dev_1705
the state space size is often intractable Most prior tools are limited to pre-empting only on synchronization APIs	background	2K_dev_1705
which reduces the space further	background	2K_dev_1705
but can miss unsynchronized thread communication bugs	background	2K_dev_1705
	background	2K_dev_1705
QUICKSAND found 1	finding	2K_dev_1705
25x as many bugs and verified 4	finding	2K_dev_1705
3x as many tests compared to prior model checking approaches	finding	2K_dev_1705
We present QUICKSAND	mechanism	2K_dev_1705
a new stateless model checking framework using different preemption points It uses state space estimation most likely to complete in a fixed CPU budget	mechanism	2K_dev_1705
and it incorporates data-race analysis Preempting threads during a data race 's instructions can automatically classify the race as buggy or benign	mechanism	2K_dev_1705
and uncovers new bugs not reachable by prior model checkers	mechanism	2K_dev_1705
It also enables full verification of all possible schedules when every data race is verified as benign within the CPU budget	mechanism	2K_dev_1705
	mechanism	2K_dev_1705
In our evaluation	method	2K_dev_1705
Data race detection	purpose	2K_dev_1705
another concurrency testing approach	purpose	2K_dev_1705
focuses on suspicious memory access pairs during a single test execution	purpose	2K_dev_1705
It avoids concerns of state space size	purpose	2K_dev_1705
but may report races that do not lead to observable failures	purpose	2K_dev_1705
which jeopardizes a user 's willingness to use the analysis	purpose	2K_dev_1705
which manages the exploration of many state spaces to prioritize jobs to add new preemption points on the fly	purpose	2K_dev_1705
	purpose	2K_dev_1705
Previous work on muscle activity sensing has leveraged specialized sensors such as electromyography and force sensitive resistors Our work is the first to explore the feasibility of using solely motion sensors on everyday wearable devices to detect fine-grained gestures	background	2K_dev_1706
This promising technology can be deployed today on current smartwatches and has the potential to be applied to cross-device interactions	background	2K_dev_1706
or as a tool for research in fields involving finger and hand motion	background	2K_dev_1706
	background	2K_dev_1706
Our system demonstrates the potential to distinguish 5 fine-motor gestures like pinching	finding	2K_dev_1706
tapping and rubbing fingers with an average f1-score of 87\ %	finding	2K_dev_1706
	finding	2K_dev_1706
	mechanism	2K_dev_1706
a new technique using integrated motion sensors ( accelerometer and gyroscope ) in off-the-shelf smartwatches	mechanism	2K_dev_1706
	mechanism	2K_dev_1706
	method	2K_dev_1706
While these sensors show great potential for detecting finger/hand gestures	purpose	2K_dev_1706
they require additional hardware that adds to the cost and user discomfort	purpose	2K_dev_1706
Past research has utilized sensors on commercial devices	purpose	2K_dev_1706
focusing on recognizing gross hand gestures	purpose	2K_dev_1706
In this work we present Serendipity for recognizing unremarkable and fine-motor finger gestures	purpose	2K_dev_1706
Clinical decision support tools ( DSTs ) are computational systems that aid healthcare decision-making While effective in labs	background	2K_dev_1707
almost all these systems failed when they moved into clinical practice Healthcare researchers speculated it is most likely due to a lack of user-centered HCI considerations in the design of these systems	background	2K_dev_1707
and we discuss new forms it might take in these situations	background	2K_dev_1707
Our findings reveal a lack of perceived need for and trust of machine intelligence	finding	2K_dev_1707
as well as many barriers to computer use at the point of clinical decision-making	finding	2K_dev_1707
These findings suggest an alternative perspective to the traditional use models	finding	2K_dev_1707
in which clinicians engage with DSTs at the point of making a decision	finding	2K_dev_1707
We identify situations across patients ' healthcare trajectories when decision supports would help	finding	2K_dev_1707
	finding	2K_dev_1707
	mechanism	2K_dev_1707
a field study	method	2K_dev_1707
This paper describes investigating how clinicians make a heart pump implant decision with a focus on how to best integrate an intelligent DST into their work process	purpose	2K_dev_1707
	purpose	2K_dev_1707
There is a significant gap in the body of research on cross-device interfaces	background	2K_dev_1708
	background	2K_dev_1708
We demonstrate that an end-user customization tool like XDBrowser is a powerful means to conduct user-driven elicitation studies useful for understanding user preferences and design requirements for cross-device interfaces elicited 144 desirable multi-device designs for five popular web interfaces when using two mobile devices in parallel and establish new requirements from observed user behavior	finding	2K_dev_1708
with XDBrowser	mechanism	2K_dev_1708
a cross-device web browser we are developing We describe the design space in this context	mechanism	2K_dev_1708
the usage scenarios targeted by users the strategies used for designing cross-device interfaces	mechanism	2K_dev_1708
and seven concrete mobile multi-device design patterns that emerged	mechanism	2K_dev_1708
We discuss the method	mechanism	2K_dev_1708
	mechanism	2K_dev_1708
an exploratory user study Our study with 15 participants compare the cross-device interfaces from our users and those defined by developers in prior work	method	2K_dev_1708
Research has largely focused on enabling them technically	purpose	2K_dev_1708
but when and how users want to use cross-device interfaces is not well understood	purpose	2K_dev_1708
This paper presents to enable non-technical users to adapt existing single-device web interfaces for cross-device use while viewing them in the browser	purpose	2K_dev_1708
In particular	purpose	2K_dev_1708
we identify the need to easily switch between different interface distributions depending on the task and to have more fine-grained control over synchronization	purpose	2K_dev_1708
	purpose	2K_dev_1708
Social media is an increasingly important part of modern life While Twitter has traditionally been thought of as the most accessible social media platform for blind users	background	2K_dev_1709
Twitter 's increasing integration of image content and users ' diverse uses for images have presented emergent accessibility challenges	background	2K_dev_1709
	background	2K_dev_1709
Our findings illuminate the importance of the ability to use social media for people who are blind	finding	2K_dev_1709
while also highlighting the many challenges such media currently present this user base	finding	2K_dev_1709
including difficulty in creating profiles	finding	2K_dev_1709
in awareness of available features and settings	finding	2K_dev_1709
in controlling revelations of one 's disability status	finding	2K_dev_1709
and in dealing with the increasing pervasiveness of image based content	finding	2K_dev_1709
	finding	2K_dev_1709
	mechanism	2K_dev_1709
via a combination of surveys of blind Twitter users	method	2K_dev_1709
large-scale analysis of tweets from and Twitter profiles of blind and sighted users	method	2K_dev_1709
and analysis of tweets containing embedded imagery	method	2K_dev_1709
	method	2K_dev_1709
We investigate the use of and usability of Twitter by blind users	purpose	2K_dev_1709
We propose changes that Twitter and other social platforms should make to promote fuller access to users with visual impairments	purpose	2K_dev_1709
	purpose	2K_dev_1709
Due to the rapid deployability and low cost of the tags used	background	2K_dev_1710
we can create a new class of interactive paper devices that are drawn on demand for simple tasks	background	2K_dev_1710
These capabilities allow new interactive possibilities for pop-up books and other papercraft objects	background	2K_dev_1710
	background	2K_dev_1710
	finding	2K_dev_1710
We describe techniques We use sensing and signal processing techniques that determine how a tag is being manipulated by the user via an RFID reader and show how tags may be enhanced with a simple set of conductive traces that can be printed on paper	mechanism	2K_dev_1710
stencil-traced	mechanism	2K_dev_1710
or even hand-drawn	mechanism	2K_dev_1710
These traces modify the behavior of contiguous tags to serve as input devices Our techniques provide the capability to use off-the-shelf RFID tags to sense touch	mechanism	2K_dev_1710
cover	mechanism	2K_dev_1710
overlap of tags by conductive or dielectric ( insulating ) materials	mechanism	2K_dev_1710
and tag movement trajectories	mechanism	2K_dev_1710
Paper prototypes can be made functional in seconds	mechanism	2K_dev_1710
	mechanism	2K_dev_1710
	method	2K_dev_1710
that allow inexpensive	purpose	2K_dev_1710
ultra-thin	purpose	2K_dev_1710
battery-free Radio Frequency Identification ( RFID ) tags to be turned into simple paper input devices	purpose	2K_dev_1710
	purpose	2K_dev_1710
which has been successfully used for this purpose	background	2K_dev_1711
AutoSLEX finds the best basis in a library of smoothed localized exponentials ( SLEX ) basis functions that are orthogonal and localized in both time and frequency	background	2K_dev_1711
	background	2K_dev_1711
We demonstrate the utility of the proposed improvements	finding	2K_dev_1711
by improving AutoSLEX { [ } 1 ]	mechanism	2K_dev_1711
We introduce DynamicSLEX	mechanism	2K_dev_1711
a variant of AutoSLEX that relaxes the dyadic intervals constraint of AutoSLEX	mechanism	2K_dev_1711
allowing for more flexible segmentation while maintaining tractability	mechanism	2K_dev_1711
Then	mechanism	2K_dev_1711
we introduce RandSLEX	mechanism	2K_dev_1711
which uses random projections to scale-up SLEX-based segmentation to high dimensional inputs and to establish a notion of strength of splitting points in the segmentation	mechanism	2K_dev_1711
	mechanism	2K_dev_1711
on synthetic and real data	method	2K_dev_1711
We address the problem of segmenting a multi-dimensional time series into stationary blocks	purpose	2K_dev_1711
Current symbol-based dictionaries providing vocabulary support for persons with the language disorder	background	2K_dev_1712
aphasia	background	2K_dev_1712
are housed on smartphones or other portable devices	background	2K_dev_1712
To employ the support on these external devices requires the user to divert their attention away from their conversation partner	background	2K_dev_1712
to the neglect of conversation dynamics like eye contact or verbal inflection	background	2K_dev_1712
A prior study investigated head-worn displays ( HWDs ) as an alternative form factor for supporting glanceable	background	2K_dev_1712
unobtrusive	background	2K_dev_1712
and always-available conversation support	background	2K_dev_1712
Our findings should motivate further work on head-worn conversation support for persons with aphasia	background	2K_dev_1712
	background	2K_dev_1712
Our work contributes ( 1 ) evidence that a HWD can support more efficient communication	finding	2K_dev_1712
( 2 ) preliminary results that a HWD can provide a better overall experience using assistive vocabulary	finding	2K_dev_1712
and ( 3 ) a characterization of the design features persons with aphasia value in portable conversation support technologies	finding	2K_dev_1712
	finding	2K_dev_1712
	mechanism	2K_dev_1712
we compared vocabulary support on a HWD to equivalent support on a smartphone in terms of overall experience	method	2K_dev_1712
perceived focus	method	2K_dev_1712
and conversational success	method	2K_dev_1712
Lastly	method	2K_dev_1712
we elicited critical discussion of how each device might be better designed for conversation support	method	2K_dev_1712
	method	2K_dev_1712
but it did not directly compare the HWD to a control condition	purpose	2K_dev_1712
To address this limitation	purpose	2K_dev_1712
	purpose	2K_dev_1712
When navigating indoors	background	2K_dev_1713
blind people are often unaware of key visual information	background	2K_dev_1713
such as posters	background	2K_dev_1713
signs	background	2K_dev_1713
and exit doors	background	2K_dev_1713
With VizMap	background	2K_dev_1713
we move towards integrating the strengths of the end user	background	2K_dev_1713
on-site crowd	background	2K_dev_1713
online crowd	background	2K_dev_1713
and computer vision to solve a long-standing challenge in indoor blind exploration	background	2K_dev_1713
	finding	2K_dev_1713
Our VizMap system uses computer vision and crowdsourcing VizMap starts with videos taken by on-site sighted volunteers and uses these to create a 3D spatial model	mechanism	2K_dev_1713
These video frames are semantically labeled by remote crowd workers with key visual information	mechanism	2K_dev_1713
These semantic labels are located within and embedded into the reconstructed 3D model	mechanism	2K_dev_1713
forming a query-able spatial representation of the environment	mechanism	2K_dev_1713
VizMap can then localize the user with a photo from their smartphone	mechanism	2K_dev_1713
and enable them to explore the visual elements that are nearby	mechanism	2K_dev_1713
We explore a range of example applications enabled by our reconstructed spatial representation	method	2K_dev_1713
to collect this information and make it available non-visually	purpose	2K_dev_1713
Playtesting	background	2K_dev_1714
or using play to guide game design	background	2K_dev_1714
gives designers feedback about whether their game is meeting their goals and the player 's expectations We conclude with lessons learned and next steps in our research on playtesting	background	2K_dev_1714
	background	2K_dev_1714
novice game designers leveraged playtest methods and tools	finding	2K_dev_1714
employed playtesting and data collection methods appropriate for their goals	finding	2K_dev_1714
and effectively applied playtest data in iterative design	finding	2K_dev_1714
	finding	2K_dev_1714
	mechanism	2K_dev_1714
case study We identify common missteps made by novice designers and address these missteps through the concept of purposefulness	method	2K_dev_1714
understanding why you are playtesting as well as how to playtest	method	2K_dev_1714
We ground our workshops in the development of rich player experience goals	method	2K_dev_1714
which inform playtest design	method	2K_dev_1714
data collection and iteration	method	2K_dev_1714
We show that by applying methods taught in our workshops	method	2K_dev_1714
	method	2K_dev_1714
We report a of designing	purpose	2K_dev_1714
deploying	purpose	2K_dev_1714
and iterating on a series of playtesting workshops for novice game designers	purpose	2K_dev_1714
	purpose	2K_dev_1714
Unease over data privacy will retard consumer acceptance of IoT deployments	background	2K_dev_1715
	finding	2K_dev_1715
We propose a solution that interposes a locally-controlled software component called a privacy mediator on every raw sensor stream	mechanism	2K_dev_1715
Each mediator is in the same administrative domain as the sensors whose data is being collected	mechanism	2K_dev_1715
and dynamically enforces the current privacy policies of the owners of the sensors or mobile users within the domain	mechanism	2K_dev_1715
This solution necessitates a logical point of presence for mediators within the administrative boundaries of each organization	mechanism	2K_dev_1715
Such points of presence are provided by cloudlets	mechanism	2K_dev_1715
which are small locally-administered data centers at the edge of the Internet that can support code mobility	mechanism	2K_dev_1715
The use of cloudlet-based mediators aligns well with natural personal and organizational boundaries of trust and responsibility	mechanism	2K_dev_1715
	method	2K_dev_1715
The primary source of discomfort is a lack of user control over raw data that is streamed directly from sensors to the cloud	purpose	2K_dev_1715
This is a direct consequence of the over-centralization of today 's cloud-based IoT hub designs	purpose	2K_dev_1715
	purpose	2K_dev_1715
1	background	2K_dev_1716
When hybrid systems are complicated	background	2K_dev_1716
it is useful to prove properties about simpler and related subsystems before tackling the system as a whole	background	2K_dev_1716
2	background	2K_dev_1716
Some models of hybrid systems can be implementation-specific	background	2K_dev_1716
Verification can be aided by abstracting the system down to the core components necessary for safety	background	2K_dev_1716
but only if the relations between the abstraction and the original system can be guaranteed	background	2K_dev_1716
3 One approach to taming the complexities of hybrid systems is to start with a simplified version of the system and iteratively expand it	background	2K_dev_1716
However	background	2K_dev_1716
this approach can be costly	background	2K_dev_1716
since every iteration has to be proved safe from scratch	background	2K_dev_1716
unless refinement relations can be leveraged in the proof	background	2K_dev_1716
4 When proofs become large	background	2K_dev_1716
it is difficult to maintain a modular or comprehensible proof structure	background	2K_dev_1716
	background	2K_dev_1716
We demonstrate its usefulness results in easier and better-structured proofs	finding	2K_dev_1716
	finding	2K_dev_1716
We introduce differential refinement logic ( dRL )	mechanism	2K_dev_1716
a logic with first-class support and a proof calculus dRL simultaneously solves several seemingly different challenges common in theorem proving for hybrid systems : By using a refinement relation to arrange proofs hierarchically according to the structure of natural subsystems	mechanism	2K_dev_1716
we can increase the readability and modularity of the resulting proof	mechanism	2K_dev_1716
dRL extends an existing specification and verification language for hybrid systems ( differential dynamic logic	mechanism	2K_dev_1716
dL ) by adding a refinement relation to directly compare hybrid systems	mechanism	2K_dev_1716
	mechanism	2K_dev_1716
with examples where using refinement	method	2K_dev_1716
for refinement relations on hybrid systems for verifying such relations This paper gives a syntax	purpose	2K_dev_1716
semantics	purpose	2K_dev_1716
and proof calculus for dRL	purpose	2K_dev_1716
	purpose	2K_dev_1716
Self-adaptive systems have the ability to adapt their behavior to dynamic operating conditions	background	2K_dev_1717
In reaction to changes in the environment	background	2K_dev_1717
these systems determine the appropriate corrective actions based in part on information about which action will have the best impact on the system	background	2K_dev_1717
	background	2K_dev_1717
can improve the accuracy of predictions used for decision-making	finding	2K_dev_1717
by describing an approach based on architectural system descriptions	mechanism	2K_dev_1717
which at the same time	mechanism	2K_dev_1717
hence improving the selection of the best corrective action	mechanism	2K_dev_1717
The core of our approach is a language equipped with a formal semantics defined in terms of Discrete Time Markov Chains that enables us to describe both the impact of adaptation tactics	mechanism	2K_dev_1717
as well as the assumptions about the environment	mechanism	2K_dev_1717
To validate our approach	method	2K_dev_1717
we show how employing our language in the Rainbow framework for architecture-based self-adaptation	method	2K_dev_1717
Existing models used to describe the impact of adaptations are either unable to capture the underlying uncertainty and variability of such dynamic environments	purpose	2K_dev_1717
or are not compositional and described at a level of abstraction too low to scale in terms of specification effort required for non-trivial systems	purpose	2K_dev_1717
In this paper	purpose	2K_dev_1717
we address these shortcomings to the specification of impact models allows us to represent both variability and uncertainty in the outcome of adaptations	purpose	2K_dev_1717
Everyday tools and objects often need to be customized for an unplanned use or adapted for specific user	background	2K_dev_1718
such as adding a bigger pull to a zipper or a larger grip for a pen The advent of low-cost 3D printing offers the possibility to rapidly construct a wide range of such adaptations	background	2K_dev_1718
We believe this work would benefit makers and designers for prototyping lifehacking solutions and assistive technologies	background	2K_dev_1718
	finding	2K_dev_1718
In this paper	mechanism	2K_dev_1718
we describe Reprise-a design tool for specifying	mechanism	2K_dev_1718
generating	mechanism	2K_dev_1718
customizing and fitting adaptations onto existing household objects	mechanism	2K_dev_1718
Reprise allows users to express at a high level what type of action is applied to an object Based on this high level specification	mechanism	2K_dev_1718
Reprise automatically generates adaptations	mechanism	2K_dev_1718
Users can use simple sliders to customize the adaptations to better suit their particular needs and preferences	mechanism	2K_dev_1718
such as increasing the tightness for gripping	mechanism	2K_dev_1718
enhancing torque for rotation	mechanism	2K_dev_1718
or making a larger base for stability	mechanism	2K_dev_1718
Finally	mechanism	2K_dev_1718
Reprise provides a toolkit of fastening methods and support structures for fitting the adaptations onto existing objects	mechanism	2K_dev_1718
	mechanism	2K_dev_1718
To validate our approach	method	2K_dev_1718
we used Reprise to replicate 15 existing adaptation examples	method	2K_dev_1718
each of which represents a specific category in a design space distilled from an analysis of over 3000 cases found in the literature and online communities	method	2K_dev_1718
	method	2K_dev_1718
However	purpose	2K_dev_1718
while 3D printers are now affordable enough for even home use	purpose	2K_dev_1718
the tools needed to design custom adaptations normally require skills that are beyond users with limited 3D modeling experience	purpose	2K_dev_1718
	purpose	2K_dev_1718
Patients researching medical diagnoses	background	2K_dev_1719
scientist exploring new fields of literature	background	2K_dev_1719
and students learning about new domains are all faced with the challenge of capturing information they find for later use	background	2K_dev_1719
However	background	2K_dev_1719
saving information is challenging on mobile devices	background	2K_dev_1719
where the small screen and font sizes combined with the inaccuracy of finger based touch screens makes it time consuming and stressful for people to select and save text for future use Furthermore	background	2K_dev_1719
beyond the challenge of simply selecting a region of bounded text on a mobile device	background	2K_dev_1719
in many learning and data exploration tasks the boundaries of what text may be relevant and useful later are themselves uncertain for the user	background	2K_dev_1719
In contrast to previous approaches which focused on speeding up the selection process by making the identification of hard boundaries faster	background	2K_dev_1719
	background	2K_dev_1719
we find that this approach reduced selection time and was preferred by participants over the default system text selection method	finding	2K_dev_1719
	finding	2K_dev_1719
We embody this idea in a system that uses force touch and fuzzy bounding boxes along with posthoc expandable context	mechanism	2K_dev_1719
In a two part user study	method	2K_dev_1719
we introduce the idea of intentionally supporting uncertain input in the context of saving information during complex reading and information exploration	purpose	2K_dev_1719
to support identifying and saving information in an intentionally uncertain way on mobile devices	purpose	2K_dev_1719
	purpose	2K_dev_1719
The world is full of physical interfaces that are inaccessible to blind people	background	2K_dev_1720
from microwaves and information kiosks to thermostats and checkout terminals	background	2K_dev_1720
Blind people can not independently use such devices without at least first learning their layout	background	2K_dev_1720
and usually only after labeling them with sighted assistance	background	2K_dev_1720
and foreshadows a future of increasingly powerful interactive applications that would be currently impossible with either alone	background	2K_dev_1720
	background	2K_dev_1720
We show that VizLens provides accurate and usable real-time feedback and our crowdsourcing labeling workflow was fast ( 8 minutes )	finding	2K_dev_1720
accurate ( 99	finding	2K_dev_1720
7\ % )	finding	2K_dev_1720
and cheap ( \ $ 1	finding	2K_dev_1720
15 ) VizLens robustly solves a long-standing challenge in accessibility	finding	2K_dev_1720
We introduce VizLens-an accessible mobile application and supporting backend VizLens users capture a photo of an inaccessible interface and send it to multiple crowd workers	mechanism	2K_dev_1720
who work in parallel to quickly label and describe elements of the interface to make subsequent computer vision easier	mechanism	2K_dev_1720
The VizLens application helps users recapture the interface in the field of the camera	mechanism	2K_dev_1720
and uses computer vision to interactively describe the part of the interface beneath their finger ( updating 8 times per second ) We then explore extensions of VizLens that allow it to ( i ) adapt to state changes in dynamic interfaces	mechanism	2K_dev_1720
( ii ) combine crowd labeling with OCR technology to handle dynamic displays	mechanism	2K_dev_1720
and ( iii ) benefit from head-mounted cameras by deeply integrating crowdsourcing and computer vision	mechanism	2K_dev_1720
	mechanism	2K_dev_1720
in a study with 10 blind participants	method	2K_dev_1720
	method	2K_dev_1720
that can robustly and interactively help blind people use nearly any interface they encounter	purpose	2K_dev_1720
The recent advances in image captioning stimulate the research in generating natural language description for visual content	background	2K_dev_1721
which can be widely applied in many applications such as assisting blind people	background	2K_dev_1721
Video description generation is a more complex task than image caption	background	2K_dev_1721
Most works of video description generation focus on visual information in the video	background	2K_dev_1721
	background	2K_dev_1721
prove that fusing audio information greatly improves the video description performance	finding	2K_dev_1721
	finding	2K_dev_1721
In this paper	mechanism	2K_dev_1721
we propose using both audio and visual cues	mechanism	2K_dev_1721
We use unified deep neural networks with both convolutional and recurrent structure	mechanism	2K_dev_1721
	mechanism	2K_dev_1721
Experimental results on the Microsoft Research Video Description ( MSVD ) corpus	method	2K_dev_1721
However	purpose	2K_dev_1721
audio provides rich information for describing video contents as well	purpose	2K_dev_1721
to generate video descriptions in natural sentences	purpose	2K_dev_1721
	background	2K_dev_1722
	finding	2K_dev_1722
	mechanism	2K_dev_1722
	method	2K_dev_1722
	purpose	2K_dev_1722
An important feature of functional programs is that they are parallel by default	background	2K_dev_1723
We prove the safety of this collector In addition	finding	2K_dev_1723
we describe how the proposed techniques can be implemented on modern shared-memory machines	finding	2K_dev_1723
In this paper	mechanism	2K_dev_1723
we present a technique At the highest level of abstraction	mechanism	2K_dev_1723
the approach consists of a technique to organize memory as a hierarchy of heaps	mechanism	2K_dev_1723
and an algorithm for performing automatic memory reclamation by taking advantage of a disentanglement property of parallel functional programs	mechanism	2K_dev_1723
More specifically	mechanism	2K_dev_1723
the idea is to assign to each parallel task its own heap in memory and organize the heaps in a hierarchy/tree that mirrors the hierarchy of tasks	mechanism	2K_dev_1723
We present a nested-parallel calculus that specifies hierarchical heaps and prove in this calculus a disentanglement property	mechanism	2K_dev_1723
which prohibits a task from accessing objects allocated by another task that might execute in parallel	mechanism	2K_dev_1723
Leveraging the disentanglement property	mechanism	2K_dev_1723
we present a garbage collection technique that can operate on any subtree in the memory hierarchy concurrently as other tasks ( and/or other collections ) proceed in parallel	mechanism	2K_dev_1723
and present a prototype implementation as an extension to MLton	mechanism	2K_dev_1723
a high-performance compiler for the Standard ML language	mechanism	2K_dev_1723
	mechanism	2K_dev_1723
by formalizing it in the context of our parallel calculus	method	2K_dev_1723
Finally	method	2K_dev_1723
we evaluate the performance of this implementation on a number of parallel benchmarks	method	2K_dev_1723
	method	2K_dev_1723
Implementing an efficient parallel functional language	purpose	2K_dev_1723
however	purpose	2K_dev_1723
is a major challenge	purpose	2K_dev_1723
in part because the high rate of allocation and freeing associated with functional programs requires an efficient and scalable memory manager for parallel memory management for strict functional languages with nested parallelism	purpose	2K_dev_1723
	purpose	2K_dev_1723
Micro-clones are small pieces of redundant code	background	2K_dev_1724
such as repeated subexpressions or statements	background	2K_dev_1724
Our results suggest that the detection and removal of micro-clones is valued by developers	background	2K_dev_1724
can be automated at scale	background	2K_dev_1724
and may be fixed with rapid turnaround times	background	2K_dev_1724
In summary	finding	2K_dev_1724
95\ % of our patches to active GitHub repositories are merged rapidly ( within 15 hours on average )	finding	2K_dev_1724
Moreover	finding	2K_dev_1724
none of our patches were contested ; they either constituted a real flaw	finding	2K_dev_1724
or have not been considered due to repository inactivity	finding	2K_dev_1724
	finding	2K_dev_1724
We leverage the Boa software mining infrastructure in a data set containing 380125 Java repositories	mechanism	2K_dev_1724
and yield thousands of instances where redundant code may be safely removed	mechanism	2K_dev_1724
By filtering our results to target popular Java projects on GitHub	mechanism	2K_dev_1724
we proceed to issue 43 pull requests that patch micro-clones	mechanism	2K_dev_1724
	mechanism	2K_dev_1724
	method	2K_dev_1724
In this paper	purpose	2K_dev_1724
we establish the considerations and value toward automated detection and removal of micro-clones at scale	purpose	2K_dev_1724
to detect micro-clones	purpose	2K_dev_1724
Imperfect-recall abstraction has emerged as the leading paradigm for practical large-scale equilibrium computation in imperfect-information games	background	2K_dev_1725
	background	2K_dev_1725
They show that running counterfactual regret minimization on such abstractions leads to good strategies in the original games	finding	2K_dev_1725
	finding	2K_dev_1725
We develop the first general	mechanism	2K_dev_1725
algorithm-agnostic	mechanism	2K_dev_1725
solution quality guarantees for Nash equilibria and approximate self-trembling equilibria computed in imperfect-recall abstractions	mechanism	2K_dev_1725
when implemented in the original ( perfect-recall ) game	mechanism	2K_dev_1725
Our results are for a class of games that generalizes the only previously known class of imperfect-recall abstractions for which any such results have been obtained	mechanism	2K_dev_1725
Further	mechanism	2K_dev_1725
our analysis is tighter in two ways	mechanism	2K_dev_1725
each of which can lead to an exponential reduction in the solution quality error bound	mechanism	2K_dev_1725
We then show that for extensive-form games that satisfy certain properties	mechanism	2K_dev_1725
the problem of computing a bound-minimizing abstraction for a single level of the game reduces to a clustering problem	mechanism	2K_dev_1725
where the increase in our bound is the distance function	mechanism	2K_dev_1725
This reduction leads to the first imperfect-recall abstraction algorithm with solution quality bounds	mechanism	2K_dev_1725
We proceed to show a divide in the class of abstraction problems	mechanism	2K_dev_1725
If payoffs are at the same scale at all information sets considered for abstraction	mechanism	2K_dev_1725
the input forms a metric space	mechanism	2K_dev_1725
and this immediately yields a 2-approximation algorithm for abstraction	mechanism	2K_dev_1725
Conversely	mechanism	2K_dev_1725
if this condition is not satisfied	mechanism	2K_dev_1725
we show that the input does not form a metric space	mechanism	2K_dev_1725
	mechanism	2K_dev_1725
Finally	method	2K_dev_1725
we provide computational experiments to evaluate the practical usefulness of the abstraction techniques	method	2K_dev_1725
	method	2K_dev_1725
However	purpose	2K_dev_1725
imperfect-recall abstractions are poorly understood	purpose	2K_dev_1725
and only weak algorithm-specific guarantees on solution quality are known	purpose	2K_dev_1725
	purpose	2K_dev_1725
	background	2K_dev_1726
results demonstrate that SwitchKV can achieve up to 5x throughput and 3x latency improvements over traditional system designs	finding	2K_dev_1726
	finding	2K_dev_1726
SwitchKV is a new key-value store system design that combines high-performance cache nodes with resource-constrained backend nodes The cache nodes absorb the hottest queries so that no individual backend node is over-burdened	mechanism	2K_dev_1726
Compared with previous designs	mechanism	2K_dev_1726
SwitchKV exploits SDN techniques and deeply optimized switch hardware Programmable network switches keep track of cached keys and route requests to the appropriate nodes at line speed	mechanism	2K_dev_1726
based on keys encoded in packet headers	mechanism	2K_dev_1726
A new hybrid caching strategy keeps cache and switch forwarding rules updated with low overhead and ensures that system load is always well-balanced under rapidly changing workloads	mechanism	2K_dev_1726
	mechanism	2K_dev_1726
Our evaluation	method	2K_dev_1726
to provide load balancing in the face of unpredictable workload skew	purpose	2K_dev_1726
to enable efficient content-based routing	purpose	2K_dev_1726
	purpose	2K_dev_1726
Multi-stage log-structured ( MSLS ) designs	background	2K_dev_1727
such as LevelDB	background	2K_dev_1727
RocksDB	background	2K_dev_1727
HBase	background	2K_dev_1727
and Cassandra	background	2K_dev_1727
are a family of storage system designs that exploit the high sequential write speeds of hard disks and flash drives by using multiple append-only data structures	background	2K_dev_1727
find optimized system parameters that decrease LevelDB 's insert cost by up to 9	finding	2K_dev_1727
4-26	finding	2K_dev_1727
2\ % ; our analytic primitives and model also suggest changes to RocksDB that reduce its insert cost by up to 32	finding	2K_dev_1727
0\ %	finding	2K_dev_1727
without reducing query performance or requiring extra memory	finding	2K_dev_1727
	finding	2K_dev_1727
As a first step	mechanism	2K_dev_1727
we propose new analytic primitives and MSLS design models Our model can almost perfectly estimate the cost of inserts in LevelDB	mechanism	2K_dev_1727
whereas the conventional worst-case analysis gives 1	mechanism	2K_dev_1727
83	mechanism	2K_dev_1727
5X higher estimates than the actual cost	mechanism	2K_dev_1727
	mechanism	2K_dev_1727
A few minutes of offline analysis using our model can	method	2K_dev_1727
towards accurate and fast evaluation of MSLS that quickly give accurate performance estimates	purpose	2K_dev_1727
	purpose	2K_dev_1727
Motivation : Reconstructing regulatory networks from expression and interaction data is a major goal of systems biology	background	2K_dev_1728
While much work has focused on trying to experimentally and computationally determine the set of transcription-factors ( TFs ) and microRNAs ( miRNAs ) that regulate genes in these networks	background	2K_dev_1728
relatively little work has focused on inferring the regulation of miRNAs by TFs	background	2K_dev_1728
Such regulation can play an important role in several biological processes including development and disease	background	2K_dev_1728
The main challenge for predicting such interactions is the very small positive training set currently available	background	2K_dev_1728
Another challenge is the fact that a large fraction of miRNAs are encoded within genes making it hard to determine the specific way in which they are regulated	background	2K_dev_1728
and can be used by any method that combines miRNAs	background	2K_dev_1728
genes	background	2K_dev_1728
and TFs	background	2K_dev_1728
	background	2K_dev_1728
Results As we show	finding	2K_dev_1728
the methods we develop achieve good performance demonstrating the advantage of using the predicted set of interactions for identifying more coherent and relevant modules	finding	2K_dev_1728
genes	finding	2K_dev_1728
and miRNAs The complete set of predictions is available on the supporting website	finding	2K_dev_1728
	mechanism	2K_dev_1728
we extended semisupervised machine-learning approaches to integrate a large set of different types of data including sequence	mechanism	2K_dev_1728
expression	mechanism	2K_dev_1728
ChIP-seq and epigenetic data	mechanism	2K_dev_1728
	mechanism	2K_dev_1728
on both a labeled test set	method	2K_dev_1728
and when analyzing general co-expression networks	method	2K_dev_1728
We next analyze mRNA and miRNA cancer expression data	method	2K_dev_1728
To enable genome wide predictions of TF-miRNA interactions	purpose	2K_dev_1728
	background	2K_dev_1729
We validate uSpark and demonstrating only minor performance overhead with low verification costs	finding	2K_dev_1729
	finding	2K_dev_1729
We present uberSpark ( uSpark )	mechanism	2K_dev_1729
an innovative architecture uSpark comprises two key ideas : ( i ) endowing low-level system software with abstractions found in higher-level languages ( e	mechanism	2K_dev_1729
g	mechanism	2K_dev_1729
	mechanism	2K_dev_1729
objects	mechanism	2K_dev_1729
interfaces	mechanism	2K_dev_1729
function-call semantics for implementations of interfaces	mechanism	2K_dev_1729
access control on interfaces	mechanism	2K_dev_1729
concurrency and serialization )	mechanism	2K_dev_1729
enforced using a combination of commodity hardware mechanisms and lightweight static analysis ; and ( ii ) interfacing with platform hardware by programming in Assembly using an idiomatic style ( called CASM ) that is verifiable via tools aimed at C	mechanism	2K_dev_1729
while retaining its performance and low-level access to hardware After verification	mechanism	2K_dev_1729
the C code is compiled using a certified compiler while the CASM code is translated into its corresponding Assembly instructions	mechanism	2K_dev_1729
Collectively	mechanism	2K_dev_1729
these innovations enable compositional verification of security invariants without sacrificing performance	mechanism	2K_dev_1729
by building and verifying security invariants of an existing open-source commodity x86 micro-hypervisor and several of its extensions	method	2K_dev_1729
for compositional verification of security properties of extensible hypervisors written in C and Assembly	purpose	2K_dev_1729
	purpose	2K_dev_1729
Human-chosen text passwords	background	2K_dev_1730
today 's dominant form of authentication	background	2K_dev_1730
are vulnerable to guessing attacks	background	2K_dev_1730
	background	2K_dev_1730
We show that neural networks can often guess passwords more effectively than state-of-the-art approaches	finding	2K_dev_1730
such as probabilistic context-free grammars and Markov models We also show that our neural networks can be highly compressed-to as little as hundreds of kilobytes-without substantially worsening guessing effectiveness	finding	2K_dev_1730
Together	finding	2K_dev_1730
our contributions enable more accurate and practical password checking than was previously possible	finding	2K_dev_1730
	finding	2K_dev_1730
We propose using artificial neural networks to model text passwords ' resistance to guessing attacks and explore how different architectures and training methods impact neural networks ' guessing effectiveness	mechanism	2K_dev_1730
Building on these results	mechanism	2K_dev_1730
we implement in JavaScript the first principled client-side model of password guessing	mechanism	2K_dev_1730
which analyzes a password 's resistance to a guessing attack of arbitrary duration with sub-second latency	mechanism	2K_dev_1730
	mechanism	2K_dev_1730
	method	2K_dev_1730
Unfortunately	purpose	2K_dev_1730
existing approaches for evaluating password strength by modeling adversarial password guessing are either inaccurate or orders of magnitude too large and too slow for real-time	purpose	2K_dev_1730
client-side password checking	purpose	2K_dev_1730
	purpose	2K_dev_1730
Modern RDMA hardware offers the potential for exceptional performance	background	2K_dev_1731
	background	2K_dev_1731
that outperforms an existing design by 50x	finding	2K_dev_1731
and improve the CPU efficiency of a prior high-performance key-value store by 83\ %	finding	2K_dev_1731
This paper lays out guidelines that can be used by system designers Our guidelines emphasize paying attention to low-level details such as individual PCIe transactions and NIC architecture	mechanism	2K_dev_1731
	mechanism	2K_dev_1731
We empirically demonstrate how these guidelines can be used to improve the performance of RDMA-based systems we design a networked sequencer	method	2K_dev_1731
but design choices including which RDMA operations to use and how to use them significantly affect observed performance	purpose	2K_dev_1731
to navigate the RDMA design space	purpose	2K_dev_1731
We also present and evaluate several new RDMA optimizations and pitfalls	purpose	2K_dev_1731
and discuss how they affect the design of RDMA systems	purpose	2K_dev_1731
	purpose	2K_dev_1731
Transcription makes speech accessible to deaf and hard of hearing people	background	2K_dev_1732
This conversion of speech to text is still done manually by humans	background	2K_dev_1732
despite high cost	background	2K_dev_1732
because the quality of automated speech recognition ( ASR ) is still too low in real-world settings	background	2K_dev_1732
Manual conversion can require more than 5 times the original audio time	background	2K_dev_1732
which also introduces significant latency	background	2K_dev_1732
Giving transcriptionists ASR output as a starting point seems like a reasonable approach to making humans more efficient and thereby reducing this cost	background	2K_dev_1732
but the effectiveness of this approach is clearly related to the quality of the speech recognition output	background	2K_dev_1732
At high error rates	background	2K_dev_1732
fixing inaccurate speech recognition output may take longer than producing the transcription from scratch	background	2K_dev_1732
and transcriptionists may not realize when transcription output is too inaccurate to be useful	background	2K_dev_1732
	background	2K_dev_1732
We present results which indicate that starting with the ASR output is worse unless it is sufficiently accurate ( Word Error Rate of under 30\ % )	finding	2K_dev_1732
	finding	2K_dev_1732
	mechanism	2K_dev_1732
from 2 studies	method	2K_dev_1732
In this paper	purpose	2K_dev_1732
we empirically explore how the latency of transcriptions created by participants recruited on Amazon Mechanical Turk vary based on the accuracy of speech recognition output	purpose	2K_dev_1732
	purpose	2K_dev_1732
Malware authors have been using websites to distribute their products as a way to evade spam filters and classic anti-virus engines	background	2K_dev_1733
	background	2K_dev_1733
which could be of interest to studies on website profiling	background	2K_dev_1733
Our study is a first step towards modeling web-based malware propagation as a network-wide phenomenon and enabling researchers to develop realistic assumptions and models	background	2K_dev_1733
	background	2K_dev_1733
First	finding	2K_dev_1733
we find that legitimate but compromised websites constitute 33	finding	2K_dev_1733
1\ % of the malicious websites in our dataset	finding	2K_dev_1733
with an accuracy of 95	finding	2K_dev_1733
3\ % Second	finding	2K_dev_1733
we find that malicious URLs can be surprisingly long-lived	finding	2K_dev_1733
with 10\ % of malicious sites staying active for three months or more	finding	2K_dev_1733
Third	finding	2K_dev_1733
we observe that a significant number of URLs exhibit the same temporal pattern that suggests a flush-crowd behavior	finding	2K_dev_1733
inflicting most of their damage during the first few days of appearance Finally	finding	2K_dev_1733
the distribution of the visits to malicious sites per user is skewed	finding	2K_dev_1733
with 1	finding	2K_dev_1733
4\ % of users visiting more than 10 malicious sites in 8 months	finding	2K_dev_1733
	finding	2K_dev_1733
In order to conduct this study	mechanism	2K_dev_1733
we develop a classifier to distinguish between compromised vs	mechanism	2K_dev_1733
malicious websites	mechanism	2K_dev_1733
We conduct an extensive study and follow a website-centric and user-centric point of view	method	2K_dev_1733
We collect data from four online databases	method	2K_dev_1733
including Symantec 's WINE Project	method	2K_dev_1733
for a total of more than 600K malicious URLs and over 500K users	method	2K_dev_1733
Yet there has been relatively little work in modeling the behaviors and temporal properties of websites	purpose	2K_dev_1733
as most research focuses on detecting whether a website distributes malware	purpose	2K_dev_1733
In this paper we ask : How does web-based malware spread ?	purpose	2K_dev_1733
Modern Internet applications are being disaggregated into a microservice-based architecture	background	2K_dev_1734
with services being updated and deployed hundreds of times a day	background	2K_dev_1734
The accelerated software life cycle and heterogeneity of language runtimes in a single application necessitates a new approach for testing the resiliency of these applications in production infrastructures	background	2K_dev_1734
	background	2K_dev_1734
	finding	2K_dev_1734
We present Gremlin	mechanism	2K_dev_1734
a framework Gremlin is based on the observation that microservices are loosely coupled and thus rely on standard message-exchange patterns over the network	mechanism	2K_dev_1734
Gremlin allows the operator to easily design tests and executes them by manipulating inter-service messages at the network layer	mechanism	2K_dev_1734
We show how to use Gremlin to express common failure scenarios and how developers of an enterprise application were able to discover previously unknown bugs in their failure-handling code without modifying the application	mechanism	2K_dev_1734
	mechanism	2K_dev_1734
	method	2K_dev_1734
for systematically testing the failure-handling capabilities of microservices	purpose	2K_dev_1734
Given an n-party protocol that takes R rounds assuming noiseless communication Rajagopalan and Schulman ( STOC `94 ) were the first to consider this question	background	2K_dev_1735
and provided a coding scheme with rate O ( 1/ log ( d + 1 ) )	background	2K_dev_1735
where d is the maximal degree in the network	background	2K_dev_1735
While that scheme provides a constant rate coding for many practical situations	background	2K_dev_1735
in the worst case	background	2K_dev_1735
e	background	2K_dev_1735
g	background	2K_dev_1735
	background	2K_dev_1735
when the network is a complete graph	background	2K_dev_1735
the rate is O ( 1/ log n )	background	2K_dev_1735
which tends to 0 as n tends to infinity	background	2K_dev_1735
This implies a constant rate coding scheme for any n-party protocol over a d-regular network with a constant mixing time	background	2K_dev_1735
	background	2K_dev_1735
We furthermore extend the result and show then there exists an efficient coding scheme with rate O ( 1/m ( 3 ) log m ) and in particular for random graphs with n vertices and degrees n ( Omega ( 1 ) )	finding	2K_dev_1735
	finding	2K_dev_1735
We revisit this question and provide an efficient coding scheme with a constant rate for the interesting case of fully connected networks	mechanism	2K_dev_1735
	mechanism	2K_dev_1735
that if a ( d-regular ) network has mixing time m	method	2K_dev_1735
We consider the task of multiparty computation performed over networks in the presence of random noise the goal is to find a coding scheme that takes R ' rounds and computes the same function with high probability even when the communication is noisy	purpose	2K_dev_1735
while maintaining a constant asymptotic rate	purpose	2K_dev_1735
i	purpose	2K_dev_1735
e	purpose	2K_dev_1735
	purpose	2K_dev_1735
while keeping inf ( n	purpose	2K_dev_1735
R - > infinity ) R/R ' positive	purpose	2K_dev_1735
	purpose	2K_dev_1735
Concurrency bugs that stem from schedule-dependent branches are hard to understand and debug	background	2K_dev_1736
because	background	2K_dev_1736
shows that Cortex is able to expose failing schedules with only a few perturbations to non-failing executions	finding	2K_dev_1736
and takes a practical amount of time	finding	2K_dev_1736
We present Cortex : a system without relying on information from failing executions Cortex preemptively exposes failing executions by perturbing the order of events and control-flow behavior in non-failing schedules from production runs of a program	mechanism	2K_dev_1736
By leveraging this information from production runs	mechanism	2K_dev_1736
Cortex synthesizes executions to guide the search for failing schedules	mechanism	2K_dev_1736
Production-guided search helps cope with the large execution search space by targeting failing executions that are similar to observed non-failing	mechanism	2K_dev_1736
Evaluation on popular benchmarks	method	2K_dev_1736
their root causes imply not only different event orderings	purpose	2K_dev_1736
but also changes in the control-flow between failing and non-failing executions that helps exposing and understanding concurrency bugs that result from schedule-dependent branches	purpose	2K_dev_1736
	purpose	2K_dev_1736
	background	2K_dev_1737
	finding	2K_dev_1737
	mechanism	2K_dev_1737
	method	2K_dev_1737
	purpose	2K_dev_1737
The most basic distributed radio network broadcasting primitive - called Decay - dates back to a PODC'87 result of Bar-Yehuda	background	2K_dev_1738
Goldreich	background	2K_dev_1738
and Itai In any radio network with some informed source nodes	background	2K_dev_1738
running Decay for O ( d log n + log ( 2 ) n ) rounds informs all nodes at most d hops away from a source with high probability	background	2K_dev_1738
Since 1987 this primitive has been the most important building block for implementing many other functionalities in radio networks The only improvements to this decades-old algorithm are slight variations due to { [ } Czumaj	background	2K_dev_1738
Rytter ; FOCS'03 ] and { [ } Kowalski and Pelc	background	2K_dev_1738
PODC'03 ] which achieve the same functionality in O ( d log n/d + log ( 2 ) n ) rounds	background	2K_dev_1738
	background	2K_dev_1738
This improves over Decay for any super-polylogarithmic d 0 log ( omega ( 1 ) ) n and achieves near-optimal 0 ( d log log n ) running time for d 0 n ( epsilon )	finding	2K_dev_1738
	finding	2K_dev_1738
We present a faster distributed broadcasting primitive for the classical radio network model	mechanism	2K_dev_1738
d and thus also the network diameter need to be near linear	mechanism	2K_dev_1738
i	mechanism	2K_dev_1738
e	mechanism	2K_dev_1738
	mechanism	2K_dev_1738
larger than n ( 1-epsilon )	mechanism	2K_dev_1738
Our new distributed primitive spreads messages for d hops in O ( dlog n log log n/log d + log ( O ( 1 ) ) n ) rounds with high probability log This also makes progress on an open question of Peleg	mechanism	2K_dev_1738
	method	2K_dev_1738
To obtain a speedup from this	purpose	2K_dev_1738
The widespread availability of high-quality motion capture data and the maturity of solutions to animate virtual characters has paved the way for the next generation of interactive virtual worlds exhibiting intricate interactions between characters and the environments they inhabit	background	2K_dev_1739
	background	2K_dev_1739
	finding	2K_dev_1739
This paper presents an automated approach for analyzing both motions and environments We extract the salient features that characterize the contact-rich motion repertoire of a character and detect valid transitions in the environment where each of these motions may be possible	mechanism	2K_dev_1739
along with additional semantics that inform which surfaces of the environment the character may use for support during the motion	mechanism	2K_dev_1739
The precomputed motion semantics can be easily integrated into standard navigation and animation pipelines in order to greatly enhance the motion capabilities of virtual characters	mechanism	2K_dev_1739
The computational efficiency of our approach enables two additional applications	mechanism	2K_dev_1739
Environment designers can interactively design new environments and get instant feedback on how characters may potentially interact	mechanism	2K_dev_1739
which can be used for iterative modeling and refinement	mechanism	2K_dev_1739
End users can dynamically edit virtual worlds and characters will automatically accommodate the changes in the environment in their movement strategies	mechanism	2K_dev_1739
	mechanism	2K_dev_1739
	method	2K_dev_1739
However	purpose	2K_dev_1739
current motion synthesis techniques have not been designed to scale with complex environments and contact-rich motions	purpose	2K_dev_1739
requiring environment designers to manually embed motion semantics in the environment geometry in order to address online motion synthesis in order to represent the different ways in which an environment can afford a character to move	purpose	2K_dev_1739
	purpose	2K_dev_1739
Data compression can be an effective method to achieve higher system performance and energy efficiency in modern data-intensive applications by exploiting redundancy and data similarity Prior works have studied a variety of data compression techniques to improve both capacity ( e	background	2K_dev_1740
g	background	2K_dev_1740
	background	2K_dev_1740
of caches and main memory ) and bandwidth utilization ( e	background	2K_dev_1740
g	background	2K_dev_1740
	background	2K_dev_1740
of the on-chip and off-chip interconnects )	background	2K_dev_1740
While compression reduces the amount of transferred data	finding	2K_dev_1740
it leads to a substantial increase in the number of bit toggles ( i	finding	2K_dev_1740
e	finding	2K_dev_1740
	finding	2K_dev_1740
communication channel switchings from 0 to 1 or from 1 to 0 )	finding	2K_dev_1740
The increased toggle count increases the dynamic energy consumed by on-chip and off-chip buses due to more frequent charging and discharging of the wires	finding	2K_dev_1740
Our results show that the total bit toggle count can increase from 20\ % to 2	finding	2K_dev_1740
2x when compression is applied for some compression algorithms	finding	2K_dev_1740
averaged across different application suites These techniques greatly reduce the bit toggle count impact of the data compression algorithms we examine	finding	2K_dev_1740
while keeping most of their bandwidth reduction benefits	finding	2K_dev_1740
	finding	2K_dev_1740
we propose two new toggle-aware compression techniques : Energy Control and Metadata Consolidation	mechanism	2K_dev_1740
	mechanism	2K_dev_1740
We characterize and demonstrate this new problem across 242 GPU applications and six different compression algorithms	method	2K_dev_1740
	method	2K_dev_1740
In this paper	purpose	2K_dev_1740
we make a new observation about the energy-efficiency of communication when compression is applied	purpose	2K_dev_1740
To mitigate the problem	purpose	2K_dev_1740
Factorization Machines offer good performance and useful embeddings of data	background	2K_dev_1741
	background	2K_dev_1741
demonstrate its efficiency	finding	2K_dev_1741
In this paper we describe DiFacto	mechanism	2K_dev_1741
which uses a refined Factorization Machine model with sparse memory adaptive constraints and frequency adaptive regularization	mechanism	2K_dev_1741
We show how to distribute DiFacto over multiple machines using the Parameter Server framework by computing distributed sub gradients on minibatches asynchronously	mechanism	2K_dev_1741
	mechanism	2K_dev_1741
We analyze its convergence and in computational advertising datasets with billions examples and features	method	2K_dev_1741
However	purpose	2K_dev_1741
they are costly to scale to large amounts of data and large numbers of features	purpose	2K_dev_1741
	purpose	2K_dev_1741
Social community detection is a growing field of interest in the area of social network applications	background	2K_dev_1742
and many approaches have been developed	background	2K_dev_1742
including graph partitioning	background	2K_dev_1742
latent space model	background	2K_dev_1742
block model and spectral clustering	background	2K_dev_1742
show that UCGT achieves better performance than existing state-of-the-art comparison methods	finding	2K_dev_1742
	finding	2K_dev_1742
we propose by incorporating their spatiotemporal data and semantic information	mechanism	2K_dev_1742
Technically	mechanism	2K_dev_1742
we propose a unified probabilistic generative model	mechanism	2K_dev_1742
User-Community-Geo-Topic ( UCGT ) With a well-designed multi-component model structure and a parallel inference implementation to leverage the power of multicores and clusters	mechanism	2K_dev_1742
our UCGT model is expressive while remaining efficient and scalable to growing large-scale geo-social networking data	mechanism	2K_dev_1742
	mechanism	2K_dev_1742
We deploy UCGT to two application scenarios of user behavior predictions : check-in prediction and social interaction prediction	method	2K_dev_1742
Extensive experiments on two large-scale geo-social networking datasets	method	2K_dev_1742
Most existing work purely focuses on network structure information which is	purpose	2K_dev_1742
however	purpose	2K_dev_1742
often sparse	purpose	2K_dev_1742
noisy and lack of interpretability	purpose	2K_dev_1742
To improve the accuracy and interpretability of community discovery to infer users ' social communities to simulate the generative process of communities as a result of network proximities	purpose	2K_dev_1742
spatiotemporal co-occurrences and semantic similarity	purpose	2K_dev_1742
	purpose	2K_dev_1742
Given such geometric alignments	background	2K_dev_1743
the natural approach for recognition might extract pose-normalized appearance features from a canonically-aligned coordinate frame	background	2K_dev_1743
Though such approaches are extraordinarily common	background	2K_dev_1743
	background	2K_dev_1743
that synthesis is a surprisingly simple but effective strategy that allows for state-of-the-art categorization and automatic 3D alignment	finding	2K_dev_1743
To do so	mechanism	2K_dev_1743
it makes use of recent methods for automatic alignment of cuboidal objects in images we demonstrate that they are not optimal	mechanism	2K_dev_1743
both theoretically and empirically	mechanism	2K_dev_1743
One reason is that such approaches require accurate shape alignment	mechanism	2K_dev_1743
However	mechanism	2K_dev_1743
even with ground-truth alignment	mechanism	2K_dev_1743
posenormalized representations may still be sub-optimal	mechanism	2K_dev_1743
Instead	mechanism	2K_dev_1743
we introduce methods based on pose-synthesis	mechanism	2K_dev_1743
a somewhat simple approach of augmenting training data with geometrically perturbed training samples we introduce a novel dataset for cuboidal object categorization	mechanism	2K_dev_1743
	mechanism	2K_dev_1743
We demonstrate	method	2K_dev_1743
both theoretically and empirically	method	2K_dev_1743
This paper introduces and analyzes the novel task of categorical classification of cuboidal objects - e	purpose	2K_dev_1743
g	purpose	2K_dev_1743
	purpose	2K_dev_1743
distinguishing washing machines versus filing cabinets	purpose	2K_dev_1743
To aid our empirical analysis	purpose	2K_dev_1743
	background	2K_dev_1744
We demonstrate use of Spire to author complex shaders that are portable across different rendering pipelines and to rapidly explore shader optimization decisions that span multiple compute and graphics passes and even offline asset preprocessing	finding	2K_dev_1744
and demonstrate rapid	finding	2K_dev_1744
automatic re-optimization of shaders for different target hardware platforms	finding	2K_dev_1744
	finding	2K_dev_1744
We present Spire	mechanism	2K_dev_1744
a shading language and compiler framework that facilitates rapid exploration of shader optimization choices ( such as frequency reduction and algorithmic approximation ) afforded by modern real-time graphics engines	mechanism	2K_dev_1744
Our design combines ideas from rate-based shader programming with new language features that expand the scope of shader execution beyond traditional GPU hardware pipelines	mechanism	2K_dev_1744
overloading shader terms at various spatio-temporal computation rates provided by the pipeline	mechanism	2K_dev_1744
In contrast to prior work	mechanism	2K_dev_1744
neither the shading language 's design	mechanism	2K_dev_1744
nor our compiler framework 's implementation	mechanism	2K_dev_1744
is specific to the capabilities of any one rendering pipeline	mechanism	2K_dev_1744
thus Spire establishes architectural separation between the shading system and the implementation of modern rendering engines ( allowing different rendering pipelines to utilize its services	mechanism	2K_dev_1744
We further demonstrate the utility of Spire by developing a shader level-of-detail library and shader auto-tuning system on top of its abstractions	method	2K_dev_1744
	method	2K_dev_1744
and enable a diverse set of shader optimizations to be described by a single mechanism	purpose	2K_dev_1744
	background	2K_dev_1745
were it got previously discording participants	finding	2K_dev_1745
talking to each other and agreeing on the issues	finding	2K_dev_1745
	finding	2K_dev_1745
This paper describes a group interview technique designed The technique borrows from agile software development the concept of user stories to cast CMMI 's specific practices in concrete terms and the Planning Poker technique	mechanism	2K_dev_1745
instead of document reviews and audit like interviews	mechanism	2K_dev_1745
for fact finding and corroboration	mechanism	2K_dev_1745
The method was successfully used in one consulting assignment	method	2K_dev_1745
to support lightweight process assessments while promoting at the same time collaboration among assessment participants	purpose	2K_dev_1745
	purpose	2K_dev_1745
	background	2K_dev_1746
Initial results show that the proposed method does afford better segmentation compared to one of the present state of the art algorithms	finding	2K_dev_1746
a Bayesian baseline approach that segments the documents individually	finding	2K_dev_1746
	finding	2K_dev_1746
This paper proposes the use of lexical similarity across different documents Given a set of topically related documents	mechanism	2K_dev_1746
the segmentation process is carried out using a Bayesian framework By using similar sentences from different documents more accurate segment likelihood estimations are obtained	mechanism	2K_dev_1746
	mechanism	2K_dev_1746
The proposed approach was tested in an educational domain where a set of learning materials from different media sources needed to be segmented so that students could browse through them more efficiently	method	2K_dev_1746
	method	2K_dev_1746
in order to improve a topic segmentation task	purpose	2K_dev_1746
	background	2K_dev_1747
The resulting CP approach outperforms a Branch-and-Bound approach derived from two closely related problems In addition	finding	2K_dev_1747
the CP approach presented in this paper resulted in a first place position in the competition	finding	2K_dev_1747
	finding	2K_dev_1747
A global CP constraint is presented The global constraint is incorporated in a CP approach This problem was recently introduced at the 2015 ACP Summer School on Constraint Programming competition	mechanism	2K_dev_1747
	mechanism	2K_dev_1747
	method	2K_dev_1747
which improves the propagation of reservoir constraints on cumulative resources in schedules with optional tasks	purpose	2K_dev_1747
to solve a Single-Commodity Pickup and Delivery Problem : the Bicycle Rebalancing Problem with Time-Windows and heterogeneous fleet	purpose	2K_dev_1747
	purpose	2K_dev_1747
In order to achieve smooth autonomous driving in real-life urban and highway environments	background	2K_dev_1748
a motion planner must generate trajectories that are locally smooth and responsive ( reactive )	background	2K_dev_1748
and at the same time	background	2K_dev_1748
far-sighted and intelligent ( deliberative )	background	2K_dev_1748
Prior approaches achieved both planning qualities for full-speed-range operations at a high computational cost	background	2K_dev_1748
	finding	2K_dev_1748
In this paper	mechanism	2K_dev_1748
a pipelined ( phased ) framework with tunable planning modules is proposed	mechanism	2K_dev_1748
	method	2K_dev_1748
Moreover	purpose	2K_dev_1748
the planning formulations were mostly a trajectory search problem based on a single weighted cost	purpose	2K_dev_1748
which became hard to tune and highly scenario-constrained due to overfitting	purpose	2K_dev_1748
for general on-road motion planning to reduce the computational overhead and improve the tunability of the planner	purpose	2K_dev_1748
The topic of kinematics of laser rangefinders has received little attention in the robotics literature	background	2K_dev_1749
even though such sensors have been the perception sensors of choice on commercial AGVs	background	2K_dev_1749
field robots	background	2K_dev_1749
and aerial robots for some time	background	2K_dev_1749
	background	2K_dev_1749
	finding	2K_dev_1749
In recognition of the uniqueness of optical reflection mechanisms	mechanism	2K_dev_1749
this paper presents a formulation based on a matrix reflection operator	mechanism	2K_dev_1749
	method	2K_dev_1749
Unlike the physical mechanisms employed in manipulators and mobile robots	purpose	2K_dev_1749
the basic operation for bending the optical path of the transmit and receive beams of a laser rangefinder is often a reflection about a mirror	purpose	2K_dev_1749
and this operation can not be modeled naturally as a rotation	purpose	2K_dev_1749
for modeling 2 axis scanning laser rangefinders	purpose	2K_dev_1749
Many applications for robotic systems require the systems to traverse diverse	background	2K_dev_1750
unstructured environments State estimation with Visual Odometry ( VO ) in these applications is challenging because there is no single algorithm that performs well across all environments and situations	background	2K_dev_1750
The unique trade-offs inherent to each algorithm mean different algorithms excel in different environments	background	2K_dev_1750
Our method reduces the mean translational relative pose error by 3	finding	2K_dev_1750
5\ % and the angular error by 4	finding	2K_dev_1750
3\ % compared to the single best odometry algorithm	finding	2K_dev_1750
Compared to the poorest performing odometry algorithm	finding	2K_dev_1750
our method reduces the mean translational error by 39	finding	2K_dev_1750
4\ % and the angular error by 20	finding	2K_dev_1750
1\ %	finding	2K_dev_1750
	finding	2K_dev_1750
We develop a method by using an ensemble of VO algorithms The method combines the estimates by dynamically switching to the best algorithm for the current context	mechanism	2K_dev_1750
according to a statistical model of VO estimate errors The model is a Random Forest regressor that is trained to predict the accuracy of each algorithm as a function of different features extracted from the sensory input	mechanism	2K_dev_1750
	mechanism	2K_dev_1750
We evaluate our method in a dataset of consisting of four unique environments and eight runs	method	2K_dev_1750
totaling over 25min of data	method	2K_dev_1750
	method	2K_dev_1750
to increase robustness in state estimation	purpose	2K_dev_1750
One of the challenges of field testing planetary rovers on Earth is the difference in gravity between the test and the intended operating conditions	background	2K_dev_1751
This not only changes the weight exerted by the robot on the surface but also affects the behaviour of the granular surface itself	background	2K_dev_1751
and unfortunatly no field test can fully address this shortcoming	background	2K_dev_1751
Excavating with gravity offload underestimates the detrimental effects of gravity on traction	background	2K_dev_1751
but overestimates the detrimental effects on excavation resistance ; though not ideal	background	2K_dev_1751
this is a more balanced test than excavating in Earth gravity	background	2K_dev_1751
which underestimates detrimental effects on both traction and resistance	background	2K_dev_1751
	background	2K_dev_1751
Experiments demonstrate that continuous excavation ( e	finding	2K_dev_1751
g	finding	2K_dev_1751
bucket-wheel ) fares better than discrete excavation ( e	finding	2K_dev_1751
g	finding	2K_dev_1751
front-loader ) when subjected to gravity offload	finding	2K_dev_1751
and is better suited for planetary excavation	finding	2K_dev_1751
Lessons learned from the prototype development also address ways to mitigate suspension lift-off for lightweight skid-steer robots	finding	2K_dev_1751
a problem encountered during mobility field testing	finding	2K_dev_1751
	finding	2K_dev_1751
This key result is incorporated into the development of a novel planetary excavator prototype	mechanism	2K_dev_1751
	mechanism	2K_dev_1751
	method	2K_dev_1751
	background	2K_dev_1752
The resulting invariant generation method is observed to be much more scalable and efficient than the na `` ive approach	finding	2K_dev_1752
exhibiting orders of magnitude performance improvement on many of the problems	finding	2K_dev_1752
	finding	2K_dev_1752
Based on the notion of discrete abstraction	mechanism	2K_dev_1752
our method eliminates unsoundness and unnecessary coarseness found in existing approaches for computing abstractions for non-linear continuous systems and is able to construct invariants with intricate boolean structure	mechanism	2K_dev_1752
in contrast to invariants typically generated using template-based methods	mechanism	2K_dev_1752
In order to tackle the state explosion problem associated with discrete abstraction	mechanism	2K_dev_1752
we present invariant generation algorithms that exploit sound proof rules for safety verification	mechanism	2K_dev_1752
such as differential cut ( DC )	mechanism	2K_dev_1752
and a new proof rule that we call differential divide-and-conquer ( DDC )	mechanism	2K_dev_1752
which splits the verification problem into smaller sub-problems	mechanism	2K_dev_1752
	mechanism	2K_dev_1752
	method	2K_dev_1752
This paper presents a method for generating semi-algebraic invariants for systems governed by non-linear polynomial ordinary differential equations under semi-algebraic evolution constraints	purpose	2K_dev_1752
	purpose	2K_dev_1752
Reduced frequency range in vowel production is a well documented speech characteristic of individuals with psychological and neurological disorders	background	2K_dev_1753
Affective disorders such as depression and post-traumatic stress disorder ( PTSD ) are known to influence motor control and in particular speech production	background	2K_dev_1753
These findings could potentially support treatment of affective disorders	background	2K_dev_1753
like depression and PTSD in the future	background	2K_dev_1753
	background	2K_dev_1753
The experiments show a significantly reduced vowel space in subjects that scored positively on the questionnaires	finding	2K_dev_1753
We show the measure 's statistical robustness against varying demographics of individuals and articulation rate	finding	2K_dev_1753
The reduced vowel space for subjects with symptoms of depression can be explained by the common condition of psychomotor retardation influencing articulation and motor control	finding	2K_dev_1753
	finding	2K_dev_1753
Within this work	mechanism	2K_dev_1753
we investigate an automatic unsupervised machine learning based approach	mechanism	2K_dev_1753
Our experiments are based on recordings of 253 individuals Symptoms of depression and PTSD are assessed using standard self-assessment questionnaires and their cut-off scores	method	2K_dev_1753
	method	2K_dev_1753
The assessment and documentation of reduced vowel space and reduced expressivity often either rely on subjective assessments or on analysis of speech under constrained laboratory conditions ( e	purpose	2K_dev_1753
g	purpose	2K_dev_1753
sustained vowel production	purpose	2K_dev_1753
reading tasks )	purpose	2K_dev_1753
These constraints render the analysis of such measures expensive and impractical to assess a speaker 's vowel space	purpose	2K_dev_1753
Level-of-detail ( LOD ) rendering is a key optimization used by modern video game engines to achieve high-quality rendering with fast performance	background	2K_dev_1754
These LOD systems require simplified shaders	background	2K_dev_1754
but generating simplified shaders remains largely a manual optimization task for game developers	background	2K_dev_1754
	background	2K_dev_1754
	finding	2K_dev_1754
We present an end-to-end system The system operates on shaders used in both forward and deferred rendering pipelines	mechanism	2K_dev_1754
requires no additional semantic information beyond input shader source code	mechanism	2K_dev_1754
and in only seconds to minutes generates LOD policies ( consisting of simplified shader	mechanism	2K_dev_1754
the desired LOD distance set	mechanism	2K_dev_1754
and transition generation ) with performance and quality characteristics comparable to custom hand-authored solutions	mechanism	2K_dev_1754
Our design contributes new shader simplification transforms such as approximate common subexpression elimination and movement of GPU logic to parameter bind-time processing on the CPU	mechanism	2K_dev_1754
and it uses a greedy search algorithm that employs extensive caching and up-front collection of input shader statistics to rapidly identify simplified shaders with desirable performance-quality trade-offs	mechanism	2K_dev_1754
	mechanism	2K_dev_1754
	method	2K_dev_1754
Prior efforts to automate this process have taken hours to generate simplified shader candidates	purpose	2K_dev_1754
making them impractical for use in modern shader authoring workflows for complex scenes	purpose	2K_dev_1754
for automatically generating a LOD policy for an input shader	purpose	2K_dev_1754
	purpose	2K_dev_1754
	background	2K_dev_1755
validated	finding	2K_dev_1755
We present a computational tool with user-controlled aesthetics In contrast to approaches that leverage texture synthesis for creating decorative surface patterns	mechanism	2K_dev_1755
our method relies on user-defined spline curves as central design primitives More specifically	mechanism	2K_dev_1755
we build on the physically-inspired metaphor of an embedded elastic curve that can move on a smooth surface	mechanism	2K_dev_1755
deform	mechanism	2K_dev_1755
and connect with other curves We formalize this idea as a globally coupled energy-minimization problem	mechanism	2K_dev_1755
discretized with piece-wise linear curves that are optimized in the parametric space of a smooth surface	mechanism	2K_dev_1755
Building on this technical core	mechanism	2K_dev_1755
we propose a set of interactive design and editing tools that we demonstrate on manually-created layouts and semi-automated deformable packings In order to prevent excessive compliance	mechanism	2K_dev_1755
we furthermore propose a structural analysis tool that uses eigenanalysis	mechanism	2K_dev_1755
We used our approach to create a variety of designs in simulation with a set of 3D-printed physical prototypes	method	2K_dev_1755
	method	2K_dev_1755
for designing ornamental curve networks-structurally-sound physical surfaces to identify potentially large deformations between geodesically-close curves and guide the user in strengthening the corresponding regions	purpose	2K_dev_1755
	background	2K_dev_1756
We demonstrate the versatility of our method	finding	2K_dev_1756
We present an interactive tool made from flexible interlocking quadrilateral elements of a single size and shape	mechanism	2K_dev_1756
With the element shape fixed	mechanism	2K_dev_1756
the design task becomes one of finding a discrete structure-i	mechanism	2K_dev_1756
e	mechanism	2K_dev_1756
	mechanism	2K_dev_1756
element connectivity and binary orientations-that leads to a desired geometry	mechanism	2K_dev_1756
we propose a forward modeling tool that Paralleling principles from conventional modeling software	mechanism	2K_dev_1756
our approach leverages a library of base shapes that can be instantiated	mechanism	2K_dev_1756
combined	mechanism	2K_dev_1756
and extended using two fundamental operations : merging and extrusion	mechanism	2K_dev_1756
we furthermore propose a method	mechanism	2K_dev_1756
by creating a diverse set of digital and physical examples that can serve as personalized lamps or decorative items	method	2K_dev_1756
for designing physical surfaces In order to address this challenging problem of combinatorial geometry allows the user to interactively explore the space of feasible designs	purpose	2K_dev_1756
In order to assist the user in building the designs	purpose	2K_dev_1756
to automatically generate assembly instructions	purpose	2K_dev_1756
The proposed framework generalizes moderately well from textbook graphics to hand-drawn sketches	background	2K_dev_1757
and user effort ratio results demonstrate the potential power of an interactive system in which simple user interactions complement computer recognition for fast kinematic modeling	background	2K_dev_1757
	background	2K_dev_1757
Current state-of-the-art performance is achieved	finding	2K_dev_1757
In this work	mechanism	2K_dev_1757
we present a computational framework The hallmark of our approach is a novel combination of supervised learning methods for detecting mechanical parts ( e	mechanism	2K_dev_1757
g	mechanism	2K_dev_1757
joints	mechanism	2K_dev_1757
rigid bodies ) with the optimizing power of a multiobjective evolutionary algorithm	mechanism	2K_dev_1757
which concurrently maximizes image consistency and mechanical feasibility For the optimization	mechanism	2K_dev_1757
in addition to standard accuracy measures such as top-N accuracy	mechanism	2K_dev_1757
we introduce a new performance metric called user effort ratio that quantifies the amount of user interaction required to correct an inaccurate optimization solution	mechanism	2K_dev_1757
with ( i ) one ( or a cascade of ) support vector machines for joint detection	mechanism	2K_dev_1757
( ii ) foreground extraction to reduce 0 positives	mechanism	2K_dev_1757
( iii ) supervised body detection using normalized geodesic time	mechanism	2K_dev_1757
distance	mechanism	2K_dev_1757
and detected joint confidence	mechanism	2K_dev_1757
and ( iv ) feasibility constraints derived from graph theory	mechanism	2K_dev_1757
	mechanism	2K_dev_1757
A rigorous set of experiments was conducted to systematically evaluate the performance of each phase in our framework	method	2K_dev_1757
comparing various combinations of joint and body detection schemes and feasibility constraints	method	2K_dev_1757
Precision-recall curves are used to assess object detection performance	method	2K_dev_1757
for automatically generating kinematic models of planar mechanical linkages from raw images	purpose	2K_dev_1757
	purpose	2K_dev_1757
Data races complicate programming language semantics	background	2K_dev_1758
and a data race is often a bug	background	2K_dev_1758
Existing techniques detect data races and define their semantics by detecting conflicts between synchronization-free regions ( SFRs )	background	2K_dev_1758
Valor is the first region conflict detector to provide strong semantic guarantees for racy program executions with under 2X slowdown	background	2K_dev_1758
Overall	background	2K_dev_1758
Valor advances the state of the art in always-on support for strong behavioral guarantees for data races	background	2K_dev_1758
	background	2K_dev_1758
showing that Valor dramatically outperforms FastRCD and FastTrack	finding	2K_dev_1758
This paper describes Valor that achieves high performance by eliminating the costly analysis on each read operation that prior approaches require Valor instead logs a region 's reads and lazily detects conflicts for logged reads when the region ends	mechanism	2K_dev_1758
we have also developed FastRCD that leverages the epoch optimization strategy of the FastTrack data race detector	mechanism	2K_dev_1758
	mechanism	2K_dev_1758
As a comparison	method	2K_dev_1758
We evaluate Valor	method	2K_dev_1758
FastRCD	method	2K_dev_1758
and FastTrack	method	2K_dev_1758
	method	2K_dev_1758
However	purpose	2K_dev_1758
such techniques either modify hardware or slow programs dramatically	purpose	2K_dev_1758
preventing always-on use today	purpose	2K_dev_1758
a sound	purpose	2K_dev_1758
precise	purpose	2K_dev_1758
software-only region conflict detection analysis	purpose	2K_dev_1758
a conflict detector	purpose	2K_dev_1758
Much robotics research explores how robots can clearly communicate 1 information Robot deception is useful in conveying intentionality	background	2K_dev_1759
and in making games against the robot more engaging	background	2K_dev_1759
	background	2K_dev_1759
and the effects of iterated deception	finding	2K_dev_1759
	finding	2K_dev_1759
moving to a mathematical model	mechanism	2K_dev_1759
and ending with a studies on the implications of deceptive motion for human-robot interactions	method	2K_dev_1759
Here	purpose	2K_dev_1759
we focus on the counterpart : communicating 0 information	purpose	2K_dev_1759
or hiding information altogether-in one word	purpose	2K_dev_1759
deception	purpose	2K_dev_1759
We study robot deception in goal-directed motion	purpose	2K_dev_1759
in which the robot is concealing its actual goal	purpose	2K_dev_1759
We present an analysis of deceptive motion	purpose	2K_dev_1759
starting with how humans would deceive	purpose	2K_dev_1759
that enables the robot to autonomously generate deceptive motion	purpose	2K_dev_1759
Communication constraints dictated by hardware often require a multi-robot system to make decisions and take actions locally Unfortunately	background	2K_dev_1760
local knowledge may impose limits that ultimately impede global optimality in a decentralized optimization problem	background	2K_dev_1760
	background	2K_dev_1760
to show that the convergence of local searching processes is related to a shortest path routing problem on a graph subject to the network topology	finding	2K_dev_1760
results show that this fully decentralized method converges quickly while sacrificing little optimality	finding	2K_dev_1760
This paper enhances a recent anytime optimal assignment method based on a task-swap mechanism	mechanism	2K_dev_1760
redesigning the algorithm We propose a fully decentralized approach that allows local search processes to execute concurrently while minimizing interactions amongst the processes	mechanism	2K_dev_1760
needing neither global broadcast nor a multi-hop communication protocol	mechanism	2K_dev_1760
	mechanism	2K_dev_1760
The formulation is analyzed in a novel way using tools from group theory and optimization duality theory Simulation	method	2K_dev_1760
to address task allocation problems in a decentralized fashion	purpose	2K_dev_1760
Autonomous landing is an essential function for micro air vehicles ( MAVs ) for many scenarios	background	2K_dev_1761
	background	2K_dev_1761
in order to establish the efficacy and robustness of the proposed approach	finding	2K_dev_1761
	finding	2K_dev_1761
We pursue an active perception strategy with a vision-based perception system while generating trajectories The contributions of the work are twofold : ( 1 ) a perception system that employs a dense motion stereo approach that determines the 3D model of the captured scene without the need of geo-referenced images	mechanism	2K_dev_1761
scene geometry constraints	mechanism	2K_dev_1761
or external navigation aids ; and ( 2 ) an online trajectory generation approach that balances the need to concurrently explore available rooftop vantages of an interest point while ensuring confidence in the landing site suitability by considering the impact of landing site uncertainty as assessed by the perception system	mechanism	2K_dev_1761
Simulation and experimental evaluation of the performance of the perception and trajectory generation methodologies are analyzed independently and jointly	method	2K_dev_1761
that enables MAVs with limited onboard sensing and processing capabilities to concurrently assess feasible rooftop landing sites that balance continued landing site assessment and the requirement to provide visual monitoring of an interest point	purpose	2K_dev_1761
	purpose	2K_dev_1761
	background	2K_dev_1762
	finding	2K_dev_1762
We propose a new generative model of network evolution in dynamic and harsh environments	mechanism	2K_dev_1762
Our model can reproduce the range of topologies observed across known robust and fragile biological networks	mechanism	2K_dev_1762
as well as several additional transport	mechanism	2K_dev_1762
communication	mechanism	2K_dev_1762
and social networks	mechanism	2K_dev_1762
We also develop a new optimization measure based on preserving high connectivity following random or adversarial bursty node loss	mechanism	2K_dev_1762
propose a new distributed algorithm	mechanism	2K_dev_1762
Using this measure	method	2K_dev_1762
we evaluate the robustness of several real-world networks and	method	2K_dev_1762
Consider networks in harsh environments	purpose	2K_dev_1762
where nodes may be lost due to failure	purpose	2K_dev_1762
attack	purpose	2K_dev_1762
or infection-how is the topology affected by such events ? Can we mimic and measure the effect ? to evaluate robustness to construct secure networks operating within malicious environments	purpose	2K_dev_1762
	background	2K_dev_1763
	finding	2K_dev_1763
illustrating the potential to adapt and personalize the structure and motion of existing linkages	finding	2K_dev_1763
We present a method Given a working linkage as input	mechanism	2K_dev_1763
the user can make targeted edits to the shape or motion of selected parts while preserving other	mechanism	2K_dev_1763
e	mechanism	2K_dev_1763
g	mechanism	2K_dev_1763
	mechanism	2K_dev_1763
functionally-important aspects	mechanism	2K_dev_1763
In order to make this process intuitive and efficient	mechanism	2K_dev_1763
we provide a number of editing tools at different levels of abstraction	mechanism	2K_dev_1763
For instance	mechanism	2K_dev_1763
the user can directly change the structure of a linkage by displacing joints	mechanism	2K_dev_1763
edit the motion of selected points on the linkage	mechanism	2K_dev_1763
or impose limits on the size of its enclosure	mechanism	2K_dev_1763
Our method safeguards against degenerate configurations during these edits	mechanism	2K_dev_1763
thus ensuring the correct functioning of the mechanism at all times	mechanism	2K_dev_1763
Linkage editing poses strict requirements on performance that standard approaches fail to provide In order to enable interactive and robust editing	mechanism	2K_dev_1763
we build on a symbolic kinematics approach that uses closed-form expressions instead of numerical methods to compute the motion of a linkage and its derivatives	mechanism	2K_dev_1763
	mechanism	2K_dev_1763
We demonstrate our system on a diverse set of examples To validate the feasibility of our edited designs	method	2K_dev_1763
we fabricated two physical prototypes	method	2K_dev_1763
for interactive editing of planar linkages	purpose	2K_dev_1763
	purpose	2K_dev_1763
Motivation : It remains a challenge to detect associations between genotypes and phenotypes because of insufficient sample sizes and complex underlying mechanisms involved in associations	background	2K_dev_1764
Fortunately	background	2K_dev_1764
it is becoming more feasible to obtain gene expression data in addition to genotypes and phenotypes	background	2K_dev_1764
giving us new opportunities	background	2K_dev_1764
Results we show that NETAM finds significantly more phenotype-associated SNPs than traditional genotype-phenotype association analysis under 0 positive control	finding	2K_dev_1764
taking advantage of gene expression data	finding	2K_dev_1764
and identified 477 significant path associations	finding	2K_dev_1764
among which we analyzed paths related to beta-amyloid	finding	2K_dev_1764
estrogen	finding	2K_dev_1764
and nicotine pathways	finding	2K_dev_1764
We also provide hypothetical biological pathways to explain our findings	finding	2K_dev_1764
In this article	mechanism	2K_dev_1764
we propose a novel method	mechanism	2K_dev_1764
NETAM We take a network-driven approach : NETAM first constructs an association network	mechanism	2K_dev_1764
where nodes represent SNPs	mechanism	2K_dev_1764
gene traits or phenotypes	mechanism	2K_dev_1764
and edges represent the strength of association between two nodes NETAM assigns a score to each path from an SNP to a phenotype	mechanism	2K_dev_1764
and then identifies significant paths based on the scores	mechanism	2K_dev_1764
	mechanism	2K_dev_1764
In our simulation study Furthermore	method	2K_dev_1764
we applied NETAM on late-onset Alzheimer 's disease data	method	2K_dev_1764
to detect 1 genotype-phenotype associations while unveiling their association mechanisms	purpose	2K_dev_1764
that accurately detects associations between SNPs and phenotypes	purpose	2K_dev_1764
as well as gene traits involved in such associations	purpose	2K_dev_1764
	purpose	2K_dev_1764
	background	2K_dev_1765
We demonstrate the power of our approach Our method achieves superior performance	finding	2K_dev_1765
This paper presents a novel solution that automatically transforms unlabeled	mechanism	2K_dev_1765
heterogeneous motion data into new styles	mechanism	2K_dev_1765
The key idea of our approach is an online learning algorithm that automatically constructs a series of local mixtures of autoregressive models ( MAR ) We construct local MAR models on the fly by searching for the closest examples of each input pose in the database	mechanism	2K_dev_1765
Once the model parameters are estimated from the training data	mechanism	2K_dev_1765
the model adapts the current pose with simple linear transformations	mechanism	2K_dev_1765
In addition	mechanism	2K_dev_1765
we introduce an efficient local regression model	mechanism	2K_dev_1765
by transferring stylistic human motion for a wide variety of actions	method	2K_dev_1765
including walking	method	2K_dev_1765
running	method	2K_dev_1765
punching	method	2K_dev_1765
kicking	method	2K_dev_1765
jumping and transitions between those behaviors in a comparison against alternative methods	method	2K_dev_1765
We have also performed experiments to evaluate the generalization ability of our data-driven model as well as the key components of our system	method	2K_dev_1765
	method	2K_dev_1765
for realtime generation of stylistic human motion to capture the complex relationships between styles of motion	purpose	2K_dev_1765
to predict the timings of synthesized poses in the output style	purpose	2K_dev_1765
	background	2K_dev_1766
shows that	finding	2K_dev_1766
in practical time	finding	2K_dev_1766
Symbiosis generates DSPs that both isolate the small fraction of event orders and data-flows responsible for the failure	finding	2K_dev_1766
and show which event reorderings prevent failing DSPs contain 81\ % fewer events and 96\ % fewer data-flows than the full failure-inducing schedules	finding	2K_dev_1766
Moreover	finding	2K_dev_1766
by allowing developers to focus on only a few events	finding	2K_dev_1766
DSPs reduce the amount of time required to find a valid fix	finding	2K_dev_1766
	finding	2K_dev_1766
We present Symbiosis based on novel differential schedule projections ( DSPs )	mechanism	2K_dev_1766
A DSP shows the small set of memory operations and data-flows responsible for a failure	mechanism	2K_dev_1766
as well as a reordering of those elements that avoids the failure	mechanism	2K_dev_1766
To build a DSP	mechanism	2K_dev_1766
Symbiosis first generates a full	mechanism	2K_dev_1766
failing	mechanism	2K_dev_1766
multithreaded schedule via thread path profiling and symbolic constraint solving	mechanism	2K_dev_1766
Symbiosis selectively reorders events in the failing schedule to produce a non-failing	mechanism	2K_dev_1766
alternate schedule	mechanism	2K_dev_1766
A DSP reports the ordering and data-flow differences between the failing and non-failing schedules	mechanism	2K_dev_1766
	mechanism	2K_dev_1766
Our evaluation on buggy real-world software and benchmarks In our experiments	method	2K_dev_1766
a concurrency debugging technique	purpose	2K_dev_1766
Large-scale content-based semantic search in video is an interesting and fundamental problem in multimedia analysis and retrieval	background	2K_dev_1767
results validate the efficacy and the efficiency of the proposed method	finding	2K_dev_1767
The results show that our method can scale up the semantic search while maintaining state-of-the-art search performance	finding	2K_dev_1767
Specifically	finding	2K_dev_1767
the proposed method ( with reranking ) achieves the best result on the challenging TRECVID Multimedia Event Detection ( MED ) zero-example task	finding	2K_dev_1767
It only takes 0	finding	2K_dev_1767
2 second on a single CPU core to search a collection of 100 million Internet videos	finding	2K_dev_1767
	finding	2K_dev_1767
The key is a novel step called concept adjustment that represents a video by a few salient and consistent concepts that can be efficiently indexed by the modified inverted index	mechanism	2K_dev_1767
The proposed adjustment model relies on a concise optimization framework with interpretations	mechanism	2K_dev_1767
The proposed index leverages the text-based inverted index for video retrieval	mechanism	2K_dev_1767
	mechanism	2K_dev_1767
Experimental	method	2K_dev_1767
Existing methods index a video by the raw concept detection score that is dense and inconsistent	purpose	2K_dev_1767
and thus can not scale to `` big data { '' } that are readily available on the Internet	purpose	2K_dev_1767
This paper proposes a scalable solution	purpose	2K_dev_1767
	purpose	2K_dev_1767
Multimedia event detection ( MED ) and multimedia event recounting ( MER ) are fundamental tasks in managing large amounts of unconstrained web videos	background	2K_dev_1768
and have attracted a lot of attention in recent years	background	2K_dev_1768
	background	2K_dev_1768
	finding	2K_dev_1768
and obtain very promising results for both MED and MER	finding	2K_dev_1768
we propose a joint framework that simultaneously detects high-level events and localizes the indicative concepts of the events Coupled in a joint optimization framework	mechanism	2K_dev_1768
recounting improves detection by pruning irrelevant noisy concepts while detection directs recounting to the most discriminative evidences To better utilize the powerful and interpretable semantic video representation	mechanism	2K_dev_1768
we segment each video into several shots and exploit the rich temporal structures at shot level	mechanism	2K_dev_1768
The consequent computational challenge is carefully addressed through a significant improvement of the current ADMM algorithm	mechanism	2K_dev_1768
which	mechanism	2K_dev_1768
after eliminating all inner loops and equipping novel closed-form solutions for all intermediate steps	mechanism	2K_dev_1768
enables us to efficiently process extremely large video corpora	mechanism	2K_dev_1768
	mechanism	2K_dev_1768
We test the proposed method on the large scale TRECVID MEDTest 2014 and MEDTest 2013 datasets	method	2K_dev_1768
Most existing systems perform MER as a post-processing step on top of the MED results	purpose	2K_dev_1768
In order to leverage the mutual benefits of the two tasks Our premise is that a good recounting algorithm should not only explain the detection result	purpose	2K_dev_1768
but should also be able to assist detection in the first place	purpose	2K_dev_1768
( 1 ) will make the models informative across different categories ; ( 2 ) will dramatically reduce the need for manually annotating vast datasets for training detectors ; and ( 3 ) will enable rapid generation of new detectors	background	2K_dev_1769
	background	2K_dev_1769
	finding	2K_dev_1769
In this paper	mechanism	2K_dev_1769
we explore an approach that is radically different from the conventional way of learning a detector from a large corpus of annotated positive and negative data samples	mechanism	2K_dev_1769
Instead	mechanism	2K_dev_1769
we assume that we have evaluated `` off-line { '' } a large library of detectors against a large set of detection tasks Given a new target task	mechanism	2K_dev_1769
we evaluate a subset of the models on few samples from the new task and we use the matrix of models tasks ratings to predict the performance of all the models in the library on the new task	mechanism	2K_dev_1769
enabling us to select a good set of detectors for the new task	mechanism	2K_dev_1769
This approach has three key advantages of great interest in practice : 1 ) generating a large collection of expressive models in an unsupervised manner is possible ; 2 ) a far smaller set of annotated samples is needed compared to that required for training from scratch ; and 3 ) recommending models is a very fast operation compared to the notoriously expensive training procedures of modern detectors	mechanism	2K_dev_1769
	mechanism	2K_dev_1769
	method	2K_dev_1769
to generating detectors	purpose	2K_dev_1769
Results are better than or comparable to state-of-the-art results on the image and sentence retrieval tasks for methods using similar visual features	background	2K_dev_1770
State-of-the-art results are shown for the task of generating novel image descriptions our automatically generated captions are equal to or preferred by humans 21	finding	2K_dev_1770
0\ % of the time	finding	2K_dev_1770
	finding	2K_dev_1770
Critical to our approach is a recurrent neural network that attempts to dynamically build a visual representation of the scene as a caption is being generated or read	mechanism	2K_dev_1770
The representation automatically learns to remember long-term visual concepts	mechanism	2K_dev_1770
Our model is capable of both generating novel captions given an image	mechanism	2K_dev_1770
and reconstructing visual features given an image description	mechanism	2K_dev_1770
We evaluate our approach on several tasks	method	2K_dev_1770
These include sentence generation	method	2K_dev_1770
sentence retrieval and image retrieval When compared to human generated captions	method	2K_dev_1770
In this paper we explore the bi-directional mapping between images and their sentence-based descriptions	purpose	2K_dev_1770
Convolutional Neural Networks ( CNNs ) have achieved promising performance in image classification and action recognition tasks	background	2K_dev_1771
	background	2K_dev_1771
demonstrate the promising performance of our method	finding	2K_dev_1771
both for event detection and evidence recounting	finding	2K_dev_1771
	finding	2K_dev_1771
In this work	mechanism	2K_dev_1771
we propose a flexible deep CNN infrastructure	mechanism	2K_dev_1771
namely Deep Event Network ( DevNet )	mechanism	2K_dev_1771
Taking key frames of videos as input	mechanism	2K_dev_1771
we first detect the event of interest at the video level by aggregating the CNN features of the key frames	mechanism	2K_dev_1771
The pieces of evidences which recount the detection results	mechanism	2K_dev_1771
are also automatically localized	mechanism	2K_dev_1771
both temporally and spatially	mechanism	2K_dev_1771
The challenge is that we only have video level labels	mechanism	2K_dev_1771
while the key evidences usually take place at the frame levels	mechanism	2K_dev_1771
Based on the intrinsic property of CNNs	mechanism	2K_dev_1771
we first generate a spatial-temporal saliency map by back passing through DevNet	mechanism	2K_dev_1771
which then can be used to find the key frames which are most indicative to the event	mechanism	2K_dev_1771
as well as to localize the specific spatial position	mechanism	2K_dev_1771
usually an object	mechanism	2K_dev_1771
in the frame of the highly indicative area	mechanism	2K_dev_1771
	mechanism	2K_dev_1771
Experiments on the large scale TRECVID 2014 MEDTest dataset	method	2K_dev_1771
In this paper	purpose	2K_dev_1771
we focus on complex event detection in internet videos while also providing the key evidences of the detection results	purpose	2K_dev_1771
However	purpose	2K_dev_1771
it remains an open problem how to use CNNs for video event detection and recounting	purpose	2K_dev_1771
mainly due to the complexity and diversity of video events	purpose	2K_dev_1771
that simultaneously detects pre-defined events and provides key spatial-temporal evidences	purpose	2K_dev_1771
	purpose	2K_dev_1771
	background	2K_dev_1772
show that our method compares competitively with the state of the art on both 2D and 3D measures	finding	2K_dev_1772
while yielding a richer interpretation of the 3D scene behind the image	finding	2K_dev_1772
	finding	2K_dev_1772
In this paper	mechanism	2K_dev_1772
we propose a novel algorithm that infers the 3D layout of building facades from a single 2D image of an urban scene	mechanism	2K_dev_1772
Different from existing methods that only yield coarse orientation labels or qualitative block approximations	mechanism	2K_dev_1772
our algorithm quantitatively using a set of planes mutually related by 3D geometric constraints	mechanism	2K_dev_1772
Each plane is characterized by a continuous orientation vector and a depth distribution	mechanism	2K_dev_1772
An optimal solution is reached through inter-planar interactions Due to the quantitative and plane-based nature of our geometric reasoning	mechanism	2K_dev_1772
our model is more expressive and informative than existing approaches	mechanism	2K_dev_1772
	mechanism	2K_dev_1772
Experiments	method	2K_dev_1772
reconstructs building facades in 3D space	purpose	2K_dev_1772
two of the most prevalent sources of data on the Web	background	2K_dev_1773
Blogs consist of sequences of images and associated text : they portray events and experiences with concise sentences and representative images	background	2K_dev_1773
In the opposite direction	background	2K_dev_1773
blog posts can be enhanced with sets of photo streams by showing interpolations between consecutive images in the blogs	background	2K_dev_1773
	background	2K_dev_1773
we demonstrate that blog posts and photo streams are mutually beneficial for summarization	finding	2K_dev_1773
exploration	finding	2K_dev_1773
semantic knowledge transfer	finding	2K_dev_1773
and photo interpolation	finding	2K_dev_1773
We propose an approach that utilize large collections of photo streams and blog posts	mechanism	2K_dev_1773
We leverage Hogs to help achieve story-based semantic summarization of collections of photo streams	mechanism	2K_dev_1773
We formulate the problem of joint alignment from blogs to photo streams and photo stream summarization in a unified latent ranking SVM framework	mechanism	2K_dev_1773
We alternate between solving the two coupled latent SVM problems	mechanism	2K_dev_1773
by first fixing the summarization and solving for the alignment from blog images to photo streams and vice versa	mechanism	2K_dev_1773
	mechanism	2K_dev_1773
On a newly collected large-scale Disneyland dataset of 10K blogs ( 120K associated images ) and OK photo streams ( 540K images )	method	2K_dev_1773
	method	2K_dev_1773
for joint story-based summarization and exploration	purpose	2K_dev_1773
In contrast	background	2K_dev_1774
existing approaches either do not consider multiple object instances per video	background	2K_dev_1774
or rely heavily on the motion of the objects present	background	2K_dev_1774
	background	2K_dev_1774
demonstrate the effectiveness of our approach	finding	2K_dev_1774
We present a semi-supervised approach that We start with a handful of labeled boxes and iteratively learn and label hundreds of thousands of object instances	mechanism	2K_dev_1774
We propose criteria for for constraining the semi-supervised learning process and minimizing semantic drift	mechanism	2K_dev_1774
Our approach does not assume exhaustive labeling of each object instance in any single frame	mechanism	2K_dev_1774
or any explicit annotation of negative data	mechanism	2K_dev_1774
Working in such a generic setting allow us to tackle multiple object instances in video	mechanism	2K_dev_1774
many of which are static	mechanism	2K_dev_1774
	mechanism	2K_dev_1774
The experiments by evaluating the automatically labeled data on a variety of metrics like quality	method	2K_dev_1774
coverage ( recall )	method	2K_dev_1774
diversity	method	2K_dev_1774
and relevance to training an object detector	method	2K_dev_1774
localizes multiple unknown object instances in long videos	purpose	2K_dev_1774
reliable object detection and tracking	purpose	2K_dev_1774
Contact behaviors in physics simulations are important for real-time interactive applications	background	2K_dev_1775
especially in virtual reality applications where user 's body parts are tracked and interact with the environment via contact	background	2K_dev_1775
For these contact simulations	background	2K_dev_1775
it is ideal to have small changes in initial condition yield predictable changes in the output	background	2K_dev_1775
Predictable simulation is key for success in iterative learning processes as well	background	2K_dev_1775
such as learning controllers for manipulations or locomotion tasks	background	2K_dev_1775
Our results confirmed that parameter settings do matter a great deal and suggest that there may be a trade-off between accuracy and predictability	background	2K_dev_1775
	background	2K_dev_1775
We found that in the commonly available physics engines	finding	2K_dev_1775
small changes in initial condition can sometimes induce different sequences of contact events to occur and ultimately lead to a vastly different result	finding	2K_dev_1775
	finding	2K_dev_1775
	mechanism	2K_dev_1775
We first tune each engine to match an analytical solution as closely as possible and then compare the results for a more complex simulation	method	2K_dev_1775
	method	2K_dev_1775
Here	purpose	2K_dev_1775
we present an extensive comparison of contact simulations using Bullet Physics	purpose	2K_dev_1775
Dynamic Animation and Robotics Toolkit ( DART )	purpose	2K_dev_1775
MuJoCo	purpose	2K_dev_1775
and Open Dynamics Engine	purpose	2K_dev_1775
with a focus on predictability of behavior	purpose	2K_dev_1775
	background	2K_dev_1776
	finding	2K_dev_1776
We present a co-clustering framework Unlike traditional clustering approaches which assume a one-to-one mapping between the clusters in the text-based feature space and the visual space	mechanism	2K_dev_1776
we adopt a one-to-many mapping between the two spaces	mechanism	2K_dev_1776
This is primarily because each semantic sense ( concept ) can correspond to different visual senses due to viewpoint and appearance variations Our structure-EM style optimization not only	mechanism	2K_dev_1776
We introduce a challenging dataset ( CMU Polysemy-30 ) for this problem consisting of 30 NPs ( similar to 5600 labeled instances out of similar to 22K total instances )	method	2K_dev_1776
We have also conducted a large-scale experiment that performs sense disambiguation for similar to 2000 NPs	method	2K_dev_1776
that can be used to discover multiple semantic and visual senses of a given Noun Phrase ( NP )	purpose	2K_dev_1776
extracts the multiple senses in both semantic and visual feature space	purpose	2K_dev_1776
but also discovers the mapping between the senses	purpose	2K_dev_1776
We envision a future time when wearable cameras ( e	background	2K_dev_1777
g	background	2K_dev_1777
	background	2K_dev_1777
small cameras in glasses or pinned on a shirt collar ) are worn by the masses and record first-person point-of-view ( POV ) videos of everyday life	background	2K_dev_1777
Furthermore	background	2K_dev_1777
we show how our approach can enable several practical applications such as privacy filtering	background	2K_dev_1777
automated video collection and social group discovery	background	2K_dev_1777
	background	2K_dev_1777
Our proposed approach significantly improves self-search performance over several well-known face detectors and recognizers	finding	2K_dev_1777
	finding	2K_dev_1777
Motivated by these benefits and risks	mechanism	2K_dev_1777
we develop a self-search technique tailored to first-person POV videos	mechanism	2K_dev_1777
The key observation of our work is that the egocentric head motions of a target person ( i	mechanism	2K_dev_1777
e	mechanism	2K_dev_1777
	mechanism	2K_dev_1777
the self ) are observed both in the POV video of the target and observer The motion correlation between the target person 's video and the observer 's video can then be used to uniquely identify instances of the self	mechanism	2K_dev_1777
We incorporate this feature into our proposed approach that computes the motion correlation over supervoxel hierarchies to localize target instances in observer videos	mechanism	2K_dev_1777
	mechanism	2K_dev_1777
	method	2K_dev_1777
While these cameras can enable new assistive technologies and novel research challenges	purpose	2K_dev_1777
they also raise serious privacy concerns	purpose	2K_dev_1777
For example	purpose	2K_dev_1777
first-person videos passively recorded by wearable cameras will necessarily include anyone who comes into the view of a camera - with or without consent	purpose	2K_dev_1777
	purpose	2K_dev_1777
Semantic search in video is a novel and challenging problem in information and multimedia retrieval Existing solutions are mainly limited to text matching	background	2K_dev_1778
in which the query words are matched against the textual metadata generated by users	background	2K_dev_1778
We share our observations and lessons in building such a state-of-the-art system	background	2K_dev_1778
which may be instrumental in guiding the design of the future system for semantic search in video	background	2K_dev_1778
	background	2K_dev_1778
The novelty and practicality is demonstrated where the proposed system achieves the best performance	finding	2K_dev_1778
	finding	2K_dev_1778
This paper presents a state-of-the-art system The system relies on substantial video content understanding and allows for semantic search over a large collection of videos	mechanism	2K_dev_1778
by the evaluation in NIST TRECVID 2014	method	2K_dev_1778
	method	2K_dev_1778
for event search without any textual metadata or example videos	purpose	2K_dev_1778
	purpose	2K_dev_1778
Many recent works propose mechanisms demonstrating the potential advantages of managing memory at a fine ( e	background	2K_dev_1779
g	background	2K_dev_1779
	background	2K_dev_1779
cache line ) granularity-e	background	2K_dev_1779
g	background	2K_dev_1779
	background	2K_dev_1779
fine-grained deduplication and fine-grained memory protection	background	2K_dev_1779
	background	2K_dev_1779
We show that our framework can enable simple and efficient implementations of seven memory management techniques	finding	2K_dev_1779
each of which has a wide variety of applications	finding	2K_dev_1779
Our evaluations show that overlay-on-write	finding	2K_dev_1779
when applied to fork	finding	2K_dev_1779
can improve performance by 15\ % and reduce memory capacity requirements by 53\ % on average compared to traditional copy-on-write	finding	2K_dev_1779
For sparse data computation	finding	2K_dev_1779
our framework can outperform a state-of-the-art software-based sparse representation on a number of real-world sparse matrices	finding	2K_dev_1779
Our framework is general	finding	2K_dev_1779
powerful	finding	2K_dev_1779
and effective in enabling fine-grained memory management at low cost	finding	2K_dev_1779
	finding	2K_dev_1779
We propose a new virtual memory framework In our framework	mechanism	2K_dev_1779
each virtual page can be mapped to a structure called a page overlay	mechanism	2K_dev_1779
in addition to a regular physical page	mechanism	2K_dev_1779
An overlay contains a subset of cache lines from the virtual page	mechanism	2K_dev_1779
Cache lines that are present in the overlay are accessed from there and all other cache lines are accessed from the regular physical page	mechanism	2K_dev_1779
Our page-overlay framework enables cache-line-granularity memory management without significantly altering the existing virtual memory framework or introducing high overheads	mechanism	2K_dev_1779
	mechanism	2K_dev_1779
We quantitatively evaluate the potential benefits of two of these techniques : overlay-on-write and sparse-data-structure computation	method	2K_dev_1779
Unfortunately	purpose	2K_dev_1779
existing virtual memory systems track memory at a larger granularity ( e	purpose	2K_dev_1779
g	purpose	2K_dev_1779
	purpose	2K_dev_1779
4 KB pages )	purpose	2K_dev_1779
inhibiting efficient implementation of such techniques	purpose	2K_dev_1779
Simply reducing the page size results in an unacceptable increase in page table overhead and TLB pressure that enables efficient implementation of a variety of fine-grained memory management techniques	purpose	2K_dev_1779
	purpose	2K_dev_1779
Distributed in-memory key-value stores ( KVSs )	background	2K_dev_1780
such as memcached	background	2K_dev_1780
have become a critical data serving layer in modern Internet-oriented datacenter infrastructure	background	2K_dev_1780
Their performance and efficiency directly affect the QoS of web services and the efficiency of datacenters Traditionally	background	2K_dev_1780
these systems have had significant overheads from inefficient network processing	background	2K_dev_1780
OS kernel involvement	background	2K_dev_1780
and concurrency control	background	2K_dev_1780
	background	2K_dev_1780
to achieve a record setting throughput of 120 million requests per second ( MRPS ) on a single commodity server	finding	2K_dev_1780
Our implementation delivers 9	finding	2K_dev_1780
2X the performance ( RPS ) and 2	finding	2K_dev_1780
8X the system energy efficiency ( RPS/watt ) of the best-published FPGA-based claims	finding	2K_dev_1780
demonstrate the capability of achieving a billion RPS with a single server constructed following our principles	finding	2K_dev_1780
and start with a rigorous architectural characterization across system stacks over a collection of representative KVS implementations	mechanism	2K_dev_1780
Our detailed full-system characterization not only identifies the critical hardware/software ingredients for high-petformance KVS systems	mechanism	2K_dev_1780
but also leads to guided optimizations atop a recent design We craft a set of design principles for future platform architectures	mechanism	2K_dev_1780
	mechanism	2K_dev_1780
and via detailed simulations	method	2K_dev_1780
Two recent research thrusts have focused upon improving key-value performance	purpose	2K_dev_1780
Hardware-centric research has started to explore specialized platforms including FPGA5 for KVSs ; results demonstrated an order of magnitude increase in throughput and energy efficiency over stock memcached	purpose	2K_dev_1780
Software-centric research revisited the KVS application to address fundamental software bottlenecks and to exploit the full potential of modern commodity hardware ; these efforts too showed orders of magnitude improvement over stock memcached	purpose	2K_dev_1780
We aim at architecting high performance and efficient KVS platforms	purpose	2K_dev_1780
	purpose	2K_dev_1780
Recovering the motion of a non-rigid body from a set of monocular images permits the analysis of dynamic scenes in uncontrolled environments However	background	2K_dev_1781
the extension of factorisation algorithms for rigid structure from motion to the low-rank non-rigid case has proved challenging	background	2K_dev_1781
We therefore make the recommendation that 3D reconstruction error always be measured relative to a trivial reconstruction such as a planar one	background	2K_dev_1781
	background	2K_dev_1781
{ [ } 1 ]	finding	2K_dev_1781
which we find to produce only coplanar reconstructions	finding	2K_dev_1781
	finding	2K_dev_1781
We elucidate that this greater difficulty is due to the need to find multiple solutions to a non-trivial problem	mechanism	2K_dev_1781
casting a number of previous approaches as alleviating this issue by either a ) introducing constraints on the basis	mechanism	2K_dev_1781
making the problems nonidentical	mechanism	2K_dev_1781
or b ) incorporating heuristics to encourage a diverse set of solutions	mechanism	2K_dev_1781
making the problems inter-dependent	mechanism	2K_dev_1781
However	mechanism	2K_dev_1781
we acknowledge that our method minimises an algebraic error and is thus inherently sensitive to deviation from the low-rank model	mechanism	2K_dev_1781
	mechanism	2K_dev_1781
We compare our closed-form solution for non-rigid structure with known cameras to the closed-form solution of Dai et al	method	2K_dev_1781
	method	2K_dev_1781
This stems from the comparatively hard problem of finding a linear `` corrective transform { '' } which recovers the projection and structure matrices from an ambiguous factorisation While it has previously been recognised that finding a single solution to this problem is sufficient to estimate cameras	purpose	2K_dev_1781
we show that it is possible to bootstrap this partial solution to find the complete transform in closed-form	purpose	2K_dev_1781
	purpose	2K_dev_1781
These two types of images are captured from orthogonal viewpoints and have different resolutions	background	2K_dev_1782
thus conveying very different types of information that can be used in a complementary way Moreover	background	2K_dev_1782
their integration is necessary to enable an accurate understanding of changes in natural phenomena over massive city-scale landscapes	background	2K_dev_1782
	background	2K_dev_1782
	finding	2K_dev_1782
our proposed method is capable of generating detailed estimates of land surface conditions over an entire city	finding	2K_dev_1782
	finding	2K_dev_1782
The strategy proposed in this work uses macro-level imaging to learn the extent to which the land condition corresponds between land regions that share similar visual characteristics ( e	mechanism	2K_dev_1782
g	mechanism	2K_dev_1782
	mechanism	2K_dev_1782
mountains	mechanism	2K_dev_1782
streets	mechanism	2K_dev_1782
buildings	mechanism	2K_dev_1782
rivers )	mechanism	2K_dev_1782
whereas micro-level images are used to acquire high resolution statistics of land conditions ( e	mechanism	2K_dev_1782
g	mechanism	2K_dev_1782
	mechanism	2K_dev_1782
the amount of debris on the ground )	mechanism	2K_dev_1782
By combining macro- and micro-level information about regional correspondences and surface conditions	mechanism	2K_dev_1782
	method	2K_dev_1782
We address the task of estimating large-scale land surface conditions using overhead aerial ( macro-level ) images and street view ( micro-level ) images The key technical challenge is devising a method to integrate these two disparate types of image data in an effective manner	purpose	2K_dev_1782
to leverage the wide coverage capabilities of macro-level images and detailed resolution of micro-level images	purpose	2K_dev_1782
A popular approach in this regard is to represent a sequence using a bag of words ( BOW ) representation due to its : ( i ) fixed dimensionality irrespective of the sequence length	background	2K_dev_1783
and ( ii ) its ability to compactly model the statistics in A drawback to the BOW representation	background	2K_dev_1783
however	background	2K_dev_1783
is the intrinsic destruction of the temporal ordering information	background	2K_dev_1783
	background	2K_dev_1783
show significant performance improvements across both isolated and continuous event detection tasks	finding	2K_dev_1783
	finding	2K_dev_1783
In this paper we propose a new representation that leverages the uncertainty in relative temporal alignments between pairs of sequences while not destroying temporal ordering Our representation	mechanism	2K_dev_1783
like BOW	mechanism	2K_dev_1783
is of a fixed dimensionality making it easily integrated with a linear detection function	mechanism	2K_dev_1783
	mechanism	2K_dev_1783
Extensive experiments on CK+	method	2K_dev_1783
6DMG	method	2K_dev_1783
and UvA-NEMO databases	method	2K_dev_1783
In this paper we tackle the problem of efficient video event detection	purpose	2K_dev_1783
We argue that linear detection functions should be preferred in this regard due to their scalability and efficiency during estimation and evaluation	purpose	2K_dev_1783
	purpose	2K_dev_1783
Occupancy count in rooms is valuable for applications such as room utilization	background	2K_dev_1784
opportunistic meeting support	background	2K_dev_1784
and efficient heating-cooling operations	background	2K_dev_1784
	background	2K_dev_1784
PerCSS estimates occupancy with a normalized mean squared error ( NMSE ) of 0	finding	2K_dev_1784
075 and outperformed our comparative methods in predicting occupancy count with 91 \ % and 15 \ % for exact occupancy estimation	finding	2K_dev_1784
when the room was unoccupied and occupied respectively	finding	2K_dev_1784
whereas the competing methods failed mostly	finding	2K_dev_1784
In this paper we present the PerCCS algorithm that explores the possibility from CO2 sensors already integrated in everyday room airconditioning infrastructure	mechanism	2K_dev_1784
PerCSS uses task-driven Sparse Non-negative Matrix Factorization ( SNMF ) to learn a nonnegative low-dimensional representation of the CO2 data in the preprocessing stage This denoised CO2 acts as the predictor variable for estimating occupancy count using Ensemble Least Square Regression	mechanism	2K_dev_1784
	mechanism	2K_dev_1784
We tested the algorithm to estimate 15 minutes average occupancy count from a classroom of capacity 42 and compared its performance against existing methods from the literature	method	2K_dev_1784
	method	2K_dev_1784
Few buildings	purpose	2K_dev_1784
however	purpose	2K_dev_1784
have the means of knowing occupancy beyond simple binary presence-absence of estimating person count	purpose	2K_dev_1784
Understanding the purpose of why sensitive data is used could help improve privacy as well as enable new kinds of access control	background	2K_dev_1785
	finding	2K_dev_1785
and achieved an accuracy of about 85\ % and 94\ % respectively in inferring purposes	finding	2K_dev_1785
We have also found that text-based features alone are highly effective in inferring purposes	finding	2K_dev_1785
In this paper	mechanism	2K_dev_1785
we introduce a new technique We extract multiple kinds of features from decompiled code	mechanism	2K_dev_1785
focusing on app-specific features and text-based features These features are then used to train a machine learning classifier	mechanism	2K_dev_1785
We have evaluated our approach in the context of two sensitive permissions	method	2K_dev_1785
namely ACCESS FINE LOCATION and READ CONTACT LIST	method	2K_dev_1785
for inferring the purpose of sensitive data usage in the context of Android smartphone apps	purpose	2K_dev_1785
	purpose	2K_dev_1785
Some languages have very consistent mappings between graphemes and phonemes	background	2K_dev_1786
while in other languages	background	2K_dev_1786
this mapping is more ambiguous	background	2K_dev_1786
Consonantal writing systems prove to be a challenge for Text to Speech Systems ( TTS ) because they do not indicate short vowels	background	2K_dev_1786
which creates an ambiguity in pronunciation Special letter-to-sound rules may be needed for some cases in languages that otherwise have a good correspondence between graphemes and phonemes Our methods can be generalized to other languages that exhibit similar phenomena	background	2K_dev_1786
and show significant improvements for dialects of Arabic	finding	2K_dev_1786
	finding	2K_dev_1786
We propose a technique during ITS training and predict pronunciations from text during synthesis time	mechanism	2K_dev_1786
We conduct experiments on dialects of Arabic for disambiguating homographs and Hindi for discovering the schwa-deletion rules	mechanism	2K_dev_1786
	mechanism	2K_dev_1786
We evaluate our systems using objective and subjective metrics of TTS	method	2K_dev_1786
In the low-resource scenario	purpose	2K_dev_1786
we may not have linguistic resources such as diacritizers or hand-written rules for the language	purpose	2K_dev_1786
to automatically learn pronunciations iteratively from acoustics	purpose	2K_dev_1786
Distant speech recognition ( DSR ) remains to be an open challenge	background	2K_dev_1787
even for the state-of-the-art deep neural network ( DNN ) models	background	2K_dev_1787
Previous work has attempted to improve DNNs under constantly distant speech	background	2K_dev_1787
	background	2K_dev_1787
Our experiments show that in the simplest case	finding	2K_dev_1787
incorporating the SMD descriptors improves word error rates of DNNs by 5	finding	2K_dev_1787
6\ % relative	finding	2K_dev_1787
Further optimizing SMD extraction and integration results in more gains	finding	2K_dev_1787
Our solution is to incorporate the frame-level SMD information into DNN training	mechanism	2K_dev_1787
Generation of the SMD information relies on a universal extractor that is learned on a meeting corpus	mechanism	2K_dev_1787
	mechanism	2K_dev_1787
We study the utility of different architectures in instantiating the SMD extractor	method	2K_dev_1787
On our target acoustic modeling task	method	2K_dev_1787
two approaches are proposed to build distance-aware DNN models using the SMD information : simple concatenation and distance adaptive training ( DAT )	method	2K_dev_1787
	method	2K_dev_1787
However	purpose	2K_dev_1787
in real applications	purpose	2K_dev_1787
the speaker-microphone distance ( SMD ) can be quite dynamic	purpose	2K_dev_1787
varying even within a single utterance	purpose	2K_dev_1787
This paper investigates how to alleviate the impact of dynamic SMD on DNN models	purpose	2K_dev_1787
	purpose	2K_dev_1787
Spoken Term Detection ( STD ) or Keyword Search ( KWS ) techniques can locate keyword instances but do not differentiate between meanings	background	2K_dev_1788
	background	2K_dev_1788
We show that the distributed representation approach outperforms all other approaches	finding	2K_dev_1788
regardless of the WER Although LDA-based approaches do well on clean data	finding	2K_dev_1788
they degrade significantly with WER	finding	2K_dev_1788
Paradoxically	finding	2K_dev_1788
lower WER does not guarantee better SWSI performance	finding	2K_dev_1788
due to the influence of common locutions	finding	2K_dev_1788
	finding	2K_dev_1788
In this paper we present a fully unsupervised SWSI approach based on distributed representations of spoken utterances To determine how ASR performance affects SWSI	mechanism	2K_dev_1788
we used three different levels of Word Error Rate ( WER )	mechanism	2K_dev_1788
40\ %	mechanism	2K_dev_1788
20\ % and 0\ % ; 40\ % WER is representative of online video	mechanism	2K_dev_1788
0\ % of text	mechanism	2K_dev_1788
We compare this approach to several others	method	2K_dev_1788
including the state-of-the-art Hierarchical Dirichlet Process ( HDP )	method	2K_dev_1788
	method	2K_dev_1788
Spoken Word Sense Induction ( SWSI ) differentiates target instances by clustering according to context	purpose	2K_dev_1788
providing a more useful result	purpose	2K_dev_1788
	purpose	2K_dev_1788
Ensuring language coverage in dialog systems can be a challenge	background	2K_dev_1789
since the language in a domain may drift over time	background	2K_dev_1789
creating a mismatch between the original training data and current input	background	2K_dev_1789
This in turn degrades performance by increasing misunderstanding and eventually leading to task failure	background	2K_dev_1789
Without the capability of adapting the vocabulary and the language model based on certain domains or users	background	2K_dev_1789
recognition errors may degrade the understanding performance	background	2K_dev_1789
and even lead to a task failure	background	2K_dev_1789
which incurs more time and effort to recover	background	2K_dev_1789
	background	2K_dev_1789
show that both recognition and semantic parsing accuracy can thereby be improved	finding	2K_dev_1789
	finding	2K_dev_1789
by leveraging different types of relatedness between vocabulary items and words retrieved from web-based resources	mechanism	2K_dev_1789
	mechanism	2K_dev_1789
Our experiments	method	2K_dev_1789
This paper investigates how coverage can be maintained by automatically acquiring potential out-of-vocabulary ( OOV ) words	purpose	2K_dev_1789
	background	2K_dev_1790
The experiments show that high-level semantic information can accurately estimate the prominence of slots	finding	2K_dev_1790
significantly improving the slot induction performance ; furthermore	finding	2K_dev_1790
a semantic decoder trained on the data with automatically extracted slots achieves about 68\ % F-measure	finding	2K_dev_1790
which is close to the one from hand-crafted grammars	finding	2K_dev_1790
	finding	2K_dev_1790
	mechanism	2K_dev_1790
Given unlabelled conversations	method	2K_dev_1790
we augment a frame-semantic based unsupervised slot induction approach with hierarchical agglomerative clustering to merge topically-related slots ( e	method	2K_dev_1790
g	method	2K_dev_1790
	method	2K_dev_1790
both slots `` direction { '' } and `` locale { '' } convey location-related information ) for building a coherent semantic hierarchy	method	2K_dev_1790
and then estimate the slot importance at different levels	method	2K_dev_1790
The high-level semantic estimation involves not only within-slot but also cross slot relations	method	2K_dev_1790
	method	2K_dev_1790
We study the problem of unsupervised ontology learning for semantic understanding in spoken dialogue systems	purpose	2K_dev_1790
in particular	purpose	2K_dev_1790
learning the hierarchical semantic structure from the data	purpose	2K_dev_1790
	purpose	2K_dev_1790
Self-adaptive systems overcome many of the limitations of human supervision in complex software-intensive systems by endowing them with the ability to automatically adapt their structure and behavior in the presence of runtime changes	background	2K_dev_1791
However	background	2K_dev_1791
adaptation in some classes of systems ( e	background	2K_dev_1791
g	background	2K_dev_1791
	background	2K_dev_1791
safety-critical ) can benefit by receiving information from humans ( e	background	2K_dev_1791
g	background	2K_dev_1791
	background	2K_dev_1791
acting as sophisticated sensors	background	2K_dev_1791
decision-makers )	background	2K_dev_1791
or by involving them as system-level effectors to execute adaptations ( e	background	2K_dev_1791
g	background	2K_dev_1791
	background	2K_dev_1791
when automation is not possible	background	2K_dev_1791
or as a fallback mechanism ) However	background	2K_dev_1791
human participants are influenced by factors external to the system ( e	background	2K_dev_1791
g	background	2K_dev_1791
	background	2K_dev_1791
training level	background	2K_dev_1791
fatigue ) that affect the likelihood of success when they perform a task	background	2K_dev_1791
its duration	background	2K_dev_1791
or even if they are willing to perform it in the first place	background	2K_dev_1791
We illustrate our approach	finding	2K_dev_1791
We contribute a formal framework	mechanism	2K_dev_1791
focusing on the role of human participants as actors ( i	mechanism	2K_dev_1791
e	mechanism	2K_dev_1791
	mechanism	2K_dev_1791
effectors ) during the execution stage of adaptation	mechanism	2K_dev_1791
The approach consists of : ( i ) a language to express adaptation models that capture factors affecting human behavior and its interactions with the system	mechanism	2K_dev_1791
and ( ii ) a formalization of these adaptation models as stochastic multiplayer games ( SMGs ) that can be used to analyze human-system-environment interactions	mechanism	2K_dev_1791
	mechanism	2K_dev_1791
in an adaptive industrial middleware used to monitor and manage sensor networks in renewable energy production plants	method	2K_dev_1791
	method	2K_dev_1791
Without careful consideration of these factors	purpose	2K_dev_1791
it is unclear how to decide when to involve humans in adaptation	purpose	2K_dev_1791
and in which way	purpose	2K_dev_1791
In this paper	purpose	2K_dev_1791
we investigate how the explicit modeling of human participants can provide a better insight into the trade-offs of involving humans in adaptation	purpose	2K_dev_1791
to reason about human involvement in self-adaptation	purpose	2K_dev_1791
	background	2K_dev_1792
	finding	2K_dev_1792
	mechanism	2K_dev_1792
	method	2K_dev_1792
	purpose	2K_dev_1792
	background	2K_dev_1793
Our experiments demonstrate that our synthesis method is precise and efficient	finding	2K_dev_1793
The implicit specification helped us find one concurrency bug previously missed when model-checking using an explicit	finding	2K_dev_1793
user-provided specification and observed that different synchronization placements are produced for our experiments	finding	2K_dev_1793
favoring a minimal number of synchronization operations or maximum concurrency	finding	2K_dev_1793
respectively	finding	2K_dev_1793
We present a computer-aided programming approach to concurrency	mechanism	2K_dev_1793
and our synthesis procedure inserts synchronization The correctness specification is implicit	mechanism	2K_dev_1793
inferred from the non-preemptive behavior	mechanism	2K_dev_1793
Let us consider sequences of calls that the program makes to an external interface	mechanism	2K_dev_1793
The specification requires that any such sequence produced under a preemptive scheduler should be included in the set of sequences produced under a non-preemptive scheduler	mechanism	2K_dev_1793
We guarantee that our synthesis does not introduce deadlocks and that the synchronization inserted is optimal w	mechanism	2K_dev_1793
r	mechanism	2K_dev_1793
t	mechanism	2K_dev_1793
a given objective function	mechanism	2K_dev_1793
The solution is based on a finitary abstraction	mechanism	2K_dev_1793
an algorithm for bounded language inclusion modulo an independence relation	mechanism	2K_dev_1793
and generation of a set of global constraints over synchronization placements	mechanism	2K_dev_1793
Each model of the global constraints set corresponds to a correctness-ensuring synchronization placement	mechanism	2K_dev_1793
The placement that is optimal w	mechanism	2K_dev_1793
r	mechanism	2K_dev_1793
t	mechanism	2K_dev_1793
the given objective function is chosen as the synchronization solution	mechanism	2K_dev_1793
	mechanism	2K_dev_1793
We apply the approach to device-driver programming	method	2K_dev_1793
where the driver threads call the software interface of the device and the API provided by the operating system	method	2K_dev_1793
We implemented objective functions for coarse-grained and fine-grained locking	method	2K_dev_1793
The approach allows programmers to program assuming a friendly	purpose	2K_dev_1793
non-preemptive scheduler to ensure that the final program works even with a preemptive scheduler	purpose	2K_dev_1793
Self-adaptive systems tend to be reactive and myopic	background	2K_dev_1794
adapting in response to changes without anticipating what the subsequent adaptation needs will be	background	2K_dev_1794
Adapting reactively can result in inefficiencies due to the system performing a suboptimal sequence of adaptations	background	2K_dev_1794
Furthermore	background	2K_dev_1794
when adaptations have latency	background	2K_dev_1794
and take some time to produce their effect	background	2K_dev_1794
they have to be started with sufficient lead time so that they complete by the time their effect is needed	background	2K_dev_1794
Proactive latency-aware adaptation addresses these issues by making adaptation decisions with a look-ahead horizon and taking adaptation latency into account	background	2K_dev_1794
	background	2K_dev_1794
Our results show that the decision based on a look-ahead horizon	finding	2K_dev_1794
and the factoring of both tactic latency and environment uncertainty	finding	2K_dev_1794
considerably improve the effectiveness of adaptation decisions	finding	2K_dev_1794
	finding	2K_dev_1794
In this paper we present an approach that uses probabilistic model checking for adaptation decisions	mechanism	2K_dev_1794
The key idea is to use a formal model of the adaptive system in which the adaptation decision is left underspecified through nondeterminism	mechanism	2K_dev_1794
and have the model checker resolve the nondeterministic choices so that the accumulated utility over the horizon is maximized	mechanism	2K_dev_1794
The adaptation decision is optimal over the horizon	mechanism	2K_dev_1794
and takes into account the inherent uncertainty of the environment predictions needed for looking ahead	mechanism	2K_dev_1794
	mechanism	2K_dev_1794
	method	2K_dev_1794
for proactive latency-aware adaptation under uncertainty	purpose	2K_dev_1794
Almost every complex software system today is configurable	background	2K_dev_1795
While configurability has many benefits	background	2K_dev_1795
it challenges performance prediction	background	2K_dev_1795
optimization	background	2K_dev_1795
and debugging	background	2K_dev_1795
Worse	background	2K_dev_1795
configuration options may interact	background	2K_dev_1795
giving rise to a configuration space of possibly exponential size	background	2K_dev_1795
	background	2K_dev_1795
demonstrates the feasibility of our approach in terms of the accuracy of the models learned as well as the accuracy of the performance predictions one can make with them	finding	2K_dev_1795
	finding	2K_dev_1795
we propose an approach that derives a performance-influence model for a given configurable system	mechanism	2K_dev_1795
Our approach combines machine-learning and sampling heuristics in a novel way	mechanism	2K_dev_1795
It improves over standard techniques in that it ( 1 ) represents influences of options and their interactions explicitly ( which eases debugging )	mechanism	2K_dev_1795
( 2 ) smoothly integrates binary and numeric configuration options for the first time	mechanism	2K_dev_1795
( 3 ) incorporates domain knowledge	mechanism	2K_dev_1795
if available ( which eases learning and increases accuracy )	mechanism	2K_dev_1795
( 4 ) considers complex constraints among options	mechanism	2K_dev_1795
and ( 5 ) systematically reduces the solution space to a tractable size	mechanism	2K_dev_1795
	mechanism	2K_dev_1795
A series of experiments	method	2K_dev_1795
Often	purpose	2K_dev_1795
the influences of individual configuration options on performance are unknown	purpose	2K_dev_1795
Addressing this challenge describing all relevant influences of configuration options and their interactions	purpose	2K_dev_1795
	purpose	2K_dev_1795
Column subset selection ( CSS ) is the problem of selecting a small portion of columns from a large data matrix as one form of interpretable data summarization	background	2K_dev_1796
Leverage score sampling	background	2K_dev_1796
which enjoys both sound theoretical guarantee and superior empirical performance	background	2K_dev_1796
is widely recognized as the state-of-the-art algorithm for column subset selection	background	2K_dev_1796
and demonstrate its competitive performance show its superior performance in terms of both approximation accuracy and computational efficiency	finding	2K_dev_1796
We conclude that further theoretical investigation and practical consideration should be devoted to iterative norm sampling in column subset selection	finding	2K_dev_1796
	finding	2K_dev_1796
	mechanism	2K_dev_1796
under a wide range of experimental settings	method	2K_dev_1796
We also compare iterative norm sampling with several of its other competitors and	method	2K_dev_1796
In this paper	purpose	2K_dev_1796
we revisit iterative norm sampling	purpose	2K_dev_1796
another sampling based CSS algorithm proposed even before leverage score sampling	purpose	2K_dev_1796
	purpose	2K_dev_1796
In geometrically complex situations	background	2K_dev_1797
where many surfaces intersect a pixel	background	2K_dev_1797
current rendering systems shade each contributing surface at least once per pixel	background	2K_dev_1797
As the sample density and geometric complexity increase	background	2K_dev_1797
the shading cost becomes prohibitive for real-time rendering	background	2K_dev_1797
Under deferred shading	background	2K_dev_1797
so does the required framebuffer memory	background	2K_dev_1797
	background	2K_dev_1797
AGAA with 2 aggregate surfaces per-pixel generates results comparable to 8x MSAA	finding	2K_dev_1797
but requires 30\ % less memory ( 45\ % savings for 16x MSAA )	finding	2K_dev_1797
and is up to 1	finding	2K_dev_1797
3x faster	finding	2K_dev_1797
We present Aggregate G-Buffer Anti-Aliasing ( AGAA )	mechanism	2K_dev_1797
a new technique using modern graphics hardware AGAA uses the rasterization pipeline to generate a compact	mechanism	2K_dev_1797
pre-filtered geometric representation inside each pixel	mechanism	2K_dev_1797
We then shade this at a fixed rate	mechanism	2K_dev_1797
independent of geometric complexity	mechanism	2K_dev_1797
By decoupling shading rate from geometric sampling rate	mechanism	2K_dev_1797
the algorithm reduces the storage and bandwidth costs of a geometry buffer	mechanism	2K_dev_1797
and allows scaling to high visibility sampling rates for anti-aliasing	mechanism	2K_dev_1797
	mechanism	2K_dev_1797
	method	2K_dev_1797
for efficient anti-aliased deferred rendering of complex geometry	purpose	2K_dev_1797
The Unique Games Conjecture ( UGC ) has emerged in recent years as the starting point for several optimal inapproximability results	background	2K_dev_1798
A gamma ( 2 ) ( p )	background	2K_dev_1798
approximation algorithm has also been independently obtained by Naor and Schechtman	background	2K_dev_1798
These are the first approximation thresholds	background	2K_dev_1798
proven under P NP	background	2K_dev_1798
that involve the Gaussian random variable in a fundamental way	background	2K_dev_1798
Note that the problem statements themselves do not explicitly involve the Gaussian distribution	background	2K_dev_1798
	background	2K_dev_1798
In this work	mechanism	2K_dev_1798
we bypass the need for UGC assumption in inapproximability results for two geometric problems	mechanism	2K_dev_1798
obtaining a tight NP-hardness result in each case	mechanism	2K_dev_1798
The first problem	mechanism	2K_dev_1798
known as L-p Subspace Approximation	mechanism	2K_dev_1798
is a generalization of the classic least squares regression problem	mechanism	2K_dev_1798
Here	mechanism	2K_dev_1798
the input consists of a set of points X 0 \ { a1	mechanism	2K_dev_1798
	mechanism	2K_dev_1798
	mechanism	2K_dev_1798
	mechanism	2K_dev_1798
	mechanism	2K_dev_1798
a ( m ) \ } subset of R-n and a parameter k ( possibly depending on n )	mechanism	2K_dev_1798
For p 0 2	mechanism	2K_dev_1798
k 0 n-1	mechanism	2K_dev_1798
this reduces to the least squares regression problem	mechanism	2K_dev_1798
while for p 0 cc	mechanism	2K_dev_1798
k 0 0 it reduces to the problem of finding a ball of minimum radius enclosing all the points	mechanism	2K_dev_1798
The second problem we study is the related L-p Quadratic Grothendieck Maximization Problem	mechanism	2K_dev_1798
considered by Kindler	mechanism	2K_dev_1798
Naor	mechanism	2K_dev_1798
and Schechtman Here	mechanism	2K_dev_1798
the input is a multilinear quadratic form Sigma ( n ) ( i	mechanism	2K_dev_1798
j ) 1 ( aijxixj ) and The problem is polynomial time solvable for p 0 2	mechanism	2K_dev_1798
	mechanism	2K_dev_1798
	method	2K_dev_1798
While for none of these results a reverse reduction to Unique Games is known	purpose	2K_dev_1798
the assumption of bijective projections in the Label Cover instance nevertheless seems critical in these proofs	purpose	2K_dev_1798
The goal is to find a subspace H of R-n of dimension k that minimizes the tp norm of the Euclidean distances to the points in X	purpose	2K_dev_1798
the goal is to maximize the quadratic form over the	purpose	2K_dev_1798
ep unit ball	purpose	2K_dev_1798
namely	purpose	2K_dev_1798
all x with Sigma ( n ) ( i=1 ) vertical bar xi vertical bar ( p ) < 0 1	purpose	2K_dev_1798
	purpose	2K_dev_1798
Although substantial progress has been achieved in speech-to-speech translation systems over the last few years	background	2K_dev_1799
	background	2K_dev_1799
	finding	2K_dev_1799
from the other end and expects that speech alone is available in the target language	mechanism	2K_dev_1799
and that no ( standard or nonstandard ) orthography exists It	mechanism	2K_dev_1799
therefore	mechanism	2K_dev_1799
treats the acoustic representation of the language as primary and uses language-independent methods that is then used in the translation system Thus	mechanism	2K_dev_1799
the speech translation system is created for the target language as defined by the recording of that language rather than some body of orthographic transcripts In this work	mechanism	2K_dev_1799
we are creating an application called APT ( Acoustic Patient Translator ) which uses a novel scheme of speech recognition and translation within a targeted domain	mechanism	2K_dev_1799
By working with a set of predefined sentences appropriately chosen to fit a scenario	mechanism	2K_dev_1799
we use utterance classification as a speech recognition algorithm The utterance classification is achieved using cross-lingual	mechanism	2K_dev_1799
language-independent phonetic labeling	mechanism	2K_dev_1799
Since we are working with a set of select phrases	mechanism	2K_dev_1799
the translation part is trivial	mechanism	2K_dev_1799
	mechanism	2K_dev_1799
We are concentrating on communication with hospital staff	method	2K_dev_1799
such as scheduling a doctor 's appointment	method	2K_dev_1799
as our domain	method	2K_dev_1799
In addition to English	method	2K_dev_1799
we also run experiments on Tamil	method	2K_dev_1799
	method	2K_dev_1799
such systems still require that the speech be written in some appropriate orthography	purpose	2K_dev_1799
As speech may differ greatly from the standardized written form of a language	purpose	2K_dev_1799
it can be non-trivial to collect written data when there is no standard way for it to be represented This project addresses the problem to produce a phonetically-related symbolic representation	purpose	2K_dev_1799
Traditional automated response grading approaches use manually engineered time-aggregated features ( such as mean length of pauses	background	2K_dev_1800
We find such models reach the best performance in terms of correlation with human raters We also find that when there are limited time-aggregated features available	finding	2K_dev_1800
our model that incorporates time-sequence features improves performance drastically	finding	2K_dev_1800
We introduce a new method We propose to incorporate general time-sequence features ( such as pitch ) which preserve more information than time-aggregated features and do not require human effort to design	mechanism	2K_dev_1800
We use a type of recurrent neural network to jointly optimize the learning of high level abstractions from time-sequence features with the time-aggregated features	mechanism	2K_dev_1800
We first automatically learn high level abstractions from time-sequence features with a Bidirectional Long Short Term Memory ( BLSTM ) and then combine the high level abstractions with time-aggregated features in a Multilayer Perceptron ( MLP ) /Linear Regression ( LR )	mechanism	2K_dev_1800
We optimize the BLSTM and the MLP/LR jointly	mechanism	2K_dev_1800
	mechanism	2K_dev_1800
	method	2K_dev_1800
to grade non-native spoken language tests automatically	purpose	2K_dev_1800
Programmers often need to revert some code to an earlier state	background	2K_dev_1801
or restore a block of code that was deleted a while ago	background	2K_dev_1801
However	background	2K_dev_1801
support for this backtracking in modern programming environments is limited	background	2K_dev_1801
showed that programmers can successfully use AZURITE	finding	2K_dev_1801
and were twice as fast as when limited to conventional features	finding	2K_dev_1801
	finding	2K_dev_1801
In this paper	mechanism	2K_dev_1801
we present AZURITE	mechanism	2K_dev_1801
an Eclipse plug-in With AZURITE	mechanism	2K_dev_1801
programmers can easily perform backtracking tasks	mechanism	2K_dev_1801
even when the desired code is not in the undo stack or a version control system	mechanism	2K_dev_1801
AZURITE also provides novel user interfaces specifically designed for selective undo	mechanism	2K_dev_1801
which were iteratively improved through user feedback gathered from actual users in a preliminary field trial	mechanism	2K_dev_1801
	mechanism	2K_dev_1801
A formal lab study	method	2K_dev_1801
Many of the backtracking tasks can be accomplished by having a selective undo feature in code editors	purpose	2K_dev_1801
but this has major challenges : there can be conflicts among edit operations	purpose	2K_dev_1801
and it is difficult to provide usable interfaces for selective undo	purpose	2K_dev_1801
that allows programmers to selectively undo fine-grained code changes made in the code editor	purpose	2K_dev_1801
	purpose	2K_dev_1801
We prove the conjecture	finding	2K_dev_1802
We suggest attempting the conjecture in the case that X-1	mechanism	2K_dev_1802
	mechanism	2K_dev_1802
	mechanism	2K_dev_1802
	mechanism	2K_dev_1802
	mechanism	2K_dev_1802
X-n are the leaves of an information flow tree	mechanism	2K_dev_1802
	mechanism	2K_dev_1802
in the case that the information flow tree is a caterpillar graph ( similar to a two-state hidden Markov model )	method	2K_dev_1802
	method	2K_dev_1802
We conjecture that O ( 1/epsilon ( 2 ) ) can be improved to O ( 1/epsilon )	purpose	2K_dev_1802
Vehicular networks are inherently unstable networks with high mobility and intermittent connectivity	background	2K_dev_1803
These networks can greatly benefit from Delay Tolerant Networking ( DTN ) solutions for opportunistic connectivity in the transmission of delaytolerant data	background	2K_dev_1803
experimental insight	finding	2K_dev_1803
and extract lessons for DTN routing protocol design	finding	2K_dev_1803
	finding	2K_dev_1803
	mechanism	2K_dev_1803
Our case-study application is the upload of delay-tolerant sensing data from vehicular nodes to a server on the Internet	method	2K_dev_1803
We deploy DTN in 3 vehicular testbeds : a heterogeneous lab testbed with controlled mobility	method	2K_dev_1803
a low-mobility high-connectivity network of harbor trucks	method	2K_dev_1803
and a high-mobility low-connectivity city bus network	method	2K_dev_1803
We compare 3 routing protocols : epidemic	method	2K_dev_1803
static and PRoPHET	method	2K_dev_1803
for which we measure delivery ratio	method	2K_dev_1803
average delay	method	2K_dev_1803
path length	method	2K_dev_1803
as well as transmission and storage overhead	method	2K_dev_1803
We analyze the results for	method	2K_dev_1803
In this paper	purpose	2K_dev_1803
we evaluate the performance of different DTN routing protocols in real world vehicular networks with different degrees of connectivity in order to understand their feasibility in real vehicular environments	purpose	2K_dev_1803
	purpose	2K_dev_1803
Syntax extension mechanisms are powerful	background	2K_dev_1804
but reasoning about syntax extensions can be difficult	background	2K_dev_1804
Recent work on type-specific languages ( TSLs ) addressed reasoning about composition	background	2K_dev_1804
hygiene and typing for extensions introducing new literal forms	background	2K_dev_1804
and show interesting where the two mechanisms operate in concert	finding	2K_dev_1804
	finding	2K_dev_1804
We supplement TSLs with typed syntax macros ( TSMs )	mechanism	2K_dev_1804
which	mechanism	2K_dev_1804
unlike TSLs	mechanism	2K_dev_1804
are explicitly invoked we describe two flavors of term-level TSMs : synthetic TSMs specify the type of term that they generate	mechanism	2K_dev_1804
while analytic TSMs can generate terms of arbitrary type	mechanism	2K_dev_1804
but can only be used in positions where the type is otherwise known	mechanism	2K_dev_1804
At the level of types	mechanism	2K_dev_1804
we describe a third flavor of TSM	mechanism	2K_dev_1804
use cases	method	2K_dev_1804
to give meaning to delimited segments of arbitrary syntax	purpose	2K_dev_1804
To maintain a typing discipline	purpose	2K_dev_1804
that generates a type of a specified kind along with its TSL	purpose	2K_dev_1804
Multimodal analysis has long been an integral part of studying learning	background	2K_dev_1805
Historically multimodal analyses of learning have been extremely laborious and time intensive and the implications that this work may have in non-education-related contexts	background	2K_dev_1805
we find that affect-and pose-based segmentation are more effective	finding	2K_dev_1805
than traditional approaches	finding	2K_dev_1805
for drawing correlations between learning-relevant constructs	finding	2K_dev_1805
and multimodal behaviors We also find that pose-based segmentation outperforms the two more traditional segmentation strategies for predicting student success on the hands-on task	finding	2K_dev_1805
our results	finding	2K_dev_1805
	finding	2K_dev_1805
In particular	mechanism	2K_dev_1805
we propose affect-and pose-based data segmentation	mechanism	2K_dev_1805
as alternatives to human-based segmentation	mechanism	2K_dev_1805
and fixed-window segmentation	mechanism	2K_dev_1805
	mechanism	2K_dev_1805
we present a comparative analysis of four different data segmentation techniques	method	2K_dev_1805
In a study of ten dyads working on an open-ended engineering design task	method	2K_dev_1805
However	purpose	2K_dev_1805
researchers have recently been exploring ways to use multimodal computational analysis in the service of studying how people learn in complex learning environments	purpose	2K_dev_1805
In an effort to advance this research agenda	purpose	2K_dev_1805
In this paper we discuss the algorithms used	purpose	2K_dev_1805
One powerful aspect of 3D printing is its ability to extend	background	2K_dev_1806
repair	background	2K_dev_1806
or more generally modify everyday objects	background	2K_dev_1806
	background	2K_dev_1806
Our validation helps to illustrate the strengths and weaknesses of each technique	finding	2K_dev_1806
	finding	2K_dev_1806
For example	method	2K_dev_1806
we characterize how surface curvature and roughness affect print-over 's strength compared to the conventional print-in-one-piece	method	2K_dev_1806
	method	2K_dev_1806
However	purpose	2K_dev_1806
nearly all existing work implicitly assumes that whole objects are to be printed from scratch	purpose	2K_dev_1806
Designing objects as extensions or enhancements of existing ones is a laborious process in most of today 's 3D authoring tools	purpose	2K_dev_1806
for 3D printing to augment existing objects that covers a wide range of attachment options	purpose	2K_dev_1806
	purpose	2K_dev_1806
	background	2K_dev_1807
	finding	2K_dev_1807
	mechanism	2K_dev_1807
	method	2K_dev_1807
	purpose	2K_dev_1807
Do we really need 3D labels in order to learn how to predict 3D ?	background	2K_dev_1808
Despite never seeing a 3D label	finding	2K_dev_1808
our method produces competitive results	finding	2K_dev_1808
Rather than use explicit supervision	mechanism	2K_dev_1808
we use the regularity of indoor scenes	mechanism	2K_dev_1808
We demonstrate this on both a standard 3D scene understanding dataset as well as Internet images for which 3D is unavailable	method	2K_dev_1808
precluding supervised learning	method	2K_dev_1808
In this paper	purpose	2K_dev_1808
we show that one can learn a mapping from appearance to 3D properties without ever seeing a single explicit 3D label to learn the mapping in a completely unsupervised manner	purpose	2K_dev_1808
	purpose	2K_dev_1808
Contemporary approaches extract features from a single output layer	background	2K_dev_1809
While finetuning such models helps performance	finding	2K_dev_1809
we show that even `` off-the-self { '' } multi-scale features perform quite well	finding	2K_dev_1809
and demonstrate state-of-the-art classification performance our results reduce the lowest previously-reported error by 23	finding	2K_dev_1809
9\ % and 9	finding	2K_dev_1809
5\ %	finding	2K_dev_1809
respectively	finding	2K_dev_1809
By extracting features from multiple layers	mechanism	2K_dev_1809
one can simultaneously reason about high	mechanism	2K_dev_1809
mid	mechanism	2K_dev_1809
and low-level features during classification	mechanism	2K_dev_1809
The resulting multi-scale architecture can itself be seen as a feed-forward model that is structured as a directed acyclic graph ( DAG-CNNs )	mechanism	2K_dev_1809
We use DAG-CNNs	mechanism	2K_dev_1809
We present extensive analysis on three standard scene benchmarks ( SUN397	method	2K_dev_1809
MIT67	method	2K_dev_1809
and Scene15 ) In terms of the heavily benchmarked MIT67 and Scene15 datasets	method	2K_dev_1809
We explore multi-scale convolutional neural nets ( CNNs ) for image classification	purpose	2K_dev_1809
to learn a set of multi-scale features that can be effectively shared between coarse and fine-grained classification tasks	purpose	2K_dev_1809
	purpose	2K_dev_1809
	background	2K_dev_1810
We demonstrate that the feature representation learned using this within-image context indeed captures visual similarity across images For example	finding	2K_dev_1810
this representation allows us to perform unsupervised visual discovery of objects like cats	finding	2K_dev_1810
people	finding	2K_dev_1810
and even birds from the Pascal VOC 2011 detection dataset	finding	2K_dev_1810
Furthermore	finding	2K_dev_1810
we show that the learned ConvNet can be used in the R-CNN framework { [ } 19 ] and provides a significant boost over a randomly-initialized ConvNet	finding	2K_dev_1810
resulting in state-of-the-art performance among algorithms which use only Pascal provided training set annotations	finding	2K_dev_1810
Given only a large	mechanism	2K_dev_1810
unlabeled image collection	mechanism	2K_dev_1810
we extract random pairs of patches from each image and train a convolutional neural net to predict the position of the second patch relative to the first	mechanism	2K_dev_1810
	mechanism	2K_dev_1810
	method	2K_dev_1810
This work explores the use of spatial context as a source of free and plentiful supervisory signal for training a rich visual representation	purpose	2K_dev_1810
We argue that doing well on this task requires the model to learn to recognize objects and their parts	purpose	2K_dev_1810
	purpose	2K_dev_1810
Mobile applications frequently access sensitive personal information to meet user or business requirements	background	2K_dev_1811
Because such information is sensitive in general	background	2K_dev_1811
regulators increasingly require mobile-app developers to publish privacy policies that describe what information is collected	background	2K_dev_1811
Furthermore	background	2K_dev_1811
regulators have fined companies when these policies are inconsistent with the actual data practices of mobile apps	background	2K_dev_1811
	background	2K_dev_1811
Our empirical evaluation on 477 top Android apps discovered 341 potential privacy policy violations	finding	2K_dev_1811
	finding	2K_dev_1811
we propose a semi-automated framework that consists of a policy terminology-API method map that links policy phrases to API methods that produce sensitive information	mechanism	2K_dev_1811
and information flow analysis to detect misalignments	mechanism	2K_dev_1811
We present an implementation of our framework based on a privacy-policy-phrase ontology and a collection of mappings from API methods to policy phrases	method	2K_dev_1811
	method	2K_dev_1811
To help mobile-app developers check their privacy policies against their apps ' code for consistency	purpose	2K_dev_1811
	purpose	2K_dev_1811
	background	2K_dev_1812
We demonstrate that our two-stage CNN outperforms a fine-tuned CNN trained We also demonstrate the strength of webly supervised learning It achieves the best performance on VOC 2007 where no VOC training data is used Finally	finding	2K_dev_1812
we show our approach is quite robust to noise and performs comparably even	finding	2K_dev_1812
Specifically inspired by curriculum learning	mechanism	2K_dev_1812
we present a two-step approach for CNN training	mechanism	2K_dev_1812
First	mechanism	2K_dev_1812
we use easy images to train an initial visual representation	mechanism	2K_dev_1812
We then use this initial CNN and adapt it to harder	mechanism	2K_dev_1812
more realistic images by leveraging the structure of data and categories	mechanism	2K_dev_1812
on ImageNet on Pascal VOC 2012	method	2K_dev_1812
by localizing objects in web images and training a R-CNN style { [ } 19 ] detector	method	2K_dev_1812
when we use image search results from March 2013 ( pre-CNN image search era )	method	2K_dev_1812
	method	2K_dev_1812
We present an approach to utilize large amounts of web data for learning CNNs	purpose	2K_dev_1812
While feedforward deep convolutional neural networks ( CNNs ) have been a great success in computer vision	background	2K_dev_1813
it is important to note that the human visual cortex generally contains more feedback than feedforward connections	background	2K_dev_1813
	background	2K_dev_1813
demonstrate its effectiveness in solving tasks such as image classification and object localization	finding	2K_dev_1813
	finding	2K_dev_1813
a computational feedback mechanism in deep neural networks In addition to the feedforward inference in traditional neural networks	mechanism	2K_dev_1813
a feedback loop is introduced according to the `` goal { '' } of the network	mechanism	2K_dev_1813
e	mechanism	2K_dev_1813
g	mechanism	2K_dev_1813
	mechanism	2K_dev_1813
high-level semantic labels	mechanism	2K_dev_1813
We analogize this mechanism as `` Look and Think Twice	mechanism	2K_dev_1813
{ '' } The feedback networks help better visualize and understand how deep neural networks work	mechanism	2K_dev_1813
and capture visual attention on expected objects	mechanism	2K_dev_1813
even in images with cluttered background and multiple	mechanism	2K_dev_1813
Experiments on ImageNet dataset	method	2K_dev_1813
In this paper	purpose	2K_dev_1813
we will briefly introduce the background of feedbacks in the human visual cortex	purpose	2K_dev_1813
which motivates us to develop to infer the activation status of hidden layer neurons	purpose	2K_dev_1813
The core challenges in capturing social interactions are : ( 1 ) occlusion is functional and frequent ; ( 2 ) subtle motion needs to be measured over a space large enough to host a social group ; and ( 3 ) human appearance and configuration variation is immense	background	2K_dev_1814
	background	2K_dev_1814
	finding	2K_dev_1814
We present an approach The Panoptic Studio is a system organized around the thesis that social interactions should be measured through the perceptual integration of a large variety of view points	mechanism	2K_dev_1814
We present a modularized system designed around this principle	mechanism	2K_dev_1814
consisting of integrated structural	mechanism	2K_dev_1814
hardware	mechanism	2K_dev_1814
and software innovations	mechanism	2K_dev_1814
The system takes	mechanism	2K_dev_1814
as input	mechanism	2K_dev_1814
480 synchronized video streams of multiple people engaged in social activities	mechanism	2K_dev_1814
and produces	mechanism	2K_dev_1814
as output	mechanism	2K_dev_1814
the labeled time-varying 3D structure of anatomical landmarks on individuals in the space	mechanism	2K_dev_1814
The algorithmic contributions include a hierarchical approach for generating skeletal trajectory proposals	mechanism	2K_dev_1814
and an optimization framework for skeletal reconstruction with trajectory reassociation	mechanism	2K_dev_1814
	mechanism	2K_dev_1814
	method	2K_dev_1814
to capture the 3D structure and motion of a group of people engaged in a social interaction	purpose	2K_dev_1814
	purpose	2K_dev_1814
Varied sources of error contribute to the challenge of facial action unit detection	background	2K_dev_1815
Previous approaches address specific and known sources	background	2K_dev_1815
However	background	2K_dev_1815
many sources are unknown	background	2K_dev_1815
	background	2K_dev_1815
With few exceptions	finding	2K_dev_1815
CPM outperformed baseline and state-of-the art methods	finding	2K_dev_1815
	finding	2K_dev_1815
we propose a Confident Preserving Machine ( CPM that follows an easy-to-hard classification strategy	mechanism	2K_dev_1815
During training	mechanism	2K_dev_1815
CPM learns two confident classifiers	mechanism	2K_dev_1815
A confident positive classifier separates easily identified positive samples from all else ; a confident negative classifier does same for negative samples	mechanism	2K_dev_1815
During testing	mechanism	2K_dev_1815
CPM then learns a person-specific classifier using `` virtual labels { '' } provided by confident classifiers	mechanism	2K_dev_1815
This step is achieved using a quasi-semi-supervised ( QSS ) approach	mechanism	2K_dev_1815
Hard samples are typically close to the decision boundary	mechanism	2K_dev_1815
and the QSS approach disambiguates them using spatio-temporal constraints	mechanism	2K_dev_1815
To evaluate CPM	method	2K_dev_1815
we compared it with a baseline single-margin classifier and state-of-the-art semi-supervised learning	method	2K_dev_1815
transfer learning	method	2K_dev_1815
and boosting methods in three datasets of spontaneous facial behavior	method	2K_dev_1815
	method	2K_dev_1815
To address the ubiquity of error	purpose	2K_dev_1815
Determining dense semantic correspondences across objects and scenes is a difficult problem that underpins many higher-level computer vision algorithms Unlike canonical dense correspondence problems which consider images that are spatially or temporally adjacent	background	2K_dev_1816
semantic correspondence is characterized by images that share similar high-level structures whose exact appearance and geometry may differ	background	2K_dev_1816
	finding	2K_dev_1816
LDA classifiers have two distinct benefits : ( i ) they exhibit higher average precision than similarity metrics typically used in correspondence problems	mechanism	2K_dev_1816
and ( ii ) unlike exemplar SVM	mechanism	2K_dev_1816
can output globally interpretable posterior probabilities without calibration	mechanism	2K_dev_1816
whilst also being significantly faster to train	mechanism	2K_dev_1816
We pose the correspondence problem as a graphical model	mechanism	2K_dev_1816
where the unary potentials are computed via convolution with the set of exemplar classifiers	mechanism	2K_dev_1816
and the joint potentials enforce smoothly varying correspondence assignment	mechanism	2K_dev_1816
	mechanism	2K_dev_1816
	method	2K_dev_1816
Motivated by object recognition literature and recent work on rapidly estimating linear classifiers	purpose	2K_dev_1816
we treat semantic correspondence as a constrained detection problem	purpose	2K_dev_1816
where an exemplar LDA classifier is learned for each pixel	purpose	2K_dev_1816
Starting with the seminal work by Kempe et al	background	2K_dev_1817
	background	2K_dev_1817
a broad variety of problems	background	2K_dev_1817
such as targeted marketing and the spread of viruses and malware	background	2K_dev_1817
have been modeled as selecting a subset of nodes to maximize diffusion through a network	background	2K_dev_1817
In cyber-security applications	background	2K_dev_1817
however	background	2K_dev_1817
a key consideration largely ignored in this literature is stealth	background	2K_dev_1817
In particular	background	2K_dev_1817
an attacker often has a specific target in mind	background	2K_dev_1817
but succeeds only if the target is reached ( e	background	2K_dev_1817
g	background	2K_dev_1817
	background	2K_dev_1817
by malware ) before the malicious payload is detected and corresponding countermeasures deployed	background	2K_dev_1817
The dual side of this problem is deployment of a limited number of monitoring units	background	2K_dev_1817
such as cyber-forensics specialists	background	2K_dev_1817
so as to limit the likelihood of such targeted and stealthy diffusion processes reaching their intended targets	background	2K_dev_1817
	background	2K_dev_1817
show that a number of natural variants of this problem are NP-hard to approximate	finding	2K_dev_1817
On the positive side	finding	2K_dev_1817
we show that if stealthy diffusion starts from randomly selected nodes	finding	2K_dev_1817
the defender 's objective is submodular	finding	2K_dev_1817
and a fast greedy algorithm has provable approximation guarantees	finding	2K_dev_1817
show that the proposed algorithms are highly effective and scalable	finding	2K_dev_1817
In addition	mechanism	2K_dev_1817
we present approximation algorithms by adaptively selecting the starting nodes for the diffusion process	mechanism	2K_dev_1817
	mechanism	2K_dev_1817
Our experimental results	method	2K_dev_1817
We investigate the problem of optimal monitoring of targeted stealthy diffusion processes	purpose	2K_dev_1817
and for the setting in which an attacker optimally responds to the placement of monitoring nodes	purpose	2K_dev_1817
Poor spelling is a challenge faced by people with dyslexia throughout their lives	background	2K_dev_1818
Spellcheckers are therefore a crucial tool for people with dyslexia	background	2K_dev_1818
but current spellcheckers do not detect real-word errors	background	2K_dev_1818
which are a common type of errors made by people with dyslexia	background	2K_dev_1818
Real-word errors are spelling mistakes that result in an unintended but real word	background	2K_dev_1818
for instance	background	2K_dev_1818
form instead of from	background	2K_dev_1818
Nearly 20\ % of the errors that people with dyslexia make are real-word	background	2K_dev_1818
	finding	2K_dev_1818
and showed that it detects more of these errors than widely used spellcheckers	finding	2K_dev_1818
people with dyslexia corrected sentences more accurately and in less time with Real Check	finding	2K_dev_1818
	finding	2K_dev_1818
In this paper	mechanism	2K_dev_1818
we introduce a system called Real Check that uses a probabilistic language model	mechanism	2K_dev_1818
a statistical dependency parser and Google n-grams	mechanism	2K_dev_1818
We evaluated Real Check on text written by people with dyslexia In an experiment with 34 people ( 17 with dyslexia )	method	2K_dev_1818
	method	2K_dev_1818
to detect real-world errors	purpose	2K_dev_1818
	purpose	2K_dev_1818
Today	background	2K_dev_1819
many data-driven web pages present information in a way that is difficult for blind and low vision users to navigate and to understand	background	2K_dev_1819
	finding	2K_dev_1819
EnTable as accessible tables	mechanism	2K_dev_1819
EnTable allows blind and low vision users to submit requests for pages they wish to access	mechanism	2K_dev_1819
The system then employs sighted informants to markup the desired page with semantic information	mechanism	2K_dev_1819
allowing the page to be re-written using straightforward < table > tags	mechanism	2K_dev_1819
Screen reader users who browse the web using the EnTable browser extension can report data sets that are confusing	mechanism	2K_dev_1819
and utilize data sets re-written with the < table > tag based on their own requests or on the requests of other users	mechanism	2K_dev_1819
	mechanism	2K_dev_1819
	method	2K_dev_1819
addresses this challenge	purpose	2K_dev_1819
It re-writes confusing and complicated template-based data sets	purpose	2K_dev_1819
Large scale deployment of sensors is essential to practical applications in cyber physical systems	background	2K_dev_1820
For instance	background	2K_dev_1820
instrumenting a commercial building for `smart energy ' management requires deployment and operation of thousands of measurement and metering sensors and actuators that direct operation of the HVAC system	background	2K_dev_1820
Each of these sensors need to be named consistently and constantly calibrated	background	2K_dev_1820
we show that Zodiac can successfully classify sensors with an average accuracy of 98\ % with 28\ % fewer training examples when compared to a regular expression based method	finding	2K_dev_1820
	finding	2K_dev_1820
we propose Zodiac-a framework based on active learning from sensor metadata	mechanism	2K_dev_1820
In contrast to prior work	mechanism	2K_dev_1820
Zodiac requires minimal user input in terms of labelling examples while being more accurate	mechanism	2K_dev_1820
	mechanism	2K_dev_1820
To evaluate Zodiac	method	2K_dev_1820
we deploy it across four real buildings on our campus and label the ground truth metadata for all the sensors in these buildings manually	method	2K_dev_1820
Using a combination of hierarchical clustering and random forest classifiers	method	2K_dev_1820
Doing this process manually is not only time consuming but also error prone given the scale	purpose	2K_dev_1820
heterogeneity and complexity of buildings as well as lack of uniform naming schemas	purpose	2K_dev_1820
To address this challenge for automatically classifying	purpose	2K_dev_1820
naming and managing sensors	purpose	2K_dev_1820
Modern cyber-physical systems interact closely with continuous physical processes like kinematic movement	background	2K_dev_1821
Software component frameworks do not provide an explicit way to represent or reason about these processes	background	2K_dev_1821
Meanwhile	background	2K_dev_1821
hybrid program models have been successful in proving critical properties of discrete-continuous systems	background	2K_dev_1821
These programs deal with diverse aspects of a cyber-physical system such as controller decisions	background	2K_dev_1821
component communication protocols	background	2K_dev_1821
and mechanical dynamics	background	2K_dev_1821
requiring several programs to address the variation	background	2K_dev_1821
However	background	2K_dev_1821
currently these aspects are often intertwined in mostly monolithic hybrid programs	background	2K_dev_1821
which are difficult to understand	background	2K_dev_1821
change	background	2K_dev_1821
and organize	background	2K_dev_1821
	finding	2K_dev_1821
architectural models We build formal architectural abstractions of hybrid programs and formulas	mechanism	2K_dev_1821
enabling analysis of hybrid programs at the component level	mechanism	2K_dev_1821
reusing parts of hybrid programs	mechanism	2K_dev_1821
and automatic transformation from views into hybrid programs and formulas	mechanism	2K_dev_1821
Our approach is evaluated in the context of a robotic collision avoidance case study	method	2K_dev_1821
	method	2K_dev_1821
These issues can be addressed by component-based engineering	purpose	2K_dev_1821
making hybrid modeling more practical	purpose	2K_dev_1821
This paper lays the foundation for using to provide component-based benefits to developing hybrid programs	purpose	2K_dev_1821
	purpose	2K_dev_1821
Dependencies among software projects and libraries are an indicator of the often implicit collaboration among many developers in software ecosystems	background	2K_dev_1822
Negotiating change can be tricky : changes to one module may cause ripple effects to many other modules that depend on it	background	2K_dev_1822
yet insisting on only backward-compatible changes may incur significant opportunity cost and stifle change	background	2K_dev_1822
	finding	2K_dev_1822
we are finding that developers in fact struggle with change	finding	2K_dev_1822
that they often use adhoc mechanisms to negotiate change	finding	2K_dev_1822
and that existing awareness mechanisms like Github notification feeds are rarely used due to information overload	finding	2K_dev_1822
	finding	2K_dev_1822
outline a vision toward a change-based awareness system	mechanism	2K_dev_1822
	mechanism	2K_dev_1822
In ongoing interviews with developers in two software ecosystems ( CRAN and Node	method	2K_dev_1822
js ) We study the state of the art and current information needs and	method	2K_dev_1822
We argue that awareness mechanisms based on various notions of stability can enable developers to make decisions that are independent yet wise and provide stewardship rather than disruption to the ecosystem	purpose	2K_dev_1822
	purpose	2K_dev_1822
Research has shown that understanding conversational structure between students is paramount to evaluating the productivity of the collaboration and estimating outcomes	background	2K_dev_1823
However	background	2K_dev_1823
previous methods often rely on human supplied dialogue act labels or discourse parsing algorithms requiring large labeled datasets	background	2K_dev_1823
	background	2K_dev_1823
In this paper we present a new method In particular	mechanism	2K_dev_1823
we introduce a machine learning method	mechanism	2K_dev_1823
for example when one student provides the answer to a question or comments on something another student previously said Our method	mechanism	2K_dev_1823
which utilizes a fast	mechanism	2K_dev_1823
exact optimization process known as spectral optimization	mechanism	2K_dev_1823
does not require manually annotated training data and is highly scalable and generalizable	mechanism	2K_dev_1823
	mechanism	2K_dev_1823
Empirical using real world datasets consisting of conversations between students participating in Coursera courses	method	2K_dev_1823
	method	2K_dev_1823
for understanding discussions between students in MOOC forums	purpose	2K_dev_1823
for discovering instances in which a response relation exists between a pair of posts in a forum thread	purpose	2K_dev_1823
	background	2K_dev_1824
	finding	2K_dev_1824
	mechanism	2K_dev_1824
	method	2K_dev_1824
	purpose	2K_dev_1824
Mobile and web applications increasingly leverage service-oriented architectures in which developers integrate third-party services into end user applications	background	2K_dev_1825
This includes identity management	background	2K_dev_1825
mapping and navigation	background	2K_dev_1825
cloud storage	background	2K_dev_1825
and advertising services	background	2K_dev_1825
among others	background	2K_dev_1825
The study results include detected conflicts and violations of the principles as well as two patterns for balancing privacy and data use flexibility in requirements specifications	finding	2K_dev_1825
show that reasoning over complex compositions of multi-party systems is feasible within exponential asymptotic timeframes proportional to the policy size	finding	2K_dev_1825
the number of expressed data	finding	2K_dev_1825
and orthogonal to the number of conflicts found	finding	2K_dev_1825
	finding	2K_dev_1825
	mechanism	2K_dev_1825
we propose new techniques based on Description Logic ( DL ) which are prominent privacy properties found in international standards and guidelines	mechanism	2K_dev_1825
We evaluate our techniques in an empirical case study that examines the data practices of the Waze mobile application and three of their service providers : Facebook Login	method	2K_dev_1825
Amazon Web Services ( a cloud storage provider )	method	2K_dev_1825
and Flurry	method	2K_dev_1825
com ( a popular mobile analytics and advertising platform )	method	2K_dev_1825
Analysis of automation reasoning over the DL models	method	2K_dev_1825
While service reuse reduces development time	purpose	2K_dev_1825
it introduces new privacy and security risks due to data repurposing and over-collection as data is shared among multiple parties who lack transparency into third-party data practices	purpose	2K_dev_1825
To address this challenge for modeling multiparty data flow requirements and verifying the purpose specification and collection and use limitation principles	purpose	2K_dev_1825
	purpose	2K_dev_1825
In software development	background	2K_dev_1826
IDE services such as syntax highlighting	background	2K_dev_1826
code completion	background	2K_dev_1826
and `` jump to declaration { '' } are used to assist developers in programming	background	2K_dev_1826
is available at http : //www	finding	2K_dev_1826
youtube	finding	2K_dev_1826
com/watch ? v=w1TECeRXGrg	finding	2K_dev_1826
	finding	2K_dev_1826
In this work	mechanism	2K_dev_1826
we introduce Varis Technically	mechanism	2K_dev_1826
we first perform symbolic execution on a PHP program to approximate all possible variations of the generated client-side code and subsequently parse this client code into a VarDOM that compactly represents all its variations	mechanism	2K_dev_1826
Finally	mechanism	2K_dev_1826
using the VarDOM	mechanism	2K_dev_1826
we implement various types of IDE services for embedded client code including syntax highlighting	mechanism	2K_dev_1826
code completion	mechanism	2K_dev_1826
and `` jump to declaration { '' }	mechanism	2K_dev_1826
	mechanism	2K_dev_1826
The video demonstration for Varis	method	2K_dev_1826
In dynamic web applications	purpose	2K_dev_1826
however	purpose	2K_dev_1826
since the client-side code is dynamically generated from the server-side code and is embedded in the server-side program as string literals	purpose	2K_dev_1826
providing IDE services for such embedded code is challenging a tool that provides editor services on the client-side code of a PHP-based web application	purpose	2K_dev_1826
while it is still embedded within server-side code	purpose	2K_dev_1826
To ensure quality and trustworthiness of mobile apps	background	2K_dev_1827
Google Play store imposes various developer policies	background	2K_dev_1827
Once an app is reported for exhibiting policy-violating behaviors	background	2K_dev_1827
it is removed from the store to protect users	background	2K_dev_1827
Currently	background	2K_dev_1827
Google Play store relies on mobile users ' feedbacks to identify policy violations	background	2K_dev_1827
	background	2K_dev_1827
which reveals that many violating behaviors have not been studied well by industry or research communities We discover that 53\ % of the reported apps are either copying popular apps or violating copy-rights or trademarks of brands	finding	2K_dev_1827
Moreover	finding	2K_dev_1827
49\ % of reported apps are violating ads policies by sending push notifications	finding	2K_dev_1827
adding homescreen icon and changing browser settings	finding	2K_dev_1827
Only 8\ % show malware-like behaviors	finding	2K_dev_1827
such as downloading malicious files to users ' mobile phones Our experiment result shows that the best algorithm can detect them with 86	finding	2K_dev_1827
80\ % 1 positive rate and 13	finding	2K_dev_1827
6\ % 0 positive rate On the other hand	finding	2K_dev_1827
the same samples of policy violating apps are detected by VirusTotal with 1 positive rate of 55	finding	2K_dev_1827
63\ % and 0 positive rate of 17	finding	2K_dev_1827
48\ %	finding	2K_dev_1827
	finding	2K_dev_1827
Based on our empirical analysis results	mechanism	2K_dev_1827
we extract 175 features for differentiating bad apps from benign apps	mechanism	2K_dev_1827
Our features cover use of brand names and other keywords	mechanism	2K_dev_1827
third-party libraries	mechanism	2K_dev_1827
network activities	mechanism	2K_dev_1827
meta data	mechanism	2K_dev_1827
permissions	mechanism	2K_dev_1827
and suspicious API calls originated from third-party libraries	mechanism	2K_dev_1827
	mechanism	2K_dev_1827
First	method	2K_dev_1827
we crawl 302 Android apps	method	2K_dev_1827
which are reported in the Reddit forum by mobile users for policy violations and are later removed from the Google Play store	method	2K_dev_1827
Second	method	2K_dev_1827
we perform empirical analysis	method	2K_dev_1827
We then apply 10 machine learning classifiers on the extracted features to detect reported bad apps	method	2K_dev_1827
	method	2K_dev_1827
Our paper takes the first step towards understanding these policy-violating apps	purpose	2K_dev_1827
	purpose	2K_dev_1827
The distance-keeping target can either be used for lane following for a standalone ACC system or an autonomous vehicle	background	2K_dev_1828
Our object tracking algorithm can also be extended to find the target of interest for lane changing or ramp merging for an autonomous vehicle	background	2K_dev_1828
	background	2K_dev_1828
We demonstrate that the overall performance of the proposed algorithm is better than that of a commercial ACC system	finding	2K_dev_1828
	finding	2K_dev_1828
We propose a robust object tracking algorithm Taking advantage of a context-based region of interest	mechanism	2K_dev_1828
we are able to maximize the performance of each sensor	mechanism	2K_dev_1828
and reduce the computation time since we only focus on the targets inside the region Tracking targets in road coordinates enables finding the distance-keeping target on any curved road	mechanism	2K_dev_1828
while a commercial Adaptive Cruise Control ( ACC ) system works best on straight roads	mechanism	2K_dev_1828
	mechanism	2K_dev_1828
	method	2K_dev_1828
for distance keeping	purpose	2K_dev_1828
Suppose you are a teacher	background	2K_dev_1829
and have to convey a set of object-property pairs ( 'lions eat meat ' ; or `aspirin is a blood-thinner ' )	background	2K_dev_1829
A good teacher will convey a lot of information	background	2K_dev_1829
with little effort on the student side	background	2K_dev_1829
Specifically	background	2K_dev_1829
given a list of objects ( like animals or medical drugs ) and their associated properties	background	2K_dev_1829
what is the best and most intuitive way to convey this information to the student	background	2K_dev_1829
without the student being overwhelmed	background	2K_dev_1829
it is effective achieving excellent results on real data	finding	2K_dev_1829
both with respect to our proposed metric	finding	2K_dev_1829
but also with respect to encoding length demonstrate the effectiveness of HYTRA	finding	2K_dev_1829
We also design a multi-pronged algorithm	mechanism	2K_dev_1829
HYTRA	mechanism	2K_dev_1829
Our proposed HYTRA is scalable ( near-linear in the dataset size ) ; and it is intuitive	mechanism	2K_dev_1829
conforming to well-known educational principles	mechanism	2K_dev_1829
such as grouping related concepts	mechanism	2K_dev_1829
and `` comparing { '' } and `` contrasting { '' }	mechanism	2K_dev_1829
	mechanism	2K_dev_1829
Experiments on real and synthetic datasets	method	2K_dev_1829
A related	purpose	2K_dev_1829
harder problem is : how can we assign a numerical score to each lesson plan ( i	purpose	2K_dev_1829
e	purpose	2K_dev_1829
way of conveying information ) ? Here	purpose	2K_dev_1829
we give a formal definition of this problem of forming learning units and we provide a metric for comparing different approaches based on information theory	purpose	2K_dev_1829
for this problem	purpose	2K_dev_1829
	purpose	2K_dev_1829
This approach is complementary to other efforts in the literature on speeding up computation through GPU implementation	background	2K_dev_1830
fast matrix operations	background	2K_dev_1830
or quantization	background	2K_dev_1830
in that any of these optimizations can be incorporated	background	2K_dev_1830
	background	2K_dev_1830
	finding	2K_dev_1830
we are able to dramatically reduce the rate of growth of computation as the number of models increases	finding	2K_dev_1830
show that we are able to maintain	finding	2K_dev_1830
or even exceed	finding	2K_dev_1830
the level of performance compared to the default approach of using all the models directly	finding	2K_dev_1830
in both detection and classification tasks	finding	2K_dev_1830
	finding	2K_dev_1830
We show that by formulating the visual task as a large matrix multiplication problem	mechanism	2K_dev_1830
something that is possible for a broad set of modern detectors and classifiers The approach	mechanism	2K_dev_1830
based on a bilinear separation model	mechanism	2K_dev_1830
combines standard matrix factorization with a task-dependent term which ensures that the resulting smaller size problem maintains performance on the original task	mechanism	2K_dev_1830
	mechanism	2K_dev_1830
Experiments	method	2K_dev_1830
In this paper	purpose	2K_dev_1830
we investigate the issue of evaluating efficiently a large set of models on an input image in detection and classification tasks	purpose	2K_dev_1830
	purpose	2K_dev_1830
The rapid growth of cloud storage systems calls for fast and scalable namespace processing	background	2K_dev_1831
suggests that if directory lookup state mutation is a fixed fraction of operations ( strong scaling for metadata )	finding	2K_dev_1831
server replication does not scale as well as client caching	finding	2K_dev_1831
but if directory lookup state mutation is proportional to the number of jobs	finding	2K_dev_1831
not the number of processes per job	finding	2K_dev_1831
( weak scaling for metadata )	finding	2K_dev_1831
then server replication can scale more linearly than client caching and provide lower 70 percentile response times as well	finding	2K_dev_1831
	finding	2K_dev_1831
In this paper we explore explicit replication of directory lookup state in all servers Both eliminate most repeated RPCs to different servers in order Our realization for server replicated directory lookup state	mechanism	2K_dev_1831
ShardFS	mechanism	2K_dev_1831
employs a novel file system specific hybrid optimistic and pessimistic concurrency control favoring single object transactions over distributed transactions	mechanism	2K_dev_1831
	mechanism	2K_dev_1831
Our experimentation	method	2K_dev_1831
While few commercial file systems offer anything better than federating individually non- scalable namespace servers	purpose	2K_dev_1831
a recent academic file system	purpose	2K_dev_1831
IndexFS	purpose	2K_dev_1831
demonstrates scalable namespace processing based on client caching of directory entries and permissions ( directory lookup state ) with no per-client state in servers	purpose	2K_dev_1831
as an alternative to caching this information in all clients	purpose	2K_dev_1831
to resolve hierarchical permission tests	purpose	2K_dev_1831
	purpose	2K_dev_1831
Humans play an active role in the execution of certain kinds of programs	background	2K_dev_1832
such as spreadsheets	background	2K_dev_1832
workflows and interactive notebooks	background	2K_dev_1832
Interacting closely with execution is especially useful when end-users are learning from examples while doing their to derive implications for the design of interactive and mixed-initiative programming languages	background	2K_dev_1832
	background	2K_dev_1832
These protocols present a linear	finding	2K_dev_1832
idealized process despite the complex contingencies of the lab work they describe	finding	2K_dev_1832
However	finding	2K_dev_1832
they employ a variety of techniques for limiting or expanding the semantic interpretation of individual steps and for integrating outside protocols	finding	2K_dev_1832
We use these observations	finding	2K_dev_1832
	mechanism	2K_dev_1832
we investigated a particularly rigid and formalized category of `` program { '' } people write for each other : lab protocols	method	2K_dev_1832
	method	2K_dev_1832
In order to better understand the language features needed to support this kind of use	purpose	2K_dev_1832
	purpose	2K_dev_1832
Requirements analysts can model regulated data practices to identify and reason about risks of noncompliance	background	2K_dev_1833
If terminology is inconsistent or ambiguous	background	2K_dev_1833
however	background	2K_dev_1833
these models and their conclusions will be unreliable	background	2K_dev_1833
Tregex is a utility to match regular expressions against constituency parse trees	background	2K_dev_1833
which are hierarchical expressions of natural language clauses	background	2K_dev_1833
including noun and verb phrases	background	2K_dev_1833
	background	2K_dev_1833
From this dataset	finding	2K_dev_1833
three semantic and four syntactic categories of hyponymy emerged based on category completeness and word-order	finding	2K_dev_1833
The patterns identify information type hypernym-hyponym pairs with an average precision of 0	finding	2K_dev_1833
83 and recall of 0	finding	2K_dev_1833
52 across our dataset of 15 policies	finding	2K_dev_1833
	mechanism	2K_dev_1833
We discovered the Tregex patterns by applying content analysis to 15 privacy policies from three domains ( shopping	method	2K_dev_1833
telecommunication and social networks ) to identify all instances of information type hyponymy Among these	method	2K_dev_1833
we identified and empirically evaluated 26 Tregex patterns to automate the extraction of hyponyms from privacy policies	method	2K_dev_1833
	method	2K_dev_1833
To study this problem	purpose	2K_dev_1833
we investigated an approach to automatically construct an information type ontology by identifying information type hyponymy in privacy policies using Tregex patterns	purpose	2K_dev_1833
	purpose	2K_dev_1833
Cilk Plus and OpenMP are parallel language extensions for the C and C++ programming languages	background	2K_dev_1834
The CPLEX Study Group of the ISO/IEC C Standards Committee is developing a proposal for a parallel programming extension to C that combines ideas from Cilk Plus and OpenMP	background	2K_dev_1834
We found several usability problems worthy of further investigation based on student performance	finding	2K_dev_1834
including declaring and using reductions	finding	2K_dev_1834
multi-line compiler directives	finding	2K_dev_1834
and the understandability of task assignment to threads	finding	2K_dev_1834
	finding	2K_dev_1834
	mechanism	2K_dev_1834
We conducted a preliminary comparison of Cilk Plus and OpenMP in a master 's level course on security	method	2K_dev_1834
to evaluate the design tradeoffs in the usability and security of these two approaches The eventual goal is to inform decision-making within the committee	purpose	2K_dev_1834
The widespread presence of motion sensors on users ' personal mobile devices has spawned a growing research interest in human activity recognition ( HAR )	background	2K_dev_1835
	background	2K_dev_1835
Our results indicate that on-device sensor and sensor handling heterogeneities impair HAR performances significantly	finding	2K_dev_1835
Moreover	finding	2K_dev_1835
the impairments vary significantly across devices and depends on the type of recognition technique used	finding	2K_dev_1835
	finding	2K_dev_1835
propose a novel clustering-based mitigation technique suitable	mechanism	2K_dev_1835
where heterogeneity of devices and their usage scenarios are intrinsic	mechanism	2K_dev_1835
In this paper	method	2K_dev_1835
we systematically investigate sensor-	method	2K_dev_1835
device-and workload-specific heterogeneities using 3 6 smart-phones and smartwatches	method	2K_dev_1835
consisting of 1 3 different device models from four manufacturers	method	2K_dev_1835
Furthermore	method	2K_dev_1835
we conduct experiments with nine users and investigate popular feature representation and classification techniques in HAR research We systematically evaluate the effect of mobile sensing heterogeneities on HAR and	method	2K_dev_1835
However	purpose	2K_dev_1835
when deployed at a large-scale	purpose	2K_dev_1835
e	purpose	2K_dev_1835
g	purpose	2K_dev_1835
	purpose	2K_dev_1835
on multiple devices	purpose	2K_dev_1835
the performance of a HAR system is often significantly lower than in reported research results	purpose	2K_dev_1835
This is due to variations in training and test device hardware and their operating system characteristics among others for large-scale deployment of HAR	purpose	2K_dev_1835
	background	2K_dev_1836
The method has been validated Experimental findings strongly support the validity of real-time	finding	2K_dev_1836
3D registration and reconstruction from 2D video	finding	2K_dev_1836
The software is available online at http : //zface	finding	2K_dev_1836
org	finding	2K_dev_1836
	finding	2K_dev_1836
we developed a 3D cascade regression approach in which facial landmarks remain invariant across pose over a range of approximately 60 degrees	mechanism	2K_dev_1836
From a single 2D image of a person 's face	mechanism	2K_dev_1836
a dense 3D shape is registered in real time for each frame	mechanism	2K_dev_1836
The algorithm utilizes a fast cascade regression framework trained on high-resolution 3D face-scans of posed and spontaneous emotion expression	mechanism	2K_dev_1836
The algorithm first estimates the location of a dense set of markers and their visibility	mechanism	2K_dev_1836
then reconstructs face shapes by fitting a part-based 3D model	mechanism	2K_dev_1836
Because no assumptions are required about illumination or surface properties	mechanism	2K_dev_1836
the method can be applied to a wide range of imaging conditions that include 2D video and uncalibrated multi-view video	mechanism	2K_dev_1836
in a battery of experiments that evaluate its precision of 3D reconstruction and extension to multi-view reconstruction	method	2K_dev_1836
	method	2K_dev_1836
To enable real-time	purpose	2K_dev_1836
person-independent 3D registration from 2D video	purpose	2K_dev_1836
	purpose	2K_dev_1836
Cultural events are kinds of typical events closely related to history and nationality	background	2K_dev_1837
which play an important role in cultural heritage through generations	background	2K_dev_1837
	background	2K_dev_1837
Our method achieves the best performance of mAP 0 0	finding	2K_dev_1837
854 among all the participants in the track of cultural event recognition	finding	2K_dev_1837
	finding	2K_dev_1837
by combining both ideas of object / scene contents mining and strong image representation via CNN into a whole framework	mechanism	2K_dev_1837
Specifically	mechanism	2K_dev_1837
	mechanism	2K_dev_1837
we employ selective search to extract a batch of bottom-up region proposals	mechanism	2K_dev_1837
which are served as key object / scene candidates in each event image ; while	mechanism	2K_dev_1837
we investigate two state-of-the-art deep architectures	mechanism	2K_dev_1837
VGGNet and GoogLeNet	mechanism	2K_dev_1837
and adapt them to our task by performing domain-specific ( i	mechanism	2K_dev_1837
e	mechanism	2K_dev_1837
	mechanism	2K_dev_1837
event ) fine-tuning on both global image and hierarchical region proposals	mechanism	2K_dev_1837
These two models can complementarily exploit feature hierarchies spatially	mechanism	2K_dev_1837
which simultaneously capture the global context and local evidences within the image	mechanism	2K_dev_1837
	mechanism	2K_dev_1837
In our final submission for ChaLearn LAP Challenge ICCV 2015	method	2K_dev_1837
nine kinds of features extracted from five different deep models were exploited and followed with two kinds of classifiers for decision level fusion	method	2K_dev_1837
However	purpose	2K_dev_1837
automatically recognizing cultural events still remains a great challenge since it depends on understanding of complex image contents such as people	purpose	2K_dev_1837
objects	purpose	2K_dev_1837
and scene context	purpose	2K_dev_1837
Therefore	purpose	2K_dev_1837
it is intuitive to associate this task with other high-level vision problems	purpose	2K_dev_1837
e	purpose	2K_dev_1837
g	purpose	2K_dev_1837
	purpose	2K_dev_1837
object detection	purpose	2K_dev_1837
recognition	purpose	2K_dev_1837
and scene understanding	purpose	2K_dev_1837
In this paper	purpose	2K_dev_1837
we address this problem for object / scene contents mining for representation via CNN	purpose	2K_dev_1837
Regulatory definitions establish the scope and boundary for legal statements and provide software designers with means to assess the coverage of their designs under the law	background	2K_dev_1838
However	background	2K_dev_1838
the number of phrases that serve to define this boundary in a legal statement are usually large and often a simple legal statement contains or is affected by up to 10 definition-related phrases	background	2K_dev_1838
In addition	background	2K_dev_1838
software designers may need to design their software to operate under multiple jurisdictions	background	2K_dev_1838
which may not use the same terminology to express conditions	background	2K_dev_1838
	background	2K_dev_1838
	finding	2K_dev_1838
to develop a method Our method helps reduce the number of comparison between definitions across multiple jurisdictions as well as allows software designers keep track of several inter-related definitions in a systematic way	mechanism	2K_dev_1838
	mechanism	2K_dev_1838
	method	2K_dev_1838
Thus	purpose	2K_dev_1838
it is necessary for designers to keep track of definitions in one or more regulations and to compare these definitions across jurisdictions	purpose	2K_dev_1838
In this paper we report a study to analyze and compare natural language definitions across legal texts and how to analyze the legal statements with respect to definitions	purpose	2K_dev_1838
Automated program repair ( APR ) is a challenging process of detecting bugs	background	2K_dev_1839
localizing buggy code	background	2K_dev_1839
generating fix candidates and validating the fixes	background	2K_dev_1839
Effectiveness of program repair methods relies on the generated fix candidates	background	2K_dev_1839
and the methods used to traverse the space of generated candidates to search for the best ones Existing approaches generate fix candidates based on either syntactic searches over source code or semantic analysis of specification	background	2K_dev_1839
e	background	2K_dev_1839
g	background	2K_dev_1839
	background	2K_dev_1839
test cases	background	2K_dev_1839
	background	2K_dev_1839
achieving promising results	finding	2K_dev_1839
In this paper	mechanism	2K_dev_1839
we propose to combine both syntactic and semantic fix candidates We present an automated repair method based on structured specifications	mechanism	2K_dev_1839
deductive verification and genetic programming	mechanism	2K_dev_1839
Given a function with its specification	mechanism	2K_dev_1839
we utilize a modular verifier to detect bugs and localize both program statements and sub-formulas in the specification that relate to those bugs While the former are identified as buggy code	mechanism	2K_dev_1839
the latter are transformed as semantic fix candidates	mechanism	2K_dev_1839
We additionally generate syntactic fix candidates via various mutation operators	mechanism	2K_dev_1839
Best candidates	mechanism	2K_dev_1839
which receives fewer warnings via a static verification	mechanism	2K_dev_1839
are selected for evolution though genetic programming until we find one satisfying the specification	mechanism	2K_dev_1839
Another interesting feature of our proposed approach is that we efficiently ensure the soundness of repaired code through modular ( or compositional ) verification	mechanism	2K_dev_1839
	mechanism	2K_dev_1839
We implemented our proposal and tested it on C programs taken from the SIR benchmark that are seeded with bugs	method	2K_dev_1839
to enhance the search space of APR	purpose	2K_dev_1839
and provide a function to effectively traverse the search space	purpose	2K_dev_1839
	purpose	2K_dev_1839
	background	2K_dev_1840
Our behavioral data supports In fact	finding	2K_dev_1840
one third of our detection instances occurred during robot transit	finding	2K_dev_1840
i	finding	2K_dev_1840
e	finding	2K_dev_1840
	finding	2K_dev_1840
while the robots were making no verbal offer	finding	2K_dev_1840
We find that candy accessibility dominates any social influence of robot orientation and that robot speed influences both whether people will interrupt a robot in transit ( slow more interruptible ) and whether they will respond to its verbal offer ( fast more salient )	finding	2K_dev_1840
	finding	2K_dev_1840
	mechanism	2K_dev_1840
In our experiment	method	2K_dev_1840
two autonomously moving costumed robots visit 256 offices during a `reverse ' trick-or-treating task close to Halloween	method	2K_dev_1840
	method	2K_dev_1840
the idea that people interpret a robot 's non-verbal cues	purpose	2K_dev_1840
as the robots ' costuming and baskets of candy seem to have communicated an implicit offer of candy	purpose	2K_dev_1840
The advent of multi-core systems set off a race to get concurrent programming to the masses	background	2K_dev_1841
	background	2K_dev_1841
and we show its application to the construction of concurrent software	finding	2K_dev_1841
	finding	2K_dev_1841
In this paper we propose an exception-handling model for concurrent systems Its main quality attributes are simplicity and expressiveness	mechanism	2K_dev_1841
allowing programmers to deal with exceptional situations in a concurrent setting in a familiar way	mechanism	2K_dev_1841
The proposal is centered on a new kind of exception type that defines new paths for exception propagation among concurrent threads of execution In our model	mechanism	2K_dev_1841
beyond being able to control where exceptions are raised	mechanism	2K_dev_1841
the developer can define in which thread	mechanism	2K_dev_1841
and when during its execution	mechanism	2K_dev_1841
a particular exception will be handled	mechanism	2K_dev_1841
	mechanism	2K_dev_1841
The proposed model has been implemented in Scala	method	2K_dev_1841
	method	2K_dev_1841
One of the challenging aspects of this type of system is how to deal with exceptional situations	purpose	2K_dev_1841
since it is very difficult to assert the precise state of a concurrent program when an exception arises	purpose	2K_dev_1841
The noise model of deletions poses significant challenges in coding theory	background	2K_dev_1842
with basic questions like the capacity of the binary deletion channel still being open	background	2K_dev_1842
The abovementioned results bring our understanding of deletion code constructions in these regimes to a similar level as worst case errors	background	2K_dev_1842
	background	2K_dev_1842
This paper gives the first efficient constructions which meet the qualitative goals of correcting a deletion fraction approaching 1 over bounded alphabets	finding	2K_dev_1842
and correcting a constant fraction of bit deletions with rate approaching 1 over a fixed alphabet	finding	2K_dev_1842
	finding	2K_dev_1842
	method	2K_dev_1842
In this paper	purpose	2K_dev_1842
we study the harder model of worst case deletions	purpose	2K_dev_1842
for the two extreme regimes of high-noise and high-rate	purpose	2K_dev_1842
Interface-confinement is a common mechanism that secures untrusted code by executing it inside a sandbox	background	2K_dev_1843
The sandbox limits ( confines ) the code 's interaction with key system resources to a restricted set of interfaces	background	2K_dev_1843
This practice is seen in web browsers	background	2K_dev_1843
hypervisors	background	2K_dev_1843
and other security-critical systems	background	2K_dev_1843
System M is the first program logic that allows proofs of safety for programs that execute adversary-supplied code without forcing the adversarial code to be available for deep static analysis	background	2K_dev_1843
System M can be used to model and verify protocols as well as system designs	background	2K_dev_1843
	background	2K_dev_1843
and prove the soundness of System M relative to the model	finding	2K_dev_1843
We demonstrate the reasoning principles of System M	finding	2K_dev_1843
Motivated by these systems	mechanism	2K_dev_1843
we present a program logic	mechanism	2K_dev_1843
called System M In addition to using computation types to specify effects of computations	mechanism	2K_dev_1843
System M includes a novel invariant type to specify the properties of interface-confined code	mechanism	2K_dev_1843
The interpretation of invariant type includes terms whose effects satisfy an invariant	mechanism	2K_dev_1843
We construct a step-indexed model built over traces by verifying the state integrity property of the design of Memoir	method	2K_dev_1843
a previously proposed trusted computing system	method	2K_dev_1843
	method	2K_dev_1843
	purpose	2K_dev_1843
for modeling and proving safety properties of systems that execute adversary-supplied code via interface-confinement	purpose	2K_dev_1843
	purpose	2K_dev_1843
Information flow analysis has largely focused on methods that require access to the program in question or total control over an analyzed system	background	2K_dev_1844
We reduce these problems to ones of causal inference Our systematic study leads to practical advice for detecting web data usage	finding	2K_dev_1844
a previously unformalized area	finding	2K_dev_1844
	finding	2K_dev_1844
Leveraging this connection	mechanism	2K_dev_1844
we provide a systematic black-box methodology based on experimental science and statistical analysis	mechanism	2K_dev_1844
We formalize such limited information flow analyses and study an instance of it : detecting the usage of data by websites by proving a connection between noninterference and causation	method	2K_dev_1844
We illustrate these concepts with a series of experiments collecting data on the use of information by websites	method	2K_dev_1844
	method	2K_dev_1844
We consider the case where the analyst has neither control over nor a white-box model of the analyzed system	purpose	2K_dev_1844
In today 's ubiquitous computing environment where the number of devices	background	2K_dev_1845
applications and web services are ever increasing	background	2K_dev_1845
human attention is the new bottleneck in computing	background	2K_dev_1845
	background	2K_dev_1845
proved the effectiveness of Attelia showed that notifications at detected breakpoint timing resulted in 46\ % lower cognitive load compared to randomly-timed notifications	finding	2K_dev_1845
further validated Attelia 's value	finding	2K_dev_1845
with a 33\ % decrease in cognitive load compared to randomly-timed notifications	finding	2K_dev_1845
	finding	2K_dev_1845
we propose Attelia	mechanism	2K_dev_1845
a novel middleware that identifies breakpoints in user interaction and delivers notifications at these moments	mechanism	2K_dev_1845
Attelia works in real-time and uses only the mobile devices that users naturally use and wear	mechanism	2K_dev_1845
without any modifications to applications	mechanism	2K_dev_1845
and without any dedicated psycho-physiological sensors	mechanism	2K_dev_1845
	mechanism	2K_dev_1845
Our evaluation A controlled user study Furthermore	method	2K_dev_1845
our `` in-the-wild { '' } user study with 30 participants for 16 days	method	2K_dev_1845
To minimize user cognitive load	purpose	2K_dev_1845
Applications	background	2K_dev_1846
such as construction monitoring and planning for renovations	background	2K_dev_1846
require the accurate recovery of existing conditions of structures	background	2K_dev_1846
	background	2K_dev_1846
We demonstrate the capability and robustness of our approach	finding	2K_dev_1846
To address this issue	mechanism	2K_dev_1846
this paper presents an approach from a 3D point cloud containing a complex network of thin structures	mechanism	2K_dev_1846
and In our approach	mechanism	2K_dev_1846
each beam is evolved from a seed by matching and aligning the cross section images	mechanism	2K_dev_1846
This growing algorithm can model beams with arbitrary cross sections By performing the algorithm on a point connectivity graph	mechanism	2K_dev_1846
we distinguish beams from joints and improve the algorithm 's robustness to closely spaced objects	mechanism	2K_dev_1846
In parallel	mechanism	2K_dev_1846
planes and joints are also extracted and modeled	mechanism	2K_dev_1846
The connectivity graph of these primitives allows for a compact	mechanism	2K_dev_1846
object-level understanding of the entire structure	mechanism	2K_dev_1846
	mechanism	2K_dev_1846
on both synthetic and real datasets	method	2K_dev_1846
	method	2K_dev_1846
Many types of infrastructure are primarily comprised of arbitrarily-shaped thin structures ( e	purpose	2K_dev_1846
g	purpose	2K_dev_1846
	purpose	2K_dev_1846
truss bridges	purpose	2K_dev_1846
steel frame buildings under construction	purpose	2K_dev_1846
and transmission towers )	purpose	2K_dev_1846
which existing automatic modeling methods are incapable of handling	purpose	2K_dev_1846
to automatically recognize and model beams	purpose	2K_dev_1846
planes	purpose	2K_dev_1846
and joints to recover their topology	purpose	2K_dev_1846
Many learning-based computer vision algorithms perform poorly when faced with examples that are dissimilar to those on which they were trained	background	2K_dev_1847
show that the proposed approach outperforms existing single-step methods on a dataset of nine building styles	finding	2K_dev_1847
	finding	2K_dev_1847
We propose a two-step approach The first step uses a small number of labeled examples	mechanism	2K_dev_1847
while the second step uses traditional domain adaptation methods	mechanism	2K_dev_1847
We demonstrate this two-step domain adaptation algorithm in the context of style-independent building component recognition	method	2K_dev_1847
which suffers from the problem of inter-domain performance degradation In this case	method	2K_dev_1847
different building styles represent the domains	method	2K_dev_1847
and the task is to reverse engineer a new building of unknown style	method	2K_dev_1847
We evaluate several variants of the two-step method	method	2K_dev_1847
and experiments We demonstrate the generality of the approach on a large	method	2K_dev_1847
multi-domain dataset with 22 product review categories ( i	method	2K_dev_1847
e	method	2K_dev_1847
	method	2K_dev_1847
styles ) from the natural language processing field	method	2K_dev_1847
	method	2K_dev_1847
Domain adaptation methods attempt to address this problem	purpose	2K_dev_1847
but usually assume that the source domain is specified a priori for situations where more than one source domain available to choose the source domain most similar to the target domain to further adapt the chosen source domain to the target data	purpose	2K_dev_1847
	purpose	2K_dev_1847
Registration of Point Cloud Data ( PCD ) forms a core component of many 3D vision algorithms such as object matching and environment reconstruction	background	2K_dev_1848
	background	2K_dev_1848
showing better convergence for a wider range of initial conditions and higher speeds than previous state of the art methods	finding	2K_dev_1848
	finding	2K_dev_1848
In this paper	mechanism	2K_dev_1848
we introduce a PCD registration algorithm that utilizes Gaussian Mixture Models ( GMM ) and a novel dual-mode parameter optimization technique which we call mixture decoupling	mechanism	2K_dev_1848
by first optimizing over the mixture parameters ( decoupling the mixture weights	mechanism	2K_dev_1848
means	mechanism	2K_dev_1848
and covariances from the points ) before optimizing over the 6DOF registration parameters	mechanism	2K_dev_1848
Furthermore	mechanism	2K_dev_1848
we frame both the decoupling and registration process inside a unified	mechanism	2K_dev_1848
dual-mode Expectation Maximization ( EM ) framework	mechanism	2K_dev_1848
for which we derive a Maximum Likelihood Estimation ( MLE ) solution along with a parallel implementation on the GPU	mechanism	2K_dev_1848
	mechanism	2K_dev_1848
We evaluate our MLE-based mixture decoupling ( MLMD ) registration method over both synthetic and real data	method	2K_dev_1848
	method	2K_dev_1848
We show how this decoupling technique facilitates both faster and more robust registration	purpose	2K_dev_1848
	background	2K_dev_1849
	finding	2K_dev_1849
	mechanism	2K_dev_1849
	method	2K_dev_1849
	purpose	2K_dev_1849
Formal verification of industrial systems is very challenging	background	2K_dev_1850
due to reasons ranging from scalability issues to communication difficulties with engineering-focused teams	background	2K_dev_1850
More importantly	background	2K_dev_1850
industrial systems are rarely designed for verification	background	2K_dev_1850
but rather for operational needs	background	2K_dev_1850
The effort presented in this paper is an integral part of the ACAS X development and was performed in tight collaboration with the ACAS X development team	background	2K_dev_1850
	finding	2K_dev_1850
In this paper we present an overview of our experience using hybrid systems theorem proving scheduled to be operational around 2020	mechanism	2K_dev_1850
The methods and proof techniques presented here are an overview of the work already presented in { [ } 8 ]	mechanism	2K_dev_1850
	mechanism	2K_dev_1850
while the evaluation of ACAS X has been significantly expanded and updated to the most recent version of the system	method	2K_dev_1850
run 13	method	2K_dev_1850
	method	2K_dev_1850
to formally verify ACAS X	purpose	2K_dev_1850
an airborne collision avoidance system for airliners	purpose	2K_dev_1850
Human swarm interaction ( HSI ) involves operators gathering information about a swarm 's state as it evolves	background	2K_dev_1851
and using it to make informed decisions on how to influence the collective behavior of the swarm	background	2K_dev_1851
In order to determine the proper input	background	2K_dev_1851
an operator must have an accurate representation and understanding of the current swarm state	background	2K_dev_1851
including what emergent behavior is currently happening	background	2K_dev_1851
	background	2K_dev_1851
Our results show that	finding	2K_dev_1851
while participants were good at recognizing all behaviors	finding	2K_dev_1851
there are indeed differences between the three	finding	2K_dev_1851
with rendezvous being easier to recognize than flocking or dispersion Furthermore	finding	2K_dev_1851
differences in recognition are also affected by viewing time for flocking	finding	2K_dev_1851
was also especially insightful for understanding how participants went about recognizing behaviors-allowing for potential avenues of research in future studies	finding	2K_dev_1851
	finding	2K_dev_1851
	mechanism	2K_dev_1851
Feedback from participants	method	2K_dev_1851
In this paper	purpose	2K_dev_1851
we investigate how human operators perceive three types of common	purpose	2K_dev_1851
emergent swarm behaviors : rendezvous	purpose	2K_dev_1851
flocking	purpose	2K_dev_1851
and dispersion	purpose	2K_dev_1851
Particularly	purpose	2K_dev_1851
we investigate how recognition of these behaviors differ from each other in the presence of background noise	purpose	2K_dev_1851
A server has constantly received various reference time series Q of length X and seeks the exact kNN over a collection of time series distributed across a set of M local sites	background	2K_dev_1852
When X and M are large	background	2K_dev_1852
and when the amount of query increases	background	2K_dev_1852
simply sending each Q to all M sites incurs high communication bandwidth costs	background	2K_dev_1852
which we would like to avoid	background	2K_dev_1852
Prior work has presented a communication-efficient kNN algorithm for the Euclidean distance similarity measure	background	2K_dev_1852
	background	2K_dev_1852
show that our method reduces communication bandwidth by up to 92\ %	finding	2K_dev_1852
	finding	2K_dev_1852
In this paper	mechanism	2K_dev_1852
we present the first kNN algorithm	mechanism	2K_dev_1852
which is generally believed a better measure for time series	mechanism	2K_dev_1852
we design a new multi-resolution structure for the reference time series	mechanism	2K_dev_1852
and multi-resolution lower bounds that can effectively prune the search space	mechanism	2K_dev_1852
We present a new protocol between the server and the local sites that leverages multi-resolution pruning and cascading lower bounds	mechanism	2K_dev_1852
Empirical studies on both real-world and synthetic data sets	method	2K_dev_1852
We study the fundamental k-nearest neighbor ( kNN ) search problem on distributed time series communication-efficient for the dynamic time warping ( DTW ) similarity measure To handle the complexities of DTW for communication efficiency for computational efficiency	purpose	2K_dev_1852
A multi-faceted graph defines several facets on a set of nodes	background	2K_dev_1853
Each facet is a set of edges that represent the relationships between the nodes in a specific context	background	2K_dev_1853
Mining multi-faceted graphs have several applications	background	2K_dev_1853
including finding fraudster rings that launch advertising traffic fraud attacks	background	2K_dev_1853
tracking IP addresses of botnets over time	background	2K_dev_1853
analyzing interactions on social networks and co-authorship of scientific papers	background	2K_dev_1853
	background	2K_dev_1853
	finding	2K_dev_1853
where NeSim is shown to be superior to MCL	finding	2K_dev_1853
JP and AP	finding	2K_dev_1853
the well-established clustering algorithms	finding	2K_dev_1853
We also report the success stories of MuFace in finding advertisement click rings	finding	2K_dev_1853
	finding	2K_dev_1853
We propose NeSim	mechanism	2K_dev_1853
a distributed efficient clustering algorithm that does We also propose optimizations to further improve the scalability	mechanism	2K_dev_1853
the efficiency and the clusters quality	mechanism	2K_dev_1853
We employ generalpurpose graph-clustering algorithms in a novel way Due to the qualities of NeSim	mechanism	2K_dev_1853
we employ it as a backbone in the distributed MuFace algorithm	mechanism	2K_dev_1853
which discovers multi-faceted communities	mechanism	2K_dev_1853
	mechanism	2K_dev_1853
We evaluate the proposed algorithms on several real and synthetic datasets	method	2K_dev_1853
soft clustering on individual facets	purpose	2K_dev_1853
to discover communities across facets	purpose	2K_dev_1853
	purpose	2K_dev_1853
Dataflow analysis-based dynamic parallel monitoring ( DADPM ) is a recent approach for identifying bugs in parallel software as it executes	background	2K_dev_1854
based on the key insight of explicitly modeling a sliding window of uncertainty across parallel threads	background	2K_dev_1854
provides new provable guarantees that reported 1 errors are now precise	finding	2K_dev_1854
First	mechanism	2K_dev_1854
by explicitly tracking new `` uncertain { '' } states in the metadata lattice	mechanism	2K_dev_1854
Second	mechanism	2K_dev_1854
as the analysis tool runs dynamically	mechanism	2K_dev_1854
it can use the existence ( or absence ) of observed uncertain states For example	mechanism	2K_dev_1854
we demonstrate how the epoch size parameter can be adjusted dynamically in response to uncertainty in order	mechanism	2K_dev_1854
This paper shows how to adapt a canonical dataflow analysis problem ( reaching definitions ) and a popular security monitoring tool ( TAINTCHECK ) to our new uncertainty-tracking framework	method	2K_dev_1854
and	method	2K_dev_1854
While this makes the approach practical and scalable	purpose	2K_dev_1854
it also introduces the possibility of 0 positives in the analysis In this paper	purpose	2K_dev_1854
we improve upon the DADPM framework through two observations	purpose	2K_dev_1854
we can distinguish potential 0 positives from 1 positives	purpose	2K_dev_1854
to adjust the tradeoff between precision and performance on-the-fly	purpose	2K_dev_1854
to achieve better performance and precision than when the tool is statically configured	purpose	2K_dev_1854
	purpose	2K_dev_1854
Retinal vein cannulation is a demanding procedure proposed to treat retinal vein occlusion by direct therapeutic agent delivery methods	background	2K_dev_1855
	background	2K_dev_1855
demonstrates a significant improvement in the total time the needle could be maintained stably inside of the vein	finding	2K_dev_1855
This was especially evident in smaller veins and is attributed to decreased movement of the positioned cannula following venous cannulation	finding	2K_dev_1855
	finding	2K_dev_1855
In this study	mechanism	2K_dev_1855
with an assistive system combining a handheld micromanipulator	mechanism	2K_dev_1855
Micron	mechanism	2K_dev_1855
with a force-sensing microneedle	mechanism	2K_dev_1855
The integrated system senses the instant of vein puncture based on measured forces and the position of the needle tip	mechanism	2K_dev_1855
The system actively holds the cannulation device securely in the vein following cannulation and during drug delivery	mechanism	2K_dev_1855
	mechanism	2K_dev_1855
Preliminary testing of the system in a dry phantom	method	2K_dev_1855
stretched vinyl membranes	method	2K_dev_1855
Challenges in identifying the moment of venous puncture	purpose	2K_dev_1855
achieving cannulation and maintaining cannulation during drug delivery currently limit the feasibility of the procedure we respond to these problems	purpose	2K_dev_1855
Public speaking has become an integral part of many professions and is central to career building opportunities Yet	background	2K_dev_1856
public speaking anxiety is often referred to as the most common fear in everyday life and can hinder one 's ability to speak in public severely	background	2K_dev_1856
While virtual and real audiences have been successfully utilized to treat public speaking anxiety in the past	background	2K_dev_1856
little work has been done on identifying behavioral characteristics of speakers suffering from anxiety Complementary to automatic measures of anxiety	background	2K_dev_1856
we are also interested in speakers ' perceptual differences when interacting with a virtual audience based on their level of anxiety in order to improve and further the development of virtual audiences for the training of public speaking and the reduction of anxiety	background	2K_dev_1856
	background	2K_dev_1856
achieves a high correlation between ground truth and our estimation ( r=0	finding	2K_dev_1856
825 )	finding	2K_dev_1856
	mechanism	2K_dev_1856
We identify several indicators for public speaking anxiety	method	2K_dev_1856
among them are less eye contact with the audience	method	2K_dev_1856
reduced variability in the voice	method	2K_dev_1856
and more pauses	method	2K_dev_1856
We automatically assess the public speaking anxiety as reported by the speakers through a self-assessment questionnaire using a speaker independent paradigm	method	2K_dev_1856
Our approach using ensemble trees	method	2K_dev_1856
In this work	purpose	2K_dev_1856
we focus on the characterization of behavioral indicators and the automatic assessment of public speaking anxiety	purpose	2K_dev_1856
	purpose	2K_dev_1856
Action Unit ( AU ) detection from facial images is an important classification task in affective computing	background	2K_dev_1857
However most existing approaches use carefully engineered feature extractors along with off-the-shelf classifiers	background	2K_dev_1857
There has also been less focus on how well classifiers generalize when tested on different datasets	background	2K_dev_1857
	background	2K_dev_1857
indicate that our approach obtains competitive results on all datasets	finding	2K_dev_1857
also indicate that the network generalizes well to other datasets	finding	2K_dev_1857
even when under different training and testing conditions	finding	2K_dev_1857
	finding	2K_dev_1857
In our paper	mechanism	2K_dev_1857
we propose a multi-label convolutional neural network approach	mechanism	2K_dev_1857
Experiments on three AU datasets-CK+	method	2K_dev_1857
DISFA and BP4D Cross-dataset experiments	method	2K_dev_1857
to learn a shared representation between multiple AUs directly from the input image	purpose	2K_dev_1857
	purpose	2K_dev_1857
Large teams of robots that operate collectively	background	2K_dev_1858
whose behavior emerges from local interactions with neighbors	background	2K_dev_1858
are known as swarms This research is necessary if real world swarms are to be deployed in the future	background	2K_dev_1858
With these results	background	2K_dev_1858
and with participant feedback about the helpfulness of the four display types	background	2K_dev_1858
we hope future studies can make more informed decision about interface design when it comes to the control of swarms	background	2K_dev_1858
Results show that summarizing the swarm 's current state to just an average position and bounding ellipse allowed predictions as accurate as those made when full state information was shown However	finding	2K_dev_1858
such display methods were inferior for prediction than either the summary center and ellipse or full information methods	finding	2K_dev_1858
	finding	2K_dev_1858
	mechanism	2K_dev_1858
In the study	method	2K_dev_1858
participants are shown swarms performing one of three different behaviors	method	2K_dev_1858
and are asked to use the information available from the display to make their predictions	method	2K_dev_1858
Furthermore	method	2K_dev_1858
two leader-based methods were used	method	2K_dev_1858
whereby the operators were shown only a small subset of the swarm	method	2K_dev_1858
	method	2K_dev_1858
While significant progress has been made improving the hardware	purpose	2K_dev_1858
communication capabilities	purpose	2K_dev_1858
and autonomous operation of these swarms	purpose	2K_dev_1858
we still have much to learn about how human operators control and interact with them	purpose	2K_dev_1858
The study presented here investigates different methods of displaying information about the swarm state to operators	purpose	2K_dev_1858
and asks them to make predictions about the swarm 's future state	purpose	2K_dev_1858
	purpose	2K_dev_1858
Planning for multirobot manipulation in dense clutter becomes particularly challenging as the motion of the manipulated object causes the connectivity of the robots ' free space to change and discuss future adaptations to general environments	background	2K_dev_1859
	background	2K_dev_1859
Finally	finding	2K_dev_1859
we show how to construct the FTG	finding	2K_dev_1859
This paper introduces a data structure	mechanism	2K_dev_1859
the Feasible Transition Graph ( FTG )	mechanism	2K_dev_1859
and algorithms that We define an equivalence relation over object configurations based on the robots ' free space connectivity Within an equivalence class	mechanism	2K_dev_1859
the homogeneous multirobot motion planning problem is straightforward	mechanism	2K_dev_1859
which allows us The FTG captures transitions among the equivalence classes and encodes constraints that must be satisfied for the robots to manipulate the object	mechanism	2K_dev_1859
From this data structure	mechanism	2K_dev_1859
we readily derive a complete planner to coordinate such motion	mechanism	2K_dev_1859
	mechanism	2K_dev_1859
in some sample environments	method	2K_dev_1859
solve such complex motion planning problems	purpose	2K_dev_1859
to decouple the problems of composing feasible object motions and planning paths for individual robots	purpose	2K_dev_1859
	purpose	2K_dev_1859
Sharing scientific data	background	2K_dev_1860
software	background	2K_dev_1860
and instruments is becoming increasingly common as science moves toward large-scale	background	2K_dev_1860
distributed collaborations	background	2K_dev_1860
Sharing these resources requires extra work to make them generally useful	background	2K_dev_1860
Our results have important implications for future empirical studies as well as funding policy	background	2K_dev_1860
Our findings indicate that they conduct a rich set of extra work around community management	finding	2K_dev_1860
code maintenance	finding	2K_dev_1860
education and training	finding	2K_dev_1860
developer-user interaction	finding	2K_dev_1860
and foreseeing user needs	finding	2K_dev_1860
We identify several conditions under which they are likely to do this work	finding	2K_dev_1860
as well as design principles that can facilitate it	finding	2K_dev_1860
	finding	2K_dev_1860
	mechanism	2K_dev_1860
a qualitative	method	2K_dev_1860
interview-based study	method	2K_dev_1860
Although we know much about the extra work associated with sharing data	purpose	2K_dev_1860
we know little about the work associated with sharing contributions to software	purpose	2K_dev_1860
even though software is of vital importance to nearly every scientific result	purpose	2K_dev_1860
This paper presents of the extra work that developers and end users of scientific software undertake	purpose	2K_dev_1860
	purpose	2K_dev_1860
Eye tracking is a compelling tool for revealing people 's spatial-temporal distribution of visual attention Such an approach will allow designers to evaluate and refine their visual design without requiring the use of limited/expensive eye trackers	background	2K_dev_1861
which demonstrated good accuracy when compared to a real eye tracker	finding	2K_dev_1861
and showed that it accurately generated gaze heatmaps and trajectory maps	finding	2K_dev_1861
	finding	2K_dev_1861
we introduce a new approach that harnesses the crowd In our approach	mechanism	2K_dev_1861
crowdsourcing participants use mouse clicks to self-report the positions and trajectory for the following valuable eye tracking measures : first gaze	mechanism	2K_dev_1861
last gaze and all gazes	mechanism	2K_dev_1861
	mechanism	2K_dev_1861
We validate our crowdsourcing approach with a user study	method	2K_dev_1861
We then deployed our prototype	method	2K_dev_1861
GazeCrowd	method	2K_dev_1861
in a crowdsourcing setting	method	2K_dev_1861
	method	2K_dev_1861
But quality eye tracking hardware is expensive and can only be used with one person at a time	purpose	2K_dev_1861
Further	purpose	2K_dev_1861
webcam eye tracking systems have significant limitations on head movement and lighting conditions that result in significant data loss and inaccuracies	purpose	2K_dev_1861
To address these drawbacks	purpose	2K_dev_1861
to understand allocation of visual attention	purpose	2K_dev_1861
	purpose	2K_dev_1861
In a variety of peer production settings	background	2K_dev_1862
from Wikipedia to open source software development to crowdsourcing	background	2K_dev_1862
individuals may encounter	background	2K_dev_1862
edit	background	2K_dev_1862
or review the work of unknown others Typically this is done without much context to the person 's past behavior or performance	background	2K_dev_1862
This work provides insight into the impact of activity history design factors on psychological and behavioral outcomes that can be of use in other related settings	background	2K_dev_1862
	background	2K_dev_1862
Surprisingly	finding	2K_dev_1862
negative work history did not lead to negative outcomes	finding	2K_dev_1862
but in contrast	finding	2K_dev_1862
a positive work history led to positive initial impressions that persisted in the face of contrary information	finding	2K_dev_1862
	finding	2K_dev_1862
	mechanism	2K_dev_1862
we conducted an online experiment on Mechanical Turk varying the content	method	2K_dev_1862
quality	method	2K_dev_1862
and presentation of information about another Turker 's work history	method	2K_dev_1862
	method	2K_dev_1862
To understand how exposure to an unknown individual 's activity history influences attitudes and behaviors	purpose	2K_dev_1862
	purpose	2K_dev_1862
Telepresence means business people can make deals in other countries	background	2K_dev_1863
doctors can give remote medical advice	background	2K_dev_1863
and soldiers can rescue someone from thousands of miles away	background	2K_dev_1863
When interaction is mediated	background	2K_dev_1863
people are removed from and lack context about the person they are making decisions about	background	2K_dev_1863
We discuss implications of our results for theory and future research	background	2K_dev_1863
	background	2K_dev_1863
The results suggest that technological mediation influences decision making	finding	2K_dev_1863
but its influence depends on an individual 's self-construal : participants who saw themselves as defined through their relationships ( interdependent self-construal ) recommended riskier and more painful treatments in video conferencing than when face-to-face	finding	2K_dev_1863
	finding	2K_dev_1863
	mechanism	2K_dev_1863
We conducted a laboratory experiment involving medical treatment decisions	method	2K_dev_1863
In this paper	purpose	2K_dev_1863
we explore the impact of technological mediation on risk and dehumanization in decision-making	purpose	2K_dev_1863
and discuss possible incentives and safeguards to context sharing from a user standpoint	background	2K_dev_1864
	background	2K_dev_1864
that show how GCF 's ability to form groups increases users ' access to relevant and timely information	finding	2K_dev_1864
	finding	2K_dev_1864
In this paper	mechanism	2K_dev_1864
we present the Group Context Framework ( GCF )	mechanism	2K_dev_1864
a general-purpose toolkit GCF provides a standardized The framework then intelligently groups with other devices to satisfy these requirements Through two prototypes	mechanism	2K_dev_1864
we demonstrate how GCF can be used to support a broad range of collaborative and cooperative tasks	mechanism	2K_dev_1864
We then show how our framework 's architecture allows devices to opportunistically detect and collaborate with one another	mechanism	2K_dev_1864
even when running different applications	mechanism	2K_dev_1864
Finally	method	2K_dev_1864
we present two real-world domains	method	2K_dev_1864
that allows mobile devices to opportunistically share contextual information	purpose	2K_dev_1864
way for developers to request contextual data for their applications	purpose	2K_dev_1864
	purpose	2K_dev_1864
In many scenarios involving human interaction with a remote swarm	background	2K_dev_1865
the human operator needs to be periodically updated with state information from the robotic swarm	background	2K_dev_1865
A complete representation of swarm state is high dimensional and perceptually inaccessible to the human Thus	background	2K_dev_1865
a summary representation is often required	background	2K_dev_1865
In addition	background	2K_dev_1865
it is often the case that the human-swarm communication channel is extremely bandwidth constrained and may have high latency	background	2K_dev_1865
This motivates the need for the swarm itself to compute a summary representation of its own state for transmission to the human operator	background	2K_dev_1865
The summary representation may be generated by selecting a subset of robots	background	2K_dev_1865
known as the information leaders	background	2K_dev_1865
whose own states suffice to give a bounded approximation of the entire swarm	background	2K_dev_1865
even in the presence of uncertainty	background	2K_dev_1865
	background	2K_dev_1865
and proof of convergence for the algorithms demonstrating the performance and effectiveness of the proposed algorithms	finding	2K_dev_1865
	finding	2K_dev_1865
In this paper	mechanism	2K_dev_1865
we propose two fully distributed asynchronous algorithms that only rely on inter-robot local communication	mechanism	2K_dev_1865
In particular	mechanism	2K_dev_1865
by representing noisy robot states as error ellipsoids with tunable confidence level	mechanism	2K_dev_1865
the information leaders are selected such that the Minimum-Volume Covering Ellipsoid ( MVCE ) summarizes the noisy swarm state boundary	mechanism	2K_dev_1865
	mechanism	2K_dev_1865
We provide bounded optimality analysis We present simulation results	method	2K_dev_1865
for information leader selection	purpose	2K_dev_1865
High-mobility walking robots offer unique capabilities in complex off-road environments where wheeled vehicles are not able to travel	background	2K_dev_1866
Key steps in planning a safe path for the robot autonomously include estimating the height of the support ground surface - which is often occluded by vegetation - and classifying the terrain and obstacles above the ground surface	background	2K_dev_1866
	background	2K_dev_1866
	finding	2K_dev_1866
This paper describes the development and experimental evaluation of a terrain classification and ground surface height estimation system	mechanism	2K_dev_1866
We provide experimental evaluation on an extensive	method	2K_dev_1866
manually-labeled dataset collected from geographically diverse sites over a 28-month period	method	2K_dev_1866
	method	2K_dev_1866
However	purpose	2K_dev_1866
these environments can also pose significant autonomous navigation challenges	purpose	2K_dev_1866
to support autonomous navigation for a high-mobility walking robot	purpose	2K_dev_1866
	purpose	2K_dev_1866
	background	2K_dev_1867
	finding	2K_dev_1867
We present the design	mechanism	2K_dev_1867
fabrication	mechanism	2K_dev_1867
and characterization of a fiber optically sensorized robotic hand The robotic hand has three fingers that enable both pinch and power grips	mechanism	2K_dev_1867
The main bone structure was made of a rigid plastic material and covered by soft skin Both bone and skin contain embedded fiber optics for force and tactile sensing	mechanism	2K_dev_1867
respectively	mechanism	2K_dev_1867
Eight fiber optic strain sensors were used for rigid bone force sensing	mechanism	2K_dev_1867
and six fiber optic strain sensors were used for soft skin tactile sensing	mechanism	2K_dev_1867
For characterization	mechanism	2K_dev_1867
different loads were applied in two orthogonal axes at the fingertip and the sensor signals were measured from the bone structure The skin was also characterized by applying a light load on different places for contact localization	mechanism	2K_dev_1867
The actuation of the hand was achieved by a tendon-driven under-actuated system Gripping motions are implemented using an active tendon located on the volar side of each finger and connected to a motor	mechanism	2K_dev_1867
Opening motions of the hand were enabled by passive elastic tendons located on the dorsal side of each finger	mechanism	2K_dev_1867
	mechanism	2K_dev_1867
	method	2K_dev_1867
for multi purpose manipulation tasks	purpose	2K_dev_1867
	background	2K_dev_1868
Our key insight is we can formalize the selection problem as the `` best arm { '' } variant of the multi-armed bandit problem	finding	2K_dev_1868
We show that the successive rejects algorithm identifies the best candidate using fewer rollouts than a baseline algorithm in simulation	finding	2K_dev_1868
We also show that selecting a good candidate increases the likelihood of successful execution on a real robot	finding	2K_dev_1868
	finding	2K_dev_1868
We present an algorithm We frame this as a selection problem where the goal is to choose the most robust trajectory from a finite set of candidates	mechanism	2K_dev_1868
We generate each candidate using a kinodynamic state space planner and evaluate it using noisy rollouts	mechanism	2K_dev_1868
We use the successive rejects algorithm to efficiently allocate rollouts between candidate trajectories given a rollout budget	mechanism	2K_dev_1868
	mechanism	2K_dev_1868
	method	2K_dev_1868
for generating open-loop trajectories that solve the problem of rearrangement planning under uncertainty	purpose	2K_dev_1868
	purpose	2K_dev_1868
Because Simple Hand gives limited space for links	background	2K_dev_1869
current iteration of links is not obviously nonlinear	background	2K_dev_1869
	background	2K_dev_1869
	finding	2K_dev_1869
This paper presents a novel nonlinear compliant link It has two major properties : bi-directionality and stiffening compliance	mechanism	2K_dev_1869
Bi-directionality means it can be stretched and compressed	mechanism	2K_dev_1869
and is realized by antagonistic arrangement of an extension spring and a compression spring	mechanism	2K_dev_1869
Stiffening compliance means it becomes stiffer as it is stretched	mechanism	2K_dev_1869
and is realized by asymmetric geometry	mechanism	2K_dev_1869
The links are parts of Simple Hand	mechanism	2K_dev_1869
	mechanism	2K_dev_1869
	method	2K_dev_1869
However	purpose	2K_dev_1869
nonlinearity should be more obvious if links are designed for larger grippers	purpose	2K_dev_1869
	purpose	2K_dev_1869
A key challenge of developing robots that work closely with people is creating a user interface that allows a user to communicate complex instructions to a robot quickly and easily	background	2K_dev_1870
	background	2K_dev_1870
to show that the proposed system is able to detect and track a leader through unconstrained and cluttered off-road environments under a wide variety of illumination and motion conditions	finding	2K_dev_1870
	finding	2K_dev_1870
This paper presents a marker tracking system that uses near infrared cameras	mechanism	2K_dev_1870
retro-reflective markers	mechanism	2K_dev_1870
and LIDAR	mechanism	2K_dev_1870
In this application the robot is carrying equipment and supplies for a group of pedestrians	method	2K_dev_1870
and the primary task for the user interface is to keep the robot traveling with the overall group in the right formation	method	2K_dev_1870
We provide an extensive quantitative evaluation	method	2K_dev_1870
We consider a walking logistics support robot	purpose	2K_dev_1870
which is designed to carry heavy loads to locations that are too difficult to reach with a wheeled or tracked vehicle to allow a particular user to designate himself as the robot 's leader	purpose	2K_dev_1870
and guide the robot along a desired path	purpose	2K_dev_1870
	purpose	2K_dev_1870
Exploration of unknown environments is an important aspect to fielding teams of robots Without the ability to determine on their own where to go in the environment	background	2K_dev_1871
the full potential of robotic teams is limited to the abilities of human operators to deploy them for search and rescue	background	2K_dev_1871
mapping	background	2K_dev_1871
or other tasks that are predicated on gaining knowledge from the environment	background	2K_dev_1871
This is of particular importance in real-world 3-Dimensional ( 3-D ) environments where simple planar assumptions can lead to incomplete exploration	background	2K_dev_1871
for example	background	2K_dev_1871
real-world environments have areas underneath overhangs or inside caves	background	2K_dev_1871
	background	2K_dev_1871
demonstrate its applicability	finding	2K_dev_1871
In this paper	mechanism	2K_dev_1871
we present a combined air-ground system We first describe the hardware and software components of the system We then present our algorithm for planning 3-D goal locations for a heterogeneous team of robots to efficiently explore a previously unknown environment and	mechanism	2K_dev_1871
in real-world experiments	method	2K_dev_1871
	method	2K_dev_1871
As an additional challenge	purpose	2K_dev_1871
when the teams of robots have vastly different capabilities	purpose	2K_dev_1871
the planning system must take those into account to efficiently utilize the available assets	purpose	2K_dev_1871
for conducting 3-D exploration in cluttered environments	purpose	2K_dev_1871
	purpose	2K_dev_1871
Navigating in a previously unknown environment and recognizing naturally occurring text in a scene are two important autonomous capabilities that are typically treated as distinct	background	2K_dev_1872
	background	2K_dev_1872
We show that we are able to improve SLAM illustrating how location priors enable improved loop closure with text features	finding	2K_dev_1872
In this work	mechanism	2K_dev_1872
we propose a novel high-level feature descriptor	mechanism	2K_dev_1872
the `` junction { '' }	mechanism	2K_dev_1872
which is particularly well-suited to and is also	mechanism	2K_dev_1872
through text spotting on datasets collected with a Google Tango	method	2K_dev_1872
However	purpose	2K_dev_1872
these two tasks are potentially complementary	purpose	2K_dev_1872
( i ) scene and pose priors can benefit text spotting	purpose	2K_dev_1872
and ( ii ) the ability to identify and associate text features can benefit navigation accuracy through loop closures	purpose	2K_dev_1872
Previous approaches to autonomous text spotting typically require significant training data and are too slow for real-time implementation	purpose	2K_dev_1872
text representation fast to compute	purpose	2K_dev_1872
	purpose	2K_dev_1872
Robot perception is generally viewed as the interpretation of data from various types of sensors such as cameras suggesting further investigation on the use of non-visual perception in human-robot team operations	background	2K_dev_1873
	background	2K_dev_1873
Experimental results achieve an F-measure of over 0	finding	2K_dev_1873
9 on average	finding	2K_dev_1873
	finding	2K_dev_1873
We use a special type of the Noisy-OR model known as BN2O model of Bayesian inference network	mechanism	2K_dev_1873
As a proof-of-concept study	method	2K_dev_1873
we specifically focus on a door detection problem in a stealth mission setting where a team operation must not be exposed to the visibility of the team 's opponents	method	2K_dev_1873
on both synthetic data and real person tracking data	method	2K_dev_1873
In this paper	purpose	2K_dev_1873
we study indirect perception where a robot can perceive new information by making inferences from non-visual observations of human teammates	purpose	2K_dev_1873
to represent the inter-visibility and to infer the locations of the doors	purpose	2K_dev_1873
i	purpose	2K_dev_1873
e	purpose	2K_dev_1873
	purpose	2K_dev_1873
potential locations of the opponents	purpose	2K_dev_1873
	purpose	2K_dev_1873
	background	2K_dev_1874
The final version of this machine studied here bounds up a ledge 1	finding	2K_dev_1874
5 times its hip height and crosses a gap 2 times its body length	finding	2K_dev_1874
exceeding in this last regard the mark set by the far more mature RHex hexapod	finding	2K_dev_1874
include a non-existence proof of a useful class of leaps for a stripped-down initial version of the new machine	finding	2K_dev_1874
setting in motion the sequence of improvements leading to the final resulting performance include a growing understanding of the Ground Reaction Complex as an effective abstraction for classifying and generating transitional contact behaviors in robotics	finding	2K_dev_1874
	finding	2K_dev_1874
	mechanism	2K_dev_1874
Using a combination of formal reasoning and physical intuition	method	2K_dev_1874
we analyze and test successively more capable leaping behaviors through successively more complicated body mechanics	method	2K_dev_1874
Theoretical contributions Conceptual contributions	method	2K_dev_1874
This paper explores the design space of simple legged robots capable of leaping culminating in new behaviors for the Penn Jerboa	purpose	2K_dev_1874
an underactuated	purpose	2K_dev_1874
dynamically dexterous robot	purpose	2K_dev_1874
	purpose	2K_dev_1874
Robotic swarms are distributed systems whose members interact via local control laws to achieve a variety of behaviors	background	2K_dev_1875
such as flocking	background	2K_dev_1875
In many practical applications	background	2K_dev_1875
human operators may need to change the current behavior of a swarm from the goal that the swarm was going towards into a new goal due to dynamic changes in mission objectives	background	2K_dev_1875
There are two related but distinct capabilities needed to supervise a robotic swarm The first is comprehension of the swarm 's state and the second is prediction of the effects of human inputs on the swarm 's behavior	background	2K_dev_1875
Both of them are very challenging	background	2K_dev_1875
Prior work in the literature has shown that inserting the human input as soon as possible to divert the swarm from its original goal towards the new goal does not always result in optimal performance ( measured by some criterion such as the total time required by the swarm to reach the second goal )	background	2K_dev_1875
This phenomenon has been called Neglect Benevolence	background	2K_dev_1875
conveying the idea that in many cases it is preferable to neglect the swarm for some time before inserting human input	background	2K_dev_1875
	background	2K_dev_1875
Our results show that humans can learn to approximate optimal timing and that displays which make consensus variables perceptually accessible can enhance performance	finding	2K_dev_1875
	finding	2K_dev_1875
We developed the swarm configuration shape-changing Neglect Benevolence Task as a Human Swarm Interaction ( HSI ) reference task	mechanism	2K_dev_1875
	method	2K_dev_1875
In this paper	purpose	2K_dev_1875
we study how humans can develop an understanding of swarm dynamics so they can predict the effects of the timing of their input on the state and performance of the swarm allowing comparison between human and optimal input timing performance in control of swarms	purpose	2K_dev_1875
	purpose	2K_dev_1875
In the future	background	2K_dev_1876
we envision domestic robots to play a large role in our everyday lives	background	2K_dev_1876
This requires robots able to anticipate our needs and preferences and adapt their behavior	background	2K_dev_1876
	background	2K_dev_1876
qualitative insights towards robot behavior during kitchen organization	finding	2K_dev_1876
	finding	2K_dev_1876
an open source dataset of real life kitchens	mechanism	2K_dev_1876
	mechanism	2K_dev_1876
through a home study	method	2K_dev_1876
Our analysis includes and a proof-of-concept application of this dataset	method	2K_dev_1876
Since current robotics research takes place primarily in laboratory settings	purpose	2K_dev_1876
it fails to take into account real users	purpose	2K_dev_1876
In this work	purpose	2K_dev_1876
we explore how organization occurs in the kitchen to the problem of object return	purpose	2K_dev_1876
	purpose	2K_dev_1876
	background	2K_dev_1877
We demonstrate that our design works in practice	finding	2K_dev_1877
We develop a new paradigm By focusing on avoiding redundant computation we achieve a reduction of one to two orders of magnitude reduction in design area utilization as compared to previous implementations	mechanism	2K_dev_1877
	mechanism	2K_dev_1877
by building five 325 frames per second	method	2K_dev_1877
high resolution Harris corner detection cores onto a single FPGA	method	2K_dev_1877
	method	2K_dev_1877
for designing fully streaming	purpose	2K_dev_1877
area-efficient FPGA implementations of common building blocks for vision algorithm	purpose	2K_dev_1877
	purpose	2K_dev_1877
Experience Graphs have been shown to accelerate motion planning using parts of previous paths in an A { * } framework	background	2K_dev_1878
Experience Graphs work by computing a new heuristic for weighted A { * } search on top of the domain 's original heuristic and the edges in an Experience Graph	background	2K_dev_1878
The new heuristic biases the search toward relevant prior experience and uses the original heuristic for guidance otherwise	background	2K_dev_1878
In previous work	background	2K_dev_1878
Experience Graphs were always built on top of domain heuristics which were computed by dynamic programming ( a lower dimensional version of the original planning problem )	background	2K_dev_1878
When the original heuristic is computed this way the Experience Graph heuristic can be computed very efficiently However	background	2K_dev_1878
there are many commonly used heuristics in planning that are not computed in this fashion	background	2K_dev_1878
such as euclidean distance	background	2K_dev_1878
	background	2K_dev_1878
we show an average 8 times reduction in heuristic computation time	finding	2K_dev_1878
resulting in overall planning time being reduced by 66\ %	finding	2K_dev_1878
with no change in the expanded states or resulting path	finding	2K_dev_1878
by making use of popular nearest neighbor algorithms	mechanism	2K_dev_1878
	mechanism	2K_dev_1878
Experimentally	method	2K_dev_1878
While the Experience Graph heuristic can be computed using these heuristics	purpose	2K_dev_1878
it is not efficient	purpose	2K_dev_1878
and in many cases the heuristic computation takes much of the planning time	purpose	2K_dev_1878
In this work	purpose	2K_dev_1878
we present a more efficient way to use these heuristics for motion planning problems	purpose	2K_dev_1878
Many robot applications involve lifelong planning in relatively static environments e	background	2K_dev_1879
g	background	2K_dev_1879
assembling objects or sorting mail in an office building In these types of scenarios	background	2K_dev_1879
the robot performs many tasks over a long period of time	background	2K_dev_1879
Thus	background	2K_dev_1879
the time required for computing a motion plan becomes a significant concern	background	2K_dev_1879
prompting the need for a fast and efficient motion planner	background	2K_dev_1879
Since these environments remain similar in between planning requests	background	2K_dev_1879
planning from scratch is wasteful	background	2K_dev_1879
	background	2K_dev_1879
We show the improvements with our method	finding	2K_dev_1879
This work describes a method given changes in the environment by lazily evaluating the validity of past experiences during the planning process	mechanism	2K_dev_1879
	mechanism	2K_dev_1879
in a single-arm manipulation domain with simulations on the PR2 robot	method	2K_dev_1879
	method	2K_dev_1879
Recently	purpose	2K_dev_1879
Experience Graphs ( E-Graphs ) were proposed to accelerate the planning process by reusing parts of previously computed paths to solve new motion planning queries more efficiently	purpose	2K_dev_1879
to improve planning times with E-Graphs	purpose	2K_dev_1879
	background	2K_dev_1880
The results produced by our algorithm	finding	2K_dev_1880
In this paper	mechanism	2K_dev_1880
we present an algorithm Here	mechanism	2K_dev_1880
we seek to compute a schedule that will allow a fleet of agents to visit all targets of a given set while maximizing the frequency of visitation and maintaining a sufficient fuel capacity by refueling at depots	mechanism	2K_dev_1880
We also present a heuristic method to allow us to compute bounded suboptimal results in real time will allow a team of robots to efficiently cover a given set of targets or tasks persistently over long periods of time	mechanism	2K_dev_1880
even when the cost to transition between tasks is dynamic	mechanism	2K_dev_1880
	mechanism	2K_dev_1880
	method	2K_dev_1880
to solve the Multi-Robot Persistent Coverage Problem ( MRPCP )	purpose	2K_dev_1880
	purpose	2K_dev_1880
	background	2K_dev_1881
	finding	2K_dev_1881
our approach produces 3D models that are more structurally representative of the environment being surveyed	finding	2K_dev_1881
We show that the method produces reasonably accurate surface reconstruction and blending consistency	finding	2K_dev_1881
with and without the use of a prior mesh	finding	2K_dev_1881
	finding	2K_dev_1881
The pipeline projects and blends 21 ) imaging sonar data onto a large-scale 3D mesh that is either given a priori or derived from SLAM	mechanism	2K_dev_1881
Additionally	mechanism	2K_dev_1881
our system leverages recent work in underwater SLAM using sparse point clouds derived from Doppler velocity log range returns	mechanism	2K_dev_1881
using data collected from an autonomous underwater vehicle performing simultaneous localization and mapping ( SLAM ) Compared to other methods that generate a 2D-only mosaic We experimentally evaluate our approach with a Hovering Autonomous Underwater Vehicle ( HAUV ) performing inspection of a large underwater ship hull	method	2K_dev_1881
	method	2K_dev_1881
This paper reports on a 3D photomosaicing pipeline to relax the need for a prior model	purpose	2K_dev_1881
	purpose	2K_dev_1881
Wearable cameras provide a first-person perspective which enables continuous visual hand grasp analysis of everyday activities	background	2K_dev_1882
In contrast to previous work focused on manual analysis of first-person videos of hand grasps	background	2K_dev_1882
The average F1 score of our grasp classifiers achieves over 0	finding	2K_dev_1882
8 for the indoor grasp dataset shows that it is possible to automatically learn intuitive visual grasp structures that are consistent with expert-designed grasp taxonomies	finding	2K_dev_1882
	finding	2K_dev_1882
	mechanism	2K_dev_1882
we propose a fully automatic vision-based approach for grasp analysis A set of grasp classifiers are trained for discriminating between different grasp types based on large margin visual predictors Building on the output of these grasp classifiers	mechanism	2K_dev_1882
visual structures among hand grasps are learned based on an iterative discriminative clustering procedure	mechanism	2K_dev_1882
	mechanism	2K_dev_1882
We first evaluated our classifiers on a controlled indoor grasp dataset and then validated the analytic power of our approach on real-world data taken from a machinist Analysis of real-world video	method	2K_dev_1882
Our goal is to automatically recognize hand grasps and to discover the visual structures ( relationships ) between hand grasps using wearable cameras	purpose	2K_dev_1882
Assembly of large structures requires large fixtures	background	2K_dev_1883
often referred to as monuments Their cost and massive size limit flexibility and scalability of the manufacturing process	background	2K_dev_1883
Numerous small mobile robots can replace these large structures and	background	2K_dev_1883
therefore	background	2K_dev_1883
replicate the efficiency of the assembly line with far more flexibility	background	2K_dev_1883
An assembly line made up of mobile manipulators can easily and rapidly be reconfigured to support scalability and a varied product mix	background	2K_dev_1883
while allowing for near optimal resource assignment	background	2K_dev_1883
demonstrate these techniques	finding	2K_dev_1883
In this paper	mechanism	2K_dev_1883
we describe a set of techniques that we combine We describe and	mechanism	2K_dev_1883
in the context of a testbed we implemented for assembling a wing ladder	method	2K_dev_1883
The challenge to using small robots in place of monuments is making their joint behavior precise enough to accomplish the task and efficient enough to execute subtasks in a reasonable period of time	purpose	2K_dev_1883
to achieve the necessary precision and overall efficiency to build a large structure	purpose	2K_dev_1883
	purpose	2K_dev_1883
is mapping each noun in the command into a physical object in the environment	background	2K_dev_1884
	background	2K_dev_1884
Our experiments clearly show that the proposed approach is efficient for commanding outdoor robots	finding	2K_dev_1884
	finding	2K_dev_1884
We propose a language-driven navigation approach We consider unknown environments that contain previously unseen objects The proposed approach Robots receive from human teammates commands in natural language	mechanism	2K_dev_1884
such as `` Navigate around the building to the car left of the fire hydrant and near the tree { '' }	mechanism	2K_dev_1884
A robot needs first to classify its surrounding objects into categories	mechanism	2K_dev_1884
using images obtained from its sensors	mechanism	2K_dev_1884
The result of this classification is a map of the environment	mechanism	2K_dev_1884
where each object is given a list of semantic labels	mechanism	2K_dev_1884
such as `` tree { '' } and `` car { '' }	mechanism	2K_dev_1884
with varying degrees of confidence	mechanism	2K_dev_1884
Then	mechanism	2K_dev_1884
the robot needs to ground the nouns in the command We use a probabilistic model	mechanism	2K_dev_1884
such as `` left of { '' } and `` near { '' } The model is learned from examples provided by humans	mechanism	2K_dev_1884
For each noun in the command	mechanism	2K_dev_1884
a distribution on the objects in the environment is computed by combining spatial constraints with a prior given as the semantic classifier 's confidence values The robot needs also to ground the navigation mode specified in the command	mechanism	2K_dev_1884
such as `` navigate quickly { '' } and `` navigate covertly { '' }	mechanism	2K_dev_1884
as a cost map	mechanism	2K_dev_1884
The cost map is also learned from examples	mechanism	2K_dev_1884
using Inverse Optimal Control ( IOC )	mechanism	2K_dev_1884
The cost map and the grounded goal are used to generate a path for the robot	mechanism	2K_dev_1884
	mechanism	2K_dev_1884
This approach is evaluated on a robot in a real-world environment	method	2K_dev_1884
	method	2K_dev_1884
for commanding mobile robots in outdoor environments	purpose	2K_dev_1884
aims at making interactions in human-robot teams natural	purpose	2K_dev_1884
Grounding	purpose	2K_dev_1884
the main focus of this paper for interpreting the spatial relations	purpose	2K_dev_1884
	background	2K_dev_1885
The method shows improvements in performance over the state of the art	finding	2K_dev_1885
particularly in robustness to aggressive motion and temporary lack of visual features We show results Our proposed method is ranked \ # 1 on the benchmark in terms of average translation and rotation errors	finding	2K_dev_1885
with a 0	finding	2K_dev_1885
75\ % of relative position drift	finding	2K_dev_1885
Here	mechanism	2K_dev_1885
we present a general framework in a fundamental and first principle method The proposed on-line method starts with visual odometry to estimate the ego-motion and to register point clouds from a scanning lidar at a high frequency but low fidelity	mechanism	2K_dev_1885
Then	mechanism	2K_dev_1885
scan matching based lidar odometry refines the motion estimation and point cloud registration simultaneously	mechanism	2K_dev_1885
	mechanism	2K_dev_1885
with datasets collected in our own experiments as well as using the KITTI odometry benchmark In addition to comparison of the motion estimation accuracy	method	2K_dev_1885
we evaluate robustness of the method when the sensor suite moves at a high speed and is subject to significant ambient lighting changes	method	2K_dev_1885
	method	2K_dev_1885
for combining visual odometry and lidar odometry	purpose	2K_dev_1885
	background	2K_dev_1886
show that this can significantly improve the robot 's ability to accurately generalize the demonstration	finding	2K_dev_1886
	finding	2K_dev_1886
We formalize as an optimization problem over a Hilbert space of trajectories : minimize the distance between the demonstration and the new trajectory subject to the new end point constraints	mechanism	2K_dev_1886
We show that the commonly used version of Dynamic Movement Primitives ( DMPs ) implement this minimization in the way they adapt demonstrations	mechanism	2K_dev_1886
for a particular choice of the Hilbert space norm	mechanism	2K_dev_1886
The generalization to arbitrary norms	mechanism	2K_dev_1886
Our experiments	method	2K_dev_1886
the problem of adapting a demonstrated trajectory to a new start and goal configuration enables the robot to select a more appropriate norm for the task	purpose	2K_dev_1886
as well as learn how to adapt the demonstration from the user	purpose	2K_dev_1886
	purpose	2K_dev_1886
Many motion planning problems in robotics are high dimensional planning problems	background	2K_dev_1887
While sampling-based motion planning algorithms handle the high dimensionality very well	background	2K_dev_1887
the solution qualities are often hard to control due to the inherent randomization	background	2K_dev_1887
In addition	background	2K_dev_1887
they suffer severely when the configuration space has several `narrow passages '	background	2K_dev_1887
Search-based planners on the other hand typically provide good solution qualities and are not affected by narrow passages	background	2K_dev_1887
However	background	2K_dev_1887
in the absence of a good heuristic or when there are deep local minima in the heuristic	background	2K_dev_1887
they suffer from the curse of dimensionality	background	2K_dev_1887
and show its benefits over these approaches	finding	2K_dev_1887
	finding	2K_dev_1887
In this work	mechanism	2K_dev_1887
our primary contribution is a method in addition to the original heuristic ( s ) used	mechanism	2K_dev_1887
With the ability to escape local minima easily	mechanism	2K_dev_1887
the effect of dimensionality becomes less pronounced	mechanism	2K_dev_1887
	mechanism	2K_dev_1887
We compare our proposed method with the recently published Multi-Heuristic A { * } search	method	2K_dev_1887
and the popular RRT-Connect in a full-body mobile manipulation domain for the PR2 robot	method	2K_dev_1887
	method	2K_dev_1887
for dynamically generating heuristics to guide the search out of local minima	purpose	2K_dev_1887
On the theoretical side	purpose	2K_dev_1887
we provide guarantees on completeness and bounds on suboptimality of the solution found	purpose	2K_dev_1887
	purpose	2K_dev_1887
Autonomous systems that navigate in unknown environments encounter a variety of planning problems	background	2K_dev_1888
This work opens the door on the more general problem of adaptive motion planning	background	2K_dev_1888
	background	2K_dev_1888
We present results where the selected ensemble outperforms the best single planner and does almost as well as an off-line planner We also present results that has flown missions several kilometers long at speeds of up to 56 ( m ) /s which involved avoiding unmapped mountains	finding	2K_dev_1888
no-fly zones and landing in cluttered areas with trees and buildings	finding	2K_dev_1888
	finding	2K_dev_1888
We have developed a planning system that does this by running competing planners in parallel	mechanism	2K_dev_1888
In this paper	mechanism	2K_dev_1888
we present an approach that constructs a planner ensemble - a set of complementary planners that leverage a diverse set of assumptions	mechanism	2K_dev_1888
Our approach optimizes the submodular selection criteria with a greedy approach and lazy evaluation	mechanism	2K_dev_1888
We seed our selection with learnt priors on planner performance	mechanism	2K_dev_1888
thus allowing us to solve new applications without evaluating every planner on that application	mechanism	2K_dev_1888
	mechanism	2K_dev_1888
in simulation from an autonomous helicopter	method	2K_dev_1888
The success of any one particular planning strategy depends on the validity of assumptions it leverages about the structure of the problem	purpose	2K_dev_1888
e	purpose	2K_dev_1888
g	purpose	2K_dev_1888
	purpose	2K_dev_1888
Is the cost map locally convex ? Does the feasible state space have good connectivity ? We address the problem of determining suitable motion planning strategies that can work on a diverse set of applications	purpose	2K_dev_1888
	purpose	2K_dev_1888
	background	2K_dev_1889
We demonstrate the ability to solve more rearrangement by pushing tasks than existing primitive based solutions	finding	2K_dev_1889
Finally	finding	2K_dev_1889
we show the plans we generate are feasible for execution on a real robot	finding	2K_dev_1889
	finding	2K_dev_1889
We present a randomized kinodynamic planner We embed a physics model into the planner to allow reasoning about interaction with objects in the environment By carefully selecting this model	mechanism	2K_dev_1889
we are able to reduce our state and action space	mechanism	2K_dev_1889
gaining tractability in the search The result is a planner capable of generating trajectories for full arm manipulation and simultaneous object interaction	mechanism	2K_dev_1889
	method	2K_dev_1889
that solves rearrangement planning problems	purpose	2K_dev_1889
	purpose	2K_dev_1889
	background	2K_dev_1890
and show that on a variety of environments we can achieve a higher planning success rate given a restricted time budget for planning	finding	2K_dev_1890
	finding	2K_dev_1890
In this work we present a fast kinodynamic RRT-planner that uses dynamic nonprehensile actions In contrast to many previous works	mechanism	2K_dev_1890
the presented planner is not restricted to quasi-static interactions and monotonicity	mechanism	2K_dev_1890
Instead the results of dynamic robot actions are predicted using a black box physics model	mechanism	2K_dev_1890
Given a general set of primitive actions and a physics model	mechanism	2K_dev_1890
the planner randomly explores the configuration space of the environment to find a sequence of actions that transform the environment into some goal configuration	mechanism	2K_dev_1890
In contrast to a naive kinodynamic RRT-planner we show that we can exploit the physical fact that in an environment with friction any object eventually comes to rest	mechanism	2K_dev_1890
This allows a search on the configuration space rather than the state space	mechanism	2K_dev_1890
reducing the dimension of the search space by a factor of two without restricting us to non-dynamic interactions	mechanism	2K_dev_1890
	mechanism	2K_dev_1890
We compare our algorithm against a naive kinodynamic RRT-planner	method	2K_dev_1890
to rearrange cluttered environments	purpose	2K_dev_1890
Modeling the effects of actions based on the state of the world enables robots to make intelligent decisions in different situations	background	2K_dev_1891
However	background	2K_dev_1891
it is often infeasible to have globally accurate models	background	2K_dev_1891
Task performance is often hindered by discrepancies between models and the real world	background	2K_dev_1891
since the 1 outcome of executing a plan may be significantly worse than the expected outcome used during planning	background	2K_dev_1891
Furthermore	background	2K_dev_1891
expectations about the world are often stochastic in robotics	background	2K_dev_1891
making the discovery of model-world discrepancies non-trivial	background	2K_dev_1891
	background	2K_dev_1891
	finding	2K_dev_1891
We present an execution monitoring framework In our approach	mechanism	2K_dev_1891
plans are initially based on a model of the world that is only as faithful as computational and algorithmic limitations allow Through experience	mechanism	2K_dev_1891
the monitor discovers previously unmodeled modes of the world	mechanism	2K_dev_1891
defined as regions of a feature space in which the experienced outcome of a plan deviates significantly from the predicted outcome	mechanism	2K_dev_1891
The monitor may then make suggestions to change the model to match the real world more accurately	mechanism	2K_dev_1891
	mechanism	2K_dev_1891
We demonstrate this approach on the adversarial domain of robot soccer : we monitor pass interception performance of potentially unknown opponents to try to find unforeseen modes of behavior that affect their interception performance	method	2K_dev_1891
	method	2K_dev_1891
capable of finding statistically significant discrepancies	purpose	2K_dev_1891
determining the situations in which they occur	purpose	2K_dev_1891
and making simple corrections to the world model to improve performance	purpose	2K_dev_1891
	purpose	2K_dev_1891
	background	2K_dev_1892
We demonstrate the advantages of our algorithm Our results show that spare work surfaces are beneficial to assembly	finding	2K_dev_1892
Tilted work surfaces are only sometimes beneficial	finding	2K_dev_1892
depending on the objects	finding	2K_dev_1892
	finding	2K_dev_1892
The goal of this paper is to develop a regrasp planning algorithm general enough We focus on pick-and-place regrasp which reorients an object from one placement to another by using a sequence of pickups and place-downs	mechanism	2K_dev_1892
We improve the pick-and-place regrasp approach developed in 1990s and analyze its performance in robotic assembly with different work surfaces in the workcell Our algorithm will automatically compute the stable placements of an object	mechanism	2K_dev_1892
find several force-closure grasps	mechanism	2K_dev_1892
generate a graph of regrasp actions	mechanism	2K_dev_1892
and search for regrasp sequences	mechanism	2K_dev_1892
	mechanism	2K_dev_1892
with various mesh models and use the algorithm to evaluate the completeness	method	2K_dev_1892
the cost and the length of regrasp sequences with different mesh models and different assembly tasks in the presence of different work surfaces	method	2K_dev_1892
	method	2K_dev_1892
to perform statistical analysis with thousands of experiments and arbitrary mesh models	purpose	2K_dev_1892
	purpose	2K_dev_1892
Simultaneous localization and mapping with infinite planes is attractive because of the reduced complexity with respect to both sparse point-based and dense volumetric methods	background	2K_dev_1893
to show its advantages over alternative solutions results	finding	2K_dev_1893
using a homogeneous plane parametrization with a corresponding minimal representation for the optimization	mechanism	2K_dev_1893
Because it is a minimal representation	mechanism	2K_dev_1893
it is suitable for use with Gauss-Newton	mechanism	2K_dev_1893
Powell 's Dog Leg and incremental solvers such as iSAM	mechanism	2K_dev_1893
We also introduce a relative plane formulation We also introduce a simple mapping system and present	mechanism	2K_dev_1893
We evaluate our proposed approach on simulated data experimental	method	2K_dev_1893
showing real-time mapping of select indoor environments with a hand-held RGBD sensor	method	2K_dev_1893
We show how to include infinite planes into a least-squares formulation for mapping that improves convergence	purpose	2K_dev_1893
	background	2K_dev_1894
demonstrates applications	finding	2K_dev_1894
We develop a computationally efficient control policy for active perception that incorporates explicit models of sensing and mobility Like previous work	mechanism	2K_dev_1894
our policy maximizes an information-theoretic objective function between the discrete occupancy belief distribution ( e	mechanism	2K_dev_1894
g	mechanism	2K_dev_1894
	mechanism	2K_dev_1894
voxel grid ) and future measurements that can be made by mobile sensors	mechanism	2K_dev_1894
However	mechanism	2K_dev_1894
our work is unique in three ways	mechanism	2K_dev_1894
First	mechanism	2K_dev_1894
we show that by using Cauchy-Schwarz Quadratic Mutual Information ( CSQMI )	mechanism	2K_dev_1894
we get significant gains in efficiency	mechanism	2K_dev_1894
Second	mechanism	2K_dev_1894
while most previous methods adopt a myopic	mechanism	2K_dev_1894
gradient-following approach that yields poor convergence properties	mechanism	2K_dev_1894
our algorithm searches over a set of paths and is less susceptible to local minima	mechanism	2K_dev_1894
In doing so	mechanism	2K_dev_1894
we explicitly incorporate models of sensors	mechanism	2K_dev_1894
and model the dependence ( and independence ) of measurements over multiple time steps in a path	mechanism	2K_dev_1894
Third	mechanism	2K_dev_1894
because we consider models of sensing and mobility	mechanism	2K_dev_1894
our method naturally applies to both ground and aerial vehicles	mechanism	2K_dev_1894
	mechanism	2K_dev_1894
via simulation and experimentation	method	2K_dev_1894
to build 3D maps with ground and aerial robots The paper describes the basic models	purpose	2K_dev_1894
the problem formulation and the algorithm	purpose	2K_dev_1894
and	purpose	2K_dev_1894
With the prevalence of social media	background	2K_dev_1895
such as Twitter	background	2K_dev_1895
short-length text like microblogs have become an important mode of text on the Internet	background	2K_dev_1895
In contrast to other forms of media	background	2K_dev_1895
such as newspaper	background	2K_dev_1895
the text in these social media posts usually contains fewer words	background	2K_dev_1895
and is concentrated on a much narrower selection of topics	background	2K_dev_1895
For these reasons	background	2K_dev_1895
traditional LDA-based sentiment and topic modeling techniques generally do not work well in case of social media data	background	2K_dev_1895
Another characteristic feature of this data is the use of special meta tokens	background	2K_dev_1895
such as hashtags	background	2K_dev_1895
which contain unique semantic meanings that are not captured by other ordinary words	background	2K_dev_1895
	finding	2K_dev_1895
In this paper	mechanism	2K_dev_1895
we propose probabilistic graphical models We first propose MTM ( Microblog Topic Model )	mechanism	2K_dev_1895
a generative model that assumes each social media post generates from a single topic	mechanism	2K_dev_1895
and models both words and hashtags separately	mechanism	2K_dev_1895
We then propose MSTM ( Microblog Sentiment Topic Model )	mechanism	2K_dev_1895
an extension of MTM	mechanism	2K_dev_1895
which also embodies the sentiment associated with the topics	mechanism	2K_dev_1895
	mechanism	2K_dev_1895
We evaluated our models using Twitter dataset	method	2K_dev_1895
and experimental	method	2K_dev_1895
In the recent years	purpose	2K_dev_1895
many topic modeling techniques have been proposed for social media data	purpose	2K_dev_1895
but the majority of this work does not take into account the specialty of tokens	purpose	2K_dev_1895
such as hashtags	purpose	2K_dev_1895
and treats them as ordinary words	purpose	2K_dev_1895
to address the problem of discovering latent topics and their sentiment from social media data	purpose	2K_dev_1895
mainly microblogs like Twitter	purpose	2K_dev_1895
There have been increasing interests in the robotics community in building smaller and more agile autonomous micro aerial vehicles ( MAVs )	background	2K_dev_1896
	background	2K_dev_1896
	finding	2K_dev_1896
In this paper	mechanism	2K_dev_1896
we present a tightly-coupled nonlinear optimization-based monocular VINS estimator for autonomous rotorcraft MAVs	mechanism	2K_dev_1896
Our estimator allows the MAV to execute trajectories at 2 m/s with roll and pitch angles up to 30 degrees	mechanism	2K_dev_1896
	mechanism	2K_dev_1896
We present extensive statistical analysis to verify the performance of our approach in different environments with varying flight speeds	method	2K_dev_1896
	method	2K_dev_1896
In particular	purpose	2K_dev_1896
the monocular visual-inertial system ( VINS ) that consists of only a camera and an inertial measurement unit ( IMU ) forms a great minimum sensor suite due to its superior size	purpose	2K_dev_1896
weight	purpose	2K_dev_1896
and power ( SWaP ) characteristics	purpose	2K_dev_1896
	purpose	2K_dev_1896
Learning from demonstration ( LfD ) is a common technique applied to many problems in robotics	background	2K_dev_1897
such as populating grasp databases	background	2K_dev_1897
training for reinforcement learning of high-level skill sets and bootstrapping motion planners	background	2K_dev_1897
The data set collected has been made available to the robotics community	background	2K_dev_1897
to teach a robot how to grasp	finding	2K_dev_1897
to teach a robot how to perform dexterous manipulation tasks such as scooping and to accelerate motion planning for full-body manipulation tasks	finding	2K_dev_1897
	finding	2K_dev_1897
In this paper	mechanism	2K_dev_1897
we present a tool capable of recording large numbers of high-dimensional demonstrations of mobile manipulation tasks provided by non-experts in the field	mechanism	2K_dev_1897
Our tool accomplishes this via a web interface that requires no additional software to be installed beyond a web browser	mechanism	2K_dev_1897
as well as a scalable architecture that is capable of supporting 10 concurrent demonstrators on a single server	mechanism	2K_dev_1897
Our architecture employs a lightweight simulation environment to reduce unnecessary computations and improve performance	mechanism	2K_dev_1897
	mechanism	2K_dev_1897
We also present experiments in which we apply demonstrations collected through our infrastructure	method	2K_dev_1897
While such approaches are generally highly valued	purpose	2K_dev_1897
they rely on the often time-consuming process of gathering user demonstrations	purpose	2K_dev_1897
and hence it becomes difficult to attain a sizeable dataset	purpose	2K_dev_1897
Furthermore	purpose	2K_dev_1897
we show how our tool can be used to gather a large set of demonstrations of a mobile manipulation task by leveraging existing crowdsource platforms	purpose	2K_dev_1897
	purpose	2K_dev_1897
	background	2K_dev_1898
that our method can efficiently build maps of large indoor and outdoor environments in a distributed	finding	2K_dev_1898
online	finding	2K_dev_1898
and real-time setting	finding	2K_dev_1898
	finding	2K_dev_1898
We present a novel Expectation Maximization ( EM ) based approach by incorporating robot pose uncertainty An EM and hypothesis based method is used to determine a common reference frame	mechanism	2K_dev_1898
We detail a 2D laser scan correspondence method to form robust correspondences between laser scans shared amongst robots	mechanism	2K_dev_1898
The implementation is experimentally validated using teams of aerial vehicles	method	2K_dev_1898
and analyzed to determine its accuracy	method	2K_dev_1898
computational efficiency	method	2K_dev_1898
scalability to many robots	method	2K_dev_1898
and robustness to varying environments	method	2K_dev_1898
We demonstrate through multiple experiments	method	2K_dev_1898
We demonstrate distributed	purpose	2K_dev_1898
online	purpose	2K_dev_1898
and real-time cooperative localization and mapping between multiple robots operating throughout an unknown environment using indirect measurements	purpose	2K_dev_1898
to efficiently identify inlier multi-robot loop closures	purpose	2K_dev_1898
which significantly improves the trajectory accuracy over long-term navigation	purpose	2K_dev_1898
	purpose	2K_dev_1898
Our work is motivated by the potential impact of realistic simulators on the development cycle of software for real robots	background	2K_dev_1899
Unlike calibration	background	2K_dev_1899
where the goal is to identify and remove error from a signal	background	2K_dev_1899
	finding	2K_dev_1899
The case is made for building models from approximate state information	mechanism	2K_dev_1899
relieving the burden of ground truth	mechanism	2K_dev_1899
Instead of physically modeling sensor behavior	mechanism	2K_dev_1899
a data-driven approach is taken	mechanism	2K_dev_1899
	mechanism	2K_dev_1899
The implementation of our approach to simulate a simple but noisy laser rangefinder is described	method	2K_dev_1899
Finally	method	2K_dev_1899
approaches to validate the simulator are discussed	method	2K_dev_1899
We compare not only raw sensor predictions	method	2K_dev_1899
but also overall performance of algorithms on simulated versus real data	method	2K_dev_1899
	method	2K_dev_1899
We study the problem of building a sensor model for the purpose of simulation our aim to reproduce the signal in its entirety	purpose	2K_dev_1899
including its error properties	purpose	2K_dev_1899
	purpose	2K_dev_1899
	background	2K_dev_1900
Our first contribution is two discoveries : ( i ) the number of comments grows as a power-law on the number of votes and ( ii ) the time between a submission creation and a user 's reaction obeys a log-logistic distribution VNC outperformed state-of-the-art baselines on accuracy	finding	2K_dev_1900
Additionally	finding	2K_dev_1900
we illustrate VNC usefulness for forecasting and outlier detection	finding	2K_dev_1900
Based on these patterns	mechanism	2K_dev_1900
we propose VNC ( VOTE-AND-COMMENT )	mechanism	2K_dev_1900
a parsimonious but accurate and scalable model that	mechanism	2K_dev_1900
We analyzed over 20000 submissions corresponding to more than 100 million user interactions from three social voting Web sites : Reddit	method	2K_dev_1900
Imgur and Digg	method	2K_dev_1900
In our experiments on real data	method	2K_dev_1900
	method	2K_dev_1900
In social voting Web sites	purpose	2K_dev_1900
how do the user actions - up-votes	purpose	2K_dev_1900
down-votes and comments - evolve over time ? Are there relationships between votes and comments ? What is normal and what is suspicious ? These are the questions we focus on	purpose	2K_dev_1900
models the coevolution of user activities	purpose	2K_dev_1900
Autonomous mobile robots are required to operate in partially known and unstructured environments	background	2K_dev_1901
It is imperative to guarantee safety of such systems for their successful deployment	background	2K_dev_1901
Current state of the art does not fully exploit the sensor and dynamic capabilities of a robot	background	2K_dev_1901
Also	background	2K_dev_1901
given the non-holonomic systems with non-linear dynamic constraints	background	2K_dev_1901
it becomes computationally infeasible to find an optimal solution if the full dynamics are to be exploited online	background	2K_dev_1901
	background	2K_dev_1901
We present results	finding	2K_dev_1901
In this paper we present an online algorithm through an emergency maneuver library	mechanism	2K_dev_1901
The maneuvers in the emergency maneuver library are optimized such that the probability of finding an emergency maneuver that lies in the known obstacle free space is maximized	mechanism	2K_dev_1901
We prove that the related trajectory set diversity problem is monotonic and submodular which enables one to develop an efficient trajectory set generation algorithm with bounded sub-optimality	mechanism	2K_dev_1901
We generate an off-line computed trajectory set that exploits the full dynamics of the robot and the known obstacle-free region	mechanism	2K_dev_1901
	mechanism	2K_dev_1901
We test and validate the algorithm on a full-size autonomous helicopter flying up to speeds of 56m/s in partially-known environments	method	2K_dev_1901
from 4 months of flight testing where the helicopter has been avoiding trees	method	2K_dev_1901
performing autonomous landing	method	2K_dev_1901
avoiding mountains while being guaranteed safe	method	2K_dev_1901
	method	2K_dev_1901
to guarantee the safety of the robot	purpose	2K_dev_1901
One example is server-side scheduling for video service	background	2K_dev_1902
where clients request flows of content from a server with limited capacity	background	2K_dev_1902
and any content not delivered by its deadline is lost State-of-the-art policies	background	2K_dev_1902
like Discriminatory Processor Sharing and Weighted Fair Queueing	background	2K_dev_1902
use a fixed static proportional allocation of service rate and fail to achieve both goals	background	2K_dev_1902
The well-known Earliest Deadline First policy minimizes overall loss	background	2K_dev_1902
but fails to provide proportional loss across flows	background	2K_dev_1902
because it treats packets as independent jobs	background	2K_dev_1902
We prove that all policies in this broad class minimize overall loss Furthermore	finding	2K_dev_1902
we demonstrate that many EPDF policies accurately differentiate loss fractions in proportion to class weights	finding	2K_dev_1902
satisfying the second goal	finding	2K_dev_1902
	finding	2K_dev_1902
This paper introduces the Earliest Progressive Deadline First ( EPDF ) class of policies	mechanism	2K_dev_1902
	mechanism	2K_dev_1902
	method	2K_dev_1902
This complements recent work of Acharya et al	background	2K_dev_1903
All of our lower bounds also easily extend to the model where CDF queries ( given x	background	2K_dev_1903
return Sigma ( y < 0 x ) p { [ } y ] ) are allowed	background	2K_dev_1903
	background	2K_dev_1903
For the usual Shannon entropy H ( p )	finding	2K_dev_1903
we show that Omega ( log ( 2 ) n/Delta ( 2 ) ) queries are necessary	finding	2K_dev_1903
matching a recent upper bound of Canonne and Rubinfeld	finding	2K_dev_1903
For the Renyi entropy Th ( p )	finding	2K_dev_1903
where a > 1	finding	2K_dev_1903
we show that Theta ( n ( 1-1/alpha ) ) queries are necessary and sufficient	finding	2K_dev_1903
in the SAMP-only model that showed Omicron ( n ( 1-1/alpha ) ) queries suffice when a is an integer	finding	2K_dev_1903
but Omega ( n ) queries are necessary when a is a non integer	finding	2K_dev_1903
	finding	2K_dev_1903
	mechanism	2K_dev_1903
Let p be an unknown probability distribution on { [ } n ] : 0 \ { 1	method	2K_dev_1903
2	method	2K_dev_1903
	method	2K_dev_1903
n\ } that we can access via two kinds of queries : A SAM P query takes no input and returns x epsilon { [ } n ] with probability p { [ } x ] ; a PMF query takes as input x E { [ } n ] and returns the value p { [ } x ]	method	2K_dev_1903
	method	2K_dev_1903
We consider the task of estimating the entropy of p to within +/- Delta ( with high probability )	purpose	2K_dev_1903
	purpose	2K_dev_1903
Theoretical and practical implications for collaboration across culture are discussed	background	2K_dev_1904
we predicted and found that overall	finding	2K_dev_1904
Chinese individuals were less helpful than Canadians	finding	2K_dev_1904
This effect was stronger for males than females Interestingly	finding	2K_dev_1904
more helping behavior was observed among Canadians with high levels of internal moral identity Yet	finding	2K_dev_1904
this effect was not observed among Chinese individuals	finding	2K_dev_1904
	mechanism	2K_dev_1904
105 participants engaged in a dyadic intracultural interaction via the FireSim computer game	method	2K_dev_1904
Each participant was assigned a village and was tasked to protect the village from seasonal fires	method	2K_dev_1904
Participants had the option of requesting or providing help to the neighboring village	method	2K_dev_1904
i	method	2K_dev_1904
e	method	2K_dev_1904
their counterpart We examined collaborative behavior by measuring help given	method	2K_dev_1904
while controlling for help request	method	2K_dev_1904
Using theories of face and dignity cultures	method	2K_dev_1904
moral identity	method	2K_dev_1904
and gender roles	method	2K_dev_1904
We examined the effects gender and moral identity on collaborative behavior among Face ( Chinese ) and Dignity ( Canadian ) cultures	purpose	2K_dev_1904
Human activity recognition is an important and challenging task for video content analysis and understanding	background	2K_dev_1905
Individual activity recognition has been well studied recently	background	2K_dev_1905
	background	2K_dev_1905
demonstrate effectiveness of the proposed method	finding	2K_dev_1905
	finding	2K_dev_1905
In this paper	mechanism	2K_dev_1905
a novel human group activity recognition method is proposed this paper proposes three types of group-activity descriptor using motion trajectory and appearance information of people	mechanism	2K_dev_1905
	mechanism	2K_dev_1905
Experimental results on a public human group activity dataset	method	2K_dev_1905
However	purpose	2K_dev_1905
recognizing the activities of human group with more than three people having complex interactions is still a formidable challenge to deal with complex situation where there are multiple sub-groups	purpose	2K_dev_1905
To characterize the inherent interactions of intra-subgroups and inter-subgroups with the varying number of participants	purpose	2K_dev_1905
In many markets	background	2K_dev_1906
products are highly complex with an extremely large set of features	background	2K_dev_1906
In advertising auctions	background	2K_dev_1906
for example	background	2K_dev_1906
an impression	background	2K_dev_1906
i	background	2K_dev_1906
e	background	2K_dev_1906
	background	2K_dev_1906
a viewer on a web page	background	2K_dev_1906
has numerous features describing the viewer 's demographics	background	2K_dev_1906
browsing history	background	2K_dev_1906
temporal aspects	background	2K_dev_1906
etc	background	2K_dev_1906
In these markets	background	2K_dev_1906
an auctioneer must select a few key features to signal to bidders	background	2K_dev_1906
	finding	2K_dev_1906
We present an efficient algorithmic in a setting where the product 's features are drawn independently from a known distribution	mechanism	2K_dev_1906
the bidders ' values for a product are additive over their known values for the features of the product	mechanism	2K_dev_1906
and the number of features is exponentially larger than the number of bidders and the number of signals	mechanism	2K_dev_1906
Our approach involves solving a novel optimization problem regarding the expectation of a sum of independent random vectors that may be of independent interest	mechanism	2K_dev_1906
We complement our positive result with a hardness result for the problem when features are arbitrarily correlated This result is based on the conjectured hardness of learning k-juntas	mechanism	2K_dev_1906
a central open problem in learning theory	mechanism	2K_dev_1906
	method	2K_dev_1906
These features should be selected such that the bidder with the highest value for the product can construct a bid so as to win the auction	purpose	2K_dev_1906
solution for this problem	purpose	2K_dev_1906
Standard approaches to reachability problems for linear hybrid systems require numerical solutions for large optimization problems	background	2K_dev_1907
and become infeasible for systems involving both nonlinear dynamics over the reals and stochasticity	background	2K_dev_1907
	background	2K_dev_1907
We demonstrate SReach 's applicability	finding	2K_dev_1907
In this paper	mechanism	2K_dev_1907
we present a new tool SReach The first one is ( nonlinear ) hybrid automata with parametric uncertainty	mechanism	2K_dev_1907
The second one is probabilistic hybrid automata with additional randomness for both transition probabilities and variable resets	mechanism	2K_dev_1907
SReach encodes stochastic information by using a set of introduced random variables	mechanism	2K_dev_1907
and combines delta-complete decision procedures and statistical tests to solve delta-reachability problems in a sound manner Compared to standard simulation-based methods	mechanism	2K_dev_1907
it supports non-deterministic branching	mechanism	2K_dev_1907
increases the coverage of simulation	mechanism	2K_dev_1907
and avoids the zero-crossing problem	mechanism	2K_dev_1907
by discussing three representative biological models and additional benchmarks for nonlinear hybrid systems with multiple probabilistic system parameters	method	2K_dev_1907
	method	2K_dev_1907
which solves probabilistic bounded reachability problems for two classes of models of stochastic hybrid systems	purpose	2K_dev_1907
	purpose	2K_dev_1907
Weighted signed networks ( WSNs ) are networks in which edges are labeled with positive and negative weights	background	2K_dev_1908
WSNs can capture like/dislike	background	2K_dev_1908
trust/distrust	background	2K_dev_1908
and other social relationships between people	background	2K_dev_1908
	background	2K_dev_1908
Furthermore	finding	2K_dev_1908
we show	finding	2K_dev_1908
our fairness and goodness metrics almost always have the best predictive power and show that we can predict edge weights on 2 Bitcoin WSNs	finding	2K_dev_1908
an Epinions WSN	finding	2K_dev_1908
2 WSNs derived from Wikipedia	finding	2K_dev_1908
and a WSN derived from Twitter with more accurate results than past work	finding	2K_dev_1908
Moreover	finding	2K_dev_1908
fairness and goodness metrics form the most significant feature for prediction in most ( but not all ) cases	finding	2K_dev_1908
	finding	2K_dev_1908
We propose two novel measures of node behavior : the goodness of a node intuitively captures how much this node is liked/trusted by other nodes	mechanism	2K_dev_1908
while the fairness of a node captures how fair the node is in rating other nodes ' likeability or trust level We provide axioms that these two notions need to satisfy and show that past work does not meet these requirements for WSNs	mechanism	2K_dev_1908
We provide a mutually recursive definition of these two concepts and prove that they converge to a unique solution in linear time	mechanism	2K_dev_1908
We use the two measures to predict the edge weight in WSNs	mechanism	2K_dev_1908
that when compared against several individual algorithms from both the signed and unsigned social network literature We then use these as features in different multiple regression models	method	2K_dev_1908
In this paper	purpose	2K_dev_1908
we consider the problem of predicting the weights of edges in such networks	purpose	2K_dev_1908
	purpose	2K_dev_1908
The collective buys energy as a group through a central coordinator who also decides about the storage and usage of renewable energy produced by the collective	background	2K_dev_1909
Minimizing the cost is not only of interest to the consumers but is also socially desirable because it reduces the consumption at times of peak demand	background	2K_dev_1909
We prove that our algorithm converges	finding	2K_dev_1909
and it achieves the optimal solution We also present simulation results to quantify the performance of our algorithm	finding	2K_dev_1909
	finding	2K_dev_1909
We develop an iterative coordination algorithm in which the coordinator makes the storage decision and shapes the demands of the consumers by designing a virtual price signal for the agents	mechanism	2K_dev_1909
under realistic conditions	method	2K_dev_1909
based on real world consumption data	method	2K_dev_1909
In this paper	purpose	2K_dev_1909
we focus on demand side management in consumer collectives with community owned renewable energy generation and storage facilities for effective integration of renewable energy with the existing fossil fuel-based power supply system	purpose	2K_dev_1909
Our objective is to design coordination algorithms to minimize the cost of electricity consumption of the consumer collective while allowing the consumers to make their own consumption decisions based on their private consumption constraints and preferences	purpose	2K_dev_1909
A key challenge in ITS research and development is to support tutoring at scale	background	2K_dev_1910
for example by embedding tutors in MOOCs	background	2K_dev_1910
	background	2K_dev_1910
The feasibility of this general approach to ITS/MOOC integration was demonstrated	finding	2K_dev_1910
a widely used ITS authoring tool suite	mechanism	2K_dev_1910
CTAT/TutorShop	mechanism	2K_dev_1910
was modified Specifically	mechanism	2K_dev_1910
the inner loop ( the example-tracing tutor engine ) was moved to the client by reimplementing it in JavaScript	mechanism	2K_dev_1910
and the tutors were made compatible with the LTI e-learning standard	mechanism	2K_dev_1910
	mechanism	2K_dev_1910
a case study in which with simple tutors in an edX MOOC `` Data Analytics and Learning	method	2K_dev_1910
{ '' }	method	2K_dev_1910
An obstacle to at-scale deployment is that ITS architectures tend to be complex	purpose	2K_dev_1910
not easily deployed in browsers without significant server-side processing	purpose	2K_dev_1910
and not easily embedded in a learning management system ( LMS )	purpose	2K_dev_1910
We present so that tutors can be embedded in MOOCs	purpose	2K_dev_1910
	purpose	2K_dev_1910
To be able to provide better support for collaborative learning in Intelligent Tutoring Systems	background	2K_dev_1911
it is important to understand how collaboration patterns change Although interactive talk is often held as a gold standard in collaboration	background	2K_dev_1911
as students become more proficient	background	2K_dev_1911
it may not be as important	background	2K_dev_1911
We found that	finding	2K_dev_1911
over time	finding	2K_dev_1911
the frequency of interactive talk and errors both decrease in dyads working together on conceptual problems	finding	2K_dev_1911
	finding	2K_dev_1911
	mechanism	2K_dev_1911
We address this question by analyzing the shift in types of collaborative talk occurring within a single session and in particular how they relate to errors for 26 4th and 5th grade dyads working on a fractions tutor	method	2K_dev_1911
	method	2K_dev_1911
Prior work has looked at the interdependencies between utterances and the change of dialogue over time	purpose	2K_dev_1911
but it has not addressed how dialogue changes during a lesson	purpose	2K_dev_1911
an analysis that allows us to investigate the adaptivity of student strategies as students gain domain knowledge	purpose	2K_dev_1911
Better conversational alignment can lead to shared understanding	background	2K_dev_1912
changed beliefs	background	2K_dev_1912
and increased rapport	background	2K_dev_1912
provide guidelines for development of peer tutoring agents that can increase learning gains through subtle changes to improve tutor-tutee alignment	background	2K_dev_1912
	background	2K_dev_1912
Our results	finding	2K_dev_1912
which illustrate that rapport as well as convergence are significantly correlated with learning gains	finding	2K_dev_1912
	finding	2K_dev_1912
We develop an approach by accounting for the horizontal richness and time-based dependencies that arise in non-stationary and noisy longitudinal interaction streams	mechanism	2K_dev_1912
	method	2K_dev_1912
We investigate the relationship in peer tutoring of convergence	purpose	2K_dev_1912
interpersonal rapport	purpose	2K_dev_1912
and student learning	purpose	2K_dev_1912
for computational modeling of convergence	purpose	2K_dev_1912
Collaborative and individual learning appear to have complementary strengths ; however	background	2K_dev_1913
the best way to combine these learning methods is still unclear	background	2K_dev_1913
While previous work has demonstrated the effectiveness of Intelligent Tutoring Systems ( ITSs ) for individual learning	background	2K_dev_1913
collaborative learning with ITSs is much less frequent - especially for young students	background	2K_dev_1913
In addition	background	2K_dev_1913
we propose future research to understand how to best combine individual and collaborative learning within an ITS	background	2K_dev_1913
	background	2K_dev_1913
Our previous findings demonstrate that ITSs are able to support collaboration	finding	2K_dev_1913
as well as individual learning	finding	2K_dev_1913
for this population	finding	2K_dev_1913
	finding	2K_dev_1913
	mechanism	2K_dev_1913
	method	2K_dev_1913
In this paper	purpose	2K_dev_1913
we discuss our prior and future work with elementary school students that aims to investigate how to best combine individual and collaborative learning using their complementary strengths within an ITS	purpose	2K_dev_1913
	purpose	2K_dev_1913
Internet of Things ( IoT ) allows for cyber-physical applications to be created and composed to provide intelligent support or automation of end-user tasks For many of such tasks	background	2K_dev_1914
human participation is crucial to the success and the quality of the tasks	background	2K_dev_1914
The cyber systems should proactively request help from the humans to accomplish the tasks when needed	background	2K_dev_1914
	background	2K_dev_1914
We illustrate our approach	finding	2K_dev_1914
In this paper	mechanism	2K_dev_1914
we propose an approach We investigate Specifically	mechanism	2K_dev_1914
our approach consists of : ( 1 ) a formal framework for modeling cooperation between cyber system and human	mechanism	2K_dev_1914
and ( 2 ) a formalization of system-human cooperative task planning as strategy synthesis of stochastic multiplayer game	mechanism	2K_dev_1914
through an example of indoor air quality control in smart homes	method	2K_dev_1914
However	purpose	2K_dev_1914
the outcome of such system-human synergy may be affected by factors external to the systems	purpose	2K_dev_1914
Failure to consider those factors when involving human participants in the tasks may result in suboptimal performance and negative experience on the humans for automated generation of control strategies of cyber-human systems	purpose	2K_dev_1914
how explicit modeling of human participant can be used in automated planning to generate cooperative strategy of human and system to achieve a given task	purpose	2K_dev_1914
by means of which best and appropriately utilize the human	purpose	2K_dev_1914
	purpose	2K_dev_1914
	background	2K_dev_1915
	finding	2K_dev_1915
we found MindMiner was easy to learn and use	finding	2K_dev_1915
and could capture users ' implicit knowledge about writing performance and cluster target entities into groups that match subjects ' mental models We also found that MindMiner 's constraint suggestions and uncertainty polling functions could improve both efficiency and the quality of clustering	finding	2K_dev_1915
	finding	2K_dev_1915
We present MindMiner	mechanism	2K_dev_1915
a mixed-initiative interface via a combination of new interaction techniques and machine learning algorithms	mechanism	2K_dev_1915
MindMiner collects qualitative	mechanism	2K_dev_1915
hard to express similarity measurements from users via active polling with uncertainty and example based visual constraint creation	mechanism	2K_dev_1915
MindMiner also formulates human prior knowledge into a set of inequalities and learns a quantitative similarity distance metric via convex optimization	mechanism	2K_dev_1915
	mechanism	2K_dev_1915
In a 12-subject peer-review understanding task	method	2K_dev_1915
for capturing subjective similarity measurements	purpose	2K_dev_1915
Gestures during spoken dialog play a central role in human communication	background	2K_dev_1916
As a consequence	background	2K_dev_1916
models of gesture generation are a key challenge in research on virtual humans	background	2K_dev_1916
embodied agents capable of face-to-face interaction with people	background	2K_dev_1916
	background	2K_dev_1916
shows significant improvement over previous work on gesture prediction	finding	2K_dev_1916
shows that DCNFs outperform the state-of-the-art approaches	finding	2K_dev_1916
we proposed a gestural sign scheme and presented the DCNF model	mechanism	2K_dev_1916
a model The approach we took realizes both the mapping relation between speech and gestures while taking account temporal relations among gestures	mechanism	2K_dev_1916
	mechanism	2K_dev_1916
Our experiments on human co-verbal dataset A generalization experiment performed on handwriting recognition also	method	2K_dev_1916
Machine learning approaches to gesture generation must take into account the conceptual content in utterances	purpose	2K_dev_1916
physical properties of speech signals and the physical properties of the gestures themselves	purpose	2K_dev_1916
To address this challenge to facilitate supervised learning to jointly learn deep neural networks and second order linear chain temporal contingency	purpose	2K_dev_1916
	purpose	2K_dev_1916
	background	2K_dev_1917
	finding	2K_dev_1917
	mechanism	2K_dev_1917
	method	2K_dev_1917
	purpose	2K_dev_1917
Automated visual analysis is an effective method for understanding changes in natural phenomena over massive city-scale landscapes	background	2K_dev_1918
	background	2K_dev_1918
Our results show that our approach can efficiently integrate both micro and macro-level images	finding	2K_dev_1918
along with other forms of meta-data	finding	2K_dev_1918
to efficiently estimate city-scale phenomena to show the ability of our method to generalize to a diverse set of estimation tasks	finding	2K_dev_1918
	finding	2K_dev_1918
This work presents a unified framework for robustly integrating image data taken at vastly different viewpoints	mechanism	2K_dev_1918
To validate our approach we attempt to estimate the amount of post-Tsunami damage over the entire city of Kamaishi	method	2K_dev_1918
Japan ( over 4 million square-meters ) We evaluate our approach on two modes of land condition analysis	method	2K_dev_1918
namely	method	2K_dev_1918
city-scale debris and greenery estimation	method	2K_dev_1918
	method	2K_dev_1918
However	purpose	2K_dev_1918
the view-point spectrum across which image data can be acquired is extremely wide	purpose	2K_dev_1918
ranging from macro-level overhead ( aerial ) images spanning several kilometers to micro-level front-parallel ( street-view ) images that might only span a few meters	purpose	2K_dev_1918
to generate large-scale estimates of land surface conditions	purpose	2K_dev_1918
	purpose	2K_dev_1918
Computer vision is increasingly becoming interested in the rapid estimation of object detectors	background	2K_dev_1919
The canonical strategy of using Hard Negative Mining to train a Support Vector Machine is slow	background	2K_dev_1919
since the large negative set must be traversed at least once per detector	background	2K_dev_1919
Recent work has demonstrated that	background	2K_dev_1919
with an assumption of signal stationarity	background	2K_dev_1919
Linear Discriminant Analysis is able to learn comparable detectors without ever revisiting the negative set	background	2K_dev_1919
Even with this insight	background	2K_dev_1919
the time to learn a detector can still be on the order of minutes	background	2K_dev_1919
Correlation filters	background	2K_dev_1919
on the other hand	background	2K_dev_1919
can produce a detector in under a second However	background	2K_dev_1919
this involves the unnatural assumption that the statistics are periodic	background	2K_dev_1919
and requires the negative set to be re-sampled per detector size	background	2K_dev_1919
These two methods differ chiefly in the structure which they impose on the covariance matrix of all examples	background	2K_dev_1919
verified that periodicity is detrimental	finding	2K_dev_1919
which develops techniques	mechanism	2K_dev_1919
a comparative study It is experimentally	method	2K_dev_1919
This paper is ( i ) to assume periodic statistics without needing to revisit the negative set and ( ii ) to accelerate the estimation of detectors with aperiodic statistics	purpose	2K_dev_1919
	purpose	2K_dev_1919
Given the re-broadcasts ( i	background	2K_dev_1920
e	background	2K_dev_1920
retweets ) of posts in Twitter	background	2K_dev_1920
how can we spot fake from genuine user reactions ? What will be the tell-tale sign - the connectivity of retweeters	background	2K_dev_1920
their relative timing	background	2K_dev_1920
or something else ? High retweet activity indicates influential users	background	2K_dev_1920
and can be monetized Hence	background	2K_dev_1920
there are strong incentives for fraudulent users to artificially boost their retweets ' volume	background	2K_dev_1920
Our main contributions are : ( a ) the discovery of patterns that fraudulent activity seems to follow ( the `` triangles { '' } and `` homogeneity { '' } patterns	finding	2K_dev_1920
the formation of micro-clusters in appropriate feature spaces ) ; and	finding	2K_dev_1920
b ) `` RTGen { '' }	mechanism	2K_dev_1920
a realistic generator that mimics the behaviors of both honest and fraudulent users	mechanism	2K_dev_1920
	mechanism	2K_dev_1920
We present experiments on a dataset of more than 6 million retweets crawled from Twitter	method	2K_dev_1920
	method	2K_dev_1920
Here	purpose	2K_dev_1920
we explore the identification of fraudulent and genuine retweet threads	purpose	2K_dev_1920
Given the retweeting activity for the posts of several Twitter users	background	2K_dev_1921
	background	2K_dev_1921
Our method achieves a 97\ % accuracy on a real dataset of 12 million retweets crawled from Twitter	finding	2K_dev_1921
	finding	2K_dev_1921
Here	mechanism	2K_dev_1921
we propose : ( A ) ND-Sync	mechanism	2K_dev_1921
an efficient method for detecting group fraud	mechanism	2K_dev_1921
and ( B ) a set of carefully designed features for characterizing retweet threads	mechanism	2K_dev_1921
ND-Sync is effective in spotting retweet fraudsters	mechanism	2K_dev_1921
robust to different types of abnormal activity	mechanism	2K_dev_1921
and adaptable as it can easily incorporate additional features	mechanism	2K_dev_1921
	mechanism	2K_dev_1921
We refer to the detection of such synchronized observations as the Synchonization Fraud problem	method	2K_dev_1921
and we study a specific instance of it	method	2K_dev_1921
Retweet Fraud Detection	method	2K_dev_1921
manifested in Twitter	method	2K_dev_1921
	method	2K_dev_1921
how can we distinguish organic activity from spammy retweets by paid followers to boost a post 's appearance of popularity ? More generally	purpose	2K_dev_1921
given groups of observations	purpose	2K_dev_1921
can we spot strange groups ? Our main intuition is that organic behavior has more variability	purpose	2K_dev_1921
while fraudulent behavior	purpose	2K_dev_1921
like retweets by botnet members	purpose	2K_dev_1921
is more synchronized	purpose	2K_dev_1921
	purpose	2K_dev_1921
	background	2K_dev_1922
reveal the superiority of the proposed method	finding	2K_dev_1922
This paper presents a novel descriptor	mechanism	2K_dev_1922
geodesic invariant feature ( GIF )	mechanism	2K_dev_1922
Especially in the context of parts classification of articulated objects	mechanism	2K_dev_1922
it is capable of encoding the invariance of local structures effectively and efficiently The contributions of this paper lie in our multi-level feature extraction hierarchy	mechanism	2K_dev_1922
( 1 ) Low-level feature encodes the invariance to articulation	mechanism	2K_dev_1922
Geodesic gradient is introduced	mechanism	2K_dev_1922
which is covariant with the non-rigid deformation of objects and is utilized to rectify the feature extraction process	mechanism	2K_dev_1922
( 2 ) Mid-level feature reduces the noise and improves the efficiency	mechanism	2K_dev_1922
With unsupervised clustering	mechanism	2K_dev_1922
the primitives of objects are changed from pixels to superpixels	mechanism	2K_dev_1922
The benefit is two-fold : firstly	mechanism	2K_dev_1922
superpixel reduces the effect of the noise introduced by depth sensors ; secondly	mechanism	2K_dev_1922
the processing speed can be improved by a big margin	mechanism	2K_dev_1922
( 3 ) High-level feature captures nonlinear dependencies between the dimensions	mechanism	2K_dev_1922
Deep network is utilized to discover the high-level feature representation As the feature propagates towards the deeper layers of the network	mechanism	2K_dev_1922
the ability of the feature capturing the data 's underlying regularities is improved	mechanism	2K_dev_1922
	mechanism	2K_dev_1922
Comparisons with the state-of-the-art methods	method	2K_dev_1922
for representing objects in depth images	purpose	2K_dev_1922
Ensemble methods for classification have been effectively used for decades	background	2K_dev_1923
while for outlier detection it has only been studied recently	background	2K_dev_1923
	background	2K_dev_1923
we show that CARE performs significantly better than or at least similar to the individual baselines as well as the existing state-of-the-art outlier ensembles	finding	2K_dev_1923
	finding	2K_dev_1923
In this work	mechanism	2K_dev_1923
we design a new ensemble approach which provides improved accuracy by reducing error through both bias and variance by considering outlier detection as a binary classification task with unobserved labels In this paper	mechanism	2K_dev_1923
we propose a sequential ensemble approach called CARE that employs a two-phase aggregation of the intermediate results in each iteration to reach the final outcome Unlike existing outlier ensembles	mechanism	2K_dev_1923
our ensemble incorporates both the parallel and sequential building blocks to reduce bias as well as variance by ( i ) successively eliminating outliers from the original dataset to build a better data model on which outlierness is estimated ( sequentially )	mechanism	2K_dev_1923
and ( ii ) combining the results from individual base detectors and across iterations ( parallelly )	mechanism	2K_dev_1923
	mechanism	2K_dev_1923
Through extensive experiments on 16 real-world datasets mainly from the UCI machine learning repository { [ } 1 ]	method	2K_dev_1923
	method	2K_dev_1923
for outlier detection in multi-dimensional point data	purpose	2K_dev_1923
	purpose	2K_dev_1923
	background	2K_dev_1924
that active learning driven experimentation using KBMF can result in highly accurate models while performing as few as 14\ % of the possible experiments	finding	2K_dev_1924
and more accurately than random sampling of an equivalent number	finding	2K_dev_1924
and show how it can be used in practice to decide when to stop an active learning process	finding	2K_dev_1924
An active learning method is presented which considers the interaction between multiple drugs and multiple targets at the same time Kernelized Bayesian matrix factorization ( KBMF ) is used to model the interactions We also provide a method based on the learning curve	mechanism	2K_dev_1924
We demonstrate on four previously characterized drug effect data sets	method	2K_dev_1924
for identifying drug-target interactions The goal of the proposed method is not simply to predict such interactions from experiments that have already been conducted	purpose	2K_dev_1924
but to iteratively choose as few new experiments as possible to improve the accuracy of the predictive model	purpose	2K_dev_1924
for estimating the accuracy of the current model	purpose	2K_dev_1924
	background	2K_dev_1925
	finding	2K_dev_1925
In this paper we present a method Contrary to standard classification techniques such as Support Vector Machines or Random Forest	mechanism	2K_dev_1925
the proposed Fuzzy Fingerprints method is able to detect all the event classes present in the ACE 2005 Multilingual Corpus	mechanism	2K_dev_1925
and largely improves the obtained G-Mean value	mechanism	2K_dev_1925
	mechanism	2K_dev_1925
	method	2K_dev_1925
to improve the automatic detection of events in short sentences when in the presence of a large number of event classes	purpose	2K_dev_1925
Problems of this nature arise in formal verification of continuous and hybrid dynamical systems	background	2K_dev_1926
where there is an increasing need for methods to expedite formal proofs	background	2K_dev_1926
	background	2K_dev_1926
The relationship between increased deductive power and running time performance of the proof rules is far from obvious ; we discuss and illustrate certain classes of problems where this relationship is interesting	finding	2K_dev_1926
	mechanism	2K_dev_1926
We study the trade-off between proof rule generality and practical performance and evaluate our theoretical observations on a set of heterogeneous benchmarks	method	2K_dev_1926
	method	2K_dev_1926
This paper presents a theoretical and experimental comparison of sound proof rules for proving invariance of algebraic sets	purpose	2K_dev_1926
that is	purpose	2K_dev_1926
sets satisfying polynomial equalities	purpose	2K_dev_1926
under the flow of polynomial ordinary differential equations	purpose	2K_dev_1926
	purpose	2K_dev_1926
The segmentation is the first step and core technology for semantic understanding of the video	background	2K_dev_1927
Many tasks in the computer vision such as tracking	background	2K_dev_1927
recognition and 3D reconstruction	background	2K_dev_1927
etc	background	2K_dev_1927
rely on the segmentation result as preprocessing	background	2K_dev_1927
However	background	2K_dev_1927
the video segmentation has been known to be a very complicated and hard problem	background	2K_dev_1927
The objects in the video change their colors and shapes according to the surrounding illumination	background	2K_dev_1927
the camera position	background	2K_dev_1927
or the object motion	background	2K_dev_1927
The color	background	2K_dev_1927
motion	background	2K_dev_1927
or depth has been utilized individually as a key clue for the segmentation in many researches	background	2K_dev_1927
	background	2K_dev_1927
The proposed segmentation method will serve as a basis for better high-level tasks such as recognition	background	2K_dev_1927
tracking { [ } 3 ]	background	2K_dev_1927
{ [ } 4 ] and video understanding { [ } 1 ]	background	2K_dev_1927
	background	2K_dev_1927
Our results show that the proposed algorithm outperforms other appearance based segmentation method in terms of semantic quality of the segmentation { [ } 15 ]	finding	2K_dev_1927
	finding	2K_dev_1927
In this paper	mechanism	2K_dev_1927
we propose the video segmentation algorithm which is motivated by the human visual system The algorithm performs the video segmentation task by simultaneously utilizing the color histogram of the color	mechanism	2K_dev_1927
the optical flow of the motion	mechanism	2K_dev_1927
and the homography of the structure	mechanism	2K_dev_1927
	mechanism	2K_dev_1927
	method	2K_dev_1927
However	purpose	2K_dev_1927
every object in the image is composed of several features such as color	purpose	2K_dev_1927
texture	purpose	2K_dev_1927
depth and motion	purpose	2K_dev_1927
That is why single-feature based segmentation method often fails Humans can segment the objects in video with ease because the human visual system enables to consider color	purpose	2K_dev_1927
texture	purpose	2K_dev_1927
depth and motion at the same time	purpose	2K_dev_1927
Many data structures ( e	background	2K_dev_1928
g	background	2K_dev_1928
	background	2K_dev_1928
matrices ) are typically accessed with multiple access patterns	background	2K_dev_1928
Depending on the layout of the data structure in physical address space	background	2K_dev_1928
some access patterns result in non-unit strides	background	2K_dev_1928
In existing systems	background	2K_dev_1928
which are optimized to store and access cache lines	background	2K_dev_1928
non-unit strided accesses exhibit low spatial locality Our framework is general	background	2K_dev_1928
and can benefit many modern data-intensive applications	background	2K_dev_1928
	background	2K_dev_1928
We show that this approach enables GS-DRAM to achieve near-ideal memory bandwidth and cache utilization for many common access patterns	finding	2K_dev_1928
Our evaluations show that 1 ) for in-memory databases	finding	2K_dev_1928
GS-DRAM obtains the best of the row store and the column store layouts	finding	2K_dev_1928
in terms of both performance and energy	finding	2K_dev_1928
and 2 ) for matrix-matrix multiplication	finding	2K_dev_1928
GS-DRAM seamlessly enables SIMD optimizations and outperforms the best tiled layout	finding	2K_dev_1928
	finding	2K_dev_1928
We propose the Gather-Scatter DRAM ( GS-DRAM ) We observe that a commodity DRAM module contains many chips Each chip stores a part of every cache line mapped to the module	mechanism	2K_dev_1928
To realize this idea	mechanism	2K_dev_1928
GS-DRAM first maps the data of each cache line to different chips such that multiple values of a strided access pattern are mapped to different chips Second	mechanism	2K_dev_1928
instead of sending a separate address to each chip	mechanism	2K_dev_1928
GS-DRAM maps each strided pattern to a small pattern ID that is communicated to the module	mechanism	2K_dev_1928
Based on the pattern ID	mechanism	2K_dev_1928
each chip independently computes the address of the value to be accessed	mechanism	2K_dev_1928
The cache line returned by the module contains different values of the strided pattern gathered from different chips	mechanism	2K_dev_1928
We design an end-to-end system to exploit GS-DRAM	method	2K_dev_1928
	method	2K_dev_1928
Therefore	purpose	2K_dev_1928
they incur high latency	purpose	2K_dev_1928
and waste memory bandwidth and cache space	purpose	2K_dev_1928
to address this problem Our idea is to enable the memory controller to access multiple values that belong to a strided pattern from different chips using a single read/write command	purpose	2K_dev_1928
	purpose	2K_dev_1928
Though most would agree that accountability and privacy are both valuable	background	2K_dev_1929
today 's Internet provides little support for either	background	2K_dev_1929
Previous efforts have explored ways to offer stronger guarantees for one of the two	background	2K_dev_1929
typically at the expense of the other ; indeed	background	2K_dev_1929
at first glance accountability and privacy appear mutually exclusive	background	2K_dev_1929
	background	2K_dev_1929
	finding	2K_dev_1929
We introduce the Accountable and Private Internet Protocol ( APIP )	mechanism	2K_dev_1929
which splits source addresses into two separate fields - an accountability address and a return address - and introduces independent mechanisms for managing each	mechanism	2K_dev_1929
Accountability addresses	mechanism	2K_dev_1929
rather than pointing to hosts	mechanism	2K_dev_1929
point to accountability delegates	mechanism	2K_dev_1929
which agree to vouch for packets on their clients ' behalves	mechanism	2K_dev_1929
taking appropriate action when misbehavior is reported	mechanism	2K_dev_1929
With accountability handled by delegates	mechanism	2K_dev_1929
senders are now free to mask their return addresses ; we discuss a few techniques for doing so	mechanism	2K_dev_1929
	mechanism	2K_dev_1929
	method	2K_dev_1929
At the center of the tussle is the source address : in an accountable Internet	purpose	2K_dev_1929
source addresses undeniably link packets and senders so hosts can be punished for bad behavior	purpose	2K_dev_1929
In a privacy-preserving Internet	purpose	2K_dev_1929
source addresses are hidden as much as possible	purpose	2K_dev_1929
In this paper	purpose	2K_dev_1929
we argue that a balance is possible	purpose	2K_dev_1929
	purpose	2K_dev_1929
The growing number of sensor-based interactive applications and services are pushing the limits of the on-board computing resources in vehicles	background	2K_dev_1930
With vehicles increasingly being connected to the Internet	background	2K_dev_1930
offloading the computation to cloud-computing infrastructures is an attractive solution	background	2K_dev_1930
	finding	2K_dev_1930
we show that our mechanism can help meet application response time constraints	finding	2K_dev_1930
	finding	2K_dev_1930
we design a system to the cloud	mechanism	2K_dev_1930
We particularly develop heuristic mechanisms for the placement and scheduling of modules on the On-Board Unit ( OBU ) and a cloud server under dynamic networking conditions during driving	mechanism	2K_dev_1930
Through an experimental evaluation of the end-end application response time using our prototype vehicular cloud offloading system	method	2K_dev_1930
However	purpose	2K_dev_1930
the large sensory data inputs of interactive applications makes offloading challenging across dynamic network conditions	purpose	2K_dev_1930
and different application requirements or policies To address this challenge to adaptively offload specific vehicular application components or modules	purpose	2K_dev_1930
We believe that HERD further serves as an effective template for the construction of RDMA-based datacenter services	background	2K_dev_1931
supports up to 26 million key-value operations per second with 5 mu s average latency	finding	2K_dev_1931
Notably	finding	2K_dev_1931
for small key-value items	finding	2K_dev_1931
our full system throughput is similar to native RDMA read throughput and is over 2X higher than recent RDMA-based key-value systems	finding	2K_dev_1931
	finding	2K_dev_1931
This paper describes the design and implementation of HERD	mechanism	2K_dev_1931
a key-value system designed Unlike prior RDMA-based key-value systems	mechanism	2K_dev_1931
HERD focuses its design on reducing network round trips while using efficient RDMA primitives ; the result is substantially lower latency	mechanism	2K_dev_1931
and throughput that saturates modern	mechanism	2K_dev_1931
commodity RDMA hardware HERD has two unconventional decisions : First	mechanism	2K_dev_1931
it does not use RDMA reads	mechanism	2K_dev_1931
despite the allure of operations that bypass the remote CPU entirely Second	mechanism	2K_dev_1931
it uses a mix of RDMA and messaging verbs	mechanism	2K_dev_1931
despite the conventional wisdom that the messaging primitives are slow A HERD client writes its request into the server 's memory ; the server computes the reply	mechanism	2K_dev_1931
This design uses a single round trip for all requests and	mechanism	2K_dev_1931
	method	2K_dev_1931
to make the best use of an RDMA network	purpose	2K_dev_1931
	purpose	2K_dev_1931
TTL caching models have recently regained significant research interest due to their connection to popular caching policies such as LRU	background	2K_dev_1932
	background	2K_dev_1932
results highlight that existing Poisson approximations in binary-tree topologies are subject to relative errors as large as 30\ %	finding	2K_dev_1932
depending on the tree depth	finding	2K_dev_1932
	finding	2K_dev_1932
developing two exact methods with orthogonal generality and computational complexity The first method generalizes existing results for line networks under renewal requests to the broad class of caching policies whereby evictions are driven by stopping times ; in addition to classical policies used in DNS and web caching	mechanism	2K_dev_1932
our stopping time model captures an emerging new policy implemented in SON switches and Amazon web services	mechanism	2K_dev_1932
The second method further generalizes these results to feedforward networks with Markov arrival process ( MAP ) requests MAPs are particularly suitable for non-line networks because they are closed not only under superposition and splitting	mechanism	2K_dev_1932
as known	mechanism	2K_dev_1932
but also under caching operations with phase-type ( PH ) TTL distributions	mechanism	2K_dev_1932
The crucial benefit of the two closure properties is that they jointly enable the first exact analysis of TTL feedforward cache networks in great generality	mechanism	2K_dev_1932
Moreover	method	2K_dev_1932
numerical	method	2K_dev_1932
This paper advances the state-of-the-art analysis of TTL-based cache networks by	purpose	2K_dev_1932
To date	background	2K_dev_1933
the study of dispatching or load balancing in server farms has primarily focused on the minimization of response time	background	2K_dev_1933
Server farms are typically modeled by a front-end router that employs a dispatching policy to route jobs to one of several servers	background	2K_dev_1933
with each server scheduling all the jobs in its queue via Processor-Sharing	background	2K_dev_1933
	background	2K_dev_1933
	finding	2K_dev_1933
we are able to deduce many unexpected results regarding dispatching	finding	2K_dev_1933
: we model each arrival as having a randomly distributed value parameter	mechanism	2K_dev_1933
independent of the arrival 's service requirement ( job size )	mechanism	2K_dev_1933
Given such value heterogeneity	mechanism	2K_dev_1933
the correct metric is no longer the minimization or response time	mechanism	2K_dev_1933
but rather	mechanism	2K_dev_1933
the minimization of value-weighted response time	mechanism	2K_dev_1933
{ '' } We propose a number of new dispatching policies that are motivated by the goal of minimizing the value-weighted response time	mechanism	2K_dev_1933
	mechanism	2K_dev_1933
Via a combination of exact analysis	method	2K_dev_1933
asymptotic analysis	method	2K_dev_1933
and simulation	method	2K_dev_1933
However	purpose	2K_dev_1933
the common assumption has been that all jobs are equally important or valuable	purpose	2K_dev_1933
in that they are equally sensitive to delay	purpose	2K_dev_1933
Our work departs from this assumption In this context	purpose	2K_dev_1933
we ask `` what is a good dispatching policy to minimize the value-weighted response time metric ?	purpose	2K_dev_1933
	background	2K_dev_1934
LM tends to be more expressive than other logic programming languages	finding	2K_dev_1934
LM programs are naturally concurrent illustrate its use	finding	2K_dev_1934
We have designed a new logic programming language called LM ( Linear Meld ) Our language is based on linear logic	mechanism	2K_dev_1934
an expressive logical system where logical facts can be consumed	mechanism	2K_dev_1934
Because LM integrates both classical and linear logic	mechanism	2K_dev_1934
because facts are partitioned by nodes of a graph data structure	mechanism	2K_dev_1934
Computation is performed at the node level while communication happens between connected nodes	mechanism	2K_dev_1934
through a number of examples	mechanism	2K_dev_1934
	mechanism	2K_dev_1934
	method	2K_dev_1934
for programming graph- based algorithms in a declarative fashion	purpose	2K_dev_1934
In this paper	purpose	2K_dev_1934
we present the syntax and operational semantics of our language and	purpose	2K_dev_1934
It is hard to efficiently model the light transport in scenes with translucent objects for interactive applications	background	2K_dev_1935
The inter-reflection between objects and their environments and the subsurface scattering through the materials intertwine to produce visual effects like color bleeding	background	2K_dev_1935
light glows	background	2K_dev_1935
and soft shading	background	2K_dev_1935
	background	2K_dev_1935
	finding	2K_dev_1935
we demonstrate scene relighting and dynamically varying object translucencies at near interactive rates	finding	2K_dev_1935
	finding	2K_dev_1935
In this paper	mechanism	2K_dev_1935
we present a simple analytic model that combines diffuse inter-reflection and isotropic subsurface scattering	mechanism	2K_dev_1935
Our approach extends the classical work in radiosity by including a subsurface scattering matrix that operates in conjunction with the traditional form factor matrix	mechanism	2K_dev_1935
This subsurface scattering matrix can be constructed using analytic	mechanism	2K_dev_1935
measurement-based or simulation-based models and can capture both homogeneous and heterogeneous translucencies	mechanism	2K_dev_1935
	mechanism	2K_dev_1935
Using a fast iterative solution to radiosity	method	2K_dev_1935
Monte-Carlo based approaches have demonstrated impressive results but are computationally expensive	purpose	2K_dev_1935
and faster approaches model either only inter-reflection or only subsurface scattering	purpose	2K_dev_1935
	purpose	2K_dev_1935
Motivation : Discovering the transcriptional regulatory architecture of the metabolism has been an important topic to understand the implications of transcriptional fluctuations on metabolism	background	2K_dev_1936
The reporter algorithm ( RA ) was proposed to determine the hot spots in metabolic networks	background	2K_dev_1936
around which transcriptional regulation is focused owing to a disease or a genetic perturbation	background	2K_dev_1936
Using a z-score-based scoring scheme	background	2K_dev_1936
RA calculates the average statistical change in the expression levels of genes that are neighbors to a target metabolite in the metabolic network	background	2K_dev_1936
The RA approach has been used in numerous studies to analyze cellular responses to the downstream genetic changes	background	2K_dev_1936
Overall	background	2K_dev_1936
MIRA is a promising algorithm for detecting metabolic drug targets and understanding the relation between gene expression and metabolic activity	background	2K_dev_1936
	background	2K_dev_1936
We show that MIRA 's results are biologically sound	finding	2K_dev_1936
empirically significant and more reliable than RA	finding	2K_dev_1936
Results and show that MIRA captures the underlying metabolic dynamics of the switch from aerobic to anaerobic respiration Results indicate that MIRA reports metabolites that highly overlap with recently found metabolic biomarkers in the autism literature	finding	2K_dev_1936
	finding	2K_dev_1936
In this article	mechanism	2K_dev_1936
we propose a mutual information-based multivariate reporter algorithm MIRA ) MIRA is a multivariate and combinatorial algorithm using mutual information	mechanism	2K_dev_1936
	mechanism	2K_dev_1936
We apply MIRA to gene expression analysis of six knockout strains of Escherichia coli We also apply MIRA to an Autism Spectrum Disorder gene expression dataset	method	2K_dev_1936
with the goal of eliminating the following problems in detecting reporter metabolites : ( i ) conventional statistical methods suffer from small sample sizes	purpose	2K_dev_1936
( ii ) as z-score ranges from minus to plus infinity	purpose	2K_dev_1936
calculating average scores can lead to canceling out opposite effects and ( iii ) analyzing genes one by one	purpose	2K_dev_1936
then aggregating results can lead to information loss	purpose	2K_dev_1936
that calculates the aggregate transcriptional response around a metabolite	purpose	2K_dev_1936
Overall	background	2K_dev_1937
we hope that the work helps to advance concurrent programming in modern programming environments	background	2K_dev_1937
	background	2K_dev_1937
The AEMINIUM implementation and all case studies are publicly available under the General Public License	finding	2K_dev_1937
to demonstrate that AEMINIUM parallelized code has performance improvements compared to its sequential counterpart	finding	2K_dev_1937
to show that AEMINIUM is powerful enough to encode them AEMINIUM can achieve a 70\ % performance improvement over the sequential counterpart Our evaluation demonstrates that AEMINIUM can be used to express parallelism in such data-structures and that the performance benefits scale with the amount of annotation effort which is put into the implementation	finding	2K_dev_1937
Our experiments show that AEMINIUM is capable of extracting parallelism from functional code and achieving performance improvements up to the limits of Plaid 's inherent performance bounds	finding	2K_dev_1937
	finding	2K_dev_1937
the design of the concurrent-by-default AEMINIUM programming language	mechanism	2K_dev_1937
AEMINIUM leverages the permission flow of object and group permissions through the program to validate the program 's correctness and to automatically infer a possible parallelization strategy via a dataflow graph	mechanism	2K_dev_1937
AEMINIUM supports not only fork-join parallelism but more general dataflow patterns of parallelism	mechanism	2K_dev_1937
In this paper we present a formal system	mechanism	2K_dev_1937
called mu AEMINIUM	mechanism	2K_dev_1937
modeling the core concepts of AEMINIUM	mechanism	2K_dev_1937
mu AEMINIUM 's static type system is based on Featherweight Java with AEMINIUM-specific extensions	mechanism	2K_dev_1937
Besides checking for correctness AEMINIUM 's type system it also uses the permission flow to compute a potential parallel execution strategy for the program mu AEMINIUM 's dynamic semantics use a concurrent-by-default evaluation approach	mechanism	2K_dev_1937
We conduct our study through Along with the formal system we present its soundness proof	method	2K_dev_1937
We provide a full description of the implementation along with the description of various optimization techniques we used	method	2K_dev_1937
We implemented AEMINIUM as an extension of the Plaid programming language	method	2K_dev_1937
which has first-class support for permissions built-in	method	2K_dev_1937
We use various case studies to evaluate AEMINIUM 's applicability and We chose to use case studies from common domains or problems that are known to benefit from parallelization	method	2K_dev_1937
We demonstrate through a webserver application	method	2K_dev_1937
which evaluates AEMINIUM 's impact on latency-bound applications	method	2K_dev_1937
that In another case study we chose to implement a dictionary function to evaluate AEMINIUM 's capabilities to express essential data structures We chose an integral computationally example to evaluate pure functional programming and computational intensive use cases	method	2K_dev_1937
	method	2K_dev_1937
The aim of AEMINIUM is to study the implications of having a concurrent-by-default programming language	purpose	2K_dev_1937
This includes language design	purpose	2K_dev_1937
runtime system	purpose	2K_dev_1937
performance and software engineering considerations	purpose	2K_dev_1937
	purpose	2K_dev_1937
Vehicular multi-hop protocols typically employ distance-based metrics	background	2K_dev_1938
where it achieved a 30\ % increase in packet delivery ratio over the benchmark GPSR protocol	finding	2K_dev_1938
	finding	2K_dev_1938
In this work we present LASP	mechanism	2K_dev_1938
a geographic protocol that uses a more accurate spatial connectivity-based metric Spatial connectivity describes the historical probability of successfully delivering a packet from one geographic area to another	mechanism	2K_dev_1938
Analysis of data collected from a vehicular testbed showed that	mechanism	2K_dev_1938
unlike other metrics	mechanism	2K_dev_1938
spatial connectivity indirectly captures all major factors affecting wireless connectivity	mechanism	2K_dev_1938
Moreover	mechanism	2K_dev_1938
it is temporally stable	mechanism	2K_dev_1938
which makes it useful in estimating the quality of future co-located links	mechanism	2K_dev_1938
When forwarding	mechanism	2K_dev_1938
LASP uses spatial connectivity information to pick a well-connected geographic forwarding zone	mechanism	2K_dev_1938
inside which multiple nodes cooperate in relaying through a distributed prioritization scheme	mechanism	2K_dev_1938
Compared with other techniques where the sender picks a specific next hop relay	mechanism	2K_dev_1938
cooperative forwarding improves resilience to losses through vehicle diversity	mechanism	2K_dev_1938
	mechanism	2K_dev_1938
We evaluated LASP on a 30-node testbed	method	2K_dev_1938
	method	2K_dev_1938
which do not capture the complexity of vehicular connectivity	purpose	2K_dev_1938
Security requirements patterns represent reusable security practices that software engineers can apply to improve security in their system	background	2K_dev_1939
Reusing best practices that others have employed could have a number of benefits	background	2K_dev_1939
such as decreasing the time spent in the requirements elicitation process or improving the quality of the product by reducing product failure risk	background	2K_dev_1939
Pattern selection can be difficult due to the diversity of applicable patterns from which an analyst has to choose	background	2K_dev_1939
	background	2K_dev_1939
	finding	2K_dev_1939
We propose a new method that combines an inquiry-cycle based approach with the feature diagram notation Similar to patterns themselves	mechanism	2K_dev_1939
our approach captures expert knowledge The resulting pattern hierarchies allow users to be guided through these decisions by questions	mechanism	2K_dev_1939
which introduce related patterns in order	mechanism	2K_dev_1939
thus resulting in better requirement generation	mechanism	2K_dev_1939
	mechanism	2K_dev_1939
We evaluate our approach using access control patterns in a pattern user study	method	2K_dev_1939
The challenge is that identifying the most appropriate pattern for a situation can be cumbersome and time-consuming	purpose	2K_dev_1939
to review only relevant patterns and quickly select the most appropriate patterns for the situation	purpose	2K_dev_1939
to relate patterns based on decisions made by the pattern user	purpose	2K_dev_1939
to help the pattern user select the most appropriate patterns for their situation	purpose	2K_dev_1939
Government laws and regulations increasingly place requirements on software systems	background	2K_dev_1940
Ideally	background	2K_dev_1940
experts trained in law will analyze and interpret legal texts to inform the software requirements process	background	2K_dev_1940
However	background	2K_dev_1940
in small companies and development teams with short launch cycles	background	2K_dev_1940
individuals with little or no legal training will be responsible for compliance	background	2K_dev_1940
Two specific challenges commonly faced by non-experts are deciding if their system is covered by a law	background	2K_dev_1940
and then deciding whether two legal requirements are similar or different	background	2K_dev_1940
	background	2K_dev_1940
In so doing	finding	2K_dev_1940
we discovered that legal experts achieved higher rates of consensus more frequently than technical professionals or laypersons and that all groups had slightly greater agreement when judging coverage conditions than requirements	finding	2K_dev_1940
we found that technical professionals and legal experts exhibited consistently greater agreement than that found between laypersons and legal experts	finding	2K_dev_1940
and that each group tended towards different justifications	finding	2K_dev_1940
such as laypersons and technical professionals tendency towards categorizing different coverage conditions or requirements as equivalent if they believed them to possess the same underlying intent	finding	2K_dev_1940
	mechanism	2K_dev_1940
measured by Fleiss ' K	method	2K_dev_1940
When comparing judgments between groups using a consensus-based Cohen 's Kappa	method	2K_dev_1940
	method	2K_dev_1940
In this study	purpose	2K_dev_1940
we assess the ability of laypersons	purpose	2K_dev_1940
technical professionals	purpose	2K_dev_1940
and legal experts to judge the similarity between legal coverage conditions and requirements	purpose	2K_dev_1940
	purpose	2K_dev_1940
Many traditional challenges in reconstructing 3D motion	background	2K_dev_1941
such as matching across wide baselines and handling occlusion	background	2K_dev_1941
reduce in significance as the number of unique viewpoints increases	background	2K_dev_1941
	background	2K_dev_1941
We demonstrate that our method estimates visibility with greater accuracy	finding	2K_dev_1941
and increases tracking performance producing longer trajectories	finding	2K_dev_1941
at more locations	finding	2K_dev_1941
and at higher accuracies than methods that ignore visibility or use photometric consistency alone	finding	2K_dev_1941
	finding	2K_dev_1941
We present a maximum a posteriori ( MAP ) estimate of the time-varying visibility of the target points Our algorithm takes	mechanism	2K_dev_1941
as input	mechanism	2K_dev_1941
camera poses and image sequences	mechanism	2K_dev_1941
and outputs the time-varying set of the cameras in which a target patch is visibile and its reconstructed trajectory	mechanism	2K_dev_1941
We model visibility estimation as a MAP estimate by incorporating various cues including photometric consistency	mechanism	2K_dev_1941
motion consistency	mechanism	2K_dev_1941
and geometric consistency	mechanism	2K_dev_1941
in conjunction with a prior that rewards consistent visibilities in proximal cameras	mechanism	2K_dev_1941
An optimal estimate of visibility is obtained by finding the minimum cut of a capacitated graph over cameras	mechanism	2K_dev_1941
	method	2K_dev_1941
However	purpose	2K_dev_1941
to obtain this benefit	purpose	2K_dev_1941
a new challenge arises : estimating precisely which cameras observe which points at each instant in time	purpose	2K_dev_1941
to reconstruct the 3D motion of an event from a large number of cameras	purpose	2K_dev_1941
	purpose	2K_dev_1941
Curse of dimensionality is a practical and challenging problem in image categorization	background	2K_dev_1942
especially in cases with a large number of classes	background	2K_dev_1942
Multi-class classification encounters severe computational and storage problems when dealing with these large scale tasks	background	2K_dev_1942
	background	2K_dev_1942
further demonstrate the effectiveness of hierarchical feature hashing	finding	2K_dev_1942
In this paper	mechanism	2K_dev_1942
we propose hierarchical feature hashing	mechanism	2K_dev_1942
We provide detailed theoretical analysis on our proposed hashing method Moreover	method	2K_dev_1942
experimental results on object recognition and scene classification	method	2K_dev_1942
to effectively reduce dimensionality of parameter space without sacrificing classification accuracy	purpose	2K_dev_1942
and at the same time exploit information in semantic taxonomy among categories	purpose	2K_dev_1942
	purpose	2K_dev_1942
With the widespread availability of video cameras	background	2K_dev_1943
we are facing an ever-growing enormous collection of unedited and unstructured video data	background	2K_dev_1943
Due to lack of an automatic way to generate summaries from this large collection of consumer videos	background	2K_dev_1943
they can be tedious and time consuming to index or search	background	2K_dev_1943
demonstrating the effectiveness of online video highlighting	finding	2K_dev_1943
	finding	2K_dev_1943
In this work	mechanism	2K_dev_1943
we propose online video highlighting	mechanism	2K_dev_1943
a principled way	mechanism	2K_dev_1943
costly both time-wise and financially for manual processing	mechanism	2K_dev_1943
Specifically	mechanism	2K_dev_1943
our method learns a dictionary from given video using group sparse coding	mechanism	2K_dev_1943
and updates atoms in the dictionary on-the-fly	mechanism	2K_dev_1943
A summary video is then generated by combining segments that can not be sparsely reconstructed using the learned dictionary	mechanism	2K_dev_1943
The online fashion of our proposed method enables it to process arbitrarily long videos and start generating summaries before seeing the end of the video Moreover	mechanism	2K_dev_1943
the processing time required by our proposed method is close to the original video length	mechanism	2K_dev_1943
achieving quasi real-time summarization speed	mechanism	2K_dev_1943
Theoretical analysis	method	2K_dev_1943
together with experimental results on more than 12 hours of surveillance and YouTube videos are provided	method	2K_dev_1943
of generating short video summarizing the most important and interesting contents of an unedited and unstructured video	purpose	2K_dev_1943
	background	2K_dev_1944
We demonstrate the ability of our system to align 3D models with 2D objects in the challenging PASCAL VOC images	finding	2K_dev_1944
which depict a wide variety of chairs in complex scenes	finding	2K_dev_1944
	finding	2K_dev_1944
	mechanism	2K_dev_1944
we propose an exemplar-based 3D category representation	mechanism	2K_dev_1944
which can explicitly model chairs of different styles as well as the large variation in viewpoint	mechanism	2K_dev_1944
We develop an approach This is achieved by ( i ) representing each 3D model using a set of view-dependent mid-level visual elements learned from synthesized views in a discriminative fashion	mechanism	2K_dev_1944
( ii ) carefully calibrating the individual element detectors on a common dataset of negative images	mechanism	2K_dev_1944
and ( iii ) matching visual elements to the test image allowing for small mutual deformations but preserving the viewpoint and style constraints	mechanism	2K_dev_1944
	mechanism	2K_dev_1944
utilizing the large quantities of 3D CAD models that have been made publicly available online	method	2K_dev_1944
Using the `` chair { '' } class as a running example	method	2K_dev_1944
This paper poses object category detection in images as a type of 2D-to-3D alignment problem	purpose	2K_dev_1944
to establish part-based correspondences between 3D CAD models and real photographs	purpose	2K_dev_1944
	purpose	2K_dev_1944
The storyline graphs can be an effective summary that visualizes various branching narrative structure of events or activities recurring across the input photo sets of a topic class	background	2K_dev_1945
	background	2K_dev_1945
we show that the proposed algorithm improves other candidate methods for both storyline reconstruction and image prediction tasks	finding	2K_dev_1945
	finding	2K_dev_1945
In this paper	mechanism	2K_dev_1945
we investigate an approach from large-scale collections of Internet images	mechanism	2K_dev_1945
and optionally other side information such as friendship graphs	mechanism	2K_dev_1945
	mechanism	2K_dev_1945
we leverage them to perform the image sequential prediction tasks	mechanism	2K_dev_1945
from which photo recommendation applications can benefit	mechanism	2K_dev_1945
We formulate the storyline reconstruction problem as an inference of sparse time-varying directed graphs	mechanism	2K_dev_1945
and develop an optimization algorithm that successfully addresses a number of key challenges of Web-scale problems	mechanism	2K_dev_1945
including global optimality	mechanism	2K_dev_1945
linear complexity	mechanism	2K_dev_1945
and easy parallelization	mechanism	2K_dev_1945
With experiments on more than 3	method	2K_dev_1945
3 millions of images of 24 classes and user studies via Amazon Mechanical Turk	method	2K_dev_1945
for reconstructing storyline graphs In order to explore further the usefulness of the storyline graphs	purpose	2K_dev_1945
	background	2K_dev_1946
we demonstrate that the proposed joint summarization approach outperforms other baselines and our own methods using videos or images only	finding	2K_dev_1946
Starting from the intuition that the characteristics of the two media types are different yet complementary	mechanism	2K_dev_1946
we develop a fast and easily-parallelizable approach for creating not only high-quality video summaries but also novel structural summaries of online images as storyline graphs The storyline graphs can illustrate various events or activities associated with the topic in a form of a branching network	mechanism	2K_dev_1946
The video summarization is achieved by diversity ranking on the similarity graphs between images and video frames	mechanism	2K_dev_1946
The reconstruction of storyline graphs is formulated as the inference of sparse time-varying directed graphs from a set of photo streams with assistance of videos	mechanism	2K_dev_1946
For evaluation	method	2K_dev_1946
we collect the datasets of 20 outdoor activities	method	2K_dev_1946
consisting of 2	method	2K_dev_1946
7M Flickr images and 16K YouTube videos Due to the large-scale nature of our problem	method	2K_dev_1946
we evaluate our algorithm via crowdsourcing using Amazon Mechanical Turk	method	2K_dev_1946
In our experiments	method	2K_dev_1946
	method	2K_dev_1946
In this paper	purpose	2K_dev_1946
we address the problem of jointly summarizing large sets of Flickr images and YouTube videos	purpose	2K_dev_1946
	background	2K_dev_1947
	finding	2K_dev_1947
	mechanism	2K_dev_1947
	method	2K_dev_1947
	purpose	2K_dev_1947
Web services offer a more reliable and efficient way to access online data than scraping web pages	background	2K_dev_1948
	background	2K_dev_1948
to demonstrate our tool 's ability to create fast and reusable data extraction and manipulation programs that work with complex web service data	finding	2K_dev_1948
In this paper	mechanism	2K_dev_1948
we present Gneiss	mechanism	2K_dev_1948
a tool that extends the familiar spreadsheet metaphor Gneiss allows users to extract the desired fields in web service data using drag-and-drop	mechanism	2K_dev_1948
and refine the results through spreadsheet formulas	mechanism	2K_dev_1948
along with sorting and filtering the data	mechanism	2K_dev_1948
Hierarchical data are stored as nested tables in the spreadsheet and can be flattened for future operations	mechanism	2K_dev_1948
Data flow is two-way between the spreadsheet and the web services	mechanism	2K_dev_1948
enabling people to easily make a new request by modifying spreadsheet cells	mechanism	2K_dev_1948
In addition	mechanism	2K_dev_1948
using the dependency between spreadsheet cells	mechanism	2K_dev_1948
our tool is able to create parallel-running data extractions based on the user 's sequential demonstration	mechanism	2K_dev_1948
	mechanism	2K_dev_1948
We use a set of examples	method	2K_dev_1948
However	purpose	2K_dev_1948
web service data are often in complex hierarchical structures that make it difficult for people to extract the desired parts or to perform any further data manipulation without writing a significant amount of surprisingly intricate code	purpose	2K_dev_1948
to support working with data returned from web services	purpose	2K_dev_1948
	purpose	2K_dev_1948
Research shows that commonly accepted security requirements are not generally applied in practice Instead of relying on requirements checklists	background	2K_dev_1949
security experts rely on their expertise and background knowledge to identify security vulnerabilities	background	2K_dev_1949
We report our preliminary results of analyzing two interviews that reveal possible decision-making patterns that could characterize how analysts perceive	finding	2K_dev_1949
comprehend and project future threats which leads them to decide upon requirements and their specifications	finding	2K_dev_1949
in addition	finding	2K_dev_1949
to how experts use assumptions to overcome ambiguity in specifications	finding	2K_dev_1949
	finding	2K_dev_1949
Our goal is to build a model that researchers can use	mechanism	2K_dev_1949
we conducted a series of interviews to encode the decision-making process of security experts and novices during security requirements analysis	method	2K_dev_1949
Participants were asked to analyze two types of artifacts : source code	method	2K_dev_1949
and network diagrams for vulnerabilities and to apply a requirements checklist to mitigate some of those vulnerabilities	method	2K_dev_1949
We framed our study using Situation Awareness-a cognitive theory from psychology-to elicit responses that we later analyzed using coding theory and grounded analysis	method	2K_dev_1949
	method	2K_dev_1949
To understand the gap between available checklists and practice	purpose	2K_dev_1949
to evaluate their security requirements methods against how experts transition through different situation awareness levels in their decision-making process	purpose	2K_dev_1949
	purpose	2K_dev_1949
The use of shared mutable state	background	2K_dev_1950
commonly seen in object-oriented systems	background	2K_dev_1950
is often problematic due to the potential conflicting interactions between aliases to the same state	background	2K_dev_1950
	background	2K_dev_1950
	finding	2K_dev_1950
We present a substructural type system outfitted with a novel lightweight interference control mechanism	mechanism	2K_dev_1950
rely-guarantee protocols	mechanism	2K_dev_1950
By assigning each alias separate roles	mechanism	2K_dev_1950
encoded in a novel protocol abstraction in the spirit of rely-guarantee reasoning	mechanism	2K_dev_1950
our type system ensures that challenging uses of shared state will never interfere in an unsafe fashion	mechanism	2K_dev_1950
In particular	mechanism	2K_dev_1950
rely-guarantee protocols ensure that each alias will never observe an unexpected value	mechanism	2K_dev_1950
or type	mechanism	2K_dev_1950
when inspecting shared memory regardless of how the changes to that shared state ( originating from potentially unknown program contexts ) are interleaved at run-time	mechanism	2K_dev_1950
	method	2K_dev_1950
that enables controlled aliasing of shared resources	purpose	2K_dev_1950
Formal verification and validation play a crucial role in making cyberphysical systems ( CPS ) safe Formal methods make strong guarantees about the system behavior if accurate models of the system can be obtained	background	2K_dev_1951
including models of the controller and of the physical dynamics	background	2K_dev_1951
	background	2K_dev_1951
	finding	2K_dev_1951
This paper introduces ModelPlex	mechanism	2K_dev_1951
a method ModelPlex provides correctness guarantees for CPS executions at runtime : it combines offline verification of CPS models with runtime validation of system executions for compliance with the model	mechanism	2K_dev_1951
ModelPlex ensures that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model	mechanism	2K_dev_1951
assuming the system dynamics deviation is bounded If	mechanism	2K_dev_1951
at some point	mechanism	2K_dev_1951
the observed behavior no longer complies with the model so that offline verification results no longer apply	mechanism	2K_dev_1951
ModelPlex initiates provably safe fallback actions This paper	mechanism	2K_dev_1951
furthermore	mechanism	2K_dev_1951
develops a systematic technique	mechanism	2K_dev_1951
	method	2K_dev_1951
In CPS	purpose	2K_dev_1951
models are essential ; but any model we could possibly build necessarily deviates from the real world	purpose	2K_dev_1951
If the real system fits to the model	purpose	2K_dev_1951
its behavior is guaranteed to satisfy the correctness properties verified w	purpose	2K_dev_1951
r	purpose	2K_dev_1951
t	purpose	2K_dev_1951
the model	purpose	2K_dev_1951
Otherwise	purpose	2K_dev_1951
all bets are off	purpose	2K_dev_1951
ensuring that verification results about models apply to CPS implementations	purpose	2K_dev_1951
to synthesize provably correct monitors automatically from CPS proofs in differential dynamic logic	purpose	2K_dev_1951
	purpose	2K_dev_1951
	background	2K_dev_1952
We show that this multi-modal approach achieves superior recognition accuracy compared to using a vision system alone	finding	2K_dev_1952
especially in cluttered scenes where a vision system would be unable to distinguish which object is of interest to the user without additional input	finding	2K_dev_1952
	finding	2K_dev_1952
We present Marvin	mechanism	2K_dev_1952
a system It integrates HOG-based object recognition	mechanism	2K_dev_1952
SURF-based localization information	mechanism	2K_dev_1952
automatic speech recognition	mechanism	2K_dev_1952
and user feedback information with a probabilistic model Once the object of interest is recognized	mechanism	2K_dev_1952
the information that the user is querying	mechanism	2K_dev_1952
e	mechanism	2K_dev_1952
g	mechanism	2K_dev_1952
reviews	mechanism	2K_dev_1952
options	mechanism	2K_dev_1952
etc	mechanism	2K_dev_1952
	mechanism	2K_dev_1952
is displayed on the user 's mobile or wearable device	mechanism	2K_dev_1952
It is computationally able to scale to large numbers of objects by focusing compute-intensive resources on the objects most likely to be of interest	mechanism	2K_dev_1952
inferred from user speech and implicit localization information	mechanism	2K_dev_1952
	mechanism	2K_dev_1952
We tested this prototype in a real-world retail store during business hours	method	2K_dev_1952
with varied degree of background noise and clutter	method	2K_dev_1952
	method	2K_dev_1952
that can search physical objects using a mobile or wearable device	purpose	2K_dev_1952
to recognize the `` object of interest { '' } at high accuracy and at interactive speeds We present the system architecture	purpose	2K_dev_1952
the probabilistic model that integrates the multi-modal information	purpose	2K_dev_1952
and empirical results showing the benefits of multi-modal integration	purpose	2K_dev_1952
Due to the diversity in appearance in real world objects	background	2K_dev_1953
an object detector must capture variations in scale	background	2K_dev_1953
viewpoint	background	2K_dev_1953
illumination etc	background	2K_dev_1953
The current approaches do this by using mixtures of models	background	2K_dev_1953
where each mixture is designed to capture one ( or a few ) axis of variation	background	2K_dev_1953
Current methods usually rely on heuristics to capture these variations ; however	background	2K_dev_1953
it is unclear which axes of variation exist and are relevant to a particular task	background	2K_dev_1953
Another issue is the requirement of a large set of training images to capture such variations	background	2K_dev_1953
Current methods do not scale to large training sets either because of training time complexity I I or test time complexity I I	background	2K_dev_1953
	background	2K_dev_1953
	finding	2K_dev_1953
We propose a two stage data-driven process	mechanism	2K_dev_1953
which selects and learns a compact set of exemplar models These selected models have an inherent ranking	mechanism	2K_dev_1953
which can be used for anytime/budgeted detection scenarios	mechanism	2K_dev_1953
Another benefit of our approach ( beyond the computational speedup ) is that the selected set of exemplar models performs better than the entire set	mechanism	2K_dev_1953
	mechanism	2K_dev_1953
	method	2K_dev_1953
We consider the problem of discovering discriminative exemplars suitable for object detection	purpose	2K_dev_1953
In this work	purpose	2K_dev_1953
we explore the idea of compactly capturing task-appropriate variation from the data itself for object detection	purpose	2K_dev_1953
	purpose	2K_dev_1953
When people observe and interact with physical spaces	background	2K_dev_1954
they are able to associate functionality to regions in the environment Additionally	background	2K_dev_1954
we offer a preliminary glance of the applicability of Action Maps	background	2K_dev_1954
We demonstrate that by capturing appearance-based attributes of the environment and associating these attributes with activity demonstrations	finding	2K_dev_1954
our proposed mathematical framework allows for the prediction of Action Maps in new environments	finding	2K_dev_1954
	finding	2K_dev_1954
by leveraging sparse activity demonstrations recorded from an ego-centric viewpoint	mechanism	2K_dev_1954
The method we describe Our method learns and predicts `` Action Maps { '' }	mechanism	2K_dev_1954
which encode the ability for a user to perform activities at various locations	mechanism	2K_dev_1954
With the usage of an egocentric camera to observe human activities	mechanism	2K_dev_1954
our method scales with the size of the scene without the need for mounting multiple static surveillance cameras and is well-suited to the task of observing activities up-close	mechanism	2K_dev_1954
by demonstrating a proof-of-concept application in which they are used in concert with activity detections to perform localization	method	2K_dev_1954
	method	2K_dev_1954
Our goal is to automate dense functional understanding of large spaces enables functionality estimation in large scenes where people have behaved	purpose	2K_dev_1954
as well as novel scenes where no behaviors are observed	purpose	2K_dev_1954
	purpose	2K_dev_1954
Growing traffic volumes and the increasing complexity of attacks pose a constant scaling challenge for network intrusion prevention systems ( NIPS )	background	2K_dev_1955
In this respect	background	2K_dev_1955
offloading NIPS processing to compute clusters offers an immediately deployable alternative to expensive hardware upgrades	background	2K_dev_1955
	background	2K_dev_1955
Our evaluations show that SNIPS can reduce the maximum load by up to 10x while only increasing the latency by 2\ %	finding	2K_dev_1955
we present the SNIPS system We design a formal optimization framework that captures tradeoffs across scalability	mechanism	2K_dev_1955
network load	mechanism	2K_dev_1955
and latency	mechanism	2K_dev_1955
	mechanism	2K_dev_1955
We provide a practical implementation using recent advances in software-defined networking without requiring modifications to NIPS hardware	method	2K_dev_1955
on realistic topologies	method	2K_dev_1955
In practice	purpose	2K_dev_1955
however	purpose	2K_dev_1955
NIPS offloading is challenging on three fronts in contrast to passive network security functions : ( 1 ) NIPS offloading can impact other traffic engineering objectives ; ( 2 ) NIPS offloading impacts user perceived latency ; and ( 3 ) NIPS actively change traffic volumes by dropping unwanted traffic To address these challenges	purpose	2K_dev_1955
This is a difficult problem due to the drastic change in perspective between the ground and aerial imagery and the lack of environmental features for image comparison	background	2K_dev_1956
We do not rely on GPS	background	2K_dev_1956
which may be jammed or uncertain	background	2K_dev_1956
	background	2K_dev_1956
The results show that vision-based UGV localization from satellite maps is not only possible	finding	2K_dev_1956
but often provides better position estimates than GPS estimates	finding	2K_dev_1956
enabling us to improve the location estimates of Google Street View	finding	2K_dev_1956
	finding	2K_dev_1956
We propose a two-step approach : ( 1 ) the UGV images are warped to obtain a bird 's eye view of the ground	mechanism	2K_dev_1956
and ( 2 ) this view is compared to a grid of satellite locations using whole-image descriptors	mechanism	2K_dev_1956
We incorporate the air-ground matching into a particle-filter framework for localization using the best-performing descriptor	mechanism	2K_dev_1956
	mechanism	2K_dev_1956
We analyze the performance of a variety of descriptors for different satellite map sizes and various terrain and environment	method	2K_dev_1956
This paper studies the problem of matching images captured from an unmanned ground vehicle ( UGV ) to those from a satellite or high-flying vehicle	purpose	2K_dev_1956
We focus on situations where the UGV navigates in remote areas with few man-made structures	purpose	2K_dev_1956
	purpose	2K_dev_1956
State lattice-based planning has been used in navigation for ground	background	2K_dev_1957
water	background	2K_dev_1957
aerial and space robots	background	2K_dev_1957
State lattices are typically constructed of simple motion primitives connecting one state to another	background	2K_dev_1957
For example	background	2K_dev_1957
if the robot has a camera it may be able to use simple visual servoing techniques to navigate through a GPS-denied region Likewise	background	2K_dev_1957
a LIDAR may allow the robot to skirt along an environmental feature even if there is not enough information to generate an accurate pose estimate	background	2K_dev_1957
	background	2K_dev_1957
showing the practical application of this approach	finding	2K_dev_1957
	finding	2K_dev_1957
In this paper we present an expansion of the state lattice framework that allows us to incorporate controller-based motion primitives and external perceptual triggers directly into the planning process	mechanism	2K_dev_1957
We provide a formal description of our method of constructing the search graph in these cases	mechanism	2K_dev_1957
as well as presenting real-world and simulated testing data	method	2K_dev_1957
There are situations where these metric motions may not be available	purpose	2K_dev_1957
such as in GPS-denied areas	purpose	2K_dev_1957
In many of these cases	purpose	2K_dev_1957
however	purpose	2K_dev_1957
the robot may have some additional sensing capability that is not being fully utilized by the planner	purpose	2K_dev_1957
	purpose	2K_dev_1957
	background	2K_dev_1958
	finding	2K_dev_1958
This paper introduces typy	mechanism	2K_dev_1958
embedded by reflection into Python	mechanism	2K_dev_1958
typy features a fragmentary semantics	mechanism	2K_dev_1958
i	mechanism	2K_dev_1958
e	mechanism	2K_dev_1958
it delegates semantic control over each term	mechanism	2K_dev_1958
drawn from Python 's fixed concrete and abstract syntax	mechanism	2K_dev_1958
to some contextually relevant user-defined semantic fragment	mechanism	2K_dev_1958
The delegated fragment programmatically 1 ) ( following a bidirectional protocol ) ; and 2 ) by computing a translation to Python	mechanism	2K_dev_1958
We argue that this design is expressive with examples of fragments that express the static and dynamic semantics of 1 ) functional records ; 2 ) labeled sums ( with nested pattern matching a la ML ) ; 3 ) a variation on JavaScript 's prototypal object system ; and 4 ) typed foreign interfaces to Python and OpenCL	mechanism	2K_dev_1958
These semantic structures are	mechanism	2K_dev_1958
or would need to be	mechanism	2K_dev_1958
defined primitively in conventionally structured languages We further argue that this design is compositionally well-behaved It avoids the expression problem and the problems of grammar composition because the syntax is fixed Moreover	mechanism	2K_dev_1958
programs are semantically stable under fragment composition ( i	mechanism	2K_dev_1958
e	mechanism	2K_dev_1958
defining a new fragment will not change the meaning of existing program components	mechanism	2K_dev_1958
)	mechanism	2K_dev_1958
	method	2K_dev_1958
a statically typed programming language typechecks the term assigns dynamic meaning to the term	purpose	2K_dev_1958
The field of object detection has made significant advances riding on the wave of region-based ConvNets	background	2K_dev_1959
	background	2K_dev_1959
But more importantly	finding	2K_dev_1959
it yields consistent and significant boosts in detection performance Its effectiveness increases as datasets become larger and more difficult	finding	2K_dev_1959
as demonstrated by the results Moreover	finding	2K_dev_1959
combined with complementary advances in the field	finding	2K_dev_1959
OHEM leads to state-of-the-art results of 78	finding	2K_dev_1959
9\ % and 76	finding	2K_dev_1959
3\ % mAP on PASCAL VOC 2007 and 2012 respectively	finding	2K_dev_1959
	finding	2K_dev_1959
We present a simple yet surprisingly effective online hard example mining ( OHEM ) algorithm Our motivation is the same as it has always been detection datasets contain an overwhelming number of easy examples and a small number of hard examples	mechanism	2K_dev_1959
Automatic selection of these hard examples can make training more effective and efficient	mechanism	2K_dev_1959
OHEM is a simple and intuitive algorithm that eliminates several heuristics and hyperparameters in common use	mechanism	2K_dev_1959
	mechanism	2K_dev_1959
on benchmarks like PASCAL VOC 2007 and 2012	method	2K_dev_1959
on the MS COCO dataset	method	2K_dev_1959
	method	2K_dev_1959
but their training procedure still includes many heuristics and hyperparameters that are costly to tune	purpose	2K_dev_1959
for training region-based ConvNet detectors	purpose	2K_dev_1959
	background	2K_dev_1960
We also present preliminary results	finding	2K_dev_1960
In this paper	mechanism	2K_dev_1960
we present both centralized and distributed algorithms based on inter-robot relative position measurements Robot orientations are not measured	mechanism	2K_dev_1960
but are computed by our algorithms	mechanism	2K_dev_1960
Our algorithms are robust to measurement error and are useful in applications where a group of robots need to establish a common coordinate frame based on relative sensing information	mechanism	2K_dev_1960
The problem of establishing a common coordinate frame is formulated in a least squares error framework minimizing the total inconsistency of the measurements We assume that robots that can sense each other can also communicate with each other	mechanism	2K_dev_1960
In this paper	mechanism	2K_dev_1960
our key contribution is a novel asynchronous distributed algorithm for multi-robot coordinate frame alignment that does not make any assumptions about the sensor noise model After minimizing the least squares error ( LSE ) objective for coordinate frame alignment of two robots	mechanism	2K_dev_1960
we develop a novel algorithm that outperforms state-of-the-art centralized optimization algorithms for minimizing the LSE objective	mechanism	2K_dev_1960
Furthermore	mechanism	2K_dev_1960
we prove that for multi-robot systems ( a ) with redundant noiseless relative sensing information	mechanism	2K_dev_1960
we will achieve the globally optimal solution ( this is non-trivial because the LSE objective is nonconvex for our problem )	mechanism	2K_dev_1960
( b ) with noisy information but no redundant sensing ( e	mechanism	2K_dev_1960
g	mechanism	2K_dev_1960
sensing graph has a tree topology )	mechanism	2K_dev_1960
our algorithm will optimally minimize the LSE objective	mechanism	2K_dev_1960
	mechanism	2K_dev_1960
of the real-world performance of our algorithm on TurtleBots equipped with Kinect sensors	method	2K_dev_1960
	method	2K_dev_1960
for aligning coordinate frames in multi-robot systems	purpose	2K_dev_1960
When one uses a hand-held tool	background	2K_dev_1961
the fingers often make the tool to be in contact with the palm in the form of multi-contact manipulation	background	2K_dev_1961
Multi-contact manipulation is useful for object-environment interaction tasks because it can provide both powerful grasping of the object body and dexterous manipulation of the object end-effector	background	2K_dev_1961
	finding	2K_dev_1961
In this paper	mechanism	2K_dev_1961
we propose Reactional Internal Contact Hypothesis that regards the internal contact force as a reaction force By taking a handwriting task as an example	mechanism	2K_dev_1961
optimal configuration search and grasping force computation problems are addressed based on this hypothesis and	mechanism	2K_dev_1961
validated via dynamic simulation	method	2K_dev_1961
However	purpose	2K_dev_1961
dealing with the internal link contact with the object is not trivial so that the desired finger force can be reduced	purpose	2K_dev_1961
	background	2K_dev_1962
The average error and execution time are reduced by 63	finding	2K_dev_1962
6\ % and 28	finding	2K_dev_1962
5\ %	finding	2K_dev_1962
respectively	finding	2K_dev_1962
compared to the unaided trials Finally	finding	2K_dev_1962
the automated laser photocoagulation was demonstrated also in an eye phantom	finding	2K_dev_1962
including compensation for the eye movement	finding	2K_dev_1962
	finding	2K_dev_1962
using a handheld micromanipulator known as Micron	mechanism	2K_dev_1962
The novel handheld manipulator enables the automated scanning of a laser probe within a cylinder of 4 mm long and 4 mm in diameter	mechanism	2K_dev_1962
For the automation	mechanism	2K_dev_1962
the surface of the retina is reconstructed using a stereomicroscope	mechanism	2K_dev_1962
and then preplanned targets are placed on the surface	mechanism	2K_dev_1962
The laser probe is precisely located on the target via visual servoing of the aiming beam	mechanism	2K_dev_1962
while maintaining a specific distance above the surface	mechanism	2K_dev_1962
In addition	mechanism	2K_dev_1962
the system is capable of tracking the surface of the eye in order to compensate for any eye movement introduced during the operation	mechanism	2K_dev_1962
We compared the performance of the automated scanning using various control thresholds	method	2K_dev_1962
in order to find the most effective threshold in terms of accuracy and speed Given the selected threshold	method	2K_dev_1962
we conducted the handheld operation above a fixed target surface	method	2K_dev_1962
This paper presents a technique for automated intraocular laser surgery	purpose	2K_dev_1962
Transfemoral amputees often suffer from falls and a fear of falling that leads to a decreased quality of life	background	2K_dev_1963
Existing control strategies for powered knee-ankle prostheses demonstrate only limited ability to react to disturbances that induce falls such as trips	background	2K_dev_1963
slips	background	2K_dev_1963
and obstacles	background	2K_dev_1963
In contrast	background	2K_dev_1963
prior work on neuromuscular modeling of human locomotion suggests that control strategies based on local reflexes exhibit robustness to unobserved terrain such as slopes and steps These results suggest that applying the proposed control to a powered knee-ankle prosthesis will substantially improve amputee gait stability	background	2K_dev_1963
We show that the proposed control allows the amputee to walk farther over rough ground than does the state-of-the-art control	finding	2K_dev_1963
The proposed controller also more readily rejects deviations from nominal walking gaits such as those encountered during a trip	finding	2K_dev_1963
	finding	2K_dev_1963
we simulate a neuromuscular model of a transfemoral amputee walking over rough ground with a powered knee-ankle prosthesis governed by the proposed reflexive controller	mechanism	2K_dev_1963
	mechanism	2K_dev_1963
	method	2K_dev_1963
Therefore	purpose	2K_dev_1963
we propose that a powered knee-ankle prosthesis governed by reflexive local controls will more competently adapt to unperceived disturbances	purpose	2K_dev_1963
To test this hypothesis	purpose	2K_dev_1963
Control design of running robots is often based on mapping the behavior of lower order models onto the robotic systems	background	2K_dev_1964
and the robustness of running is largely determined by the robustness of these underlying models	background	2K_dev_1964
However	background	2K_dev_1964
existing implementations do not take full advantage of the stability that the low order models can provide	background	2K_dev_1964
In particular	background	2K_dev_1964
analysis of the theoretical spring mass model suggests leg placement policies that generate near deadbeat rejection of large	background	2K_dev_1964
unobserved changes in ground height	background	2K_dev_1964
	background	2K_dev_1964
and show that resulting system rejects ground disturbances of up to 25\ % leg length	finding	2K_dev_1964
adapts to persistent ground slopes	finding	2K_dev_1964
and tolerates sensor noise	finding	2K_dev_1964
signal delays	finding	2K_dev_1964
and modeling errors	finding	2K_dev_1964
The results indicate that transferring control derived within the spring mass model is an effective technique for realizing highly robust running in robotic systems	finding	2K_dev_1964
	finding	2K_dev_1964
We design a control that stably embeds the spring mass model 's behavior in a planar robot model	mechanism	2K_dev_1964
	method	2K_dev_1964
Here we show in simulation that this blind robustness to rough terrain can be carried over to bipedal robots	purpose	2K_dev_1964
	purpose	2K_dev_1964
Current GPS-based devices have difficulty localizing in cases where the GPS signal is unavailable or insufficiently accurate	background	2K_dev_1965
	background	2K_dev_1965
and show that it is effective when imagery is sparsely available	finding	2K_dev_1965
This paper presents an algorithm using vision	mechanism	2K_dev_1965
road curvature estimates	mechanism	2K_dev_1965
or a combination of both The method uses an extension of topometric localization	mechanism	2K_dev_1965
which is a hybrid between topological and metric localization	mechanism	2K_dev_1965
The extension enables localization on a network of roads rather than just a single	mechanism	2K_dev_1965
non-branching route	mechanism	2K_dev_1965
The algorithm	mechanism	2K_dev_1965
which does not rely on GPS	mechanism	2K_dev_1965
is able to localize reliably in situations where GPS-based devices fail	mechanism	2K_dev_1965
including `` urban canyons { '' } in downtown areas and along ambiguous routes with parallel roads	mechanism	2K_dev_1965
	mechanism	2K_dev_1965
We demonstrate the algorithm experimentally on several road networks in urban	method	2K_dev_1965
suburban	method	2K_dev_1965
and highway scenarios	method	2K_dev_1965
We also evaluate the road curvature descriptor	method	2K_dev_1965
for localizing a vehicle on an arbitrary road network	purpose	2K_dev_1965
Active illumination based methods have a trade-off between acquisition time and resolution of the estimated 3D shapes	background	2K_dev_1966
Multi-shot approaches can generate dense reconstructions but require stationary scenes	background	2K_dev_1966
We validate the approach	finding	2K_dev_1966
In this work	mechanism	2K_dev_1966
we develop a single-shot approach The key to our approach is an image decomposition scheme that can recover the illumination and the texture images from their mixed appearance	mechanism	2K_dev_1966
Despite the complex appearances of the illuminated textured regions	mechanism	2K_dev_1966
our method can accurately compute per pixel warps from the illumination pattern and the texture template to the observed image The texture template is obtained by interleaving the projection sequence with an all-white pattern Our estimated warping functions are reliable even with infrequent interleaved projection	mechanism	2K_dev_1966
Thus	mechanism	2K_dev_1966
we obtain detailed shape reconstruction and dense motion tracking of the textured surfaces	mechanism	2K_dev_1966
	mechanism	2K_dev_1966
on synthetic and real data containing subtle non-rigid surface deformations	method	2K_dev_1966
	method	2K_dev_1966
In contrast	purpose	2K_dev_1966
singleshot methods are applicable to dynamic objects but can only estimate sparse reconstructions and are sensitive to surface texture	purpose	2K_dev_1966
to produce dense reconstructions of highly textured objects	purpose	2K_dev_1966
	purpose	2K_dev_1966
In product design	background	2K_dev_1967
designers often generate a large number of concepts in the form of sketches and drawings to develop and communicate their ideas Concrete concepts typically evolve through a progressive refinement of initially coarse and ambiguous ideas	background	2K_dev_1967
	background	2K_dev_1967
We demonstrate and discuss preliminary results of our technique on 2D shape design problems	finding	2K_dev_1967
	finding	2K_dev_1967
we describe a predictive modeling technique This helps designers take a sneak peek at the potential end result of a developing concept	mechanism	2K_dev_1967
without forcing them to commit to the suggestion	mechanism	2K_dev_1967
	method	2K_dev_1967
However	purpose	2K_dev_1967
a lack of suitable means to visualize the emerging form at these early stages forces the designer to constantly maintain and negotiate an elusive mental image	purpose	2K_dev_1967
To assist this process that allows early incomplete 2D sketches to be transformed into suggestive complete models	purpose	2K_dev_1967
	purpose	2K_dev_1967
	background	2K_dev_1968
( ii ) we show that such properties can be successfully inferred from a single image ( iv ) we show that the 3D attributes trained on this dataset generalize to images of other ( non-sculpture ) object classes ; and furthermore ( v ) we show that the CNN also provides a shape embedding that can be used to match previously unseen sculptures largely independent of viewpoint	finding	2K_dev_1968
	finding	2K_dev_1968
To this end	mechanism	2K_dev_1968
we make a number of contributions : ( i ) we introduce and define a set of 3D Shape attributes	mechanism	2K_dev_1968
including planarity	mechanism	2K_dev_1968
symmetry and occupied space ; using a Convolutional Neural Network ( CNN ) ; ( iii ) we introduce a 143K image dataset of sculptures with 2197 works over 242 artists for training and evaluating the CNN ;	mechanism	2K_dev_1968
	method	2K_dev_1968
In this paper we investigate 3D attributes as a means to understand the shape of an object in a single image	purpose	2K_dev_1968
	purpose	2K_dev_1968
Active intracellular cargo transport is essential to survival and function of eukaryotic cells	background	2K_dev_1969
The models and related computational analysis methods developed in this study are general and can be used for studying molecular machinery and spatiotemporal dynamics of other cellular processes	background	2K_dev_1969
	background	2K_dev_1969
We validated and benchmarked the image models	finding	2K_dev_1969
To this end	mechanism	2K_dev_1969
we developed related computational image models	mechanism	2K_dev_1969
we developed anisotropic spatial density kernels for reconstruction and segmentation of related super-resolution STORM ( stochastic optical reconstruction microscopy ) images	mechanism	2K_dev_1969
	mechanism	2K_dev_1969
we developed hidden Markov models and principal component analysis for representation and analysis of movement of individual transported cargoes	mechanism	2K_dev_1969
	mechanism	2K_dev_1969
using simulated and actual experimental images	method	2K_dev_1969
	method	2K_dev_1969
How this process is controlled spatially and temporally so that the right cargo is delivered to the right destination at the right time remains poorly understood	purpose	2K_dev_1969
To address this question	purpose	2K_dev_1969
it is essential to characterize and analyze the molecular machinery and spatiotemporal behavior of intracellular transport	purpose	2K_dev_1969
Specifically	purpose	2K_dev_1969
to study the molecular machinery of intracellular transport	purpose	2K_dev_1969
To study the spatiotemporal behavior of intracellular transport	purpose	2K_dev_1969
In addition	background	2K_dev_1970
the topologies predicted by the proposed method can be used as effective initial conditions for conventional topology optimization routines	background	2K_dev_1970
resulting in substantial performance gains	background	2K_dev_1970
We discuss the advantages and limitations of the presented approach and show its performance on a number of examples	background	2K_dev_1970
	background	2K_dev_1970
The results indicate that when there is an underlying structure in the set of existing solutions	finding	2K_dev_1970
the proposed method can successfully predict the optimal topologies in novel loading configurations	finding	2K_dev_1970
	finding	2K_dev_1970
data-driven approach Our approach takes as input a set of images representing optimal 2-D topologies	mechanism	2K_dev_1970
each resulting from a random loading configuration applied to a common boundary support condition	mechanism	2K_dev_1970
These images represented in a high dimensional feature space are projected into a lower dimensional space using component analysis	mechanism	2K_dev_1970
Using the resulting components	mechanism	2K_dev_1970
a mapping between the loading configurations and the optimal topologies is learned	mechanism	2K_dev_1970
	mechanism	2K_dev_1970
From this mapping	method	2K_dev_1970
we estimate the optimal topologies for novel loading configurations	method	2K_dev_1970
We explore the feasibility and performance of a to topology optimization problems involving structural mechanics	purpose	2K_dev_1970
	purpose	2K_dev_1970
An increasing number of mobile devices are capable of automatically sensing and recording rich information about the surrounding environment	background	2K_dev_1971
Spatial locations of such data can help to better learn about the environment	background	2K_dev_1971
	background	2K_dev_1971
We will show robustness the ability to propose coarse sensor noise errors	finding	2K_dev_1971
	finding	2K_dev_1971
We focus on devices equipped with odometry sensors that capture changes in motion	mechanism	2K_dev_1971
Odometry suffers from cumulative errors of dead reckoning but it captures the relative shape of the traversed path well	mechanism	2K_dev_1971
Our approach will correct such errors by matching the shape of the trajectory from odometry to traversable paths of a known map	mechanism	2K_dev_1971
Our algorithm is inspired by prior vehicular GPS map matching techniques that snap global GPS measurements to known roads	mechanism	2K_dev_1971
We similarly wish to snap the trajectory from odometry to known hallways	mechanism	2K_dev_1971
Several modifications are required to ensure these techniques are robust when given relative measurements from odometry	mechanism	2K_dev_1971
If we assume an office-like environment with only straight hallways	mechanism	2K_dev_1971
then a significant rotation indicates a transition to another hallway	mechanism	2K_dev_1971
As a result	mechanism	2K_dev_1971
we partition the trajectory into line segments based on significant turns	mechanism	2K_dev_1971
Each trajectory segment is snapped to a corresponding hallway that best maintains the shape of the original trajectory	mechanism	2K_dev_1971
These snapping decisions are made based on the similarity of the two curves as well as the rotation to transition between hallways	mechanism	2K_dev_1971
under different types of noise in complex environments and	method	2K_dev_1971
In this work	purpose	2K_dev_1971
we address the problem of identifying the locations visited by a mobile device as it moves within an indoor environment	purpose	2K_dev_1971
	purpose	2K_dev_1971
	background	2K_dev_1972
	finding	2K_dev_1972
the proposed behavioral planning architecture improves the driving quality considerably	finding	2K_dev_1972
with a 90	finding	2K_dev_1972
3\ % reduction of required computation time in representative scenarios	finding	2K_dev_1972
	finding	2K_dev_1972
In this paper	mechanism	2K_dev_1972
we propose a novel planning framework A reference planning layer first generates kinematically and dynamically feasible paths assuming no obstacles on the road	mechanism	2K_dev_1972
then a behavioral planning layer takes static and dynamic obstacles into account	mechanism	2K_dev_1972
Instead of directly commanding a desired trajectory	mechanism	2K_dev_1972
it searches for the best directives for the controller	mechanism	2K_dev_1972
such as lateral bias and distance keeping aggressiveness	mechanism	2K_dev_1972
It also considers the social cooperation between the autonomous vehicle and surrounding cars	mechanism	2K_dev_1972
	mechanism	2K_dev_1972
Based on experimental results from both simulation and a real autonomous vehicle platform	method	2K_dev_1972
that can greatly improve the level of intelligence and driving quality of autonomous vehicles	purpose	2K_dev_1972
	purpose	2K_dev_1972
Localization is a central problem for intelligent vehicles	background	2K_dev_1973
Visual localization can supplement or replace GPS-based localization approaches in situations where GPS is unavailable or inaccurate Although visual localization has been demonstrated in a variety of algorithms and systems	background	2K_dev_1973
the problem of how to best configure such a system remains largely an open question	background	2K_dev_1973
Design choices	background	2K_dev_1973
such as `` where should the camera be placed ? { '' } and `` how should it be oriented ? { '' } can have substantial effect on the cost and robustness of a fielded intelligent vehicle	background	2K_dev_1973
	background	2K_dev_1973
	finding	2K_dev_1973
of a visual localization algorithm	mechanism	2K_dev_1973
We ground the investigation using extensive field testing	method	2K_dev_1973
and the data sets used for the analysis are made available for comparative evaluation	method	2K_dev_1973
	method	2K_dev_1973
This paper analyzes how different sensor configuration parameters and environmental conditions affect visual localization performance with the goal of understanding what causes certain configurations to perform better than others and providing general principles for configuring systems for visual localization	purpose	2K_dev_1973
This problem has received much attention It is known that the RHS has to be Omega ( epsilon ( -2 ) log m ) times the left-hand sides	background	2K_dev_1974
where m is the number of constraints	background	2K_dev_1974
	background	2K_dev_1974
which we hope will be useful in other contexts	background	2K_dev_1974
	finding	2K_dev_1974
Our algorithms construct dual solutions using a regret-minimizing online learning algorithm in a black-box fashion	mechanism	2K_dev_1974
and use them to construct primal solutions	mechanism	2K_dev_1974
The adversarial guarantee that holds for the constructed duals help us to take care of most of the correlations that arise in the algorithm ; the remaining correlations are handled via martingale concentration and maximal inequalities	mechanism	2K_dev_1974
These ideas lead to conceptually simple and modular algorithms	mechanism	2K_dev_1974
	method	2K_dev_1974
Illumination defocus and global illumination effects are major challenges for active illumination scene recovery algorithms	background	2K_dev_1975
	background	2K_dev_1975
We demonstrate the effectiveness of our approach	finding	2K_dev_1975
In this paper	mechanism	2K_dev_1975
we develop an algorithm for scene recovery in the presence of both defocus and global light transport effects such as interreflections and sub-surface scattering	mechanism	2K_dev_1975
Our method extends the working volume by using structured light patterns at multiple projector focus settings	mechanism	2K_dev_1975
A careful characterization of projector blur allows us to decode even partially out-of-focus patterns This enables our algorithm to recover scene shape and the direct and global illumination components over a large depth of field while still using a relatively small number of images ( typically 25-30 )	mechanism	2K_dev_1975
	mechanism	2K_dev_1975
by recovering high quality depth maps of scenes containing objects made of optically challenging materials such as wax	method	2K_dev_1975
marble	method	2K_dev_1975
soap	method	2K_dev_1975
colored glass and translucent plastic	method	2K_dev_1975
	method	2K_dev_1975
Illumination defocus limits the working volume of projector-camera systems and global illumination can induce large errors in shape estimates	purpose	2K_dev_1975
	purpose	2K_dev_1975
Bundle adjustment jointly optimizes camera intrinsics and extrinsics and 3D point triangulation to reconstruct a static scene	background	2K_dev_1976
Because the videos are aligned with sub-frame precision	finding	2K_dev_1976
we reconstruct 3D trajectories of unconstrained outdoor activities at much higher temporal resolution than the input videos	finding	2K_dev_1976
	finding	2K_dev_1976
In this paper	mechanism	2K_dev_1976
we present a spatiotemporal bundle adjustment approach Key to our joint optimization is the careful integration of physics-based motion priors within the reconstruction pipeline	mechanism	2K_dev_1976
validated on a large motion capture corpus	mechanism	2K_dev_1976
We present an end-to-end pipeline that takes multiple uncalibrated and unsynchronized video streams and produces a dynamic reconstruction of the event	mechanism	2K_dev_1976
	mechanism	2K_dev_1976
	method	2K_dev_1976
The triangulation constraint however is invalid for moving points captured in multiple unsynchronized videos and bundle adjustment is not purposed to estimate the temporal alignment between cameras that jointly optimizes four coupled sub-problems : estimating camera intrinsics and extrinsics	purpose	2K_dev_1976
triangulating 3D static points	purpose	2K_dev_1976
as well as subframe temporal alignment between cameras and estimating 3D trajectories of dynamic points	purpose	2K_dev_1976
	purpose	2K_dev_1976
Turbulence is studied extensively in remote sensing	background	2K_dev_1977
astronomy	background	2K_dev_1977
meteorology	background	2K_dev_1977
aerodynamics and fluid dynamics	background	2K_dev_1977
The strength of turbulence is a statistical measure of local variations in the turbulent medium	background	2K_dev_1977
It influences engineering decisions made in these domains	background	2K_dev_1977
Turbulence strength ( TS ) also affects safety of aircraft and tethered balloons	background	2K_dev_1977
and reliability of free-space electromagnetic relays	background	2K_dev_1977
	background	2K_dev_1977
	finding	2K_dev_1977
	mechanism	2K_dev_1977
using videos captured from different viewpoints	mechanism	2K_dev_1977
We formulate this as a linear tomography problem with a structure unique to turbulence fields	mechanism	2K_dev_1977
No tight synchronization between cameras is needed Thus	mechanism	2K_dev_1977
realization is very simple to deploy using consumer-grade cameras	mechanism	2K_dev_1977
	mechanism	2K_dev_1977
We experimentally demonstrate this both in a lab and in a large-scale uncontrolled complex outdoor environment	method	2K_dev_1977
which includes industrial	method	2K_dev_1977
rural and urban areas	method	2K_dev_1977
	method	2K_dev_1977
We show that it is possible to estimate TS	purpose	2K_dev_1977
without having to reconstruct instantaneous fluid flow fields	purpose	2K_dev_1977
Instead	purpose	2K_dev_1977
the TS field can be directly recovered	purpose	2K_dev_1977
passively	purpose	2K_dev_1977
In many behavioral domains	background	2K_dev_1978
such as facial expression and gesture	background	2K_dev_1978
sparse structure is prevalent	background	2K_dev_1978
	background	2K_dev_1978
KSS outperformed both sparse and non-sparse methods that utilize complex image features and their temporal extensions	finding	2K_dev_1978
In the case of early facial event classification KSS had 10\ % higher accuracy over kernel SVM methods ( 1 )	finding	2K_dev_1978
	finding	2K_dev_1978
We propose a Kernel Structured Sparsity ( KSS ) method that can handle both the temporal alignment problem and the structured sparse reconstruction within a common framework	mechanism	2K_dev_1978
and it can rely on simple features	mechanism	2K_dev_1978
We characterize spatio-temporal events as time-series of motion patterns and by utilizing time-series kernels we apply standard structured-sparse coding techniques to tackle this important problem	mechanism	2K_dev_1978
	mechanism	2K_dev_1978
We evaluated the KSS method using both gesture and facial expression datasets that include spontaneous behavior and differ in degree of difficulty and type of ground truth coding	method	2K_dev_1978
as measured by F-1 score	method	2K_dev_1978
This sparsity would be well suited for event detection but for one problem	purpose	2K_dev_1978
Features typically are confounded by alignment error in space and time	purpose	2K_dev_1978
As a consequence	purpose	2K_dev_1978
high-dimensional representations such as SIFT and Gabor features have been favored despite their much greater computational cost and potential loss of information	purpose	2K_dev_1978
	purpose	2K_dev_1978
The primary goal of an automotive headlight is to improve safety in low light and poor weather conditions	background	2K_dev_1979
But	background	2K_dev_1979
despite decades of innovation on light sources	background	2K_dev_1979
more than half of accidents occur at night even with less traffic on the road Recent developments in adaptive lighting have addressed some limitations of standard headlights	background	2K_dev_1979
	background	2K_dev_1979
Anti-glare high beams	finding	2K_dev_1979
improved driver visibility during snowstorms	finding	2K_dev_1979
increased contrast of lanes	finding	2K_dev_1979
markings	finding	2K_dev_1979
and sidewalks	finding	2K_dev_1979
and early visual warning of obstacles are demonstrated	finding	2K_dev_1979
	finding	2K_dev_1979
This paper introduces an ultra-low latency reactive visual system Our single hardware design can be programmed to perform a variety of tasks	mechanism	2K_dev_1979
	method	2K_dev_1979
however	purpose	2K_dev_1979
they have limited flexibility - switching between high and low beams	purpose	2K_dev_1979
turning off beams toward the opposing lane	purpose	2K_dev_1979
or rotating the beam as the vehicle turns - and are not designed for all driving environments	purpose	2K_dev_1979
that can sense	purpose	2K_dev_1979
react	purpose	2K_dev_1979
and adapt quickly to any environment while moving at highway speeds	purpose	2K_dev_1979
	purpose	2K_dev_1979
	background	2K_dev_1980
experiments show that our method achieves good performance for parsing human motions Furthermore	finding	2K_dev_1980
we found that our method achieves better performance by using unlabeled video than adding more labeled pose images into the training set	finding	2K_dev_1980
	finding	2K_dev_1980
In this paper	mechanism	2K_dev_1980
we propose a method We use the training samples from a public image pose dataset to avoid the tediousness of labeling video streams There are two main problems confronted	mechanism	2K_dev_1980
First	mechanism	2K_dev_1980
the distribution of images and videos are different	mechanism	2K_dev_1980
Second	mechanism	2K_dev_1980
no temporal information is available in the training images	mechanism	2K_dev_1980
To smooth the inconsistency between the labeled images and unlabeled videos	mechanism	2K_dev_1980
our algorithm iteratively incorporates the pose knowledge harvested from the testing videos into the image pose detector via an adjust-and-refine method	mechanism	2K_dev_1980
During this process	mechanism	2K_dev_1980
continuity and tracking constraints are imposed to leverage the spatio-temporal information only available in videos	mechanism	2K_dev_1980
	mechanism	2K_dev_1980
For our experiments	method	2K_dev_1980
we have collected two datasets from YouTube and	method	2K_dev_1980
to parse human motion in unconstrained Internet videos without labeling any videos for training	purpose	2K_dev_1980
	purpose	2K_dev_1980
Forecasting human activities from visual evidence is an emerging area of research which aims to allow computational systems to make predictions about unseen human actions	background	2K_dev_1981
results show that our proposed method is able to properly model human interactions in a high dimensional space of human poses	finding	2K_dev_1981
results show that our method is able to generate highly plausible simulations of human interaction	finding	2K_dev_1981
We model dual-agent interactions as an optimal control problem	mechanism	2K_dev_1981
where the actions of the initiating agent induce a cost topology over the space of reactive poses - a space in which the reactive agent plans an optimal pose trajectory The technique developed in this work employs a kernel-based reinforcement learning approximation of the soft maximum value function to deal with the high-dimensional nature of human motion and applies a mean-shift procedure over a continuous cost function to infer a smooth reaction sequence	mechanism	2K_dev_1981
	mechanism	2K_dev_1981
Experimental When compared to several baseline models	method	2K_dev_1981
We explore the task of activity forecasting in the context of dual-agent interactions to understand how the actions of one person can be used to predict the actions of another	purpose	2K_dev_1981
The differential temporal dynamic logic dTL ( 2 ) is a logic to specify temporal properties of hybrid systems	background	2K_dev_1982
It combines differential dynamic logic with temporal logic to reason about the intermediate states reached by a hybrid system	background	2K_dev_1982
The logic dTL ( 2 ) supports some linear time temporal properties of LTL	background	2K_dev_1982
It extends differential temporal dynamic logic dTL with nested temporalities	background	2K_dev_1982
	background	2K_dev_1982
	finding	2K_dev_1982
We provide a semantics and a proof system and show its usefulness for nontrivial temporal properties of hybrid systems	mechanism	2K_dev_1982
We take particular care to handle the case of alternating universal dynamic and existential temporal modalities and its dual	mechanism	2K_dev_1982
solving an open problem formulated in previous work	mechanism	2K_dev_1982
	mechanism	2K_dev_1982
	method	2K_dev_1982
for the logic dTL ( 2 )	purpose	2K_dev_1982
	purpose	2K_dev_1982
	background	2K_dev_1983
We demonstrate improvements over the state-of-the art and produce interpretations of the scene that link large planar surfaces	finding	2K_dev_1983
	finding	2K_dev_1983
In this work	mechanism	2K_dev_1983
we present a method We propose the use of midlevel constraints for 3D scene understanding in the form of convex and concave edges and introduce a generic framework capable of incorporating these and other constraints Our method takes a variety of cues and uses them to infer a consistent interpretation of the scene	mechanism	2K_dev_1983
	method	2K_dev_1983
for single-view reasoning about 3D surfaces and their relationships	purpose	2K_dev_1983
	purpose	2K_dev_1983
Cyber-physical systems ( CPS )	background	2K_dev_1984
which are computerized systems directly interfacing their real-world surroundings	background	2K_dev_1984
leverage the construction of increasingly autonomous systems	background	2K_dev_1984
To meet the high safety demands of CPS	background	2K_dev_1984
verification of their behavior is crucial	background	2K_dev_1984
which has led to a wide range of tools for modeling and verification of hybrid systems	background	2K_dev_1984
These tools are often used in combination	background	2K_dev_1984
because they employ a wide range of different formalisms for modeling	background	2K_dev_1984
and aim at distinct verification goals and techniques and propose future extension	background	2K_dev_1984
	background	2K_dev_1984
Furthermore	finding	2K_dev_1984
we illustrate how the CRM can support comparing models	finding	2K_dev_1984
we unify different terminologies and concepts of a variety of modeling and verification tools in a conceptual reference model ( CRM )	mechanism	2K_dev_1984
	method	2K_dev_1984
To manage and exchange knowledge in the verification process and to overcome a lack of a common classification	purpose	2K_dev_1984
	purpose	2K_dev_1984
Demographic information has a rich context from which to make decisions about how to filter or individualize computer users in forensic analysis	background	2K_dev_1985
showed that these demographics can be accurately inferred from user interaction behavior	finding	2K_dev_1985
with recognition rates expressed by the area under the ROC curve ( AUC ) ranging from 82	finding	2K_dev_1985
11 \ % to 87	finding	2K_dev_1985
32 \ %	finding	2K_dev_1985
by analyzing the interactions between users and computers	mechanism	2K_dev_1985
From user interaction data	mechanism	2K_dev_1985
we extracted keystroke timing and mouse movement features	mechanism	2K_dev_1985
and developed weighted random forest classifiers for five demographic traits : gender	mechanism	2K_dev_1985
age	mechanism	2K_dev_1985
ethnicity	mechanism	2K_dev_1985
handedness	mechanism	2K_dev_1985
and language	mechanism	2K_dev_1985
	mechanism	2K_dev_1985
We conducted a field study that gathered users ' keystroke and mouse data during interaction with a computer	method	2K_dev_1985
Experiments	method	2K_dev_1985
Although current explorations into technologies such as face and fingerprint analysis have seen varying rates of success	purpose	2K_dev_1985
two main problems limit their applicability in the context of computer crimes : they can be intrusive	purpose	2K_dev_1985
and they can require costly equipment	purpose	2K_dev_1985
Our solution is to determine users ' demographic traits	purpose	2K_dev_1985
Refactoring of code is a common device in software engineering	background	2K_dev_1986
As cyber-physical systems ( CPS ) become ever more complex	background	2K_dev_1986
similar engineering practices become more common in CPS development	background	2K_dev_1986
Proper safe developments of CPS designs are accompanied by a proof of correctness	background	2K_dev_1986
	background	2K_dev_1986
For some of these we can give strong results by proving on a meta-level that they are correct for showing that the refactoring respects the refinement relation	finding	2K_dev_1986
	finding	2K_dev_1986
we develop proof-aware refactorings for CPS	mechanism	2K_dev_1986
That is	mechanism	2K_dev_1986
we study model transformations on CPS and show how they correspond to relations on correctness proofs	mechanism	2K_dev_1986
As the main technical device	mechanism	2K_dev_1986
we show how the impact of model transformations on correctness can be characterized by different notions of refinement in differential dynamic logic	mechanism	2K_dev_1986
	mechanism	2K_dev_1986
Furthermore	method	2K_dev_1986
we demonstrate the application of refinements on a series of safety-preserving and liveness-preserving refactorings	method	2K_dev_1986
Where this is impossible	method	2K_dev_1986
we construct proof obligations	method	2K_dev_1986
Since the inherent complexities of CPS practically mandate iterative development	purpose	2K_dev_1986
frequent changes of models are standard practice	purpose	2K_dev_1986
but require reverification of the resulting models after every change	purpose	2K_dev_1986
To overcome this issue	purpose	2K_dev_1986
	purpose	2K_dev_1986
These results suggest that	background	2K_dev_1987
when carefully designed	background	2K_dev_1987
learning by teaching can support students to not only learn cognitive skills but also employ meta-cognitive skills for effective tutoring	background	2K_dev_1987
	background	2K_dev_1987
The data showed that students with the meta-cognitive help showed better problem selection and scored higher on the post-test than those who tutored SimStudent without the meta-cognitive help	finding	2K_dev_1987
	finding	2K_dev_1987
	mechanism	2K_dev_1987
Students learned to solve algebraic equations by tutoring a teachable agent	method	2K_dev_1987
called SimStudent	method	2K_dev_1987
using an online learning environment	method	2K_dev_1987
called APLUS	method	2K_dev_1987
A version of APLUS was developed to provide meta-cognitive help on what problems students should teach	method	2K_dev_1987
as well as when to quiz SimStudent	method	2K_dev_1987
A classroom study comparing APLUS with and without the metacognitive help was conducted with 173 seventh to ninth grade students	method	2K_dev_1987
	method	2K_dev_1987
This paper investigates the effect of meta-cognitive help in the context of learning by teaching	purpose	2K_dev_1987
	purpose	2K_dev_1987
Recent work has shown that features such as hand appearance	background	2K_dev_1988
object attributes	background	2K_dev_1988
local hand motion and camera ego-motion are important for characterizing first-person actions	background	2K_dev_1988
to highlight the importance of network design decisions	background	2K_dev_1988
	background	2K_dev_1988
we show that our proposed architecture naturally learns features that capture object attributes and hand-object configurations	finding	2K_dev_1988
show that our deep architecture enables recognition rates that significantly outperform state-of-the-art techniques - an average 6	finding	2K_dev_1988
6\ % increase in accuracy over all datasets	finding	2K_dev_1988
the performance of individual recognition tasks also increase by 30\ % ( actions ) and 14\ % ( objects )	finding	2K_dev_1988
We also include the results	finding	2K_dev_1988
we propose a twin stream network architecture	mechanism	2K_dev_1988
where one stream analyzes appearance information and the other stream analyzes motion information Our appearance stream encodes prior knowledge of the egocentric paradigm by explicitly training the network to segment hands and localize objects	mechanism	2K_dev_1988
Furthermore	mechanism	2K_dev_1988
by learning to recognize objects	mechanism	2K_dev_1988
actions and activities jointly	mechanism	2K_dev_1988
By visualizing certain neuron activation of our network	method	2K_dev_1988
Our extensive experiments on benchmark egocentric action datasets of extensive ablative analysis	method	2K_dev_1988
We bring together ideas from recent work on feature design for egocentric action recognition under one framework by exploring the use of deep convolutional neural networks ( CNN )	purpose	2K_dev_1988
To integrate these ideas under one framework	purpose	2K_dev_1988
Collaborative learning has been shown to be beneficial for older students	background	2K_dev_1989
but there has not been much research to show if these results transfer to elementary school students	background	2K_dev_1989
In addition	background	2K_dev_1989
collaborative and individual modes of instruction may be better for acquiring different types of knowledge	background	2K_dev_1989
Collaborative Intelligent Tutoring Systems ( ITS ) provide a platform that may be able to provide both the cognitive and collaborative support that students need This work indicates that by embedding collaboration scripts in ITSs	background	2K_dev_1989
collaborative learning can be an effective instructional method even with young children	background	2K_dev_1989
	background	2K_dev_1989
The collaborative groups had the same learning gains as the individual groups in both the procedural and conceptual learning conditions but were able to do so with fewer problems	finding	2K_dev_1989
	mechanism	2K_dev_1989
	method	2K_dev_1989
This paper presents a study comparing collaborative and individual methods while receiving instruction on either procedural or conceptual knowledge	purpose	2K_dev_1989
	purpose	2K_dev_1989
The amount of data available to build simulation models of schools is immense	background	2K_dev_1990
but using these data effectively is difficult	background	2K_dev_1990
	finding	2K_dev_1990
In response	mechanism	2K_dev_1990
we advocate a Complex Adaptive Systems approach By simulating agent-level attributes rather than system-level attributes	mechanism	2K_dev_1990
the modeling is inherently transparent	mechanism	2K_dev_1990
easily adjustable	mechanism	2K_dev_1990
and facilitates analysis of the system due to the analogous nature of the simulated agents to real-world entities	mechanism	2K_dev_1990
	mechanism	2K_dev_1990
We explore the design a CAS model of schools using multiple levels of data from varied data streams	method	2K_dev_1990
	method	2K_dev_1990
Traditional methods of computer modeling of educational systems often either lack transparency in their implementation	purpose	2K_dev_1990
are complex	purpose	2K_dev_1990
and often do not natively simulate nonlinear systems	purpose	2K_dev_1990
towards modeling and data mining	purpose	2K_dev_1990
	purpose	2K_dev_1990
Heterogeneity of wireless networks has become an increasing problem in the wireless spectrum that breaks down spectrum sharing and exacerbates interference	background	2K_dev_1991
	background	2K_dev_1991
	finding	2K_dev_1991
In this paper	mechanism	2K_dev_1991
we focus on the potential of spectrum management We introduce novel components to a spectrum management system that overcomes limitations of current models that have remained relatively focused on homogeneous environments	mechanism	2K_dev_1991
Our approach is a centralized one	mechanism	2K_dev_1991
where we analyze information collected from heterogeneous monitors available today	mechanism	2K_dev_1991
structure the information in a hypergraph	mechanism	2K_dev_1991
and perform an analysis to detect heterogeneous conflicts Introducing a mixed integer program ( in addition to other novel components )	mechanism	2K_dev_1991
we reconfigure devices in the spectrum to avoid conflicts and improve performance	mechanism	2K_dev_1991
	mechanism	2K_dev_1991
	method	2K_dev_1991
Many coexistence techniques have been proposed to alleviate this interference	purpose	2K_dev_1991
however	purpose	2K_dev_1991
they are difficult to deploy due to changes needed in the protocols	purpose	2K_dev_1991
overhead	purpose	2K_dev_1991
and rapid changes in technology to provide a long-term solution	purpose	2K_dev_1991
When deployed in automated speech recognition ( ASR )	background	2K_dev_1992
deep neural networks ( DNNs ) can be treated as a complex feature extractor plus a simple linear classifier	background	2K_dev_1992
Previous work has investigated the utility of multilingual DNNs acting as language-universal feature extractors ( LUFEs )	background	2K_dev_1992
	background	2K_dev_1992
Each of the proposed techniques results in word error rate reduction compared with the existing DNN-based LUFEs	finding	2K_dev_1992
Combining the two methods together brings additional improvement on the target language	finding	2K_dev_1992
In this paper	mechanism	2K_dev_1992
we explore different strategies First	mechanism	2K_dev_1992
we replace the standard sigmoid nonlinearity with the recently proposed maxout units	mechanism	2K_dev_1992
The resulting maxout LUFEs have the nice property of generating sparse feature representations	mechanism	2K_dev_1992
Second	mechanism	2K_dev_1992
the convolutional neural network ( CNN ) architecture is applied	mechanism	2K_dev_1992
We evaluate the performance of LUFEs on a cross-language ASR task	method	2K_dev_1992
	method	2K_dev_1992
to further improve LUFEs	purpose	2K_dev_1992
to obtain more invariant feature space	purpose	2K_dev_1992
	purpose	2K_dev_1992
Recent studies in computer vision have shown that	background	2K_dev_1993
while practically invisible to a human observer	background	2K_dev_1993
skin color changes due to blood flow can be captured on face videos and	background	2K_dev_1993
surprisingly	background	2K_dev_1993
be used to estimate the heart rate ( HR )	background	2K_dev_1993
While considerable progress has been made in the last few years	background	2K_dev_1993
still many issues remain open	background	2K_dev_1993
	background	2K_dev_1993
that the proposed approach significantly outperforms state-of-the-art HR estimation methods in naturalistic conditions	finding	2K_dev_1993
Opposite to previous approaches that estimate the HR by processing all the skin pixels inside a fixed region of interest	mechanism	2K_dev_1993
we introduce a strategy Our approach	mechanism	2K_dev_1993
inspired by recent advances on matrix completion theory	mechanism	2K_dev_1993
allows us to predict the HR while simultaneously discover the best regions of the face to be used for estimation	mechanism	2K_dev_1993
	mechanism	2K_dev_1993
Thorough experimental evaluation conducted on public benchmarks suggests	method	2K_dev_1993
In particular	purpose	2K_dev_1993
stateof- the-art approaches are not robust enough to operate in natural conditions ( e	purpose	2K_dev_1993
g	purpose	2K_dev_1993
in case of spontaneous movements	purpose	2K_dev_1993
facial expressions	purpose	2K_dev_1993
or illumination changes )	purpose	2K_dev_1993
to dynamically select face regions useful for robust HR estimation	purpose	2K_dev_1993
	purpose	2K_dev_1993
Multilingual deep neural networks ( DNNs ) can act as deep feature extractors and have been applied successfully to cross language acoustic modeling	background	2K_dev_1994
Learning these feature extractors becomes an expensive task	background	2K_dev_1994
because of the enlarged multilingual training data and the sequential nature of stochastic gradient descent ( SGD )	background	2K_dev_1994
	background	2K_dev_1994
better acceleration but worse recognition performance	finding	2K_dev_1994
	finding	2K_dev_1994
We propose the DistModel and DistLang frameworks which distribute feature extractor learning by models and languages respectively The time-synchronous DistModel has the nice property of tolerating infrequent model averaging	mechanism	2K_dev_1994
With 3 GPUs	mechanism	2K_dev_1994
DistModel achieves 2	mechanism	2K_dev_1994
6x speed-up and causes no loss on word error rates	mechanism	2K_dev_1994
	mechanism	2K_dev_1994
When using DistLang	method	2K_dev_1994
we observe Further evaluations are conducted to scale DistModel to more languages and GPU cards	method	2K_dev_1994
This paper investigates strategies to accelerate the learning process over multiple GPU cards	purpose	2K_dev_1994
	purpose	2K_dev_1994
Solving this problem is important for ensuring correctness of the decision procedures	background	2K_dev_1995
At the same time	background	2K_dev_1995
it is a new approach for automated theorem proving over real numbers	background	2K_dev_1995
	background	2K_dev_1995
we demonstrate how proofs generated from our solver can establish many nonlinear lemmas	finding	2K_dev_1995
We design a first-order calculus	mechanism	2K_dev_1995
and transform the computational steps of constraint solving into logic proofs	mechanism	2K_dev_1995
which are then validated using proof-checking algorithms	mechanism	2K_dev_1995
As an application	method	2K_dev_1995
in the the formal proof of the Kepler Conjecture	method	2K_dev_1995
We show how to generate and validate logical proofs of unsatisfiability from delta-complete decision procedures that rely on error-prone numerical algorithms	purpose	2K_dev_1995
	purpose	2K_dev_1995
Good communication is critical to seamless human-robot interaction	background	2K_dev_1996
Among numerous communication channels	background	2K_dev_1996
showing that the resulting pointing configurations make the goal object easier to infer for novice users	finding	2K_dev_1996
We propose a mathematical model	mechanism	2K_dev_1996
We study the implications of legibility on pointing	method	2K_dev_1996
e	method	2K_dev_1996
g	method	2K_dev_1996
that the robot will sometimes need to trade off efficiency for the sake of clarity	method	2K_dev_1996
Finally	method	2K_dev_1996
we test how well our model works in practice in a series of user studies	method	2K_dev_1996
	method	2K_dev_1996
here we focus on gestures	purpose	2K_dev_1996
and in particular on spacial deixis : pointing at objects in the environment in order to reference them	purpose	2K_dev_1996
that enables robots to generate pointing configurations that make the goal object as clear as possible - pointing configurations that are legible	purpose	2K_dev_1996
	purpose	2K_dev_1996
For compelling human-robot interaction	background	2K_dev_1997
social gestures are widely believed to be important	background	2K_dev_1997
We conclude that social gesturing of a robot enhances physical interactions between humans and robots	background	2K_dev_1997
	background	2K_dev_1997
For half of the cases in which the catch was unsuccessful	finding	2K_dev_1997
the robot made a physical gesture	finding	2K_dev_1997
such as shrugging its shoulders	finding	2K_dev_1997
shaking its head	finding	2K_dev_1997
or throwing up its hands	finding	2K_dev_1997
In the other half of cases	finding	2K_dev_1997
no gestures were produced Participants smiled more and rated the robot as more engaging	finding	2K_dev_1997
responsive	finding	2K_dev_1997
and humanlike when it gestured	finding	2K_dev_1997
	finding	2K_dev_1997
	mechanism	2K_dev_1997
Human participants repeatedly threw a ball to the robot	method	2K_dev_1997
which attempted to catch it	method	2K_dev_1997
If the catch was successful	method	2K_dev_1997
the robot threw the ball back to the human	method	2K_dev_1997
We used questionnaires and smile detection to compare participants ' feelings about the robot when it made gestures after failure versus when it did not	method	2K_dev_1997
	method	2K_dev_1997
This paper investigates the effects of adding gestures to a physical game between a human and a humanoid robot	purpose	2K_dev_1997
There is a saying that 95\ % of communication is body language	background	2K_dev_1998
but few robot systems today make effective use of that ubiquitous channel and could be used to help design more effectively expressive mobile robots	background	2K_dev_1998
	background	2K_dev_1998
Results indicate that the machine analysis ( 41	finding	2K_dev_1998
7\ % match between intended and classified manner ) achieves similar accuracy overall compared to a human benchmark ( 41	finding	2K_dev_1998
2\ % match )	finding	2K_dev_1998
We conclude that these motion features perform well for analyzing expression in low degree of freedom systems	finding	2K_dev_1998
The proposed work presents a principled set of motion features based on the Laban Effort system	mechanism	2K_dev_1998
a widespread and extensively tested acting ontology for the dynamics of `` how { '' } we enact motion	mechanism	2K_dev_1998
The features allow us	mechanism	2K_dev_1998
in future work	mechanism	2K_dev_1998
using position ( x	mechanism	2K_dev_1998
y ) and orientation ( theta )	mechanism	2K_dev_1998
We formulate representative features for each Effort and parameterize them on expressive motion sample trajectories collected from experts in robotics and theater	mechanism	2K_dev_1998
We then produce classifiers for different `` manners { '' } of moving and	mechanism	2K_dev_1998
assess the quality of results by comparing them to the humans labeling the same set of paths on Amazon Mechanical Turk	method	2K_dev_1998
Motion is an essential area of social communication that will enable robots and people to collaborate naturally	purpose	2K_dev_1998
develop rapport	purpose	2K_dev_1998
and seamlessly share environments	purpose	2K_dev_1998
to analyze and generate expressive motion	purpose	2K_dev_1998
For service robots operating in indoor environments	background	2K_dev_1999
the crucial task of navigation is often complicated by the presence of people	background	2K_dev_1999
Simply treating humans in the environment as additional ( often moving ) obstacles can violate the complex set of social rules by which people navigate around each other	background	2K_dev_1999
	background	2K_dev_1999
We found that both approaches were rated comparably when the robot approached from the participant 's front or side	finding	2K_dev_1999
but the social approach was significantly preferred when the robot came from behind the participant	finding	2K_dev_1999
	finding	2K_dev_1999
We present a method of	mechanism	2K_dev_1999
We also conducted a study in which a robot approached participants using both these social paths and straight-line	method	2K_dev_1999
nonsocial paths	method	2K_dev_1999
	method	2K_dev_1999
In contrast	purpose	2K_dev_1999
emulating human behavior and navigating in a socially appropriate manner could positively affect people 's comfort with a robot 's presence and motion	purpose	2K_dev_1999
generating social paths for a robot to approach a person based on a small amount of human data	purpose	2K_dev_1999
	purpose	2K_dev_1999
Human operators in today 's control centers	background	2K_dev_2000
such as air or road traffic control	background	2K_dev_2000
need to monitor a plethora of information obtained from diverse sources	background	2K_dev_2000
To support them in detecting critical situations within this information flood and taking timely actions	background	2K_dev_2000
operators thus need adequate information fusion and decision support systems	background	2K_dev_2000
Research efforts on such dedicated Situation Awareness ( SAW ) systems have concentrated on assisting the operator in managing the current situations	background	2K_dev_2000
which encompasses the acquisition	background	2K_dev_2000
representation	background	2K_dev_2000
validation	background	2K_dev_2000
maintenance and reuse of knowledge gathered for and during the use of these systems	background	2K_dev_2000
such as configuring and maintaining suitable situation templates and exploiting already assessed situations	background	2K_dev_2000
If operators and domain experts are not supported in these tasks	background	2K_dev_2000
however	background	2K_dev_2000
this may discourage them from a successful adoption of such systems in real-world control center applications	background	2K_dev_2000
as user studies revealed	background	2K_dev_2000
	background	2K_dev_2000
	finding	2K_dev_2000
Based on these	mechanism	2K_dev_2000
and the lessons learned from the application of our SAW system implementations BeAware ! and CSI to the domain of road traffic control	mechanism	2K_dev_2000
we therefore propose a first step towards a tool suite	mechanism	2K_dev_2000
which stretches from the configuration phase of the system to its runtime maintenance in the light of evolving environments and user needs	mechanism	2K_dev_2000
	mechanism	2K_dev_2000
	method	2K_dev_2000
However	purpose	2K_dev_2000
little focus has been so far on integratively supporting the different phases of knowledge management in SAW systems	purpose	2K_dev_2000
fostering knowledge management in SAW systems	purpose	2K_dev_2000
Near-Infrared ( NIR ) images of most materials exhibit less texture or albedo variations making them beneficial for vision tasks such as intrinsic image decomposition and structured light depth estimation	background	2K_dev_2001
Understanding the reflectance properties ( BRDF ) of materials in the NIR wavelength range can be further useful for many photometric methods including shape from shading and inverse rendering	background	2K_dev_2001
	background	2K_dev_2001
to demonstrate fine-scale reconstruction of objects from a single NIR image	finding	2K_dev_2001
	finding	2K_dev_2001
In this paper	mechanism	2K_dev_2001
we present an approach by imaging materials under different IR lighting and viewing directions	mechanism	2K_dev_2001
This is achieved by an iterative scheme that alternately estimates surface detail and NIR BRDF of materials	mechanism	2K_dev_2001
Our setup does not require complicated gantries or calibration and we present the first NIR dataset of 100 materials including a variety of fabrics ( knits	mechanism	2K_dev_2001
weaves	mechanism	2K_dev_2001
cotton	mechanism	2K_dev_2001
satin	mechanism	2K_dev_2001
leather )	mechanism	2K_dev_2001
and organic ( skin	mechanism	2K_dev_2001
leaves	mechanism	2K_dev_2001
jute	mechanism	2K_dev_2001
trunk	mechanism	2K_dev_2001
fur ) and inorganic materials ( plastic	mechanism	2K_dev_2001
concrete	mechanism	2K_dev_2001
carpet )	mechanism	2K_dev_2001
	mechanism	2K_dev_2001
The NIR BRDFs measured from material samples are used with a shape-from-shading algorithm	method	2K_dev_2001
However	purpose	2K_dev_2001
even with less albedo variation	purpose	2K_dev_2001
many materials e	purpose	2K_dev_2001
g	purpose	2K_dev_2001
fabrics	purpose	2K_dev_2001
leaves	purpose	2K_dev_2001
etc	purpose	2K_dev_2001
exhibit complex fine-scale surface detail making it hard to accurately estimate BRDF	purpose	2K_dev_2001
to simultaneously estimate NIR BRDF and fine-scale surface details	purpose	2K_dev_2001
which is one of the major problems in HMM-based speech synthesis	background	2K_dev_2002
results show that the modified post-filters also yield significant quality improvements in synthetic speech as yielded by the conventional post-filter	finding	2K_dev_2002
	finding	2K_dev_2002
This paper proposes a modified post-filter to recover a Modulation Spectrum ( MS ) in HMM-based speech synthesis the MS-based post-filter has been proposed It recovers the utterance-level MS of the generated speech trajectory	mechanism	2K_dev_2002
and we have reported its benefit to the quality improvement	mechanism	2K_dev_2002
we propose two modified post-filters	mechanism	2K_dev_2002
( 1 ) the time-invariant filter with a simplified conversion form and ( 2 ) the segment-level post-filter which applicable to a short-term parameter sequence Furthermore	mechanism	2K_dev_2002
we also propose ( 3 ) the post-filter	mechanism	2K_dev_2002
Experimental	method	2K_dev_2002
To alleviate the over-smoothing effect However	purpose	2K_dev_2002
this post-filter is not applicable to various lengths of speech parameter trajectories	purpose	2K_dev_2002
such as phrases or segments	purpose	2K_dev_2002
which are shorter than an utterance	purpose	2K_dev_2002
To address this problem	purpose	2K_dev_2002
to recover the phoneme-level MS of HMM-state duration	purpose	2K_dev_2002
We will never really understand learning until we can build machines that learn many different things	background	2K_dev_2003
over years	background	2K_dev_2003
and become better learners over time	background	2K_dev_2003
	background	2K_dev_2003
The result so far is a collection of 70 million interconnected beliefs ( e	finding	2K_dev_2003
g	finding	2K_dev_2003
	finding	2K_dev_2003
servedWtih coffee	finding	2K_dev_2003
applePie ) )	finding	2K_dev_2003
NELL is considering at different levels of confidence	finding	2K_dev_2003
along with millions of learned phrasings	finding	2K_dev_2003
morphological features	finding	2K_dev_2003
and web page structures that NELL uses to extract beliefs from the web NELL is also learning to reason over its extracted knowledge	finding	2K_dev_2003
and to automatically extend its ontology Track NELL 's progress at http : //rtw	finding	2K_dev_2003
ml	finding	2K_dev_2003
cmu	finding	2K_dev_2003
edu	finding	2K_dev_2003
or follow it on Twitter at @ CMUNELL	finding	2K_dev_2003
We describe our research to build a Never-Ending Language Learner ( NELL ) that runs 24 hours per day	mechanism	2K_dev_2003
forever	mechanism	2K_dev_2003
Each day NELL extracts ( reads ) more facts from the web	mechanism	2K_dev_2003
into its growing knowledge base of beliefs	mechanism	2K_dev_2003
Each day NELL also learns to read better than the day before	mechanism	2K_dev_2003
NELL has been running 24 hours/day for over four years now	mechanism	2K_dev_2003
	mechanism	2K_dev_2003
	method	2K_dev_2003
learning to read the web	purpose	2K_dev_2003
	purpose	2K_dev_2003
Online popularity of a user or product ( via follows	background	2K_dev_2004
page-likes	background	2K_dev_2004
etc	background	2K_dev_2004
) can be monetized on the premise of higher ad click-through rates or increased sales	background	2K_dev_2004
Web services and social networks which incentivize popularity thus suffer from a major problem of fake connections from link fraudsters looking to make a quick buck	background	2K_dev_2004
Typical methods of catching this suspicious behavior use spectral techniques to spot large groups of often blatantly fraudulent ( but sometimes honest ) users	background	2K_dev_2004
	background	2K_dev_2004
it is shown to be highly effective ( c ) it is scalable ( linear on the input size )	finding	2K_dev_2004
with high precision identify many suspicious accounts which have persisted without suspension even to this day	finding	2K_dev_2004
	finding	2K_dev_2004
In this work	mechanism	2K_dev_2004
we take an adversarial approach and propose FBOX	mechanism	2K_dev_2004
an algorithm designed Our algorithm has the following desirable properties : ( a ) it has theoretical underpinnings	mechanism	2K_dev_2004
( b )	mechanism	2K_dev_2004
on real data and We evaluate FBOX on a large	method	2K_dev_2004
public 41	method	2K_dev_2004
7 million node	method	2K_dev_2004
1	method	2K_dev_2004
5 billion edge who-follows-whom social graph from Twitter in 2010 and	method	2K_dev_2004
How can we detect suspicious users in large online networks ? However	purpose	2K_dev_2004
small-scale	purpose	2K_dev_2004
stealthy attacks may go unnoticed due to the nature of low-rank eigenanalysis used in practice	purpose	2K_dev_2004
to find and prove claims about the weaknesses of modern	purpose	2K_dev_2004
state-of-the-art spectral methods to catch small-scale	purpose	2K_dev_2004
stealth attacks that slip below the radar	purpose	2K_dev_2004
	purpose	2K_dev_2004
	background	2K_dev_2005
demonstrate superior computational cost ( real-time )	finding	2K_dev_2005
memory efficiency and very competitive performance of our approach compared to the state of the arts	finding	2K_dev_2005
	finding	2K_dev_2005
In this work	mechanism	2K_dev_2005
we propose to employ multi-channel correlation filters In our framework	mechanism	2K_dev_2005
each action sequence is represented as a multi-channel signal ( frames ) and the goal is to learn a multi-channel filter for each action class that produces a set of desired outputs when correlated with training examples	mechanism	2K_dev_2005
	mechanism	2K_dev_2005
The experiments on the Weizmann and UCF sport datasets	method	2K_dev_2005
for recognizing human actions ( e	purpose	2K_dev_2005
g	purpose	2K_dev_2005
waking	purpose	2K_dev_2005
riding ) in videos	purpose	2K_dev_2005
	purpose	2K_dev_2005
Dynamic assignment and re-assignment of large number of simple and cheap robots across multiple sites is relevant to applications like autonomous survey	background	2K_dev_2006
environmental monitoring and reconnaissance	background	2K_dev_2006
This problem can be posed as an optimal control problem ( which is hard to solve optimally )	background	2K_dev_2006
and has been studied to a limited extent in the literature when the cost objective is time	background	2K_dev_2006
	background	2K_dev_2006
show that our method outperforms other proposed methods in the literature for the objective of time as well as more general objectives ( like total energy consumed )	finding	2K_dev_2006
	finding	2K_dev_2006
In this paper	mechanism	2K_dev_2006
we present supervisory control laws We consider the total energy consumed as the cost objective and present a linear programming based heuristic for computing a stochastic transition law for the robots to move between sites	mechanism	2K_dev_2006
	mechanism	2K_dev_2006
We consider a robotic swarm consisting of tens to hundreds of simple robots with limited battery life and limited computation and communication capabilities	method	2K_dev_2006
The robots have the capability to recognize the site that they are in and receive messages from a central supervisory controller	method	2K_dev_2006
but they can not communicate with other robots	method	2K_dev_2006
There is a cost ( e	method	2K_dev_2006
g	method	2K_dev_2006
	method	2K_dev_2006
energy	method	2K_dev_2006
time ) for the robots to move from one site to another	method	2K_dev_2006
These limitations make the swarm hard to control to achieve the desired configurations	method	2K_dev_2006
We evaluate our method for different objectives and through Monte Carlo simulations	method	2K_dev_2006
The study of human control of robotic swarms involves designing interfaces and algorithms for allowing a human operator to influence a swarm of robots	background	2K_dev_2007
	background	2K_dev_2007
Our results show that	finding	2K_dev_2007
while there was a large drop in the number of goals reached when moving from a 1-hop to a 2-hop guarantee	finding	2K_dev_2007
the difference between a 2-hop	finding	2K_dev_2007
3-hop	finding	2K_dev_2007
and 4-hop guarantee was not statistically significant	finding	2K_dev_2007
Furthermore	finding	2K_dev_2007
we found that sensing error impacted the explicit information-propagation method more than the tacit method conditions	finding	2K_dev_2007
and caused participants more trouble the lower the density of leaders	finding	2K_dev_2007
although the explicit method performed better overall	finding	2K_dev_2007
This paper investigates the use of a small subset of the swarm as leaders that are dynamically selected during the scenario execution and are directly controlled by the human operator to guide the rest of the swarm	mechanism	2K_dev_2007
which is operating under a flocking-style algorithm	mechanism	2K_dev_2007
The goal of the operator in this study is to move the swarm to goal regions that arise dynamically in the environment	mechanism	2K_dev_2007
	mechanism	2K_dev_2007
We experimentally investigated three different aspects of dynamic leader-based swarm control and their interactions : leader density ( in terms of guaranteed hops to a leader )	method	2K_dev_2007
sensing error	method	2K_dev_2007
and method of information propagation from leaders to the rest of the swarm	method	2K_dev_2007
	method	2K_dev_2007
One of the main difficulties	purpose	2K_dev_2007
however	purpose	2K_dev_2007
is determining how to most effectively influence the swarm after it has been deployed	purpose	2K_dev_2007
Past work has focused on influencing the swarm via statically selected leaders-swarm members that the operator directly controls	purpose	2K_dev_2007
	purpose	2K_dev_2007
Our work will impact several first-person vision tasks that need the detailed understanding of social interactions	background	2K_dev_2008
such as automatic video summarization of group events and assistive systems	background	2K_dev_2008
We show that the first-person and second-person points-of-view features of two people	finding	2K_dev_2008
enabled by paired egocentric videos	finding	2K_dev_2008
are complementary and essential for reliably recognizing micro-actions and reactions	finding	2K_dev_2008
	finding	2K_dev_2008
	mechanism	2K_dev_2008
we propose to use paired egocentric videos recorded by two interacting people	mechanism	2K_dev_2008
We also build a new dataset of dyadic ( two-persons ) interactions that comprises more than 1000 pairs of egocentric videos	mechanism	2K_dev_2008
	method	2K_dev_2008
We aim to understand the dynamics of social interactions between two people by recognizing their actions and reactions using a head-mounted camera	purpose	2K_dev_2008
To recognize micro-level actions and reactions	purpose	2K_dev_2008
such as slight shifts in attention	purpose	2K_dev_2008
subtle nodding	purpose	2K_dev_2008
or small hand actions	purpose	2K_dev_2008
where only subtle body motion is apparent to enable systematic evaluations on the task of micro-action and reaction recognition	purpose	2K_dev_2008
	purpose	2K_dev_2008
Speaker adaptive training ( SAT ) is a well studied technique for Gaussian mixture acoustic models ( GMMs )	background	2K_dev_2009
Recently we proposed to perform SAT for deep neural networks ( DNNs )	background	2K_dev_2009
with speaker i-vectors applied in feature learning	background	2K_dev_2009
The resulting SAT-DNN models significantly outperform DNNs on word error rates ( WERs )	background	2K_dev_2009
	background	2K_dev_2009
	finding	2K_dev_2009
In this paper	mechanism	2K_dev_2009
we present different methods First	mechanism	2K_dev_2009
we conduct detailed analysis Second	mechanism	2K_dev_2009
the SAT-DNN approach is extended Third	mechanism	2K_dev_2009
we enrich the i-vector representation with global speaker attributes ( age	mechanism	2K_dev_2009
gender	mechanism	2K_dev_2009
etc	mechanism	2K_dev_2009
) obtained automatically from video signals	mechanism	2K_dev_2009
On a collection of instructional videos	mechanism	2K_dev_2009
incorporation of the additional visual features is observed to boost the recognition accuracy of SAT-DNN	mechanism	2K_dev_2009
	mechanism	2K_dev_2009
	method	2K_dev_2009
to further improve and extend SAT-DNN	purpose	2K_dev_2009
to investigate i-vector extractor training and flexible feature fusion	purpose	2K_dev_2009
to improve tasks including bottleneck feature ( BNF ) generation	purpose	2K_dev_2009
convolutional neural network ( CNN ) acoustic modeling and multilingual DNN-based feature extraction	purpose	2K_dev_2009
for transcribing multimedia data	purpose	2K_dev_2009
	background	2K_dev_2010
highlight the behavior and efficacy of such networks show that these networks	finding	2K_dev_2010
while simple	finding	2K_dev_2010
are still more accurate	finding	2K_dev_2010
	finding	2K_dev_2010
In this paper we introduce a simplified architecture where word-spotting needs to be done in real-time and phoneme-level information is not available for training The network operates as a self-contained block in a strictly forward-pass configuration to directly generate keyword labels	mechanism	2K_dev_2010
We call these simple networks causal networks	mechanism	2K_dev_2010
where the current output is only weighted by the the past inputs and outputs	mechanism	2K_dev_2010
Since the basic network has a simpler architecture as compared to traditional memory networks used in keyword spotting	mechanism	2K_dev_2010
it also requires less data to train	mechanism	2K_dev_2010
Experiments on a standard speech database Comparisons with a standard HMM-based keyword spotter	method	2K_dev_2010
for gated recurrent neural networks that can be used in single-pass applications	purpose	2K_dev_2010
	purpose	2K_dev_2010
Spoken language interfaces are being incorporated into various devices ( e	background	2K_dev_2011
g	background	2K_dev_2011
smart-phones	background	2K_dev_2011
smart TVs	background	2K_dev_2011
etc )	background	2K_dev_2011
	background	2K_dev_2011
	finding	2K_dev_2011
We propose to dynamically add application-based domains according to users ' requests by using descriptions of applications as a retrieval cue to find relevant applications The approach uses structured knowledge resources ( e	mechanism	2K_dev_2011
g	mechanism	2K_dev_2011
Freebase	mechanism	2K_dev_2011
Wikipedia	mechanism	2K_dev_2011
FrameNet ) to induce types of slots for generating semantic seeds	mechanism	2K_dev_2011
and enriches the semantics of spoken queries with neural word embeddings	mechanism	2K_dev_2011
where semantically related concepts can be additionally included for acquiring knowledge that does not exist in the predefined domains	mechanism	2K_dev_2011
The system can then retrieve relevant applications or dynamically suggest users install applications that support unexplored domains	mechanism	2K_dev_2011
We find that vendor descriptions provide a reliable source of information for this purpose	mechanism	2K_dev_2011
	method	2K_dev_2011
However	purpose	2K_dev_2011
current technology typically limits conversational interactions to a few narrow predefined domains/topics	purpose	2K_dev_2011
For example	purpose	2K_dev_2011
dialogue systems for smart-phone operation fail to respond when users ask for functions not supported by currently installed applications	purpose	2K_dev_2011
	purpose	2K_dev_2011
	background	2K_dev_2012
MergePoint is currently running daily on a 100 node cluster analyzing 33248 Linux binaries ; has generated more than 15 billion SMT queries	finding	2K_dev_2012
200 million test cases	finding	2K_dev_2012
2347420 crashes	finding	2K_dev_2012
and found 11687 bugs in 4379 distinct applications	finding	2K_dev_2012
We present MergePoint	mechanism	2K_dev_2012
a new binary-only symbolic execution system MergePoint introduces veritesting	mechanism	2K_dev_2012
a new technique that employs static symbolic execution Veritesting allows MergePoint to find twice as many bugs	mechanism	2K_dev_2012
explore orders of magnitude more paths	mechanism	2K_dev_2012
and achieve higher code coverage than previous dynamic symbolic execution systems	mechanism	2K_dev_2012
	mechanism	2K_dev_2012
	method	2K_dev_2012
for large-scale testing of commodity off-the-shelf ( COTS ) software	purpose	2K_dev_2012
to amplify the effect of dynamic symbolic execution	purpose	2K_dev_2012
What defines an action like `` kicking ball { '' } ?	background	2K_dev_2013
We show that our model gives improvements on standard action recognition datasets including UCF101 and HMDB51	finding	2K_dev_2013
More importantly	finding	2K_dev_2013
our approach is able to generalize beyond learned action categories and shows significant performance improvement on cross-category generalization on our new ACT dataset	finding	2K_dev_2013
	finding	2K_dev_2013
In this paper	mechanism	2K_dev_2013
we propose by modeling an action as a transformation which changes the state of the environment before the action happens ( precondition ) to the state after the action ( effect )	mechanism	2K_dev_2013
Motivated by recent advancements of video representation using deep learning	mechanism	2K_dev_2013
we design a Siamese network which models the action as a transformation on a high-level feature space	mechanism	2K_dev_2013
	method	2K_dev_2013
We argue that the 1 meaning of an action lies in the change or transformation an action brings to the environment	purpose	2K_dev_2013
a novel representation for actions	purpose	2K_dev_2013
Product architecture structures the coordination problem that the development organization must solve	background	2K_dev_2014
The modularity strategy establishes design rules that fix module functionality and interfaces	background	2K_dev_2014
and assigns development work for each module to a single team	background	2K_dev_2014
The modules present relatively independent coordination problems that teams attempt to solve with all the traditional coordination mechanisms available to them	background	2K_dev_2014
The applicability and effectiveness of this strategy is limited with increasing technical and organizational volatility	background	2K_dev_2014
	finding	2K_dev_2014
I present a theory of coordination	mechanism	2K_dev_2014
based on decision networks	mechanism	2K_dev_2014
	mechanism	2K_dev_2014
I review evidence testing several hypotheses derived from the theory	method	2K_dev_2014
In the absence of theory explaining why and when modularity works	purpose	2K_dev_2014
the technique is brittle	purpose	2K_dev_2014
with very little firm basis for adjustment or for complementing it with other strategies	purpose	2K_dev_2014
that generalizes the modularity strategy	purpose	2K_dev_2014
and explore how this theoretical view can drive coordination research and provide a theoretical basis for practical techniques to assist architects	purpose	2K_dev_2014
developers	purpose	2K_dev_2014
and managers	purpose	2K_dev_2014
	purpose	2K_dev_2014
One of the pillars of the modern scientific method is model validation : comparing a scientific model 's predictions against empirical observations	background	2K_dev_2015
Today	background	2K_dev_2015
a scientist demonstrates the validity of a model by making an argument in a paper and submitting it for peer review	background	2K_dev_2015
a process comparable to code review in software engineering	background	2K_dev_2015
While human review helps to ensure that contributions meet high-level goals	background	2K_dev_2015
software engineers typically supplement it with unit testing to get a more complete picture of the status of a project	background	2K_dev_2015
Scientific communities differ from software communities in several key ways	background	2K_dev_2015
however	background	2K_dev_2015
	background	2K_dev_2015
	finding	2K_dev_2015
In this paper	mechanism	2K_dev_2015
we introduce Sci Unit	mechanism	2K_dev_2015
a framework for test-driven scientific model validation	mechanism	2K_dev_2015
	mechanism	2K_dev_2015
	method	2K_dev_2015
We argue that a similar test-driven methodology would be valuable to scientific communities as they seek to validate increasingly complex models against growing repositories of empirical data	purpose	2K_dev_2015
and outline how	purpose	2K_dev_2015
supported by new and existing collaborative infrastructure	purpose	2K_dev_2015
it could integrate into the modern scientific process	purpose	2K_dev_2015
Although different approaches to decision-making in self adaptive systems have shown their effectiveness in the past by factoring in predictions about the system and its environment ( e	background	2K_dev_2016
g	background	2K_dev_2016
	background	2K_dev_2016
resource availability )	background	2K_dev_2016
no proposal considers the latency associated with the execution of tactics upon the target system	background	2K_dev_2016
However	background	2K_dev_2016
different adaptation tactics can take different amounts of time until their effects can be observed	background	2K_dev_2016
In reactive adaptation	background	2K_dev_2016
ignoring adaptation tactic latency can lead to suboptimal adaptation decisions ( e	background	2K_dev_2016
g	background	2K_dev_2016
	background	2K_dev_2016
activating a server that takes more time to boot than the transient spike in traffic that triggered its activation )	background	2K_dev_2016
In proactive adaptation	background	2K_dev_2016
taking adaptation latency into account is necessary to get the system into the desired state to deal with an upcoming situation	background	2K_dev_2016
	background	2K_dev_2016
Our results show that factoring in tactic latency in decision making improves the outcome of adaptation and show that it achieves higher utility than an algorithm that under the assumption of no latency is optimal	finding	2K_dev_2016
In this paper	mechanism	2K_dev_2016
we introduce a formal analysis technique based on model checking of stochastic multiplayer games ( SMGs ) In particular	mechanism	2K_dev_2016
we apply this technique We also present an algorithm that considers tactic latency	mechanism	2K_dev_2016
	mechanism	2K_dev_2016
	method	2K_dev_2016
that enables us to quantify the potential benefits of employing different types of algorithms for self-adaptation	purpose	2K_dev_2016
to show the potential benefit of considering adaptation tactic latency in proactive adaptation algorithms	purpose	2K_dev_2016
to do proactive adaptation	purpose	2K_dev_2016
Mobile devices have become powerful ultra-portable personal computers supporting not only communication but also running a variety of complex	background	2K_dev_2017
interactive applications Because of the unique characteristics of mobile interaction Our findings underline the need for a more nuanced set of interactions that support short mobile device uses	background	2K_dev_2017
in particular review sessions	background	2K_dev_2017
	finding	2K_dev_2017
and propose a classification of use based on duration and interaction type : glance	mechanism	2K_dev_2017
review	mechanism	2K_dev_2017
and engage	mechanism	2K_dev_2017
through proactively suggesting short tasks to the user that go beyond simple application notifications	mechanism	2K_dev_2017
We use the findings from our study to create and explore the design space	mechanism	2K_dev_2017
We evaluate the concept through a user evaluation of an interactive lock screen prototype	method	2K_dev_2017
called ProactiveTasks	method	2K_dev_2017
	method	2K_dev_2017
a better understanding of the time duration and context of mobile device uses could help to improve and streamline the user experience	purpose	2K_dev_2017
In this paper	purpose	2K_dev_2017
we first explore the anatomy of mobile device use We then focus our investigation on short review interactions and identify opportunities for streamlining these mobile device uses for proactively presenting tasks to the users	purpose	2K_dev_2017
	purpose	2K_dev_2017
The growing size of modern storage systems is expected to exceed billions of objects	background	2K_dev_2018
making metadata scalability critical to overall performance	background	2K_dev_2018
	background	2K_dev_2018
we have demonstrated IndexFS scaled to 128 metadata servers	finding	2K_dev_2018
show our out-of-core metadata throughput out-performing existing solutions such as PVFS	finding	2K_dev_2018
Lustre	finding	2K_dev_2018
and HDFS by 50\ % to two orders of magnitude	finding	2K_dev_2018
	finding	2K_dev_2018
In this paper	mechanism	2K_dev_2018
we introduce a middleware design called IndexFS that adds support to existing file systems such as PVFS	mechanism	2K_dev_2018
Lustre	mechanism	2K_dev_2018
and HDFS IndexFS uses a table-based architecture that incrementally partitions the namespace on a per-directory basis	mechanism	2K_dev_2018
preserving server and disk locality for small directories	mechanism	2K_dev_2018
An optimized log-structured layout is used to store metadata and small files efficiently We also propose two client-based storm-free caching techniques : bulk namespace insertion such as N-N checkpointing ; and stateless consistent metadata caching	mechanism	2K_dev_2018
By combining these techniques	method	2K_dev_2018
Experiments	method	2K_dev_2018
Many existing distributed file systems only focus on providing highly parallel fast access to file data	purpose	2K_dev_2018
and lack a scalable metadata service	purpose	2K_dev_2018
for scalable high-performance operations on metadata and small files	purpose	2K_dev_2018
for creation intensive workloads for hot spot mitigation	purpose	2K_dev_2018
	purpose	2K_dev_2018
constructions of coding schemes against two well-studied classes of tampering functions ; namely	mechanism	2K_dev_2019
bit-wise tampering functions ( where the adversary tampers each bit of the encoding independently ) and the much more general class of split-state adversaries ( where two independent adversaries arbitrarily tamper each half of the encoded sequence )	mechanism	2K_dev_2019
	mechanism	2K_dev_2019
In this work	method	2K_dev_2019
we consider 2	method	2K_dev_2019
We initiate the study of seedless non-malleable extractors as a natural variation of the notion of non-malleable extractors introduced by Dodis and Wichs ( STOC 2009 )	method	2K_dev_2019
	method	2K_dev_2019
However	purpose	2K_dev_2019
this result is existential and has thus attracted a great deal of subsequent research on explicit constructions of non-malleable codes against natural classes of adversaries	purpose	2K_dev_2019
Recent advances in rendering and data-driven animation have enabled the creation of compelling characters with impressive levels of realism	background	2K_dev_2020
A better understanding of the factors that make human motion recognizable and appealing would be of great value in industries where creating a variety of appealing virtual characters with realistic motion is required Average faces are perceived to be less distinctive but more attractive	background	2K_dev_2020
We found that dancing motions were most easily recognized and that distinctiveness in one gait does not predict how recognizable the same actor is when performing a different motion	finding	2K_dev_2020
As hypothesized	finding	2K_dev_2020
average motions were always amongst the least distinctive and most attractive	finding	2K_dev_2020
Furthermore	finding	2K_dev_2020
as 50\ % of participants in the experiment were Caucasian European and 50\ % were Asian Korean	finding	2K_dev_2020
we found that the latter were as good as or better at recognizing the motions of the Caucasian actors than their European counterparts	finding	2K_dev_2020
in particular for dancing males	finding	2K_dev_2020
whom they also rated more highly for attractiveness	finding	2K_dev_2020
	finding	2K_dev_2020
	mechanism	2K_dev_2020
we captured thirty actors walking	method	2K_dev_2020
jogging and dancing	method	2K_dev_2020
and applied their motions to the same virtual character ( one each for the males and females )	method	2K_dev_2020
We then conducted a series of perceptual experiments	method	2K_dev_2020
While data-driven techniques can produce animations that are extremely faithful to the original motion	purpose	2K_dev_2020
many challenging problems remain because of the high complexity of human motion	purpose	2K_dev_2020
To investigate these issues to explore the distinctiveness and attractiveness of these human motions	purpose	2K_dev_2020
and whether characteristic motion features transfer across an individual 's different gaits	purpose	2K_dev_2020
	purpose	2K_dev_2020
so we explored whether this was also 1 for body motion	purpose	2K_dev_2020
	purpose	2K_dev_2020
Transport protocols must accommodate diverse application and network requirements	background	2K_dev_2021
As a result	background	2K_dev_2021
TCP has evolved over time with new congestion control algorithms such as support for generalized AIMD	background	2K_dev_2021
background flows	background	2K_dev_2021
and multipath	background	2K_dev_2021
On the other hand	background	2K_dev_2021
explicit congestion control algorithms have been shown to be more efficient	background	2K_dev_2021
However	background	2K_dev_2021
they are inherently more rigid because they rely on in-network components	background	2K_dev_2021
We show that FCP allows evolution by accommodating diversity and ensuring coexistence	finding	2K_dev_2021
while being as efficient as existing explicit congestion control algorithms	finding	2K_dev_2021
	finding	2K_dev_2021
This paper presents a flexible framework called FCP by exposing a simple abstraction for resource allocation	mechanism	2K_dev_2021
FCP incorporates novel primitives for end-point flexibility ( aggregation and preloading ) into a single framework and makes economics-based congestion control practical by explicitly handling load variations and by decoupling it from actual billing	mechanism	2K_dev_2021
	mechanism	2K_dev_2021
	method	2K_dev_2021
Therefore	purpose	2K_dev_2021
it is not clear whether they can be made flexible enough to support diverse application requirements for network resource allocation that accommodates diversity	purpose	2K_dev_2021
Phase-contrast microscopy is one of the most common and convenient imaging modalities to observe long-term multi-cellular processes	background	2K_dev_2022
which generates images by the interference of lights passing through transparent specimens and background medium with different retarded phases	background	2K_dev_2022
demonstrate that the proposed approach produces quality segmentation of individual cells and outperforms previous approaches	finding	2K_dev_2022
	finding	2K_dev_2022
the authors propose ( 1 ) a phase contrast microscopy image restoration method that produces phase retardation features	mechanism	2K_dev_2022
which are intrinsic features of phase contrast microscopy	mechanism	2K_dev_2022
and ( 2 ) a semi-supervised learning based algorithm for cell segmentation	mechanism	2K_dev_2022
which is a fundamental task for various cell behavior analysis Specifically	mechanism	2K_dev_2022
the image formation process of phase contrast microscopy images is first computationally modeled with a dictionary of diffraction patterns ; as a result	mechanism	2K_dev_2022
each pixel of a phase contrast microscopy image is represented by a linear combination of the bases	mechanism	2K_dev_2022
which we call phase retardation features	mechanism	2K_dev_2022
Images are then partitioned into phase-homogeneous atoms by clustering neighboring pixels with similar phase retardation features	mechanism	2K_dev_2022
Consequently	mechanism	2K_dev_2022
cell segmentation is performed via a semi-supervised classification technique over the phase-homogeneous atoms	mechanism	2K_dev_2022
Experiments	method	2K_dev_2022
Despite many years of study	purpose	2K_dev_2022
computer-aided phase contrast microscopy analysis on cell behavior is challenged by image qualities and artifacts caused by phase contrast optics	purpose	2K_dev_2022
Addressing the unsolved challenges	purpose	2K_dev_2022
Motivation : Several types of studies	background	2K_dev_2023
including genome-wide association studies and RNA interference screens	background	2K_dev_2023
strive to link genes to diseases Although these approaches have had some success	background	2K_dev_2023
genetic variants are often only present in a small subset of the population	background	2K_dev_2023
and screens are noisy with low overlap between experiments in different labs	background	2K_dev_2023
Neither provides a mechanistic model explaining how identified genes impact the disease of interest or the dynamics of the pathways those genes regulate	background	2K_dev_2023
Such mechanistic models could be used to accurately predict downstream effects of knocking down pathway members and allow comprehensive exploration of the effects of targeting pairs or higher-order combinations of genes	background	2K_dev_2023
	background	2K_dev_2023
Results The resulting networks correctly identified many of the known pathways and transcriptional regulators of this disease	finding	2K_dev_2023
Furthermore	finding	2K_dev_2023
they accurately predict RNA interference effects and can be used to infer genetic interactions	finding	2K_dev_2023
greatly improving over other methods suggested for this task	finding	2K_dev_2023
allowed us to identify several strain-specific targets of this infection	finding	2K_dev_2023
	finding	2K_dev_2023
We developed methods Our model	mechanism	2K_dev_2023
SDREM	mechanism	2K_dev_2023
integrates static and time series data to link proteins and the pathways they regulate in these networks	mechanism	2K_dev_2023
SDREM uses prior information about proteins ' likelihood of involvement in a disease ( e	mechanism	2K_dev_2023
g	mechanism	2K_dev_2023
from screens ) to improve the quality of the predicted signaling pathways	mechanism	2K_dev_2023
	mechanism	2K_dev_2023
We used our algorithms to study the human immune response to H1N1 influenza infection Applying our method to the more pathogenic H5N1 influenza	method	2K_dev_2023
to model the activation of signaling and dynamic regulatory networks involved in disease progression	purpose	2K_dev_2023
	purpose	2K_dev_2023
Supporting students ' self-regulated learning ( SRL ) is an important topic in the learning sciences	background	2K_dev_2024
Two critical processes involved in SRL are self-assessment and study choice	background	2K_dev_2024
Intelligent tutoring systems ( ITSs ) have been shown to be effective in supporting students ' domain-level learning through guided problem-solving practice	background	2K_dev_2024
but it is an open question how they can support SRL processes effectively	background	2K_dev_2024
while maintaining or even enhancing their effectiveness at the domain level	background	2K_dev_2024
This work informs the design of future ITS that supports SRL	background	2K_dev_2024
The evaluations reveal that the new OLM with self-assessment support facilitates students ' learning processes	finding	2K_dev_2024
and enhances their learning outcomes significantly	finding	2K_dev_2024
However	finding	2K_dev_2024
we did not find significant learning gains due to the problem selection feature	finding	2K_dev_2024
We used a combination of user-centered design techniques We added three features to the tutor ' Open Learner Model ( OLM ) that may scaffold students ' self-assessment ( self-assessment prompts	mechanism	2K_dev_2024
delaying the update of students ' progress bars	mechanism	2K_dev_2024
and providing progress information on the problem type level )	mechanism	2K_dev_2024
We also designed a problem selection screen with shared student/system control and game-like features	mechanism	2K_dev_2024
	mechanism	2K_dev_2024
and experimental classroom research We went through two iterations of design and conducted two controlled experiments with 160 local middle school students to evaluate the effectiveness of the new features	method	2K_dev_2024
to redesign and evaluate an ITS for linear equation solving so it supports self-assessment and study choice	purpose	2K_dev_2024
	purpose	2K_dev_2024
When human annotators are given a choice about what to label in an image	background	2K_dev_2025
they apply their own subjective judgments on what to ignore and what to mention	background	2K_dev_2025
	background	2K_dev_2025
Our results are highly interpretable for reporting `` what 's in the image { '' } versus `` what 's worth saying	finding	2K_dev_2025
We show significant improvements over traditional algorithms for both image classification and image captioning	finding	2K_dev_2025
doubling the performance of existing methods in some cases	finding	2K_dev_2025
	finding	2K_dev_2025
Such annotations do not use consistent vocabulary	mechanism	2K_dev_2025
and miss a significant amount of the information present in an image ; however	mechanism	2K_dev_2025
we demonstrate that the noise in these annotations exhibits structure and can be modeled	mechanism	2K_dev_2025
We propose an algorithm to decouple the human reporting bias from the correct visually grounded labels	mechanism	2K_dev_2025
{ '' } We demonstrate the algorithm 's efficacy along a variety of metrics and datasets	method	2K_dev_2025
including MS COCO and Yahoo Flickr 100M	method	2K_dev_2025
	method	2K_dev_2025
We refer to these noisy `` human-centric { '' } annotations as exhibiting human reporting bias	purpose	2K_dev_2025
Examples of such annotations include image tags and keywords found on photo sharing sites	purpose	2K_dev_2025
or in datasets containing image captions	purpose	2K_dev_2025
In this paper	purpose	2K_dev_2025
we use these noisy annotations for learning visually correct image classifiers	purpose	2K_dev_2025
leading toward a rich family of potential extensions to CW algorithms	background	2K_dev_2026
	background	2K_dev_2026
show that our robust	finding	2K_dev_2026
cost-sensitive extensions consistently reduce the cost incurred in both online and batch learning settings	finding	2K_dev_2026
We also demonstrate a correspondence between the VaR and CVaR constraints used for classification and uncertainty sets used in robust optimization	finding	2K_dev_2026
	finding	2K_dev_2026
We introduce confidence-weighted ( CW ) online learning algorithms Our work extends the original confidence-weighted optimization framework in two important directions First	mechanism	2K_dev_2026
we show how the original value at risk ( VaR ) probabilistic constraint in CW algorithms can be generalized to a worst-case conditional value at risk ( CVaR ) constraint for more robust learning from cost-weighted examples	mechanism	2K_dev_2026
Second	mechanism	2K_dev_2026
we show how to reduce adversarial feature noise	mechanism	2K_dev_2026
which can be useful in fraud detection scenarios	mechanism	2K_dev_2026
by reframing the optimization problem in terms of maximum a posteriori estimation	mechanism	2K_dev_2026
The resulting optimization problems can be solved efficiently	mechanism	2K_dev_2026
Experiments on real-world and synthetic datasets	method	2K_dev_2026
for robust	purpose	2K_dev_2026
cost-sensitive classification	purpose	2K_dev_2026
	finding	2K_dev_2027
	method	2K_dev_2027
for the problems of minimizing the maximum label ( l ( infinity ) norm ) and minimizing l ( p ) and l ( q ) norms simultaneously	purpose	2K_dev_2027
	purpose	2K_dev_2027
which are currently in clinical use for rescuing hematopoietic function during bone marrow transplants	background	2K_dev_2028
	background	2K_dev_2028
Our method achieved promising performance in the experiments with hematopoietic stem cell ( HSC ) populations	finding	2K_dev_2028
This paper proposes a vision-based method for detecting apoptosis ( programmed cell death )	mechanism	2K_dev_2028
Our method targets non-adherent cells	mechanism	2K_dev_2028
which float or are suspended freely in the culture medium-in contrast to adherent cells	mechanism	2K_dev_2028
which are attached to a petri dish	mechanism	2K_dev_2028
The method first detects cell regions and tracks them over time	mechanism	2K_dev_2028
resulting in the construction of cell tracklets	mechanism	2K_dev_2028
For each of the tracklets	mechanism	2K_dev_2028
visual properties of the cell are then examined to know whether and when the tracklet shows a transition from a live cell to a dead cell	mechanism	2K_dev_2028
in order to determine the occurrence and timing of a cell death event	mechanism	2K_dev_2028
	mechanism	2K_dev_2028
For the validation	method	2K_dev_2028
a transductive learning framework is adopted to utilize unlabeled data in addition to labeled data	method	2K_dev_2028
	method	2K_dev_2028
which is essential for non-perturbative monitoring of cell expansion	purpose	2K_dev_2028
	purpose	2K_dev_2028
Silhouettes provide rich information on three-dimensional shape	background	2K_dev_2029
since the intersection of the associated visual cones generates the `` visual hull { '' }	background	2K_dev_2029
which encloses and approximates the original shape However	background	2K_dev_2029
not all silhouettes can actually be projections of the same object in space : this simple observation has implications in object recognition and multi-view segmentation	background	2K_dev_2029
and has been ( often implicitly ) used as a basis for camera calibration	background	2K_dev_2029
	background	2K_dev_2029
and point out some possible directions for future research	background	2K_dev_2029
	background	2K_dev_2029
After discussing some general results	finding	2K_dev_2029
	mechanism	2K_dev_2029
we present a `` dual { '' } formulation for consistency	mechanism	2K_dev_2029
that gives conditions for a family of planar sets to be sections of the same object	mechanism	2K_dev_2029
Finally	mechanism	2K_dev_2029
we introduce a more general notion of silhouette `` compatibility { '' } under partial knowledge of the camera projections	mechanism	2K_dev_2029
We present this notion as a natural generalization of traditional multi-view geometry	method	2K_dev_2029
which deals with consistency for points	method	2K_dev_2029
	method	2K_dev_2029
In this paper	purpose	2K_dev_2029
we investigate the conditions for multiple silhouettes	purpose	2K_dev_2029
or more generally arbitrary closed image sets	purpose	2K_dev_2029
to be geometrically `` consistent { '' }	purpose	2K_dev_2029
	purpose	2K_dev_2029
Politeness is believed to facilitate communication in human interaction	background	2K_dev_2030
as it can minimize the potential for conflict and confrontation	background	2K_dev_2030
Regarding the role of politeness strategies for human-robot interaction	background	2K_dev_2030
conflicting findings are presented in the literature	background	2K_dev_2030
	background	2K_dev_2030
Our findings suggest that the interaction context has a greater impact on participants ' perception of the robot in HRI than the use - or lack - of politeness strategies	finding	2K_dev_2030
	finding	2K_dev_2030
	mechanism	2K_dev_2030
Thus	method	2K_dev_2030
we conducted a between-participants experimental study with a receptionist robot	method	2K_dev_2030
to gain a deeper understanding of how politeness on the one hand	purpose	2K_dev_2030
and the type of interaction itself on the other hand	purpose	2K_dev_2030
might affect and shape user experience and evaluation of HRI	purpose	2K_dev_2030
	purpose	2K_dev_2030
Large-scale information processing systems are able to extract massive collections of interrelated facts	background	2K_dev_2031
We show that compared to existing methods	finding	2K_dev_2031
our approach is able to achieve improved AUC and F1 with significantly lower running time	finding	2K_dev_2031
	finding	2K_dev_2031
can be transformed into a knowledge graph The extractions form an extraction graph and we refer to the task of removing noise	mechanism	2K_dev_2031
inferring missing information	mechanism	2K_dev_2031
and determining which candidate facts should be included into a knowledge graph as knowledge graph identification In order to perform this task	mechanism	2K_dev_2031
we must reason jointly about candidate facts and their associated extraction confidences	mechanism	2K_dev_2031
identify co-referent entities	mechanism	2K_dev_2031
and incorporate ontological constraints	mechanism	2K_dev_2031
Our proposed approach uses probabilistic soft logic ( PSL )	mechanism	2K_dev_2031
a recently introduced probabilistic modeling framework which easily scales to millions of facts	mechanism	2K_dev_2031
	mechanism	2K_dev_2031
We demonstrate the power of our method on a synthetic Linked Data corpus derived from the MusicBrainz music community and a real-world set of extractions from the NELL project containing over 1M extractions and 70K ontological relations	method	2K_dev_2031
but unfortunately transforming these candidate facts into useful knowledge is a formidable challenge	purpose	2K_dev_2031
In this paper	purpose	2K_dev_2031
we show how uncertain extractions about entities and their relations	purpose	2K_dev_2031
Occlusions are common in real world scenes and are a major obstacle to robust object detection	background	2K_dev_2032
Previous approaches primarily enforced local coherency or learned the occlusion structure from data	background	2K_dev_2032
However	background	2K_dev_2032
local coherency ignores the occlusion structure in real world scenes and learning from data requires tediously labeling many examples of occlusions for every view of every object	background	2K_dev_2032
Other approaches require binary classifications of matching scores	background	2K_dev_2032
	background	2K_dev_2032
Our method demonstrates significant improvement in estimating the mask of the occluding region and improves object instance detection on a challenging dataset of objects under severe occlusions	finding	2K_dev_2032
In this paper	mechanism	2K_dev_2032
we present a method We address these limitations by formulating occlusion reasoning as an efficient search over occluding blocks which best explain a probabilistic matching pattern	mechanism	2K_dev_2032
	method	2K_dev_2032
to coherently reason about occlusions on many types of detectors	purpose	2K_dev_2032
	purpose	2K_dev_2032
Binary codes that are binarizations of features represented by real numbers have recently been used in the object recognition field	background	2K_dev_2033
in order to achieve reduced memory and robustness with respect to noise	background	2K_dev_2033
From the results of we confirmed that the proposed method enables an increase in detection performance while maintaining the same levels of memory and computing costs as those for previous methods of binarizing features	finding	2K_dev_2033
	finding	2K_dev_2033
With this study	mechanism	2K_dev_2033
we introduce a transition likelihood model into classifiers This enables classifications that consider transitions to the desired binary code	mechanism	2K_dev_2033
even if the observed binary code differs from the actually desired binary code for some reason	mechanism	2K_dev_2033
	mechanism	2K_dev_2033
experiments	method	2K_dev_2033
However	purpose	2K_dev_2033
binarizing features represented by real numbers has a problem in that a great deal of the information within the features drops out	purpose	2K_dev_2033
That is why we focus on quantization residual	purpose	2K_dev_2033
which is information that drops out when features are binarized in order to take into consideration the possibility that a binary code which has been observed from an image will transition to another binary code	purpose	2K_dev_2033
	purpose	2K_dev_2033
`` Socially cooperative driving { '' } is an integral part of our everyday driving	background	2K_dev_2034
hence	background	2K_dev_2034
Compared with approaches that do not take social behavior into account	finding	2K_dev_2034
the iPCB algorithm shows a 41	finding	2K_dev_2034
7\ % performance improvement based on the chosen cost functions	finding	2K_dev_2034
	finding	2K_dev_2034
In this paper	mechanism	2K_dev_2034
an intention-integrated Prediction-and Cost function-Based algorithm iPCB ) framework is proposed An intention estimator is developed Then for each candidate strategy	mechanism	2K_dev_2034
a prediction engine considering the interaction between host and surrounding agents is used A cost function-based evaluation is applied	mechanism	2K_dev_2034
The algorithm was tested in simulation on an autonomous vehicle cooperating vehicles merging from freeway entrance ramps with 10000 randomly generated scenarios	method	2K_dev_2034
	method	2K_dev_2034
requiring special attention to imbue the autonomous driving with a more natural driving behavior	purpose	2K_dev_2034
to enable an autonomous vehicle to perform cooperative social behavior to extract the probability of surrounding agents ' intentions in real time	purpose	2K_dev_2034
to predict future scenarios to compute the cost for each scenario and select the decision corresponding to the lowest cost	purpose	2K_dev_2034
	purpose	2K_dev_2034
On-road motion planning for autonomous vehicles is in general a challenging problem Past efforts have proposed solutions for urban and highway environments individually	background	2K_dev_2035
	finding	2K_dev_2035
and propose a novel two-step motion planning system in a single framework	mechanism	2K_dev_2035
Reference Trajectory Planning ( I ) makes use of dense lattice sampling and optimization techniques By focused sampling around the reference trajectory	mechanism	2K_dev_2035
Tracking Trajectory Planning ( II ) generates	mechanism	2K_dev_2035
evaluates and selects parametric trajectories that further satisfy kinodynamic constraints for execution The described method retains most of the performance advantages of an exhaustive spatiotemporal planner while significantly reducing computation	mechanism	2K_dev_2035
	mechanism	2K_dev_2035
	method	2K_dev_2035
We identify the key advantages/shortcomings of prior solutions	purpose	2K_dev_2035
that addresses both urban and highway driving to generate an easy-to-tune and human-like reference trajectory accounting for road geometry	purpose	2K_dev_2035
obstacles and high-level directives	purpose	2K_dev_2035
	purpose	2K_dev_2035
Vehicular ad hoc networks ( VANETs ) are seen as an important enabling technology for improving both traffic safety and efficiency	background	2K_dev_2036
Virtual Traffic Lights ( VTLs ) are a promising proposal for reducing travel time by efficiently controlling road intersections	background	2K_dev_2036
VTLs use vehicle-to-vehicle communication to dynamically optimize traffic flow and they display traffic light information on the windshield	background	2K_dev_2036
We show that the benefits of VTLs grow as a function of the penetration rate of equipped vehicles	finding	2K_dev_2036
	finding	2K_dev_2036
In this paper we present a solution for a VTL partial deployment scenario that is based on the idea of having VTL equipped cars display traffic light information on the outside of the vehicle	mechanism	2K_dev_2036
	mechanism	2K_dev_2036
in terms of intersection throughput and average delay reduction	method	2K_dev_2036
However	purpose	2K_dev_2036
research so far has assumed that all vehicles are equipped with VTL support and it has ignored the incremental deployment phase	purpose	2K_dev_2036
which could last decades	purpose	2K_dev_2036
This allows drivers in non-equipped vehicles	purpose	2K_dev_2036
or even pedestrians	purpose	2K_dev_2036
to see the light color and respond accordingly	purpose	2K_dev_2036
	purpose	2K_dev_2036
which can be readily utilized in an active learning framework to improve identity-aware multi-object tracking	background	2K_dev_2037
show that not only is our proposed tracker effective	finding	2K_dev_2037
but also the solution path enables automatic pinpointing of potential tracking failures	finding	2K_dev_2037
	finding	2K_dev_2037
We propose an identity-aware multi-object tracker based on the solution path algorithm	mechanism	2K_dev_2037
Our tracker not only based on cues such as face recognition The tracker is formulated as a quadratic optimization problem with l ( 0 ) norm constraints	mechanism	2K_dev_2037
which we propose to solve with the solution path algorithm The algorithm successively solves the same optimization problem but under different l ( p ) norm constraints	mechanism	2K_dev_2037
where p gradually decreases from 1 to 0	mechanism	2K_dev_2037
Inspired by the success of the solution path algorithm in various machine learning tasks	mechanism	2K_dev_2037
this strategy is expected to converge to a better local minimum than directly minimizing the hardly solvable l ( 0 ) norm or the roughly approximated l ( 1 ) norm constraints	mechanism	2K_dev_2037
Furthermore	mechanism	2K_dev_2037
the acquired solution path complies with the `` decision making process { '' } of the tracker	mechanism	2K_dev_2037
which provides more insight to locating potential tracking errors	mechanism	2K_dev_2037
	mechanism	2K_dev_2037
Experiments	method	2K_dev_2037
produces identity-coherent trajectories but also has the ability to pinpoint potential tracking errors	purpose	2K_dev_2037
Spoken dialogue systems typically use predefined semantic slots to parse users ' natural language inputs into unified semantic representations	background	2K_dev_2038
Our slot filling evaluations also indicate the promising future of this proposed approach	background	2K_dev_2038
	background	2K_dev_2038
show that the automatically induced semantic slots are in line with the reference slots created by domain experts : we observe a mean averaged precision of 69	finding	2K_dev_2038
36\ % using ASR-transcribed data	finding	2K_dev_2038
	finding	2K_dev_2038
To do this	mechanism	2K_dev_2038
we propose the use of a state-of-the-art frame-semantic parser	mechanism	2K_dev_2038
and a spectral clustering based slot ranking model that adapts the generic output of the parser to the target semantic space	mechanism	2K_dev_2038
	mechanism	2K_dev_2038
Empirical experiments on a real-world spoken dialogue dataset	method	2K_dev_2038
To define the slots	purpose	2K_dev_2038
domain experts and professional annotators are often involved	purpose	2K_dev_2038
and the cost can be expensive	purpose	2K_dev_2038
In this paper	purpose	2K_dev_2038
we ask the following question : given a collection of unlabeled raw audios	purpose	2K_dev_2038
can we use the frame semantics theory to automatically induce and fill the semantic slots in an unsupervised fashion ?	purpose	2K_dev_2038
	background	2K_dev_2039
	finding	2K_dev_2039
	mechanism	2K_dev_2039
	method	2K_dev_2039
	purpose	2K_dev_2039
Smartphones are now targets of malicious viruses Furthermore	background	2K_dev_2040
the increasing `` connectedness { '' } of smartphones has resulted in new delivery vectors for malicious viruses	background	2K_dev_2040
including proximity-	background	2K_dev_2040
social- and other technology-based methods	background	2K_dev_2040
In fact	background	2K_dev_2040
Cabir and CommWarrior are two viruses-observed in the wild-that spread	background	2K_dev_2040
at least in part	background	2K_dev_2040
using proximity-based techniques ( line-of-sight bluetooth radio )	background	2K_dev_2040
	background	2K_dev_2040
find that the first eigenvalue of the system matrices lambda ( S1 )	finding	2K_dev_2040
lambda ( S2 ) of the two networks ( static and dynamic networks ) appropriately captures the competitive interplay between two viruses and effectively predicts the competition 's `` winner { '' }	finding	2K_dev_2040
which provides a feasible way to defend against smartphone viruses	finding	2K_dev_2040
	finding	2K_dev_2040
In this paper	mechanism	2K_dev_2040
we propose and evaluate SI1I2S	mechanism	2K_dev_2040
a competition model To approximate dynamic network behavior	mechanism	2K_dev_2040
we use classic mobility models from ad hoc networking	mechanism	2K_dev_2040
e	mechanism	2K_dev_2040
g	mechanism	2K_dev_2040
	mechanism	2K_dev_2040
Random Waypoint	mechanism	2K_dev_2040
Random Walk and Levy Flight	mechanism	2K_dev_2040
	mechanism	2K_dev_2040
We analyze our model using techniques from dynamic systems and	method	2K_dev_2040
that describes the spread of two mutually exclusive viruses across heterogeneous composite networks	purpose	2K_dev_2040
one static ( social connections ) and one dynamic ( mobility pattern )	purpose	2K_dev_2040
	purpose	2K_dev_2040
Together	background	2K_dev_2041
these findings suggest that head motion is strongly related to age-appropriate emotion challenge	background	2K_dev_2041
are consistent with the hypothesis that perturbations of normal responsiveness carry-over even after the parent resumes normal responsiveness in the reunion	background	2K_dev_2041
and that there are frequent changes in direction of influence in the postural domain	background	2K_dev_2041
	background	2K_dev_2041
During infant gaze toward the parent	finding	2K_dev_2041
infant angular amplitude and velocity of pitch and yaw decreased from face-to-face ( FF ) to still-face ( SF ) episodes and remained lower in the following Reunion	finding	2K_dev_2041
During infant gaze away from the parent	finding	2K_dev_2041
angular velocity of pitch decreased from FF to SF and remained lower in the Reunion ( RE ) Windowed cross-correlation suggested strong bidirectional effects with frequent shifts in the direction of influence	finding	2K_dev_2041
The number of significant positive and negative peaks was higher during FF than RE	finding	2K_dev_2041
Gaze toward and away from the parent was modestly predicted by head orientation	finding	2K_dev_2041
	finding	2K_dev_2041
	mechanism	2K_dev_2041
Participants were 12 ethnically diverse 6-month-old infants and their mother or father	method	2K_dev_2041
We investigated the dynamics of head motion in parents and infants during an age-appropriate	purpose	2K_dev_2041
well-validated emotion induction	purpose	2K_dev_2041
the Face-to-Face/Still-Face procedure	purpose	2K_dev_2041
	purpose	2K_dev_2041
It is common to represent photos as vertices of a weighted graph	background	2K_dev_2042
where edge weights measure similarity or distance between pairs of photos Ultimately	background	2K_dev_2042
our system enables everyday people to take advantage of each others ' perspectives in order to create on-the-spot spatiotemporal visual experiences similar to the popular bullet-time sequence	background	2K_dev_2042
We believe that this type of application will greatly enhance shared human experiences spanning from events as personal as parents watching their children 's football game to highly publicized red carpet galas	background	2K_dev_2042
	background	2K_dev_2042
	finding	2K_dev_2042
We present a near real-time algorithm Our system favors immediacy and local coherency to global consistency	mechanism	2K_dev_2042
We introduce Angled Graphs as a new data structure Weighted angled graphs extend weighted graphs with angles and angle weights which penalize turning along paths	mechanism	2K_dev_2042
As a result	mechanism	2K_dev_2042
locally straight paths can be computed by specifying a photo and a direction	mechanism	2K_dev_2042
The weighted angled graphs of photos used in this paper can be regarded as the result of discretizing the Riemannian geometry of the high dimensional manifold of all possible photos	mechanism	2K_dev_2042
	mechanism	2K_dev_2042
	method	2K_dev_2042
for interactively exploring a collectively captured moment without explicit 3D reconstruction	purpose	2K_dev_2042
to organize collections of photos in a way that enables the construction of visually smooth paths	purpose	2K_dev_2042
	purpose	2K_dev_2042
They are important for formal verification of realistic hybrid systems and embedded software	background	2K_dev_2043
	background	2K_dev_2043
We demonstrate scalability of the algorithms	finding	2K_dev_2043
We develop delta-complete algorithms for SMT formulas that are purely existentially quantified	mechanism	2K_dev_2043
as well as there exists for all-formulas whose universal quantification is restricted to the time variables	mechanism	2K_dev_2043
	mechanism	2K_dev_2043
as implemented in our open-source solver dReal	method	2K_dev_2043
on SMT benchmarks with several hundred nonlinear ODEs and variables	method	2K_dev_2043
	method	2K_dev_2043
We study SMT problems over the reals containing ordinary differential equations	purpose	2K_dev_2043
	purpose	2K_dev_2043
	purpose	2K_dev_2043
A robotic swarm is a decentralized group of robots which overcome failure of individual robots with robust emergent behaviors based on local interactions	background	2K_dev_2044
These behaviors are not well built for accomplishing complex tasks	background	2K_dev_2044
however	background	2K_dev_2044
because of the changing assumptions required in various applications and environments	background	2K_dev_2044
A new movement in the research field is to add human input to influence the swarm in order to help make the robots goal directed and overcome these problems Previous studies have all used visual feedback through a computer interface to give the user the swarm state information Researchers in multi-robot systems have shown benefits of haptic feedback in obstacle navigation before	background	2K_dev_2044
The study shows the benefits of the additional feedback in a target searching class	finding	2K_dev_2044
In most environments	finding	2K_dev_2044
operators were able to cover significantly more area	finding	2K_dev_2044
increasing the chance of finding more targets	finding	2K_dev_2044
The other environment found no significant difference	finding	2K_dev_2044
showing that the haptic feedback does not degrade performance in any of the tested environments	finding	2K_dev_2044
This supports our hypothesis that haptic feedback is useful in HSI and requires further research to maximize its potential	finding	2K_dev_2044
	finding	2K_dev_2044
This study adapted swarm control algorithms but this study is a novel method because of the decentralized formation of the robotic swarm	mechanism	2K_dev_2044
	mechanism	2K_dev_2044
	method	2K_dev_2044
This research in Human Swarm Interaction ( HSI ) focuses on different control laws and ways to integrate the human intent with local control laws of the robots	purpose	2K_dev_2044
to give the operator haptic feedback as well as visual feedback	purpose	2K_dev_2044
Clustering is the task of grouping a set of objects so that objects in the same cluster are more similar to each other than to those in other clusters The crucial step in most clustering algorithms is to find an appropriate similarity metric	background	2K_dev_2045
which is both challenging and problem-dependent	background	2K_dev_2045
Supervised clustering approaches	background	2K_dev_2045
which can exploit labeled clustered training data that share a common metric with the test set	background	2K_dev_2045
have thus been proposed	background	2K_dev_2045
confirm several orders of magnitude speedup while still achieving state-of-the-art performance	finding	2K_dev_2045
In this paper	mechanism	2K_dev_2045
we propose a new structured Mahalanobis Distance Metric Learning method We formulate our problem as an instance of large margin structured prediction and prove that it can be solved very efficiently in closed-form	mechanism	2K_dev_2045
The complexity of our method is ( in most cases ) linear in the size of the training dataset We further reveal a striking similarity between our approach and multivariate linear regression	mechanism	2K_dev_2045
	mechanism	2K_dev_2045
Experiments on both synthetic and real datasets	method	2K_dev_2045
Unfortunately	purpose	2K_dev_2045
current metric learning approaches for supervised clustering do not scale to large or even medium-sized datasets for supervised clustering	purpose	2K_dev_2045
	purpose	2K_dev_2045
Previous studies have examined the characteristics of physiological tremor under laboratory settings as well as different operating conditions	background	2K_dev_2046
However	background	2K_dev_2046
different test methods make the comparison of results across trials and conditions difficult	background	2K_dev_2046
	background	2K_dev_2046
	mechanism	2K_dev_2046
Two vitroretinal microsurgeons were evaluated while performing a pointing task with no entry-point constraint	method	2K_dev_2046
constrained by an artificial eye model	method	2K_dev_2046
and constrained by a rabbit eye in vivo For the three respective conditions A spectral analysis was also performed	method	2K_dev_2046
This paper presents the characterization and comparison of physiological tremor for pointing tasks in multiple environments	purpose	2K_dev_2046
as a baseline for performance evaluation of microsurgical robotics	purpose	2K_dev_2046
	purpose	2K_dev_2046
Bevel-tipped flexible needles can be robotically steered to reach clinical targets along curvilinear paths in 3D	background	2K_dev_2047
Manual needle insertion allows the clinician to control the insertion speed	background	2K_dev_2047
ensuring patient safety	background	2K_dev_2047
	background	2K_dev_2047
demonstrate the performance of the proposed controller	finding	2K_dev_2047
show the feasibility of this technique in 2D and 3D environments	finding	2K_dev_2047
	finding	2K_dev_2047
This paper presents a control law A look-ahead proportional controller for position and orientation is presented	mechanism	2K_dev_2047
The look-ahead distance is a linear function of insertion speed	mechanism	2K_dev_2047
Simulations in a 3D brain-like environment Experimental results also	method	2K_dev_2047
for automatic 3D steering of manually inserted flexible needles	purpose	2K_dev_2047
enabling path-following control	purpose	2K_dev_2047
	purpose	2K_dev_2047
remains a difficult task	background	2K_dev_2048
We demonstrated competitive performance both in accuracy relative to human annotation and computation time	finding	2K_dev_2048
	finding	2K_dev_2048
In this paper	mechanism	2K_dev_2048
we define interesting events as unusual events which occur rarely in the entire video and we propose a novel interesting event summarization framework based on the technique of density ratio estimation recently introduced in machine learning Our proposed framework is unsupervised and it can be applied to general video sources	mechanism	2K_dev_2048
including videos from moving cameras	mechanism	2K_dev_2048
	mechanism	2K_dev_2048
We evaluated the proposed approach on a publicly available dataset in the context of anomalous crowd behavior and with a challenging personal video dataset	method	2K_dev_2048
	method	2K_dev_2048
Generating meaningful digests of videos by extracting interesting frames	purpose	2K_dev_2048
Existing semi-supervised approaches are typically unreliable and face semantic drift because the learning task is under-constrained	background	2K_dev_2049
This is primarily because they ignore the strong interactions that often exist between scene categories	background	2K_dev_2049
such as the common attributes shared across categories as well as the attributes which make one scene different from another For example	background	2K_dev_2049
the knowledge that an image is an auditorium can improve labeling of amphitheaters by enforcing constraint that an amphitheater image should have more circular structures than an auditorium image	background	2K_dev_2049
	background	2K_dev_2049
We demonstrate the effectiveness of our approach including results	finding	2K_dev_2049
We propose constraints based on mutual exclusion	mechanism	2K_dev_2049
binary attributes and comparative attributes and show that they help us	mechanism	2K_dev_2049
through extensive experiments	method	2K_dev_2049
on a very large dataset of one million images	method	2K_dev_2049
	method	2K_dev_2049
We consider the problem of semi-supervised bootstrap learning for scene categorization The goal of this paper is to exploit these relationships and constrain the semi-supervised learning problem to constrain the learning problem and avoid semantic drift	purpose	2K_dev_2049
	background	2K_dev_2050
As proof-of-concept results demonstrate that our model accurately predicts distributions over future actions of individuals We show how the same techniques can improve the results of tracking algorithms by leveraging information about likely goals and trajectories	finding	2K_dev_2050
	finding	2K_dev_2050
We denote this task activity forecasting	mechanism	2K_dev_2050
our approach models the effect of the physical environment on the choice of human actions	mechanism	2K_dev_2050
This is accomplished by the use of state-of-the-art semantic scene understanding combined with ideas from optimal control theory Our unified model also integrates several other key elements of activity analysis	mechanism	2K_dev_2050
namely	mechanism	2K_dev_2050
destination forecasting	mechanism	2K_dev_2050
sequence smoothing and transfer learning	mechanism	2K_dev_2050
	mechanism	2K_dev_2050
we focus on the domain of trajectory-based activity analysis from visual input	method	2K_dev_2050
Experimental	method	2K_dev_2050
We address the task of inferring the future actions of people from noisy visual input To achieve accurate activity forecasting	purpose	2K_dev_2050
Reconstructing an arbitrary configuration of 3D points from their projection in an image is an ill-posed problem	background	2K_dev_2051
When the points hold semantic meaning	background	2K_dev_2051
such as anatomical landmarks on a body	background	2K_dev_2051
human observers can often infer a plausible 3D configuration	background	2K_dev_2051
drawing on extensive visual memory	background	2K_dev_2051
show generalization to novel 3D configurations and robustness to missing data	finding	2K_dev_2051
	finding	2K_dev_2051
We present an activity-independent method leveraging a large motion capture corpus as a proxy for visual memory Our method solves for anthropometrically regular body pose and explicitly estimates the camera via a matching pursuit algorithm operating on the image projections Anthropometric regularity ( i	mechanism	2K_dev_2051
e	mechanism	2K_dev_2051
	mechanism	2K_dev_2051
that limbs obey known proportions ) is a highly informative prior	mechanism	2K_dev_2051
but directly applying such constraints is intractable	mechanism	2K_dev_2051
Instead	mechanism	2K_dev_2051
we enforce a necessary condition on the sum of squared limb-lengths that can be solved for in closed form to discourage implausible configurations in 3D	mechanism	2K_dev_2051
	mechanism	2K_dev_2051
We evaluate performance on a wide variety of human poses captured from different viewpoints and	method	2K_dev_2051
to recover the 3D configuration of a human figure from 2D locations of anatomical landmarks in a single image	purpose	2K_dev_2051
	purpose	2K_dev_2051
Human pose estimation requires a versatile yet well-constrained spatial model for grouping locally ambiguous parts together to produce a globally consistent hypothesis	background	2K_dev_2052
	background	2K_dev_2052
	finding	2K_dev_2052
showing its ability to capture high-order dependencies of parts Second	finding	2K_dev_2052
our model achieves accurate reconstruction of unseen poses Finally	finding	2K_dev_2052
our model achieves state-of-art performance	finding	2K_dev_2052
and substantially outperforms recent hierarchical models	finding	2K_dev_2052
In this paper	mechanism	2K_dev_2052
we propose a new hierarchical spatial model that can capture an exponential number of poses with a compact mixture representation on each part	mechanism	2K_dev_2052
Using latent nodes	mechanism	2K_dev_2052
it can represent high-order spatial relationship among parts with exact inference	mechanism	2K_dev_2052
Different from recent hierarchical models that associate each latent node to a mixture of appearance templates ( like HoG )	mechanism	2K_dev_2052
we use the hierarchical structure as a pure spatial prior avoiding the large and often confounding appearance space	mechanism	2K_dev_2052
We verify the effectiveness of this model in three ways	method	2K_dev_2052
First	method	2K_dev_2052
samples representing human-like poses can be drawn from our model compared to a nearest neighbor pose representation on three challenging datasets	method	2K_dev_2052
Previous works either use local deformable models deviating from a certain template	purpose	2K_dev_2052
or use a global mixture representation in the pose space	purpose	2K_dev_2052
	purpose	2K_dev_2052
Multi-task learning in Convolutional Networks has displayed remarkable success in the field of recognition This success can be largely attributed to learning shared representations from multiple supervisory tasks	background	2K_dev_2053
	background	2K_dev_2053
Our proposed method generalizes across multiple tasks and shows dramatically improved performance over baseline methods for categories with few training examples	finding	2K_dev_2053
In this paper	mechanism	2K_dev_2053
we propose a principled approach using multi-task learning	mechanism	2K_dev_2053
Specifically	mechanism	2K_dev_2053
we propose a new sharing unit : `` cross-stitch { '' } unit	mechanism	2K_dev_2053
These units combine the activations from multiple networks and can be trained end-to-end	mechanism	2K_dev_2053
A network with cross-stitch units can learn an optimal combination of shared and task-specific representations	mechanism	2K_dev_2053
	mechanism	2K_dev_2053
	method	2K_dev_2053
However	purpose	2K_dev_2053
existing multi-task approaches rely on enumerating multiple network architectures specific to the tasks at hand	purpose	2K_dev_2053
that do not generalize	purpose	2K_dev_2053
to learn shared representations in ConvNets	purpose	2K_dev_2053
This is an important scenario that frequently arises in practice not only when two different types of sensors are used	background	2K_dev_2054
but also when the sensors are not co-located and have different sampling rates	background	2K_dev_2054
Previous work has addressed this problem by restricting interpretation to a single representation in one of the domains	background	2K_dev_2054
with augmented features that attempt to encode the information from the other modalities	background	2K_dev_2054
	background	2K_dev_2054
we demonstrate that this co-inference approach also improves performance over the canonical approach	finding	2K_dev_2054
Instead	mechanism	2K_dev_2054
we propose to analyze all modalities simultaneously while propagating information across domains during the inference procedure	mechanism	2K_dev_2054
In addition to the immediate benefit of generating a complete interpretation in all of the modalities	mechanism	2K_dev_2054
	mechanism	2K_dev_2054
	method	2K_dev_2054
We address the problem of understanding scenes from multiple sources of sensor data ( e	purpose	2K_dev_2054
g	purpose	2K_dev_2054
	purpose	2K_dev_2054
a camera and a laser scanner ) in the case where there is no one-to-one correspondence across modalities ( e	purpose	2K_dev_2054
g	purpose	2K_dev_2054
	purpose	2K_dev_2054
pixels and 3-D points )	purpose	2K_dev_2054
Object discovery algorithms group together image regions that originate from the same object	background	2K_dev_2055
This process is effective when the input collection of images contains a large number of densely sampled views of each object	background	2K_dev_2055
thereby creating strong connections between nearby views	background	2K_dev_2055
	background	2K_dev_2055
{ '' } Our approach can correctly discover links between regions of the same object even if they are captured from dramatically different viewpoints	finding	2K_dev_2055
With the help from these added links	finding	2K_dev_2055
our proposed approach can robustly discover object instances even with sparse coverage of the viewpoints	finding	2K_dev_2055
We propose an approach for object discovery We collect a database of about 5 million product images that capture 1	mechanism	2K_dev_2055
2 million objects from multiple views	mechanism	2K_dev_2055
We represent each region in the input image by a `` bag { '' } of database object regions	mechanism	2K_dev_2055
We group input regions together if they share similar `` bags of regions	mechanism	2K_dev_2055
	mechanism	2K_dev_2055
	method	2K_dev_2055
However	purpose	2K_dev_2055
existing approaches are less effective when the input data only provide sparse coverage of object views	purpose	2K_dev_2055
that addresses this problem	purpose	2K_dev_2055
	purpose	2K_dev_2055
The problem of training classifiers from limited data is one that particularly affects large-scale and social applications	background	2K_dev_2056
and as a result	background	2K_dev_2056
although carefully trained machine learning forms the backbone of many current techniques in research	background	2K_dev_2056
it sees dramatically fewer applications for end-users Recently we demonstrated a technique for selecting or recommending a single good classifier from a large library even with highly impoverished training data	background	2K_dev_2056
	background	2K_dev_2056
	finding	2K_dev_2056
a modification to the AdaBoost algorithm that incorporates recommendation	mechanism	2K_dev_2056
Evaluating on an action recognition problem	mechanism	2K_dev_2056
we present two viable methods	mechanism	2K_dev_2056
	method	2K_dev_2056
We consider alternatives for extending our recommendation technique to sets of classifiers	purpose	2K_dev_2056
including for extending model recommendation to sets	purpose	2K_dev_2056
	purpose	2K_dev_2056
We have shown in prior work how to give a Curry-Howard interpretation of the proofs in the linear sequent calculus as pi-calculus processes subject to a session type discipline	background	2K_dev_2057
We show that the resulting translations induce sharing and copying parallel evaluation strategies for the original lambda-terms	finding	2K_dev_2057
thereby providing a new logically motivated explanation for these strategies	finding	2K_dev_2057
	mechanism	2K_dev_2057
The translations proceed in two steps : standard embeddings of simply-typed lambda-calculus in a linear lambda-calculus	method	2K_dev_2057
followed by a standard translation of linear natural deduction to linear sequent calculus	method	2K_dev_2057
We study type-directed encodings of the simply-typed lambda-calculus in a session-typed pi-calculus	purpose	2K_dev_2057
	purpose	2K_dev_2057
The detection of apoptosis	background	2K_dev_2058
or programmed cell death	background	2K_dev_2058
is important to understand the underlying mechanism of cell development	background	2K_dev_2058
	background	2K_dev_2058
	finding	2K_dev_2058
the method achieved around 90\ % accuracy in terms of average precision and recall	finding	2K_dev_2058
	finding	2K_dev_2058
In this work	mechanism	2K_dev_2058
we present an image analysis method which is non-destructive imaging	mechanism	2K_dev_2058
The method first detects candidates for apoptotic cells based on the optical principle of phase-contrast microscopy in connection with the properties of apoptotic cells	mechanism	2K_dev_2058
The temporal behavior of each candidate is then examined in its neighboring frames in order	mechanism	2K_dev_2058
When applied to three C2C12 myoblastic stem cell populations	method	2K_dev_2058
which contain more than 1000 apoptosis	method	2K_dev_2058
At present	purpose	2K_dev_2058
apoptosis detection resorts to fluorescence or colorimetric assays	purpose	2K_dev_2058
which may affect cell behavior and thus not allow long-term monitoring of intact cells	purpose	2K_dev_2058
to detect apoptosis in time-lapse phase-contrast microscopy to determine if the candidate is indeed an apoptotic cell	purpose	2K_dev_2058
	purpose	2K_dev_2058
Cache compression is a promising technique to increase on-chip cache capacity and to decrease on-chip and off-chip bandwidth usage	background	2K_dev_2059
Unfortunately	background	2K_dev_2059
directly applying well-known compression algorithms ( usually implemented in software ) leads to high hardware complexity and unacceptable decompression/compression latencies	background	2K_dev_2059
which in turn can negatively affect performance	background	2K_dev_2059
	finding	2K_dev_2059
our studies show that B Delta I strikes a sweet-spot in the tradeoff between compression ratio	finding	2K_dev_2059
decompression/compression latencies	finding	2K_dev_2059
and hardware complexity Our results show that B Delta I compression improves performance for both single-core ( 8	finding	2K_dev_2059
1\ % improvement ) and multi-core workloads ( 9	finding	2K_dev_2059
5\ % /11	finding	2K_dev_2059
2\ % improvement for two/four cores )	finding	2K_dev_2059
For many applications	finding	2K_dev_2059
B Delta I provides the performance benefit of doubling the cache size of the baseline system	finding	2K_dev_2059
effectively increasing average cache capacity by 1	finding	2K_dev_2059
53X	finding	2K_dev_2059
	finding	2K_dev_2059
In this paper	mechanism	2K_dev_2059
we introduce a new compression algorithm called Base-Delta-Immediate ( B Delta I ) compression	mechanism	2K_dev_2059
The key idea is that	mechanism	2K_dev_2059
for many cache lines	mechanism	2K_dev_2059
the values within the cache line have a low dynamic range - i	mechanism	2K_dev_2059
e	mechanism	2K_dev_2059
	mechanism	2K_dev_2059
the differences between values stored within the cache line are small	mechanism	2K_dev_2059
As a result	mechanism	2K_dev_2059
a cache line can be represented using a base value and an array of differences whose combined size is much smaller than the original cache line ( we call this the base+ delta encoding Moreover	mechanism	2K_dev_2059
many cache lines intersperse such base+ delta values with small values - our B Delta I technique efficiently incorporates such immediate values into its encoding	mechanism	2K_dev_2059
Compared to prior cache compression approaches	method	2K_dev_2059
Hence	purpose	2K_dev_2059
there is a need for a simple yet efficient compression technique that can effectively compress common in-cache data patterns	purpose	2K_dev_2059
and has minimal effect on cache access latency	purpose	2K_dev_2059
a practical technique for compressing data in on-chip caches	purpose	2K_dev_2059
	purpose	2K_dev_2059
Most contemporary object detection approaches assume each object instance in the training data to be uniquely represented by a single bounding box	background	2K_dev_2060
	background	2K_dev_2060
	finding	2K_dev_2060
The new bounding box annotations are determined based on the alignment of an object instance with the other training instances in the dataset	mechanism	2K_dev_2060
Our proposal enables the training data to be reused multiple times for training richer multi-component category models We operationalize this idea by two complementary operations : bounding box shrinking	mechanism	2K_dev_2060
which finds subregions of an object instance that could be shared ; and bounding box enlarging	mechanism	2K_dev_2060
which enlarges object instances to include local contextual cues	mechanism	2K_dev_2060
	mechanism	2K_dev_2060
We empirically validate our approach on the PASCAL VOC detection dataset	method	2K_dev_2060
In this paper	purpose	2K_dev_2060
we go beyond this conventional view by allowing an object instance to be described by multiple bounding boxes	purpose	2K_dev_2060
In practical applications of robot swarms with bio-inspired behaviors	background	2K_dev_2061
a human operator will need to exert control over the swarm to fulfill the mission objectives	background	2K_dev_2061
In many operational settings	background	2K_dev_2061
human operators are remotely located and the communication environment is harsh Hence	background	2K_dev_2061
there exists some latency in information ( or control command ) transfer between the human and the swarm	background	2K_dev_2061
	background	2K_dev_2061
Our experimental results indicate that operators exploited neglect benevolence in different ways to develop successful strategies in the foraging task	finding	2K_dev_2061
Furthermore	finding	2K_dev_2061
we show that the use of a predictive display can help mitigate the adverse effects of communication latency	finding	2K_dev_2061
	finding	2K_dev_2061
	mechanism	2K_dev_2061
we conduct experiments of human-swarm interaction experimentally	method	2K_dev_2061
In this paper	purpose	2K_dev_2061
to investigate the effects of communication latency on the performance of a human-swarm system in a swarm foraging task	purpose	2K_dev_2061
We develop and investigate the concept of neglect benevolence	purpose	2K_dev_2061
where a human operator allows the swarm to evolve on its own and stabilize before giving new commands	purpose	2K_dev_2061
	purpose	2K_dev_2061
Human interaction with robot swarms ( HSI ) is a young field with very few user studies that explore operator behavior All these studies assume perfect communication between the operator and the swarm A key challenge in the use of swarm robotic systems in human supervised tasks is to understand human swarm interaction in the presence of limited communication bandwidth	background	2K_dev_2062
which is a constraint arising in many practical scenarios	background	2K_dev_2062
	background	2K_dev_2062
The lowest bandwidth condition performs poorly	finding	2K_dev_2062
but the medium and high bandwidth condition both perform well	finding	2K_dev_2062
In the medium bandwidth condition	finding	2K_dev_2062
we display useful aggregated swarm information ( like swarm centroid and spread ) to compress the swarm state information	finding	2K_dev_2062
We also observe interesting operator behavior and adaptation of operators ' swarm reaction	finding	2K_dev_2062
	mechanism	2K_dev_2062
We consider three levels of bandwidth availability in a swarm foraging task	method	2K_dev_2062
	method	2K_dev_2062
In this paper	purpose	2K_dev_2062
we present results of human-subject experiments designed to study the effect of bandwidth limitations in human swarm interaction	purpose	2K_dev_2062
	purpose	2K_dev_2062
Pose Machines provide a sequential prediction framework for learning rich implicit spatial models	background	2K_dev_2063
	background	2K_dev_2063
We demonstrate state-of-the-art performance and outperform competing methods	finding	2K_dev_2063
In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image features and image-dependent spatial models The contribution of this paper is to implicitly model long-range dependencies between variables in structured prediction tasks such as articulated pose estimation	mechanism	2K_dev_2063
We achieve this by designing a sequential architecture composed of convolutional networks that directly operate on belief maps from previous stages	mechanism	2K_dev_2063
producing increasingly refined estimates for part locations	mechanism	2K_dev_2063
without the need for explicit graphical model-style inference	mechanism	2K_dev_2063
Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision	mechanism	2K_dev_2063
thereby replenishing back-propagated gradients and conditioning the learning procedure	mechanism	2K_dev_2063
	mechanism	2K_dev_2063
on standard benchmarks including the MPII	method	2K_dev_2063
LSP	method	2K_dev_2063
and FLIC datasets	method	2K_dev_2063
	method	2K_dev_2063
for the task of pose estimation	purpose	2K_dev_2063
	purpose	2K_dev_2063
Finding meaningful	background	2K_dev_2064
structured representations of 3D point cloud data ( PCD ) has become a core task for spatial perception applications	background	2K_dev_2064
	background	2K_dev_2064
our tests showing favorable performance when compared to octree and NDT-based methods	finding	2K_dev_2064
	finding	2K_dev_2064
In this paper we introduce a method As opposed to deterministic structures such as voxel grids or octrees	mechanism	2K_dev_2064
we propose probabilistic subdivisions of the data through local mixture modeling	mechanism	2K_dev_2064
and show how these subdivisions can provide a maximum likelihood segmentation of the data	mechanism	2K_dev_2064
The final representation is hierarchical	mechanism	2K_dev_2064
compact	mechanism	2K_dev_2064
parametric	mechanism	2K_dev_2064
and statistically derived	mechanism	2K_dev_2064
facilitating run-time occupancy calculations through stochastic sampling	mechanism	2K_dev_2064
Unlike traditional deterministic spatial subdivision methods	mechanism	2K_dev_2064
our technique enables dynamic creation of voxel grids according the application 's best needs	mechanism	2K_dev_2064
In contrast to other generative models for PCD	mechanism	2K_dev_2064
we explicitly enforce sparsity among points and mixtures	mechanism	2K_dev_2064
a technique which we call expectation sparsification	mechanism	2K_dev_2064
This leads to a highly parallel hierarchical Expectation Maximization ( EM ) algorithm well-suited for the GPU and real-time execution	mechanism	2K_dev_2064
	mechanism	2K_dev_2064
We explore the trade-offs between model fidelity and model size at various levels of detail	method	2K_dev_2064
for constructing compact generative representations of PCD at multiple levels of detail	purpose	2K_dev_2064
The proposed framework provides a way to explore the interaction between climate change and policy factors at a global scale	background	2K_dev_2065
	finding	2K_dev_2065
This paper uses a country-level agent-based dynamic network model Some of the networks considered include : alliance networks	mechanism	2K_dev_2065
shared language networks	mechanism	2K_dev_2065
economic influence networks	mechanism	2K_dev_2065
and proximity networks	mechanism	2K_dev_2065
Validation of model is done for migration probabilities between countries	mechanism	2K_dev_2065
as well as for country populations and distributions	mechanism	2K_dev_2065
	mechanism	2K_dev_2065
	method	2K_dev_2065
How are the populations of the world likely to shift ? Which countries will be impacted by sea-level rise ? to examine shifts in population given network relations among countries	purpose	2K_dev_2065
which influences overall population change	purpose	2K_dev_2065
Sudden weight gain in patients living with Congestive Heart Failure ( CHF ) is often an indication that the individual is retaining fluid	background	2K_dev_2066
which often means that patient 's heart has weakened leading to increased risk of kidney or cardiac failure	background	2K_dev_2066
leading to the possibility of earlier clinical interventions	background	2K_dev_2066
potentially preventing deadly medical emergencies	background	2K_dev_2066
	background	2K_dev_2066
	finding	2K_dev_2066
In this work	mechanism	2K_dev_2066
we present a latent variable autoregression model that tracks patient weight and blood pressure over time We are also able to model continuous heart-rate signals and evaluate a subject 's response to physical activity	mechanism	2K_dev_2066
This allows us to detect signs of health decline days earlier than existing rule-based systems	mechanism	2K_dev_2066
	mechanism	2K_dev_2066
	method	2K_dev_2066
Clinical interventions can be made at this stage	purpose	2K_dev_2066
leading to better outcomes	purpose	2K_dev_2066
however it is essential that the interventions take place before the patient 's health declines too drastically	purpose	2K_dev_2066
allowing us to predict weight values into the future	purpose	2K_dev_2066
Many Android apps heavily depend on collecting and sharing sensitive privacy information	background	2K_dev_2067
such as device ID	background	2K_dev_2067
location	background	2K_dev_2067
and postal address	background	2K_dev_2067
to provide service and value	background	2K_dev_2067
To protect user privacy	background	2K_dev_2067
apps are typically required by market places to provide privacy policies informing users about how their private information will be processed	background	2K_dev_2067
	background	2K_dev_2067
	finding	2K_dev_2067
In this paper	mechanism	2K_dev_2067
we present PVDetector	mechanism	2K_dev_2067
an automatic tool that analyzes Android apps	mechanism	2K_dev_2067
	method	2K_dev_2067
to detect privacy-policy violations	purpose	2K_dev_2067
i	purpose	2K_dev_2067
e	purpose	2K_dev_2067
	purpose	2K_dev_2067
inconsistencies between an app 's data collection code and the corresponding description in its privacy policy	purpose	2K_dev_2067
	purpose	2K_dev_2067
Implications for the understanding of human behavior and social agent design are discussed	background	2K_dev_2068
	background	2K_dev_2068
We validated the discovered behavioral patterns Our framework performs significantly better than a baseline linear regression method that does not encode temporal information among behavioral features	finding	2K_dev_2068
	finding	2K_dev_2068
by predicting rapport against our ground truth via a forecasting model involving two-step fusion of learned temporal associated rules	mechanism	2K_dev_2068
	mechanism	2K_dev_2068
We mined a reciprocal peer tutoring corpus reliably annotated for nonverbals like eye gaze and smiles	method	2K_dev_2068
conversational strategies like self-disclosure and social norm violation	method	2K_dev_2068
and for rapport ( in 30s thin slices )	method	2K_dev_2068
We then performed a fine-grained investigation of how the temporal profiles of sequences of interlocutor behaviors predict increases and decreases of rapport	method	2K_dev_2068
and how this rapport management manifests differently in friends and strangers	method	2K_dev_2068
	method	2K_dev_2068
This work focuses on data-driven discovery of the temporally co-occurring and contingent behavioral patterns that signal high and low interpersonal rapport	purpose	2K_dev_2068
	purpose	2K_dev_2068
Human communication literature states that people with different culture backgrounds act differently in conversations	background	2K_dev_2069
	background	2K_dev_2069
We found that users from different culture context express engagement differently	finding	2K_dev_2069
	finding	2K_dev_2069
	mechanism	2K_dev_2069
We implemented two versions of a virtual agent targeting American and Chinese cultures	method	2K_dev_2069
Currently most virtual agents are designed for a single targeted popular culture	purpose	2K_dev_2069
	purpose	2K_dev_2069
	background	2K_dev_2070
Our results suggest that sequence multiple confounding factors corrections behave the best when different confounders contribute equally to response variables	finding	2K_dev_2070
On the other hand	finding	2K_dev_2070
when various confounders affect the response variable unevenly	finding	2K_dev_2070
results mainly rely on the degree of how the major confounder is corrected	finding	2K_dev_2070
	finding	2K_dev_2070
we introduce three different methods for multiple confounding factors correction	mechanism	2K_dev_2070
namely concatenation	mechanism	2K_dev_2070
sequence	mechanism	2K_dev_2070
and interpolation	mechanism	2K_dev_2070
	mechanism	2K_dev_2070
We first review its parameter estimation algorithms before Then we investigate the performance on variable selection task and predictive task on three different data sets	method	2K_dev_2070
synthetic data set	method	2K_dev_2070
semi-empirical synthetic data set based on genome sequences and brain wave data set connecting to confused mental states	method	2K_dev_2070
	method	2K_dev_2070
In this paper	purpose	2K_dev_2070
we inspect the performance of regularized linear mixed effect models	purpose	2K_dev_2070
as an extension of linear mixed effect model	purpose	2K_dev_2070
when multiple confounding factors coexist	purpose	2K_dev_2070
	purpose	2K_dev_2070
