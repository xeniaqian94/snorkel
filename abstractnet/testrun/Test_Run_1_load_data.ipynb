{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run 1: Load AbstractNet Dataset: 70K unlabeled (and 2K labeled) Abstracts into DB\n",
    "\n",
    "This notebook loads the dataset and create labeled *candidates* through labeling function. Before everything, please ensure that you have followed project-level ``README.md`` and installed all python dependencies, e.g. ``tika``.  \n",
    "\n",
    "We filtered out null abstracts from `ClydeDB.csv` ([AbstractSegmentationCrowdNLP Git repo](https://github.com/zhoujieli/AbstractSegmentationCrowdNLP.git)), resulting in 48,914 valid ones out of 56,851 total abstracts. The 48,914 abstracts are saved to `data/70kpaper.tsv`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we preprocess documents by parsing them into *contexts*. *Candidates* are extracted out of *contexts*, which are *instances* (one of the *background*, *mechanism*, *method*, and *findings*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# # Here, we just set how many documents we'll process for automatic testing- you can safely ignore this!\n",
    "n_docs = 500 if 'CI' in os.environ else 230 #  60,000 for real dataset \n",
    "\n",
    "from snorkel.parser import TSVDocPreprocessor\n",
    "\n",
    "doc_preprocessor = TSVDocPreprocessor('data/70kpaper.tsv', encoding=\"utf-8\",max_docs=n_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of documents and sentences, as below. This could take 5-8 minutes to load ~60K papers (see progress bar, also might have exception). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 2.66 s, sys: 449 ms, total: 3.11 s\n",
      "Wall time: 3.15 s\n",
      "Documents: 230\n",
      "Sentences: 399\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "\n",
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "%time corpus_parser.apply(doc_preprocessor, count=n_docs)\n",
    "\n",
    "\n",
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract *candidates* by following a few patterns on abstract segmentation:\n",
    "+ Background: \n",
    "  - \"Recent research ... \", \n",
    "  - \"... have/has been widely ...\", \n",
    "  - \"How ... ?\" (and as the first sentence), \n",
    "  - \"Previous work...\", \n",
    "  - \"Motivated by...\", \n",
    "  - \"The success of ...\", etc.\n",
    "+ Mechanism:\n",
    "  - something\n",
    "  - some other pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'snorkel.models.context.Document'>\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document\n",
    "from util import number_of_people\n",
    "\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
